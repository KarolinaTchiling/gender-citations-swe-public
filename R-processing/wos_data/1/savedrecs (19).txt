FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Cevik, T
   Cevik, N
AF Cevik, Taner
   Cevik, Nazife
TI RIMFRA: Rotation-invariant multi-spectral facial recognition approach by
   using orthogonal polynomials
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; rotation invariant; multi-spectral; orthogonal
   polynomial
ID LOCAL BINARY PATTERNS; GENDER CLASSIFICATION; FACE RECOGNITION; TEXTURE
   CLASSIFICATION; FEATURES; ROBUST; ILLUMINATION; VOLUME; DISCRIMINATION;
   RECONSTRUCTION
AB This paper proposes a novel rotation-invariant multi-spectral facial recognition approach (RIMFRA) by using orthogonal polynomials. In the first step, a rotation, illumination and noise invariant local descriptor (RinLd) is proposed to represent the texture patterns of a face image. Color channels of the images embodies non-trivial information about the characteristic of the image. Hence, the local descriptor matrices are extracted among the color channels. The corresponding new descriptor matrices for the red, green and blue channels of the image are extracted. Afterwards, co-occurrence matrices are obtained from the six combinations of the corresponding color channel descriptor matrices, that are red-red, blue-blue, green-green, red-blue, green-blue and red-green. Finally, these matrices are decomposed by using the orthogonal polynomials to achieve a more reliable and characteristic pattern extraction. The coefficients obtained as a result of the decomposition process are used as the ultimate features for the classification of the images. Extensive simulations are conducted over benchmark datasets. As presented by the simulation results, the ultimate features yield very high discriminating performance as well as providing resistance to rotation and illumination variations.
C1 [Cevik, Taner] Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
   [Cevik, Nazife] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Aydin University; Istanbul Arel University
RP Cevik, T (corresponding author), Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
EM tanercevik@aydin.edu.tr
RI ÇEVİK, TANER/AAD-9934-2022; ÇEVİK, TANER/AAD-9997-2022
OI ÇEVİK, TANER/0000-0001-9653-5832; ÇEVİK, TANER/0000-0001-9653-5832
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Allam S, 1997, APPL OPTICS, V36, P8313, DOI 10.1364/AO.36.008313
   Andreu Y, 2014, IMAGE VISION COMPUT, V32, P27, DOI 10.1016/j.imavis.2013.11.001
   [Anonymous], 1998, 3 IEEE INT C AUT FAC
   [Anonymous], FAC REC DAT
   [Anonymous], 2 IEEE WORKSH APPL C
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cheong M, 2008, LECT NOTES COMPUTER, V5226
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Dan ZP, 2014, OPTIK, V125, P6320, DOI 10.1016/j.ijleo.2014.08.003
   DAVIS LS, 1981, DIGITAL IMAGE PROCES
   Dubey SR, 2017, ARXIV170909518CSCV
   Eskandari M, 2014, SIGNAL IMAGE VIDEO P, V8, P1189, DOI 10.1007/s11760-014-0659-y
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Hadid A, 2011, SIGNAL IMAGE VIDEO P, V5, P495, DOI 10.1007/s11760-011-0247-3
   Hahn F, 2000, J AGR ENG RES, V75, P243, DOI 10.1006/jaer.1999.0466
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ishikawa Y, 2001, T ASAE, V44, P923, DOI 10.13031/2013.6225
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Kaya Y, 2017, SIGNAL IMAGE VIDEO P, V11, P769, DOI 10.1007/s11760-016-1021-3
   Khojastehnazhand M, 2009, INT AGROPHYS, V23, P237
   Koc AB, 2007, POSTHARVEST BIOL TEC, V45, P366, DOI 10.1016/j.postharvbio.2007.03.010
   Krylov AS, 2002, INT C GRAPH NIZHN NO
   Kyuheon Kim, 1999, Proceedings of IEEE. IEEE Region 10 Conference. TENCON 99. `Multimedia Technology for Asia-Pacific Information Infrastructure' (Cat. No.99CH37030), P934, DOI 10.1109/TENCON.1999.818573
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Melendez J, 2008, PATTERN ANAL APPL, V11, P365, DOI 10.1007/s10044-007-0097-3
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nambi VE, 2016, J FOOD QUALITY, V39, P816, DOI 10.1111/jfq.12245
   Nambi VE, 2016, POSTHARVEST BIOL TEC, V117, P152, DOI 10.1016/j.postharvbio.2016.02.009
   Nanni L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083554
   Nisenson M, 2003, LECT NOTES ARTIF INT, V2838, P363
   Quevedo RA, 2010, FOOD BIOPROCESS TECH, V3, P637, DOI 10.1007/s11947-008-0106-6
   Rai P, 2014, J VIS COMMUN IMAGE R, V25, P1118, DOI 10.1016/j.jvcir.2014.03.009
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   See KW, 2007, APPL MATH COMPUT, V193, P346, DOI 10.1016/j.amc.2007.03.080
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shih HC, 2013, PATTERN RECOGN, V46, P519, DOI 10.1016/j.patcog.2012.08.003
   Stajnko D, 2009, EUR J HORTIC SCI, V74, P260
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tseng S, 2003, THESIS
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   Wang WL, 2014, J FOOD ENG, V142, P153, DOI 10.1016/j.jfoodeng.2014.06.019
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang S, 2011, IEEE INT SYMP INFO, P2866, DOI 10.1109/ISIT.2011.6034099
   Yin Peng-Yeng, APPROACH TEXTILE REC
   Yin QB, 2008, CHINESE J ELECTRON, V17, P646
   Zaim A, 2006, INT CONF ELECTRO INF, P350
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang Qieshi, 2009, Advances in Computer Science and IT, P109
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 77
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26537
EP 26567
DI 10.1007/s11042-019-07816-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700056
DA 2024-07-18
ER

PT J
AU Ghoshal, R
   Saha, A
   Das, S
AF Ghoshal, Ranjit
   Saha, Aditya
   Das, Sayan
TI An improved vessel extraction scheme from retinal fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal fundus image; Noise removal; Binarization; Image leveling;
   Granular noise removal; Thin vessel addition; Vessel extraction
ID BLOOD-VESSELS; MATCHED-FILTER; SEGMENTATION
AB Vessel extraction from retinal fundus images is essential for the diagnosis of different opthalmologic diseases like glaucoma, diabetic retinopathy and hypertension. It is a challenging task due to presence of several noises embedded with thin vessels. In this article, we have proposed an improved vessel extraction scheme from retinal fundus images. First, mathematical morphological operation is performed on each planes of the RGB image to remove the vessels for obtaining noise in the image. Next, the original RGB and vessel removed RGB image are transformed into negative gray scale image. These negative gray scale images are subtracted and finally binarized (BW1) by leveling the image. It still contains some granular noise which is removed based on the area of connected component. Further, previously detected vessels are replaced in the gray-scale image with mean value of the gray-scale image and then the gray-scale image is enhanced to obtain the thin vessels. Next, the enhanced image is binarized and thin vessels are obtained (BW2). Finally, the thin vessel image (BW2) is merged with the previously obtained binary image (BW1) and finally we obtain the vessel extracted image. To analyze the performance of our proposed method we have experimented on publicly available DRIVE dataset. We have observed that our algorithm have provides satisfactory performance with the sensitivity, specificity and accuracy of 0.7260, 0.9802 and 0.9563 respectively which is better than the most of the recent works.
C1 [Ghoshal, Ranjit; Saha, Aditya] St Thomas Coll Engn & Technol, Kolkata, W Bengal, India.
   [Das, Sayan] St Thomas Coll Engn & Technol, Comp Sci & Engn, Kolkata, W Bengal, India.
RP Ghoshal, R (corresponding author), St Thomas Coll Engn & Technol, Kolkata, W Bengal, India.
EM ranjit.ghoshal.stcet@gmail.com; adi96saha@gmail.com;
   sayandas896@gmail.com
OI Das, Sayan/0000-0003-0505-8589
CR Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Cinsdikici M, 2009, METHODS PROGRAMS BIO, V96, P8595
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Feng ZW, 2017, IEEE IMAGE PROC, P1742, DOI 10.1109/ICIP.2017.8296580
   Franklin SW, 2014, BIOCYBERN BIOMED ENG, V34, P117, DOI 10.1016/j.bbe.2014.01.004
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P600, DOI 10.1016/j.cmpb.2011.08.009
   Frucci M, 2016, PATTERN RECOGN LETT, V82, P162, DOI 10.1016/j.patrec.2015.07.002
   Grisan E, 2003, P ANN INT IEEE EMBS, V25, P890, DOI 10.1109/IEMBS.2003.1279908
   Guo S, 2018, ARXIV180303963V1CSCV
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Lam BSY, 2008, IEEE T MED IMAGING, V27, P237, DOI 10.1109/TMI.2007.909827
   Li Q, 2012, EXPERT SYST APPL, V39, P7600, DOI 10.1016/j.eswa.2011.12.046
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Olivier Anne-Helene, 2018, IEEE Transactions on Visualization and Computer Graphics, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Pellegrini E, 2014, BIOMED OPT EXPRESS, V5, P4329, DOI 10.1364/BOE.5.004329
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Singh D, 2014, 2014 ANN IEEE IND C, P1, DOI [DOI 10.1109/INDICON.2014.7030686, DOI 10.1007/978-81-322-2006-0]
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Sohini R. C., 2015, BIOMEDICAL HLTH INFO, DOI [DOI 10.1109/JBHI.2014.2335617, 10.1109/JBHI.2014.2335617]
   Staal JJ, 2004, IEEE TRANS MED IMAGI
   Teng T, 2002, MED BIOL ENG COMPUT, V40, P2, DOI 10.1007/BF02347689
   Yang-Williams K, 2002, OPHTHALMIC PHOTOGRAP
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
NR 32
TC 14
Z9 14
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25221
EP 25239
DI 10.1007/s11042-019-7719-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700001
DA 2024-07-18
ER

PT J
AU He, L
   Xie, L
   Shu, HH
   Hu, SY
AF He, Lang
   Xie, Liang
   Shu, Haohao
   Hu, Shengyuan
TI Discrete semi-supervised learning for multi-label image classification
   and large-scale image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete learning; Multi-label learning; Image classification; Image
   hashing
ID ALGORITHMS
AB Multi-label image classification is a critical problem in image semantic learning. Traditional semi-supervised multi-label learning methods are mainly based on continuous learning of both labelled and unlabelled data. They usually learn classification functions from continuous label space. And the neglect of discrete constraint of labels impedes the classification performance. In this paper, we specifically consider the discrete constraint and propose Discrete Semi-supervised Multi-label Learning (DSML) for image classification. In DSML, we propose a semi-supervised framework with discrete constraint. Then we introduce anchor graph learning to improve the scalability, and derive an ADMM based alternating optimization process to solve our framework. The main experimental results on two real-world image datasets MIR Flickr and NUS-WIDE demonstrate the superiority of DSML compared with several advanced multi-label methods. Furthermore, additional experiments of image retrieval show the potential advantages of DSML in other image applications.
C1 [He, Lang; Xie, Liang; Shu, Haohao; Hu, Shengyuan] Wuhan Univ Technol, Dept Math, Wuhan, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Xie, L (corresponding author), Wuhan Univ Technol, Dept Math, Wuhan, Hubei, Peoples R China.
EM whutxl@hotmail.com
OI Xie, Liang/0000-0003-1718-7556
FU National Natural Science Foundation of China [61702388]; Fundamental
   Research Funds for the Central Universities [2018IB016]
FX This work was supported by the National Natural Science Foundation of
   China (No.61702388), the Fundamental Research Funds for the Central
   Universities(WUT: 2018IVB021) and the Fundamental Research Funds for the
   Central Universities (No.2018IB016).
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2006, Manifold regularization: A geometric framework for learning from labeled and unlabeled examples
   [Anonymous], 2016, P IJCAI
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Ciaccia P, 1997, INT C VER LARG DAT B
   Cui Hui, 2018, PATTERN RECOGNITION
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hajinezhad D, 2016, INT CONF ACOUST SPEE, P4742, DOI 10.1109/ICASSP.2016.7472577
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jing LP, 2017, IEEE T IMAGE PROCESS, V26, P4612, DOI 10.1109/TIP.2017.2719939
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Liu X, 2018, IEEE T CIRCUITS SYST
   Liu Y., 2006, AAAI, P421
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Luo Y, 2013, IEEE T IMAGE PROCESS, V22, P523, DOI 10.1109/TIP.2012.2218825
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Wang J., 2014, CoRR
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang L, 2018, IEEE ACCESS, V6, P27091, DOI 10.1109/ACCESS.2018.2831675
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xie LX, 2014, INT CONF DIGIT SIG, P431, DOI 10.1109/ICDSP.2014.6900700
   Yan X, 2017, JOVE-J VIS EXP, DOI 10.3791/56323
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yang YP, 2017, AER ADV ENG RES, V141, P1, DOI 10.1109/ULTSYM.2017.8091994
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhou YH, 2016, IEEE T KNOWL DATA EN, V28, P1749, DOI 10.1109/TKDE.2016.2535283
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 46
TC 6
Z9 7
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24519
EP 24537
DI 10.1007/s11042-019-7157-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900038
DA 2024-07-18
ER

PT J
AU Huang, R
   Liu, H
   Liao, XJ
   Sun, SY
AF Huang, Rong
   Liu, Hao
   Liao, Xiaojuan
   Sun, Shaoyuan
TI A divide-and-conquer fragile self-embedding watermarking with adaptive
   payload
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-embedding; Fragile watermarking; Image authentication; Content
   restoration
ID IMAGE TAMPER DETECTION; RECOVERY; AUTHENTICATION; RECONSTRUCTION;
   MECHANISM; SELECTION
AB This paper proposes a divide-and-conquer fragile self-embedding watermarking with adaptive payload for digital images. A graph-based visual saliency (GBVS) model is adopted to automatically classify image blocks into region of interest (ROI) and background (ROB). The divide-and-conquer mechanisms aim to protect the ROI blocks with higher priority, which is embodied in two procedures: backup information collection and payload allocation. We collect the ROI backup information without compression, and allocate payload in a water-filling order to preferentially maintain the visual quality of ROI. The collected backup information are encoded as reference bits through a measurement process, in which a flexible scaling factor adaptively modulates the size of payload. Auxiliary information, which records the ROI locations, is embedded into the host images together with the reference bits. Hash-based authentication bits are responsible for detecting tampered blocks. A legitimate recipient can sequentially restore the auxiliary information and the original image content as long as the tampering is not too severe. The qualitative and quantitative results demonstrate the effectiveness and the superiority of the proposed methods compared with the previous works.
C1 [Huang, Rong; Liu, Hao; Sun, Shaoyuan] Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.
   [Huang, Rong; Liu, Hao; Sun, Shaoyuan] Minist Educ, Engn Res Ctr Digitized Text & Apparel Technol, Beijing, Peoples R China.
   [Liao, Xiaojuan] Chengdu Univ Technol, Sch Cyber Secur, Chengdu, Sichuan, Peoples R China.
C3 Donghua University; Chengdu University of Technology
RP Huang, R; Liu, H (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai, Peoples R China.; Huang, R; Liu, H (corresponding author), Minist Educ, Engn Res Ctr Digitized Text & Apparel Technol, Beijing, Peoples R China.
EM rong.huang@dhu.edu.cn; liuhao@dhu.edu.cn
OI Huang, Rong/0000-0003-3248-4620
FU National Natural Science Foundation of China [61806171]; Natural Science
   Foundation of Shanghai [18ZR1400300]; Program for the Fundamental
   Research of the Shanghai Committee of Science and Technology
   [15JC1400600]; Fundamental Research Funds of the Central Universities
   [16D110412,17D110408]
FX This work was supported in part by the National Natural Science
   Foundation of China (61806171), the Natural Science Foundation of
   Shanghai (18ZR1400300), the Program for the Fundamental Research of the
   Shanghai Committee of Science and Technology (15JC1400600), and the
   Fundamental Research Funds of the Central Universities
   (16D110412,17D110408).
CR Bravo-Solorio S, 2018, DIGIT SIGNAL PROCESS, V73, P83, DOI 10.1016/j.dsp.2017.11.005
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chen F, 2011, P 10 INT C DIG FOR W, P142
   Chen F, 2014, MULTIMED TOOLS APPL, V72, P41, DOI 10.1007/s11042-012-1332-5
   Fridrich J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P792, DOI 10.1109/ICIP.1999.817228
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Hu Y. F., 2017, ENVIRON EARTH SCI, V76, P1, DOI [10.1007/x12665-017-6684.8, DOI 10.1007/S12665-017-6830-3, DOI 10.1007/X12665-017-6684.8]
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Niu DM, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/2516324
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qian ZX, 2010, IEEE SIGNAL PROC LET, V17, P929, DOI 10.1109/LSP.2010.2072991
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Tian LH, 2015, MULTIMED TOOLS APPL, V74, P2991, DOI 10.1007/s11042-013-1765-5
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wang SS, 2008, PATTERN RECOGN, V41, P701, DOI 10.1016/j.patcog.2007.05.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
NR 42
TC 12
Z9 13
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26701
EP 26727
DI 10.1007/s11042-019-07802-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700063
DA 2024-07-18
ER

PT J
AU Lu, ZY
   Wang, XM
   Shang, JZ
   Luo, ZR
   Sun, CF
   Wu, GH
AF Lu, Zhongyue
   Wang, Xiaoming
   Shang, Jianzhong
   Luo, Zirong
   Sun, Chongfei
   Wu, Guoheng
TI A multimedia image edge extraction algorithm based on flexible
   representation of quantum
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flexible representation of quantum; Image edge extraction; Quantum
   qequence; Quantum black box; Sobel gradient
AB To solve the real-time problem of edge extraction algorithm and improve image edge continuity, an edge extraction algorithm based on quantum flexible representation (flexible representation of Quantum, RFQ) is proposed. First, the image is represented by quantum flexibility, the superposition state of the quantum sequence is used to store all the pixels of the image, and the FRQ image is obtained by the quantum parallel computation which efficiency is greatly improved, secondly, by the translation transformation of the X and Y directions of the FRQ image, the relative quanta of the neighboring pixels of the whole image is obtained. According to the quantum bit to define the quantum black boxU(omega), combining the Sobel operator to compute the Sobel gradient of pixels in order to judge different categories of pixels and extract the edges of the image. The experimental results show that the proposed method has better edge continuity and richer detail edge than the current edge extraction algorithm.
C1 [Lu, Zhongyue; Shang, Jianzhong; Luo, Zirong; Sun, Chongfei; Wu, Guoheng] Natl Univ Def Technol, Coll Mechatron & Automat, Changsha 410073, Hunan, Peoples R China.
   [Wang, Xiaoming] Beijing Special Engn & Design Inst BSEDI, POB 4702 6, Beijing 101000, Peoples R China.
C3 National University of Defense Technology - China
RP Lu, ZY (corresponding author), Natl Univ Def Technol, Coll Mechatron & Automat, Changsha 410073, Hunan, Peoples R China.
EM luzyueyy@163.com
RI Luo, Zirong/AAO-4621-2021
OI Luo, Zirong/0000-0002-8247-7317
CR Abdel-Khalek S, 2016, J RUSS LASER RES, V37, P141, DOI 10.1007/s10946-016-9554-z
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   [Anonymous], 2018, CAAI T INTELL TECHNO
   Cao F, 2011, SIAM J IMAGING SCI, V4, P1143, DOI 10.1137/110823572
   Gui L, 2012, ADV MATER RES-SWITZ, V490-495, P120, DOI 10.4028/www.scientific.net/AMR.490-495.120
   Hill C, 2016, J QUANT SPECTROSC RA, V177, P4, DOI 10.1016/j.jqsrt.2015.12.012
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1735, DOI 10.1007/s11128-015-0986-0
   Jiang N, 2015, QUANTUM INF PROCESS, V14, P1559, DOI 10.1007/s11128-014-0841-8
   Landgren M, 2014, THESIS
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Qian C., 2018, INTELL TECHNOL, V3, P18, DOI DOI 10.1049/trit.2018.0007
   Thongkamwitoon T, 2015, IEEE T INF FOREN SEC, V10, P953, DOI 10.1109/TIFS.2015.2392566
   Van d SM, 2000, IEEE T CONSUM ELECTR, V46, P923, DOI [10.1109/30.920442, DOI 10.1109/30.920442]
   Wang S., 2014, ADV INTELLIGENT SYST, VII, P243
   Zhang Y, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5158-9
   Zhu X, 2010, INT S INF PROC ISIP, P555
NR 16
TC 5
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24067
EP 24082
DI 10.1007/s11042-019-7173-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900015
DA 2024-07-18
ER

PT J
AU Shakir, HR
AF Shakir, Haidar Raad
TI An image encryption method based on selective AES coding of wavelet
   transform and chaotic pixel shuffling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Haar wavelet transform; AES; Logistic map
ID HAAR WAVELET
AB Image encryption is a mainstream aspect in multimedia applications and as such it is a highly active research domain. Based on the increasing need for reliable image encryption this paper presents a new method which combines the Haar wavelet transform with the Advanced Encryption Standard (AES) and pixel shuffling based on a chaotic logistic map. In the proposed method the Haar wavelet transform is calculated from the original image to obtain the different frequency domains of the image, namely, the approximation coefficient (LL) and detail confidents (LH, HL and HH). The approximation part (LL) is then encrypted by using the AES algorithm to create the image diffusion and the inverse of the Haar wavelet transform is applied. To further enhance the encryption strength a chaotic logistic map is used to shuffle the resulting image thereby making a malicious reconstruction attempt very challenging. The proposed method was evaluated in an extensive set of tests and compared to several representative methods from the literature. Test results show that it performed well across a variety of images and achieved a better level of image encryption and a lower level of image degradation.
C1 [Shakir, Haidar Raad] Univ Thi Qar, Coll Phys Educ & Sport Sci, Nasiriyah, Iraq.
C3 University of Thi-Qar
RP Shakir, HR (corresponding author), Univ Thi Qar, Coll Phys Educ & Sport Sci, Nasiriyah, Iraq.
EM haidar.raad@utq.edu.iq
RI Shakir, Haidar Raad/Z-3350-2019
OI Shakir, Haidar Raad/0000-0002-7747-1738
CR Ahadpour S, 2017, J DISCRET MATH SCI C, V20, P1217, DOI 10.1080/09720529.2016.1187958
   Ajish S, 2015, INT J ENG RES GEN SC, V3, P943
   Arrag S, 2012, ARXIV12093061
   Bao L, 2013, PROC SPIE, V8755, DOI 10.1117/12.2015725
   Bhavik R, 2016, INT J MOD ENG RES, V6, P71
   Dieu J., 2014, COMPUT SCI APPL, V1, P232
   Gulshan K., 2016, INDIAN J SCI TECHNOL, V9, P71871, DOI [10.17485/ijst/2016/v9i15/71871, DOI 10.17485/ijst/2016/v9i15/71871]
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Juang YS, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/164869
   Khalifa N, 2016, INF TECHNOL CONTROL, V45, P235, DOI 10.5755/j01.itc.45.3.12650
   Khudhar MM, 2016, INT J COMPUT SCI MOB, V5, P93
   Mishra DC, 2013, APPL APPL MATH, V8, P777
   Nazmudeen NH, 2014, INT J ENG COMPUT SCI, V3, P6956
   Nkapkop JD, 2016, INFORM-J COMPUT INFO, V40, P437
   Ravindran A, 2016, INT J ADV INF ENG TE, V3, P22
   Samson C, 2012, INT J ADV COMPUT SC, V3, P36
   Singh S, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P1, DOI 10.1109/SPIN.2014.6776910
   Soni K, 2016, INT J ENG SCI, P6320
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wu XJ, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL SCIENCES (ICCCS), P211, DOI 10.1109/ICCACS.2015.7361352
   Yogeshwaran S., 2015, INT J ELECT ELECT DA, V3, P81
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 23
TC 28
Z9 29
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26073
EP 26087
DI 10.1007/s11042-019-07766-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700037
DA 2024-07-18
ER

PT J
AU Thirumalai, CS
   Viswanathan, P
AF Thirumalai, Chandra Segar
   Viswanathan, P.
TI Modelling a side channel resistant CHAN-PKC cryptomata for medical data
   security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Side channel attacks; Public key encryption
ID IMAGE ENCRYPTION; RSA; EFFICIENT; SCHEME; CRYPTANALYSIS; SIGNATURES;
   ISSUES; HYBRID
AB Currently, a multimedia revolution of medical data in health information becomes part of our computing environment. However, the interchange of medical information is typically outsourced by third parties, which may affect the disclosure of confidentiality. To address this issue, we address high security and confidentiality through our proposed CHAN-PKC cryptomata. The proposed scheme uses a Diophantine equation to have the three stage of decryption for high security, but ESRKGS and RSA has one level of decryption. The results show that the proposed cryptomata has efficient encryption and decryption time when compared to the existing systems. At 10 K-bit moduli of key generation, CHAN-PKC consumes only 0.65 times of RSA, but ESRKGS takes 1.83 times of RSA. The timing similarity shows that both CHAN-PKC and RSA has a 100% correlation, but ESRKGS has only 90%. Hence our CHAN scheme is robust against side channel and also has a large key space than RSA. The security analysis confirms that our CHAN-PKC is very fast, secure against brute force and side channel attacks; therefore, it is feasible for real-time applications.
C1 [Thirumalai, Chandra Segar; Viswanathan, P.] VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Thirumalai, CS (corresponding author), VIT Univ, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM chandrasegar.t@vit.ac.in; viswatry2003@gmail.com
RI Thirumalai, Chandra Segar/AAD-8720-2019; Perumal,
   Viswanathan/L-6586-2017
OI Thirumalai, Chandra Segar/0000-0001-5171-946X; Perumal,
   Viswanathan/0000-0002-9337-8760
CR Aciicmez O., 2005, 12th ACM Conference on Computer and Communications security, P139
   Aciiçmez O, 2007, IEEE SECUR PRIV, V5, P62, DOI 10.1109/MSP.2007.91
   [Anonymous], 2018, NEURAL COMPUT APPL, DOI DOI 10.1007/S00521-017-2970-3
   [Anonymous], EFFICIENT PRIVACY PR
   [Anonymous], INT WORKSH CRYPT HAR
   [Anonymous], P IPSN CAMBR MA US
   [Anonymous], FUTUR GENER COMPUT S
   [Anonymous], 2006, PUBLIC KEY CRYPTOSYS
   [Anonymous], 2003, P 12 C USENIX SEC S
   [Anonymous], DRUG DEV IND PHARM
   [Anonymous], POLYNOMIAL TIME QUAN
   [Anonymous], P 12 USENIX SEC S SE
   [Anonymous], 2007, NIST SPEC PUBL
   [Anonymous], P 4 ACM C COMP COMM
   [Anonymous], CSR9522 CWI
   [Anonymous], 1999, LNCS
   [Anonymous], J ICT RES APPL ITB
   [Anonymous], MED IMAGE SECURITY U
   [Anonymous], P 2 WORKSH INF HID I
   [Anonymous], 2001, P 10 USENIX SECURITY
   [Anonymous], NIST SPECIAL PUBLI 3
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bellini E, 2016, FINITE FIELDS TH APP, V39, P179, DOI 10.1016/j.ffa.2016.01.011
   Boneh D, 1999, LECT NOTES COMPUT SC, V1592, P1
   Cai JJ, 2017, OPT COMMUN, V403, P211, DOI 10.1016/j.optcom.2017.07.049
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chandramowliswaran N, 2015, SYST SCI CONTROL ENG, V3, P106, DOI 10.1080/21642583.2014.985803
   Chaum D., 1983, Advances in Cryptology, Proceedings of Crypto 82, P199
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Coppersmith D, 1997, J CRYPTOL, V10, P233, DOI 10.1007/s001459900030
   Dehkordi MH, 2008, INFORM SCIENCES, V178, P2262, DOI 10.1016/j.ins.2007.11.031
   Esposito C, 2016, IEEE CLOUD COMPUT, V3, P16, DOI 10.1109/MCC.2016.79
   Herrmann M, 2010, LECT NOTES COMPUT SC, V6056, P53
   Hsu CF, 2014, APPL MATH COMPUT, V249, P436, DOI 10.1016/j.amc.2014.10.051
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Iovane G, 2008, CHAOS SOLITON FRACT, V37, P23, DOI 10.1016/j.chaos.2007.10.017
   Juels A, 1997, LECT NOTES COMPUT SC, V1294, P150
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kelsey J., 2000, Journal of Computer Security, V8, P141
   Khan MA, 2016, J NETW COMPUT APPL, V71, P11, DOI 10.1016/j.jnca.2016.05.010
   Kleinjung T, 2010, LECT NOTES COMPUT SC, V6223, P333, DOI 10.1007/978-3-642-14623-7_18
   Kocher P. C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P104
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li Y., 2016, INFORM SCIENCES, P1
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Lüy E, 2016, J INF SECUR APPL, V30, P1, DOI 10.1016/j.jisa.2016.03.006
   Mehar A, 2013, EUR TRANSP
   MERKLE RC, 1978, IEEE T INFORM THEORY, V24, P525, DOI 10.1109/TIT.1978.1055927
   Modic J, 2016, COMPUT SECUR, V62, P1, DOI 10.1016/j.cose.2016.06.003
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schindler W., 2000, Cryptographic Hardware and Embedded Systems - CHES 2000. Second International Workshop. Proceedings (Lecture Notes in Computer Science Vol.1965), P109
   Schindler W., 2002, Statistics and Decisions, V20, P191
   SCHNORR CP, 1990, LECT NOTES COMPUT SC, V435, P239
   Singh S, 2016, J NETW COMPUT APPL, V75, P200, DOI 10.1016/j.jnca.2016.09.002
   Sinha A, 2016, OPT LASER ENG, V81, P79, DOI 10.1016/j.optlaseng.2016.01.013
   Sun HM, 2007, IEEE T INFORM THEORY, V53, P2922, DOI 10.1109/TIT.2007.901248
   Sun L, 2014, J NETW COMPUT APPL, V45, P134, DOI 10.1016/j.jnca.2014.07.019
   Thangavel M, 2015, J INF SECUR APPL, V20, P3, DOI 10.1016/j.jisa.2014.10.004
   Thirumalai C, 2018, SERV ORIENTED COMPUT, V12, P285, DOI 10.1007/s11761-018-0237-1
   Wan JF, 2016, IEEE ACCESS, V4, P2797, DOI [10.1109/ACCESS.2016.25749, 10.1109/ACCESS.2016.2574979]
   Wan WN, 2015, CHINA COMMUN, V12, P22, DOI 10.1109/CC.2015.7122478
   WIENER MJ, 1990, IEEE T INFORM THEORY, V36, P553, DOI 10.1109/18.54902
   Zhao TY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/732609
   Zhu RW, 2007, THEOR COMPUT SCI, V378, P198, DOI 10.1016/j.tcs.2007.02.021
NR 64
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25977
EP 25997
DI 10.1007/s11042-019-7730-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700033
DA 2024-07-18
ER

PT J
AU Wang, XH
   Tao, JZ
   Shen, YT
   Bai, SF
   Song, CM
AF Wang, Xianghai
   Tao, Jingzhe
   Shen, Yutong
   Bai, Shifu
   Song, Chuanming
TI A NSST Pansharpening method based on directional neighborhood
   correlation and tree structure matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing image; Pansharpening; NSST; Directional neighborhoods
   matching degree; Binary-tree matching degree
ID IMAGE FUSION; CONTOURLET TRANSFORM; QUALITY; IHS; MS
AB In this paper, we propose a multispectral (MS) remote sensing image pansharpening method based on non-subsampled shearlet transform (NSST). By analyzing the NSST high-frequency coefficients correlation of several datasets which are fromWorldView-2 (WV2) and Quick-Bird (QB), we verified that the high-frequency coefficients based on NSST have strong directional neighborhood correlation within the same sub-band and parent-children correlation between sub-bands in the same direction. In order to combine these two kinds of correlations, we design a type of weighted directional neighborhood templates which can be used for any number of direction sub-bands to depict the direction correlation, and use the tree structure to model the correlation between parent-children coefficients. Experiments show that the proposed method in this paper can provide a fused MS image with high spatial resolution, which can provide convenience for subsequent applications such as classification and target recognition.
C1 [Wang, Xianghai; Shen, Yutong; Bai, Shifu; Song, Chuanming] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xianghai; Tao, Jingzhe] Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University
RP Wang, XH; Song, CM (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.; Wang, XH (corresponding author), Liaoning Normal Univ, Sch Urban & Environm Sci, Dalian 116029, Peoples R China.
EM xhwang@lnnu.edu.cn; blueuranus@qq.com; 1019639189@qq.com;
   1023113604@qq.com; chmsong@163.com
RI Wang, Xianghai/GRR-4512-2022; Jingzhe, Tao/JTD-2817-2023
OI Wang, Xianghai/0000-0002-7600-9939; 
FU National Natural Science Foundation of China [41671439, 61402214];
   Innovation Team Support Program of Liaoning Higher Education Department
   [LT2017013]
FX This research has been funded by the National Natural Science Foundation
   of China (Grant Nos. 41671439 and 61402214), and Innovation Team Support
   Program of Liaoning Higher Education Department (LT2017013).
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone V, 2015, REMOTE SENSING IMAGE
   [Anonymous], MULTIM TOOLS APPL
   [Anonymous], 2002, DATA FUSION DEFINITI
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cao YL, 2017, IEEE IMAGE PROC, P920, DOI 10.1109/ICIP.2017.8296415
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dou W, 2007, COMPUT GEOSCI-UK, V33, P219, DOI 10.1016/j.cageo.2006.06.008
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Ferraris V, 2017, INT CONF ACOUST SPEE, P3346, DOI 10.1109/ICASSP.2017.7952776
   Garzelli A, 2009, IEEE GEOSCI REMOTE S, V6, P662, DOI 10.1109/LGRS.2009.2022650
   Ghahremani M, 2016, IEEE GEOSCI REMOTE S, V13, P1606, DOI 10.1109/LGRS.2016.2597271
   Ghahremani M, 2015, IEEE GEOSCI REMOTE S, V12, P502, DOI 10.1109/LGRS.2014.2347955
   Kahraman S, 2018, ELECTRICA, V18, P109, DOI 10.5152/iujeee.2018.1817
   Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Massip P, 2012, IEEE T GEOSCI REMOTE, V50, P800, DOI 10.1109/TGRS.2011.2162244
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Rahmani S, 2010, IEEE GEOSCI REMOTE S, V7, P746, DOI 10.1109/LGRS.2010.2046715
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Upla KP, 2015, IEEE T GEOSCI REMOTE, V53, P3210, DOI 10.1109/TGRS.2014.2371812
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wang XH, 2015, J OPTICS-UK, V17, DOI 10.1088/2040-8978/17/5/055702
   [王相海 Wang Xianghai], 2010, [遥感学报, Journal of Remote Sensing], V14, P905
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yuhas R., 1992, SUMMARIES 4 ANN JPL, P147
NR 37
TC 5
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26787
EP 26806
DI 10.1007/s11042-019-07841-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700067
DA 2024-07-18
ER

PT J
AU Yang, Z
   Yang, XZ
   Wu, X
AF Yang, Zhao
   Yang, Xuezhi
   Wu, Xiu
TI Motion-tolerant heart rate estimation from face videos using derivative
   filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photoplethysmography; Imaging; Derivative filter; Motion interference;
   Heart rate estimation
ID PULSE; NONCONTACT
AB Imaging photoplethysmography (IPPG) technique allows us to extract blood volume pulse (BVP) signals from face videos for measuring heart rate (HR), which is useful in applications such as neonatal monitoring, telemedicine and affective computing. Because the BVP signal is small, the HR estimation results are sensitive to face motion disturbance caused by spontaneous head movements and facial expressions of subjects. In this paper, we design a novel filtering method for refining the RGB signals with motion artifacts. Based on the observation that subtle color changes of face skin are smoother than large face motions at temporal scale, we use the three-order derivative of Gaussian filter to select subtle color changes under large motions. Our method is validated on both our self-collected dataset and public dataset MAHNOB-HCI containing face videos with head movements and facial expressions. By employing the proposed filtering method to pre-process the RGB signals before BVP signal extraction, a range of IPPG methods are improved to generate robust HR estimation results under realistic situations.
C1 [Yang, Zhao; Yang, Xuezhi; Wu, Xiu] Hefei Univ Technol, Sch Comp & Informat, 193 Tunxi Rd Baohe Dist, Hefei 230009, Anhui, Peoples R China.
   [Yang, Zhao; Yang, Xuezhi; Wu, Xiu] Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, XZ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, 193 Tunxi Rd Baohe Dist, Hefei 230009, Anhui, Peoples R China.; Yang, XZ (corresponding author), Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei, Anhui, Peoples R China.
EM xzyang@hfut.edu.cn
FU Training Programme Foundation for Application of Scientific and
   Technological Achievements of Hefei University of Technology
   [JZ2018YYPY0289]; Specialized Research Fund for the Doctoral Program of
   Higher Education of China [JZ2018HGBZ0186]
FX We acknowledge funding support from: Training Programme Foundation for
   Application of Scientific and Technological Achievements of Hefei
   University of Technology (JZ2018YYPY0289) and the Specialized Research
   Fund for the Doctoral Program of Higher Education of China
   (JZ2018HGBZ0186).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.263
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   de Haan G, 2014, PHYSIOL MEAS, V35, P1913, DOI 10.1088/0967-3334/35/9/1913
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Guven G, 2018, SIGNAL IMAGE VIDEO P, V12, P933, DOI 10.1007/s11760-018-1238-4
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551
   Kumar M, 2015, BIOMED OPT EXPRESS, V6, P1565, DOI 10.1364/BOE.6.001565
   Lindeberg T, 2013, SCALE SPACE THEORY C
   Liu XN, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aaca83
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Piazzi A, 2000, IEEE T IND ELECTRON, V47, P140, DOI 10.1109/41.824136
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Rohrer B, 2002, J NEUROSCI, V22, P8297
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Sun Y, 2016, IEEE T BIO-MED ENG, V63, P463, DOI 10.1109/TBME.2015.2476337
   Temko A, 2017, IEEE T BIO-MED ENG, V64, P2016, DOI 10.1109/TBME.2017.2676243
   Tomasi C, 1991, DETECTION TRACKING P
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang WJ, 2017, IEEE T BIO-MED ENG, V64, P1479, DOI 10.1109/TBME.2016.2609282
   Wang WJ, 2017, BIOMED OPT EXPRESS, V8, P1965, DOI 10.1364/BOE.8.001965
   Xu SC, 2014, BIOMED OPT EXPRESS, V5, P1124, DOI 10.1364/BOE.5.001124
   Zhao F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071384
NR 26
TC 5
Z9 5
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26747
EP 26757
DI 10.1007/s11042-019-07849-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700065
DA 2024-07-18
ER

PT J
AU Prakash, CS
   Panzade, PP
   Om, H
   Maheshkar, S
AF Prakash, Choudhary Shyam
   Panzade, Prajwal Pralhad
   Om, Hari
   Maheshkar, Sushila
TI Detection of copy-move forgery using AKAZE and SIFT keypoint extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Copy-move forgery; Duplicated region detection; SIFT;
   AKAZE
AB Digital image manipulation techniques are becoming increasingly sophisticated and widespread. Copy-move forgery is one of the frequently used manipulation techniques. In this paper, we propose a keypoint based copy-move forgery detection (CMFD) technique, which is a combination of accelerated KAZE (AKAZE) and scale invariant feature transform (SIFT) features. By using AKZAE and SIFT, a significant number of keypoints are extracted even in a smooth region to detect the manipulated regions efficiently. After formation of the mixed keypoints, the g2NN is used for matching process to locate the duplicated regions. The experimental results show that the proposed method can detect the duplicated regions even if the image is post-processed with scaling, rotation, noise and JPEG compression operations. To validate the robustness and effectiveness of the proposed method, a statistical analysis is performed using the ANOVA method.
C1 [Prakash, Choudhary Shyam; Panzade, Prajwal Pralhad; Om, Hari; Maheshkar, Sushila] Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Technol, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Prakash, CS (corresponding author), Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Technol, Dhanbad, Bihar, India.
EM shyamprakash2008@yahoo.com
RI Panzade, Prajwal/JMQ-7273-2023; Prakash, Choudhary/Y-2314-2019;
   Maheshkar, Sushila/KPY-5418-2024; OM, HARI/AAY-6011-2021
OI Panzade, Prajwal/0000-0002-8347-8274; Maheshkar,
   Sushila/0000-0003-3879-2800; OM, HARI/0000-0002-9750-2706; Prakash, Dr.
   Choudhary Shyam/0000-0002-9305-3472
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ammour N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040312
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2010, IEEE T INF FOREN SEC, DOI DOI 10.1109/TIFS.2010.2078506
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   Grewenig S, 2010, LECT NOTES COMPUT SC, V6376, P533
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li SX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082702
   Liu LC, 2018, IEEE T IMAGE PROCESS, V27, P4345, DOI 10.1109/TIP.2018.2831454
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muller KE., 2002, REGRESSION ANOVA INT
   Pan XY, 2010, INT CONF ACOUST SPEE, P1706, DOI 10.1109/ICASSP.2010.5495482
   Panzade PP, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P264, DOI 10.1109/PDGC.2016.7913156
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Weickert J, 2016, INT J COMPUT VISION, V118, P275, DOI 10.1007/s11263-015-0874-1
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
NR 47
TC 25
Z9 26
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23535
EP 23558
DI 10.1007/s11042-019-7629-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400059
DA 2024-07-18
ER

PT J
AU Sorrentino, F
   Spano, LD
AF Sorrentino, Fabio
   Spano, Lucio Davide
TI Post-it notes: supporting teachers in authoring vocabulary game contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Augmented reality; Mobile learning;
   Authoring environment; Storytelling; Mobile assisted language learning;
   Language learning; Education
ID AUGMENTED REALITY
AB In this work, we present Post-it Notes, a system for supporting vocabulary acquisition in a foreign language for primary school children. The system consists of an authoring tool designed for teachers and a mobile application for students. The authoring tool is a web application for creating language learning materials. It supports inserting terms, each one defining a specific meaning of a word, specifying their syntax, definition, phonetics, pronunciation and descriptive image. The correspondences between terms represent translations between languages. Furthermore, the authoring tool allows teachers to create stories, organised as a sequence of sentences, including a set of hidden words for reinforcing their usage. Once published, the story is accessible from the mobile application, which assists children in following the plot. The learning game consists of guessing the missing words by taking pictures of augmented objects distributed in the surrounding environment. A similar interface allows the student to rehearse specific term sets, attaching visual markers to real objects. We evaluated the authoring tool with teachers. The results show both good usability and good acceptance. In addition, we also carried out an observational study in a primary school, describing the children's behaviour in interacting with the mobile application and group dynamics.
C1 [Sorrentino, Fabio; Spano, Lucio Davide] Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
C3 University of Cagliari
RP Sorrentino, F (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
EM fabio.sorrentino@unica.it; davide.spano@unica.it
RI Spano, Lucio Davide/AAD-7209-2021
OI Spano, Lucio Davide/0000-0001-7106-0463
FU Sardinia Regional Government, [DGR 28/21, F72F16003030002,
   F72F16002830002]
FX The work has been partially supported by the Sardinia Regional
   Government, EmILIE project (Convenzione triennale tra la Fondazione di
   Sardegna e gli Atenei Sardi Regione Sardegna - L.R. 7/2007 anno 2016 -
   DGR 28/21 del 17.05.2015 CUP: F72F16003030002) and D3P2 project
   (Regional Law 7/07, year 2015, "Capitale Umano ad Alta Qualificazione",
   CUP: F72F16002830002)
CR [Anonymous], 2010, ENHANCING TEACHERS T
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Blake R., 2013, Brave New Digital Classroom. Technology and Foreign Language Learning
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Canning-Wilson C., 2000, INTERNET TESL J, VVI, P11
   Chan T.-W., 2006, RES PRACT TECH ENHAN, P3, DOI [10.1142/S1793206806000032, DOI 10.1142/S1793206806000032]
   Charitonos K., 2016, CALL communities and culture - short papers from EUROCALL 2016, P94, DOI DOI 10.14705/RPNET.2016.EUROCALL2016.544
   Chen J.L., 2016, TECHNOLOGY ENHANCED, V168, P3
   Dag F, 2014, PROCD SOC BEHV, V116, P888, DOI 10.1016/j.sbspro.2014.01.316
   Ellis N., 2002, Studies in Second Language Acquisition, V24, P143, DOI [10.1017/S0272263102002024, DOI 10.1017/S0272263102002024]
   Gandy M, 2004, ACM CHI Lett, V6, P197
   Gass S.M., 2001, 2 LANGUAGE ACQUISITI
   Godwin-Jones R, 2017, LANG LEARN TECHNOL, V21, P3
   Godwin-Jones R, 2016, LANG LEARN TECHNOL, V20, P9
   Harris J, 2002, ASTDS LEARNING CIRCU
   HART S G, 1988, P139
   Kabali HK, 2015, PEDIATRICS, V136, P1044, DOI 10.1542/peds.2015-2151
   KEMP Jerrold., 1985, Planning and producing Instructional Media
   Kessler G, 2018, FOREIGN LANG ANN, V51, P205, DOI 10.1111/flan.12318
   Kramsch C, 2006, INT J APPL LINGUIST, V16, P97, DOI 10.1111/j.1473-4192.2006.00109.x
   Krashen S., 1983, Principles and practice in second language acquisition
   Liu PHE, 2013, BRIT J EDUC TECHNOL, V44, pE1, DOI 10.1111/j.1467-8535.2012.01302.x
   Liu TY, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P5, DOI 10.1109/ICIS.2007.1
   Liu TY, 2010, LECT NOTES COMPUT SC, V5960, P37, DOI 10.1007/978-3-642-12349-8_3
   Mayer RE, 1998, J EDUC PSYCHOL, V90, P312, DOI 10.1037/0022-0663.90.2.312
   Media C S., 2013, Zero to eight: Children's media use in American 2013
   Murray T., 2004, Educational Technology, V44, P10
   NELSON DL, 1976, J EXP PSYCHOL-HUM L, V2, P523, DOI 10.1037/0278-7393.2.5.523
   Ogata H., 2011, International Journal of Research and Practice on Technology Enhanced Learning (RPTEL), V6, P69
   Pettersson R., 2004, J Vis Liter, V24, P129, DOI [DOI 10.1080/23796529.2004.11674609, 10.1080/23796529.2004.11674609]
   Pomerantz A, 2007, APPL LINGUIST, V28, P556, DOI 10.1093/applin/amm044
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Read J.C., 2006, P INTERACTION DESIGN, P81, DOI DOI 10.1145/1139073.1139096
   Salaberry MR, 1997, CAN MOD LANG REV, V53, P422, DOI 10.3138/cmlr.53.2.422
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Scida EE, 2006, CALICO J, V23, P517
   Scrivner O, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P395, DOI 10.1109/FTC.2016.7821639
   Sykes J., 2013, The Language Educator, V8, P32
NR 39
TC 5
Z9 5
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23049
EP 23074
DI 10.1007/s11042-019-7604-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400039
DA 2024-07-18
ER

PT J
AU Taheri, YM
   Ahmad, MO
   Swamy, MNS
AF Taheri, Yaser Mohammad
   Ahmad, M. Omair
   Swamy, M. N. S.
TI Successive refinement of side information frames in distributed video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding; Wyner-Ziv frame; Side information refinement
ID COMPRESSION
AB In distributed video coding, generation of high-quality side information is required for reliable soft-input information for decoding each DCT band of a Wyner-Ziv (WZ) frame in the decoder, which in turn leads to a more efficient decoding. Consequently, less error-correcting bits need to be transmitted from the encoder to the decoder to decode the bitplanes of each DCT band, leading to a better compression efficiency and rate-distortion performance. In this paper, we investigate the problem of successive improvements in the quality of side information frames in distributed video coding in order to improve the rate-distortion performance. A new algorithm for the successive refinement of the side information is proposed to refine the initial side information frame using the additional information obtained after decoding the previous DCT bands of a WZ frame. As more information about the WZ frame becomes available after the decoding of each DCT band of the WZ frame, the corresponding side information frame is refined and then employed to decode the next DCT band of the WZ frame. Simulations are carried out demonstrating that the proposed algorithm for refinement of side information frame results in a considerable improvement in the RD performance of distributed video coding.
C1 [Taheri, Yaser Mohammad; Ahmad, M. Omair; Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
EM y_moh@ece.concordia.ca; omair@ece.concordia.ca; swamy@ece.concordia.ca
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Regroupement Strategique en Microelectronique du Quebec (ReSMiQ)
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and in part by the Regroupement
   Strategique en Microelectronique du Quebec (ReSMiQ).
CR Aaron A, 2004, IEEE IMAGE PROC, P3097
   Aaron A, 2002, IEEE DATA COMPR CONF, P252, DOI 10.1109/DCC.2002.999963
   [Anonymous], P INT MOB MULT COMM
   Argyropoulos S, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P159, DOI 10.1109/MMSP.2007.4412842
   Artigas J., 2007, P PCS, P1
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   Ascenso Joao, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P29
   Ascenso J, 2008, J VIS COMMUN IMAGE R, V19, P600, DOI 10.1016/j.jvcir.2008.06.001
   Avaro O, 2000, SIGNAL PROCESS-IMAGE, V15, P281, DOI 10.1016/S0923-5965(99)00050-8
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Dinh TN, 2007, 2007 INTERNATIONAL SYMPOSIUM ON INFORMATION TECHNOLOGY CONVERGENCE, PROCEEDINGS, P179, DOI 10.1109/ISITC.2007.21
   Dufaux F, 2010, EURASIP J IMAGE VIDE
   Esmaili GR, 2011, IEEE T IMAGE PROCESS, V20, P2463, DOI 10.1109/TIP.2011.2121079
   Fan XP, 2009, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2009.5414618
   Huang X, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P223, DOI 10.1109/MMSP.2008.4665079
   Huang X, 2012, SIGNAL PROCESS-IMAGE, V27, P16, DOI 10.1016/j.image.2011.06.008
   Luong HV, 2012, IEEE T IMAGE PROCESS, V21, P4782, DOI 10.1109/TIP.2012.2215621
   Huynh Van Luong, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2633, DOI 10.1109/ICIP.2011.6116207
   Liu RK, 2009, CHINESE J AERONAUT, V22, P167, DOI 10.1016/S1000-9361(08)60083-7
   Liveris AD, 2002, GLOB TELECOMM CONF, P1300
   Louw DJ, 2012, 2012 INT S IEEE INF
   Martins R, 2009, IEEE T CIRC SYST VID, V19, P1327, DOI 10.1109/TCSVT.2009.2022783
   Puri R., 2002, P ANN ALLERTON C COM, V40, P586
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Taheri YM, 2014, IEEE I C ELECT CIRC, P722, DOI 10.1109/ICECS.2014.7050087
   Taheri YM, 2018, MULTIMED TOOLS APPL, V77, P7327, DOI 10.1007/s11042-017-4635-8
   Varodayan D, 2008, SIGNAL PROCESS-IMAGE, V23, P369, DOI 10.1016/j.image.2008.04.009
   Wang S, 2012, IEEE T CIRC SYST VID, V22, P649, DOI 10.1109/TCSVT.2011.2171263
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
NR 30
TC 4
Z9 4
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20697
EP 20722
DI 10.1007/s11042-019-7249-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400007
DA 2024-07-18
ER

PT J
AU Yan, YY
   Zhu, J
AF Yan, Yunyi
   Zhu, Jiang
TI Saliency detection based on superpixel correlation and cosine window
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Superpixel correlation; Cosine window filtering;
   Target extraction
AB With the development of computer vision, image salient region detection plays an important role in the field of image processing. However, existing saliency detection methods can only generate saliency maps without achieving accuracy, thereby ignoring the integrity of the significant target. The present study proposed a saliency detection algorithm based on the correlation of superpixel and cosine window filtering (SPC) algorithm that introduced a variable weight superpixel segmentation method to keep the edge of information and enhance the integration of the salient target. Space distance and color distance are used to judge the correlation between two superpixels in the proposed algorithm, and based on the superpixel correlation, the saliency map is obtained by all superpixels' voting. When the saliency map is corrected by a cosine window, we call this operation a cosine window filtering. Finally, we used the OSTU method for binarization and obtained the target position and size, using connected domain detection. The experiment results showed that the SPC algorithm can describe superpixels' significance accurately and extract salient object. As compared with other algorithms, our algorithm offers higher accurate results, regarding the accurate position and size of salient targets.
C1 [Yan, Yunyi; Zhu, Jiang] Xidian Univ, Sch Aerosp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Yan, YY (corresponding author), Xidian Univ, Sch Aerosp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM yyyan@xidian.edu.cn
RI YAN, Yunyi/HMD-9838-2023
OI Yan, Yunyi/0000-0001-8669-8451
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Achanta Radhakrishna, 2010, Tech. Rep.
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gupta R, 2011, LECT NOTES COMPUT SC, V6744, P458, DOI 10.1007/978-3-642-21786-9_74
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Wang L, 2018, IEEE T AUTOM SCI ENG, V15, P1521, DOI 10.1109/TASE.2018.2868471
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wonjun Kim, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2469, DOI 10.1109/ICIP.2011.6116161
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 19
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21205
EP 21221
DI 10.1007/s11042-019-7407-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400030
DA 2024-07-18
ER

PT J
AU Pantula, M
   Kuppusamy, KS
AF Pantula, Muralidhar
   Kuppusamy, K. S.
TI AuDIVA: A tool for embedding Audio Descriptions to enhance Video
   Accessibility for Persons with Visual Impairments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio Descriptions(AD); Video Accessibility; Persons with disabilities;
   WCAG
AB Inclusion of online videos on a website attracts a large number of audience because of its ease of perception. Even though rendering videos on the web is advantageous, persons with disabilities face difficulties in accessing the content. Web Content Accessibility Guidelines (WCAG) has recommended closed captions for persons with hearing problems and Audio descriptions for the persons with visual problems, to remove the barriers in making the video content accessible. In this paper, we have incorporated a technique called Narrating the scene before the act. With this, persons with visual impairments will get a proper understanding of the context of the scene and they will be in a better position to easily grasp the content. We have designed a tool, entitled AuDIVA (Audio Description Inserter for Video Accessibility) which will insert the audio descriptions before the scene in the video at specified intervals. A survey conducted shows that the technique eases tasks for web developers to provide audio descriptions in the video.
C1 [Pantula, Muralidhar] Pondicherry Univ, Dept Comp Sci, Pondicherry, India.
   [Kuppusamy, K. S.] Pondicherry Univ, Comp Sci, Pondicherry, India.
C3 Pondicherry University; Pondicherry University
RP Pantula, M (corresponding author), Pondicherry Univ, Dept Comp Sci, Pondicherry, India.
EM vijayamuralisarma@gmail.com; kskuppu@gmail.com
RI PANTULA, MURALIDHAR/P-5463-2015
OI Pantula, Muralidhar/0000-0001-7771-0447; KS,
   Kuppusamy/0000-0002-2382-2379
CR [Anonymous], 2008, TRANSLATION STUDIES
   Benecke B, 2004, META, V49, P78, DOI 10.7202/009022ar
   Benkacem I, 2018, P WCNC
   Bugajski M, 2017, METHOD SYSTEM TRANSF
   Caldwell Ben, 2008, WWW CONSORTIUM W3C, V290, P1
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   Fels D.I., 2006, Journal of Universal Access in the Information Society, V5, P73, DOI DOI 10.1007/s10209-006-0025-0
   Kirchner C, 2001, J VIS IMPAIR BLINDNE, V95
   Olalere A, 2011, ACCESSIBILITY US FED, V28
   Peli E, 1996, J VISUAL IMPAIR BLIN, V90, P378
   Pettitt B., 1996, British Journal of Visual Impairment, V14, P48
   Pfeiffer Silvia, 2009, P 2009 INT CROSSDISC, P98, DOI [10.1145/1535654, DOI 10.1145/1535654]
   Rodriguez-Fuentes LJ, 2013, GTTS SYSTEMS SWS TAS
   Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940
   Romero-Fresco P, 2013, J SPEC TRANSL, P201
   Saxena Mohit., 2008, NOSSDAV '08: Proceedings of the 18th International Workshop on Network and Operating Systems Support for Digital Audio and Video, P39
   Szarkowska A., 2011, J SPECIALISED TRANSL, V15, P81
   Walczak A., 2017, UNIVERSAL ACCESS INF, P1
NR 18
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20005
EP 20018
DI 10.1007/s11042-019-7363-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800049
DA 2024-07-18
ER

PT J
AU Sasikaladevi, N
   Malathi, D
AF Sasikaladevi, N.
   Malathi, D.
TI Privacy preserving light weight authentication protocol (LEAP) for WBAN
   by exploring Genus-2 HEC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WBAN; HECC; Authentication protocol; AVISPA; BAN logic; Cryptographic
   attacks
ID MUTUAL AUTHENTICATION; SCHEME; LIGHTWEIGHT; NETWORKS
AB Wireless Body Area Network (WBAN) is evolving as the successful way of monitoring patient health and offers enhanced healthcare solutions to provide the better quality of life for the urban community. As it involves wireless communications, securing the privacy-related data is a key constraint in WBAN. To ensure privacy, it is essential to include authentication to prevent unauthorized access by intruders. This paper proposes the privacy preserving LightwEight two factors Authentication Protocol (LEAP) for WBAN based on genus-2 Hyper Elliptic Curve (HEC). Personal Digital Assistant (PDA) collects signals from sensors from the BAN. PDA transmits the healthcare data to the Healthcare Service Provider (HSP) connected in the public network. Hence, the two-factor mutual authentication protocol is established between PDA and HSP. Since PDA is considered as a resource constraint device, the lightweight mutual authentication is required. Genus 2 Hyper elliptic curve (HEC) is carefully designed to prevent all possible cryptographic attacks, which is more suitable for lightweight authentication since it provides the high degree of security with the lesser key size even as compared to the elliptic curve. Using the rigorous formal security analysis using BAN logic, it is proved that the proposed scheme is secure against possible attacks. Also, the privacy preserving lightweight authentication scheme is implemented using the most-widely accepted Automated Validation of Internet Security Protocols and Applications (AVISPA) tool, and the simulation results reveal that proposed scheme is secure and robust.
C1 [Sasikaladevi, N.] SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
   [Malathi, D.] SASTRA Deemed Univ, Sch Comp, Thanjavur, TN, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Sasikaladevi, N (corresponding author), SASTRA Deemed Univ, Sch Comp, Dept CSE, Thanjavur, TN, India.
EM sasikaladevi@gmail.com
RI , Sasikaladevi/AAF-7847-2019
OI D, Malathi/0000-0003-3154-1769; , Sasikaladevi N/0000-0002-0841-502X
FU Science and Engineering Board (SERB), Government of India under the ECR
   grant [ECR/2017/000679/ES]
FX This part of the work is funded by the Science and Engineering Board
   (SERB), Government of India under the ECR grant (ECR/2017/000679/ES).
CR Amin R, 2018, FUTURE GENER COMP SY, V80, P483, DOI 10.1016/j.future.2016.05.032
   Chen ZT, 2018, FUTURE GENER COMP SY, V84, P126, DOI 10.1016/j.future.2017.10.008
   Das AK, 2017, COMPUT ELECTR ENG, V63, P196, DOI 10.1016/j.compeleceng.2017.03.008
   Ever YK, 2018, IEEE SYST J
   Fan K, 2018, IEEE T IND INFORM, V14, P1656, DOI 10.1109/TII.2018.2794996
   Hayajneh T, 2014, WIREL NETW, V20, P2165, DOI 10.1007/s11276-014-0736-8
   He DB, 2017, IEEE SYST J, V11, P2590, DOI 10.1109/JSYST.2016.2544805
   He DB, 2017, COMPUT NETW, V128, P154, DOI 10.1016/j.comnet.2016.12.013
   He DB, 2015, IEEE COMMUN MAG, V53, P71, DOI 10.1109/MCOM.2015.7010518
   Jung M, 2015, MULTIMED TOOLS APPL, V74, P6151, DOI 10.1007/s11042-014-2095-y
   Li CT, 2018, COMPUT METH PROG BIO, V157, P191, DOI 10.1016/j.cmpb.2018.02.002
   Li FG, 2018, IEEE SYST J, V12, P747, DOI 10.1109/JSYST.2016.2557850
   Li S, 2017, SEC COMMUN NETW
   Li X, 2018, J NETW COMPUT APPL, V103, P194, DOI 10.1016/j.jnca.2017.07.001
   Li X, 2017, COMPUT NETW, V129, P429, DOI 10.1016/j.comnet.2017.03.013
   Li X, 2017, COMPUT ELECTR ENG, V61, P238, DOI 10.1016/j.compeleceng.2017.02.011
   Ma LM, 2014, WIRELESS PERS COMMUN, V77, P1077, DOI 10.1007/s11277-013-1555-4
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Omala AA, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0670-7
   Salayma M, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3041956
   Sharma G, 2018, J INF SECUR APPL, V42, P95, DOI 10.1016/j.jisa.2018.08.003
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Shen J, 2018, MULTIMED TOOLS APPL, V77, P11381, DOI 10.1007/s11042-017-5559-z
   Shen J, 2018, FUTURE GENER COMP SY, V78, P956, DOI 10.1016/j.future.2016.11.033
   Ullah S, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM), P51, DOI 10.1109/BIGCOM.2017.51
   Wang MJ, 2018, IEEE T IND INFORM, V14, P3637, DOI 10.1109/TII.2017.2778090
   Wang W, 2018, SMART HLTH
   Wazid M, 2018, J NETW COMPUT APPL
   Wu F, 2018, FUTURE GENER COMP SY, V82, P727, DOI 10.1016/j.future.2017.08.042
   Wu F, 2017, COMPUT ELECTR ENG, V63, P168, DOI 10.1016/j.compeleceng.2017.04.012
   Xu J, 2018, FUTURE GEN COMPUT SY
   Zhao ZG, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0013-5
NR 32
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18037
EP 18054
DI 10.1007/s11042-019-7149-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200032
DA 2024-07-18
ER

PT J
AU Song, YJ
   Zhu, ZL
   Zhang, W
   Yu, H
AF Song, Yanjie
   Zhu, Zhiliang
   Zhang, Wei
   Yu, Hai
TI Efficient protection using chaos for Context-Adaptive Binary Arithmetic
   Coding in H.264/Advanced Video Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; CABAC; Selective encryption; Real-time; Chaos
ID SELECTIVE ENCRYPTION; IMAGE ENCRYPTION; COMPRESSION; H.264/AVC;
   ALGORITHM; SCHEME; SECURE; CABAC; CRYPTOGRAPHY; QUALITY
AB Recently, video encryption has been widely investigated to enhance the protection for video data, yet the encryption efficiency may not be considered sufficiently so that some encryption schemes are unsuitable for the real-time applications. In this paper, we propose a novel chaotic selective encryption scheme (CSES) based on Context-Adaptive Binary Arithmetic Coding (CABAC) of H.264/Advanced Video Coding (H.264/AVC) for the practical applications. To satisfy the secure and real-time requirement, we select the important and sensitive encryption objects on the basis of the analysis of syntax elements in CABAC. According to the characteristics of chosen syntax elements, two encryption methods combined with two designed chaos-based key stream generators (KSGs) are presented in CSES to implement the video encryption with the reasonable and acceptable compression and encryption performance. The experimental results and security analysis demonstrate that the proposed CSES with the format-compliance has the good confidentiality and can resist some common security attacks, such as the brute force attack, histogram attack, information entropy attack, replacement attack and some other common attacks. It can be found from the comparison experiments about the encryption efficiency that our CSES has the higher real-time performance. The comparison analysis with other video encryption methods illustrates that the proposed CSES is more suitable for the practical applications.
C1 [Song, Yanjie; Zhu, Zhiliang; Zhang, Wei; Yu, Hai] Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Zhu, ZL (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
EM zzlswc@163.com
RI YU, Hai/E-6831-2018
OI YU, Hai/0000-0002-8024-1781
FU National Natural Science Foundation of China [61374178, 61402092,
   61603182]; Online Education Research Fund of the MOE Research Center for
   Online Education, China [2016ZD306]; Ph.D. Start-Up Foundation of
   Liaoning Province, China [201501141]; Fundamental Research Funds for the
   Central Universities [N171704004]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61374178, 61402092, 61603182]; the Online Education
   Research Fund of the MOE Research Center for Online Education, China
   [qtone education, grant number 2016ZD306]; the Ph.D. Start-Up Foundation
   of Liaoning Province, China [grant number 201501141]; and the
   Fundamental Research Funds for the Central Universities [grant number
   N171704004].
CR Al-Azawi MKM, 2018, IET SIGNAL PROCESS, V12, P214, DOI 10.1049/iet-spr.2016.0708
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2010, INT J COMPUT ELECT E, DOI DOI 10.7763/IJCEE.2010.V2.141
   Asghar MN, 2015, MULTIMED TOOLS APPL, V74, P10215, DOI 10.1007/s11042-014-2160-6
   Asghar MN, 2013, IEEE T CIRC SYST VID, V23, P425, DOI 10.1109/TCSVT.2012.2204941
   Chiaraluce F, 2002, IEEE T CONSUM ELECTR, V48, P838, DOI 10.1109/TCE.2003.1196410
   Ding XL, 2017, IET INFORM SECUR, V11, P55, DOI 10.1049/iet-ifs.2015.0492
   Elhoseny M, 2016, SECUR COMMUN NETW, V9, P2024, DOI 10.1002/sec.1459
   Elhoseny M, 2016, J KING SAUD UNIV-COM, V28, P262, DOI 10.1016/j.jksuci.2015.11.001
   Fan Y, 2007, PROCEEDINGS OF THE 3RD WSEAS INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL MECHANICS (MECHANICS '07), P240
   Ghouti L, 2012, METHOD PERFORMING CI, P1
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Gutub AAA, 2011, COMM COM INF SC, V179, P104
   Hamza R, 2017, J INF SECUR APPL, V35, P119, DOI 10.1016/j.jisa.2017.06.005
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hermassi H, 2017, MULTIMED TOOLS APPL, V76, P1177, DOI 10.1007/s11042-015-3030-6
   Huang YW, 2005, IEEE T CIRC SYST VID, V15, P378, DOI 10.1109/TCSVT.2004.842620
   Joshi JM, 2016, J TEST EVAL, V44, P1461, DOI 10.1520/JTE20140332
   Khlif N, 2014, 2014 1ST INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP 2014), P1, DOI 10.1109/ATSIP.2014.6834579
   Khlif N, 2018, IET IMAGE PROCESS, V12, P42, DOI 10.1049/iet-ipr.2017.0022
   Khlif N, 2016, J TEST EVAL, V44, P160, DOI 10.1520/JTE20140182
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Martina Podesser A U., 2002, 5th Nordic Signal Processing Symposium, V10, P4
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Peng F, 2017, MULTIMED TOOLS APPL, V76, P3235, DOI 10.1007/s11042-016-3710-x
   Peng F, 2013, IEEE T INF FOREN SEC, V8, P1688, DOI 10.1109/TIFS.2013.2259819
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Sallam AI, 2018, MULTIMED TOOLS APPL, V77, P28395, DOI 10.1007/s11042-018-5994-5
   Sallam AI, 2018, IEEE T MULTIMEDIA, V20, P1636, DOI 10.1109/TMM.2017.2777470
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shen HJ, 2014, IET INFORM SECUR, V8, P199, DOI 10.1049/iet-ifs.2012.0349
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Tong XJ, 2017, MULTIMED TOOLS APPL, V76, P13995, DOI 10.1007/s11042-016-3775-6
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Varalakshmi LM, 2014, TELECOMMUN SYST, V56, P357, DOI 10.1007/s11235-013-9849-0
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu H, 2016, J OPT SOC AM A, V33, P1166, DOI 10.1364/JOSAA.33.001166
   Zhang YS, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501911
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 56
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 18967
EP 18994
DI 10.1007/s11042-019-7253-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800002
DA 2024-07-18
ER

PT J
AU Benaissa, M
   Bennia, A
AF Benaissa, Manel
   Bennia, Abdelhak
TI Block classification based edge detector and object localizer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contour detection; Edge detection; Image classification; Computer vision
AB In this paper, we proposed a new edge detector based on a statistical modelization of the image surface. We used two classical and widely used metrics to constitute our detector properties, which are the mean and standard deviation. Our approach was to take advantage from the intensities fluctuation for a better understanding of the image surface. Moreover, our detector is able to highlight pertinent regions in the image. This property has been exploited in the present work, to identify important image contours. Besides its novelty and efficiency, the main advantage of our detector is its simplicity, which makes it easy to implement in terminals with low processing capacity, it's also little memory consumer and doesn't need a training phase which makes it independent from the availability of labeled datasets. Experiments shows that our detector out-performs some state-of-the-art detector.
C1 [Benaissa, Manel; Bennia, Abdelhak] Univ Constantine 1, Dept Elect, 325 Route Ain El Bey, Constantine, Algeria.
C3 Universite Constantine
RP Benaissa, M (corresponding author), Univ Constantine 1, Dept Elect, 325 Route Ain El Bey, Constantine, Algeria.
EM menelbenaissa@gmail.com; abdelhak.bennia@laposte.net
CR [Anonymous], INT J COMPUT VIS
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2002, IEEE T PATTERN ANAL
   [Anonymous], TPAMI
   [Anonymous], 2001, P IEEE INT C COMP VI
   [Anonymous], 2015, P INT C LEARN REPR
   [Anonymous], 1965, OPTICAL ELECTROOPTIC
   [Anonymous], 2011, TPAMI
   Bertasius G, 2015, P IEEE COMP SOC C CO
   Brehar R., 1986, IEEE T PATT ANAL MAC
   Catanzaro B, 2009, 2009 IEEE 12 INT C C
   Dalal N., 2005, P 2005 IEEE COMP SOC
   Everingham M., 2009, The PASCAL Visual Object Classes Challenge 2009 (VOC) Results
   Felzenszwalb P.F., 2004, Int. J. Comput. Vis
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Hallman S, 2015, P IEEE COMP SOC C CO
   Huang J, 2009, SIGNAL PROCESS
   Hwang J-J, 2015, PIXEL WISE DEEP LEAR, V1, P4
   Kittler J, 1983, IMAGE VIS COMPUT
   Kivinen JJ, 2014, P AISTATS
   Laptev I, 2006, P BRIT MACH VIS C
   Leventon M. E., 2000, P IEEE C COMP VIS PA
   Li C., 2007, P IEEE COMP SOC C CO
   Lim JJ, 2013, P IEEE COMP SOC C CO
   Mallat S, 1992, IEEE T PATT ANAL MAC
   Mallat S, 1992, IEEE T INF THEORY
   Martin D, 2002, COMPUT
   Martin DR, 2004, IEEE T PATT ANAL MAC
   Mely DA, 2016, VIS RES
   Morrone MC, 1987, PATTERN RECOGNIT LET
   Perona P, 1990, SCIENCE, P52
   Poggio TA, 1986, IEEE T PATTERN ANAL
   Sarkalkan N, 2014, BONE, V60, P129, DOI 10.1016/j.bone.2013.12.006
   Shen W, 2015, PROC IEEE COMPUT SOC
   Tu Z., 2006, P IEEE COMP SOC C CO
   Wang X-F, 2015, PATTERN RECOGN
   Xiaofeng R, 2012, NEURAL INF PROCESS S
   Xie S, 2017, INT J COMPUT VIS
   Yu Z, 2017, P 30 IEEE C COMP VIS
   Zheng S, 2010, COMPUT VIS IMAGE UND
NR 40
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14573
EP 14589
DI 10.1007/s11042-018-6821-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700020
DA 2024-07-18
ER

PT J
AU Cao, CH
   Deng, L
   Duan, W
   Xiao, F
   Yang, WC
   Hu, K
AF Cao, Chunhong
   Deng, Liu
   Duan, Wei
   Xiao, Fen
   Yang, WanChun
   Hu, Kai
TI Hyperspectral image classification via compact-dictionary-based sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Compact dictionary; Hyperspectral image; Sparse
   representation
ID COLLABORATIVE REPRESENTATION; KERNEL
AB In this paper, a compact-dictionary-based sparse representation (CDSR) method is proposed for hyperspectral image (HSI) classification. The proposed dictionary in CDSR is dynamically generated according to the spatial and spectral context of each pixel. It can effectively shrink the decision range for classification, and reduce the computational burden since the compact dictionary is composed of the classes correlated with the target pixel in terms of spatial location and spectral information. In order to obtain better spatial context information, a spatial location expanding strategy is designed for spreading local explicit label information to a wider region. Experimental results demonstrate the effectiveness and superiority of the proposed method when compared with some widely used HSI classification approaches.
C1 [Cao, Chunhong; Deng, Liu; Duan, Wei; Xiao, Fen; Yang, WanChun; Hu, Kai] Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan, Peoples R China.
C3 Xiangtan University
RP Deng, L (corresponding author), Xiangtan Univ, Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan, Peoples R China.
EM dengliu-email@foxmail.com; kaihu@xtu.edu.cn
RI hu, kai/HSG-5888-2023
OI Xiao, Fen/0000-0001-7511-9418
FU National Natural Science Foundation of China [61401386, 61802328]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61401386 and 61802328. The authors would like to
   thank Prof. D. Landgrebe and Prof. P. Gamba for providing the
   hyperspectral data set. In addition, we also would like to thank the
   reviewers for their constructive comments on this manuscript.
CR [Anonymous], IEEE T GEOSCIENCE RE
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Chen C, 2016, IEEE GEOSCI REMOTE S, V13, P424, DOI 10.1109/LGRS.2016.2517095
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Deng X, 2017, MULTIMED TOOLS APPL, V76, P13, DOI 10.1007/s11042-015-3012-8
   Du Q, 2013, IEEE J-STARS, V6, P459, DOI 10.1109/JSTARS.2013.2257422
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Fang LY, 2014, IEEE T GEOSCI REMOTE, V52, P7738, DOI 10.1109/TGRS.2014.2318058
   Fu W, 2016, IEEE J-STARS, V9, P556, DOI 10.1109/JSTARS.2015.2477364
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P2769, DOI 10.1109/TIP.2014.2319735
   Gevaert CM, 2015, IEEE J-STARS, V8, P3140, DOI 10.1109/JSTARS.2015.2406339
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Jia S, 2017, IEEE T GEOSCI REMOTE, V55, P2575, DOI 10.1109/TGRS.2017.2647815
   Jiao HZ, 2012, IEEE T GEOSCI REMOTE, V50, P4085, DOI 10.1109/TGRS.2012.2188856
   Lampropoulos G. A., 2009, IEEE INT GEOSCI REMO, P262
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Liu JJ, 2016, REMOTE SENS LETT, V7, P975, DOI 10.1080/2150704X.2016.1207257
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Moody DI, 2014, P SPIE AUTOMATIC TAR, V9090, pC1
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Pontius J, 2008, REMOTE SENS ENVIRON, V112, P2665, DOI 10.1016/j.rse.2007.12.011
   Roscher R, 2016, IEEE T GEOSCI REMOTE, V54, P1623, DOI 10.1109/TGRS.2015.2484619
   Saha M, 2018, IEEE T IMAGE PROCESS, V27, P2189, DOI 10.1109/TIP.2018.2795742
   Soltani-Farani A, 2015, IEEE T GEOSCI REMOTE, V53, P527, DOI 10.1109/TGRS.2014.2325067
   Sun XX, 2015, IEEE T GEOSCI REMOTE, V53, P4457, DOI 10.1109/TGRS.2015.2399978
   Sun XX, 2014, IEEE GEOSCI REMOTE S, V11, P1235, DOI 10.1109/LGRS.2013.2290531
   Wang JN, 2017, REMOTE SENS LETT, V8, P11, DOI 10.1080/2150704X.2016.1230279
   Wang ZW, 2014, IEEE T GEOSCI REMOTE, V52, P4808, DOI 10.1109/TGRS.2013.2285049
   Wu S, 2016, The Metallogenic Mechanism of Distal Contact Pb-Zn-ag Vines in Shizhuyuan Ore District, Hunan Province, China, V2016, P1
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yuan H, 2018, INFRARED PHYS TECHN, V93, P1, DOI 10.1016/j.infrared.2018.07.005
   Yuan HL, 2015, IEEE J-STARS, V8, P2464, DOI 10.1109/JSTARS.2015.2442588
   Zhang B, 2012, ENVIRON EARTH SCI, V65, P649, DOI 10.1007/s12665-011-1112-y
   Zhang HY, 2014, IEEE J-STARS, V7, P2056, DOI 10.1109/JSTARS.2013.2264720
   Zhang R, 2018, TRAC-TREND ANAL CHEM, V99, P1, DOI 10.1016/j.trac.2017.11.015
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 43
TC 2
Z9 2
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15011
EP 15031
DI 10.1007/s11042-018-6885-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700039
DA 2024-07-18
ER

PT J
AU Gao, QH
   Wan, TR
   Tang, W
   Chen, L
AF Gao, Qing Hong
   Wan, Tao Ruan
   Tang, Wen
   Chen, Long
TI Object registration in semi-cluttered and partial-occluded scenes for
   augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; 3D object recognition and matching; 3D point clouds;
   SLAM algorithm
ID SLAM; RECOGNITION
AB This paper proposes a stable and accurate object registration pipeline for markerless augmented reality applications. We present two novel algorithms for object recognition and matching to improve the registration accuracy from model to scene transformation via point cloud fusion. Whilst the first algorithm effectively deals with simple scenes with few object occlusions, the second algorithm handles cluttered scenes with partial occlusions for robust real-time object recognition and matching. The computational framework includes a locally supported Gaussian weight function to enable repeatable detection of 3D descriptors. We apply a bilateral filtering and outlier removal to preserve edges of point cloud and remove some interference points in order to increase matching accuracy. Extensive experiments have been carried to compare the proposed algorithms with four most used methods. Results show improved performance of the algorithms in terms of computational speed, camera tracking and object matching errors in semi-cluttered and partial-occluded scenes.
C1 [Gao, Qing Hong] Xian Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Wan, Tao Ruan] Univ Bradford, Fac Engn & Informat, Bradford BD7 1DP, W Yorkshire, England.
   [Tang, Wen; Chen, Long] Bournemouth Univ, Fac Sci & Technol, Poole BH12 5BB, Dorset, England.
C3 Xi'an Polytechnic University; University of Bradford; Bournemouth
   University
RP Wan, TR (corresponding author), Univ Bradford, Fac Engn & Informat, Bradford BD7 1DP, W Yorkshire, England.
EM t.wan@bradford.ac.uk
FU Shanxi Natural Science and Technology Foundation of China [2016JZ026,
   2016KW-043]
FX This research work is supported by Shanxi Natural Science and Technology
   Foundation of China, grant number 2016JZ026 and grant number
   2016KW-043).
CR Alexandre LA, 2016, 3D OBJECT RECOGNITIO
   [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144
   Benko Hrvoje., 2012, P SIGCHI C HUMAN FAC, P199, DOI DOI 10.1145/2207676.2207704
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bostanci E, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0040-3
   Czerniawski T, 2016, AUTOMAT CONSTR, V71, P346, DOI 10.1016/j.autcon.2016.08.011
   Davison AJ, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P315, DOI 10.1109/ISMAR.2003.1240737
   Davison AJ, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P18, DOI 10.1109/ISMAR.2003.1240684
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614
   Fiala M, 2005, PROC CVPR IEEE, P590
   Gao QH, 2017, 2017 INT C CYBERWORL
   Gao QH, 2017, LECT NOTES COMPUT SC, V10345, P11, DOI 10.1007/978-3-319-65849-0_2
   Gross M., 2007, POINT BASED GRAPHICS
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Hagbi N, 2011, IEEE T VIS COMPUT GR, V17, P1369, DOI 10.1109/TVCG.2010.241
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Klein George, 2007, P1
   Krajník T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396
   Liarokapis F., 2010, Using Augmented reality as a medium to assist teaching in higher education
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Mur-Artal RJ D. Tardos., 2016, ORB SLAM2 OPEN SOURC
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nohyoung Park, 2011, 2011 International Symposium on Ubiquitous Virtual Reality, P40, DOI 10.1109/ISUVR.2011.20
   Pang G, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P22, DOI 10.1109/MVA.2015.7153124
   Prakhya SM, 2015, IEEE INT C INT ROBOT, P1929, DOI 10.1109/IROS.2015.7353630
   Prince SJD, 2002, IEEE COMPUT GRAPH, V22, P39, DOI 10.1109/MCG.2002.1046627
   Reitmayr G., 2010, Proceedings of the 2010 International Symposium on Ubiquitous Virtual Reality (ISUVR 2010), P5, DOI 10.1109/ISUVR.2010.12
   Rong Wen, 2010, 2010 8th IEEE International Conference on Control and Automation (ICCA 2010), P947, DOI 10.1109/ICCA.2010.5524421
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Segal AV, 2009, GEN ICP, DOI DOI 10.15607/RSS.2009.V.021
   Skrypnyk I, 2004, SCENE MODELLING RECO
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Stoyanov Todor, 2011, 2011 IEEE International Conference on Robotics and Automation, P4080
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009
   Szalavari Z, 1997, COMPUT GRAPH FORUM, V16, pC335, DOI 10.1111/1467-8659.00171
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Tombari Federico, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology, P349, DOI DOI 10.1109/PSIVT.2010.65
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
NR 55
TC 15
Z9 16
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15079
EP 15099
DI 10.1007/s11042-018-6905-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700042
OA Green Published, Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Lu, Q
   Liu, Y
   Huang, J
   Yuan, XH
   Hu, QX
AF Lu, Qiang
   Liu, Yu
   Huang, Jing
   Yuan, Xiaohui
   Hu, Qingxin
TI License plate detection and recognition using hierarchical feature
   layers from CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate detection; Character recognition; Hierarchical feature
   layers; Generated training data
AB In recent years, a variety of systems using deep convolutional neural network (CNN) approaches have achieved good performance on license plate detection and character recognition. However, most of these systems are not stable when the scenes changed, specification of each hierarchical layer to get the final detection result, which can detect multi-scale license plates from an input image. Meanwhile, at the stage of character recognition, data annotation is heavy and time-consuming, giving rise to a large burden on training a better model. We devise an algorithm to generate annotated training data automatically and approximate the data from the real scenes. Our system used for detecting license plate achieves 99.99% mean average precision (mAP) on OpenITS datasets. Character recognition also sees high accuracy, thus verifying the superiority of our method.
C1 [Lu, Qiang] Hefei Univ Technol, Hefei Engn Res Ctr Elect Power Data Applicat, Anhui Prov Key Lab Ind Safety & Emergency Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Liu, Yu; Huang, Jing; Hu, Qingxin] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Yuan, Xiaohui] Univ North Texas, Dept Sci & Engn, Denton, TX USA.
C3 Hefei University of Technology; Hefei University of Technology;
   University of North Texas System; University of North Texas Denton
RP Hu, QX (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM luqiang@hfut.edu.cn; luckyliuyu@yeah.net; hjing410@163.com;
   xiaohui.yuan@unt.edu; 9696210@163.com
RI Yuan, Xiaohui/AAQ-1172-2020; Lu, Qiang/AAU-9248-2020
OI Yuan, Xiaohui/0000-0001-6897-4563
FU National Nature Science Foundation of China [61672201]; Natural Science
   Foundation of Anhui Province of China [1708085MF158]; China Scholarship
   Council (CSC) [201706695044]
FX This work is supported by the National Nature Science Foundation of
   China (No. 61672201), the Natural Science Foundation of Anhui Province
   of China (No. 1708085MF158) and the China Scholarship Council (CSC No.
   201706695044).
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], TAMKANG J SCI ENG
   [Anonymous], IEEE T POWER ELECT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, J. Transp. Tech.
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bai HL, 2004, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2004.1334387
   Cao GZ, 2003, IEEE IND ELEC, P1786
   Chen YX, 2016, INFORM SCIENCES, V372, P148, DOI 10.1016/j.ins.2016.08.050
   Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380
   Chen YN, 2006, INT C PATT RECOG, P552
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deb K, 2009, CYBERNET SYST, V40, P689, DOI 10.1080/01969720903294601
   Feng BY, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P1, DOI 10.1109/AVSS.2014.6918635
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang HQ, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P15, DOI 10.1109/FSKD.2008.230
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo J, 2009, 2009 INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION AND SERVICE SCIENCE (NISS 2009), VOLS 1 AND 2, P770, DOI 10.1109/NISS.2009.89
   Maglad Khalid W., 2012, Journal of Computer Science, V8, P310, DOI 10.3844/jcssp.2012.310.315
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu HHR, 2006, INT C PATT RECOG, P824
   Xia Y, 2017, IEEE T MULTIMEDIA, VPP, P1
   Zhang HF, 2006, INT C PATT RECOG, P1102
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 29
TC 14
Z9 15
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15665
EP 15680
DI 10.1007/s11042-018-6889-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700067
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Wang, K
   Wang, HT
   Su, YT
AF Nie, Weizhi
   Wang, Kun
   Wang, Hongtao
   Su, Yuting
TI The assessment of 3D model representation for retrieval with CNN-RNN
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; RNN; Deep learning; Information retrieval
ID OBJECT RETRIEVAL; SEARCH ENGINE; CLASSIFICATION; FEATURES
AB In this paper, we propose a novel method for assessing 3D model representation via CNN and RNN networks. First, a visual tool developed with OpenGL is utilized to extract virtual views of each 3D model from different angles. These views are extracted by 10-degree wrap around the model. Second, a CNN model is used to extract the feature vectors of these virtual images. Then, these feature vectors as the input of an RNN are fused into a new feature to represent the 3D model. Finally, the Euclidean distance is used to obtain the similarity measure between two different models for the retrieval problem. In the experimental section, NTU, PSB and ShapeNet datasets are utilized to evaluate the performance of the proposed method. Several classic 3D model retrieval and classification methods are leveraged as comparison methods in this paper. The corresponding experiments also demonstrate the superiority of our approach.
C1 [Nie, Weizhi; Wang, Kun; Wang, Hongtao; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Nie, WZ; Su, YT (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn; ytsu@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61502337, 61872267]
FX This work was supported in part by the National Natural Science
   Foundation of China (61502337, 61872267).
CR [Anonymous], 2017, EUR WORKSH 3 OBJ RET
   [Anonymous], ARXIV14061078
   [Anonymous], ARXIV150204623
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Conrad M, 2014, EUR CONF POW ELECTR
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, SIGNAL PROCESS-IMAGE, V26, P39, DOI 10.1016/j.image.2010.10.006
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gao Z, GROUP PAIR CONVOLUTI
   He X, ARXIV180306189
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hu MC, 2015, IEEE T CYBERNETICS, V45, P742, DOI 10.1109/TCYB.2014.2335540
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Ji Y, ARXIV160301913
   Kanezaki A, ARXIV160306208
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Leibe B, 2003, PROC CVPR IEEE, P409
   Leng B, 2017, MULTIMEDIA SYST, V23, P19, DOI 10.1007/s00530-015-0454-9
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie W., 2015, ACM COMPUT SURV, V1, P1
   Nie WZ, 2017, MULTIMEDIA SYST, V23, P325, DOI 10.1007/s00530-015-0485-2
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2007, PATTERN RECOGN, V40, P2437, DOI 10.1016/j.patcog.2006.12.026
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Papoiu ADP, 2014, J NEUROPHYSIOL, V112, P1729, DOI 10.1152/jn.00827.2013
   Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5
   Pickup D., 2015, P 8 EUR WORKSH 3D OB, P99
   Qi C. R., 2017, IEEE P COMPUT VIS PA, V1, P4, DOI DOI 10.1109/CVPR.2017.16
   Rodolà E, 2015, PATTERN RECOGN LETT, V59, P41, DOI 10.1016/j.patrec.2015.03.009
   Rodolà E, 2014, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2014.532
   Roman-Rangel E, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2948069
   Sfikas K, 2018, COMPUT GRAPH-UK, V71, P208, DOI 10.1016/j.cag.2017.12.001
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wu JJ, 2016, ADV NEUR IN, V29
   Xu K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980224
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
NR 55
TC 8
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16979
EP 16994
DI 10.1007/s11042-018-7102-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500056
DA 2024-07-18
ER

PT J
AU Selvi, C
   Sivasankar, E
AF Selvi, C.
   Sivasankar, E.
TI A novel Adaptive Genetic Neural Network (AGNN) model for recommender
   systems using modified k-means clustering approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender System (RS); Collaborative Filtering (CF); Clustering
   approach; Modified k-means; Genetic Algorithm (GA); Artificial Neural
   Network (ANN); Adaptive Genetic Neural Network (AGNN)
ID ALGORITHM; OPTIMIZATION
AB The Recommender System (RS) plays an important role in information retrieval techniques in a bid to handle massive online data effectively. It gives suggestions on items/services to the target online user to ensure correct decisions quickly and easily. Collaborative Filtering (CF) is a key approach in RS providing a recommendation to the target online user, based on a rating similarity among users. Unsupervised clustering approach is a model-based CF, which is preferred as it ensures simple and effective recommendation. Such CFs suffer from a high error rate and needs additional iterations for convergence. This paper proposes a Modified k-means clustering approach to eliminate the above mentioned issues to provide well-framed clusters. The novel supervised Adaptive Genetic Neural Network (AGNN) method is proposed to locate the most favored data points in a cluster to deliver effective recommendations. The performance of the proposed RS is measured by conducting an experimental analysis on benchmark MovieLens and Netflix datasets. Results are compared with state-of-the-art methods namely Artificial Neural Network (ANN) and Fuzzy based RS models to show the effectiveness of the proposed AGNN method.
C1 [Selvi, C.; Sivasankar, E.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Selvi, C (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM selvichandran.it@gmail.com; sivasankarelango@gmail.com
RI CHANDRAN, SELVI/T-2043-2019; Elango, Sivasankar/AAY-5197-2021
OI CHANDRAN, SELVI/0000-0002-0344-3005; 
CR Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Albanese M, 2010, MULTIMED TOOLS APPL, V50, P563, DOI 10.1007/s11042-010-0480-8
   Alhijawi B., 2016, 2016 IEEE/ACIS 15th International Conference on Computer and Information Science, P1, DOI DOI 10.1109/ICIS.2016.7550751
   [Anonymous], 2012, INT J COMPUT SCI ISS
   [Anonymous], 2006, P WEBKDD
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/ijst/2016/v9i17/89936
   [Anonymous], 2002, P 5 INT C COMP INF T
   [Anonymous], 1993, NEURAL NETWORKS OPTI
   [Anonymous], THESIS
   [Anonymous], 2015, RECOMMENDER SYSTEMS
   [Anonymous], INT J COMPUTER SCI I
   [Anonymous], INT C 2 COMP ENG TEC, DOI DOI 10.1371/J0URNAL.PPAT.1000992
   Ar Y, 2016, EXPERT SYST APPL, V61, P122, DOI 10.1016/j.eswa.2016.05.021
   Berry M., 2009, Data mining techniques
   Bhaskaran S., 2019, Cluster Computing, V22, pS1137, DOI 10.1007/s10586-017-1160-5
   Bilge A, 2013, INFORM PROCESS MANAG, V49, P912, DOI 10.1016/j.ipm.2013.02.004
   Bobadilla J, 2011, KNOWL-BASED SYST, V24, P1310, DOI 10.1016/j.knosys.2011.06.005
   Braida F, 2015, EXPERT SYST APPL, V42, P4733, DOI 10.1016/j.eswa.2015.01.023
   Christakou C, 2007, INT J ARTIF INTELL T, V16, P771, DOI 10.1142/S0218213007003540
   da Silva EQ, 2016, EXPERT SYST APPL, V53, P204, DOI 10.1016/j.eswa.2015.12.050
   Dooms S, 2015, MULTIMED TOOLS APPL, V74, P11297, DOI 10.1007/s11042-014-2232-7
   Dooms S, 2015, MULTIMED TOOLS APPL, V74, P3053, DOI 10.1007/s11042-013-1768-2
   Elmisery AM, 2013, MULTIMED TOOLS APPL, V64, P249, DOI 10.1007/s11042-012-1067-3
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Gupta A, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417747
   Gupta A, 2014, IEEE INT ADV COMPUT, P1248, DOI 10.1109/IAdCC.2014.6779506
   Han JW, 2016, CLUSTER COMPUT, V19, P2273, DOI 10.1007/s10586-016-0670-x
   Hsu SH, 2007, LECT NOTES COMPUT SC, V4471, P166
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Kim KJ, 2008, EXPERT SYST APPL, V34, P1200, DOI 10.1016/j.eswa.2006.12.025
   Li XY, 2018, CHINA QUART, V234, P340, DOI 10.1017/S0305741017001382
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu X.Z., 2014, SCI WORLD J, V2014
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Madadipouya K, 2017, BRAIN-BROAD RES ARTI, V8, P109
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Mukhopadhyay A, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2742642
   Nasser S, 2006, IEEE INT CONF FUZZY, P231, DOI 10.1109/FUZZY.2006.1681719
   Nziramasanga MT, 2002, INT POL EC, P53
   Özkan C, 2003, PHOTOGRAMM ENG REM S, V69, P1225
   Paradarami TK, 2017, EXPERT SYST APPL, V83, P300, DOI 10.1016/j.eswa.2017.04.046
   Patra BK, 2015, KNOWL-BASED SYST, V82, P163, DOI 10.1016/j.knosys.2015.03.001
   Rosli AN, 2015, CLUSTER COMPUT, V18, P187, DOI 10.1007/s10586-014-0355-2
   Salehi M, 2013, EGYPT INFORM J, V14, P67, DOI 10.1016/j.eij.2012.12.001
   Selvi C, 2019, SOFT COMPUT, V23, P1901, DOI 10.1007/s00500-017-2899-6
   Tsai CF, 2012, APPL SOFT COMPUT, V12, P1417, DOI 10.1016/j.asoc.2011.11.016
   Tu JV, 1996, J CLIN EPIDEMIOL, V49, P1225, DOI 10.1016/S0895-4356(96)00002-9
   Yubo Jia, 2014, Applied Mechanics and Materials, V599-601, P1446, DOI 10.4028/www.scientific.net/AMM.599-601.1446
   Zahra S, 2015, INFORM SCIENCES, V320, P156, DOI 10.1016/j.ins.2015.03.062
   Zanardi Valentina, 2011, Database and Expert Systems Applications. Proceedings 22nd International Conference, DEXA 2011, P542, DOI 10.1007/978-3-642-23088-2_40
   Zhang RC, 2016, FRONT COMPUT SCI-CHI, V10, P270, DOI 10.1007/s11704-015-4584-1
   Zimmerman J, 2004, HUM-COMPUT INT-SPRIN, P27
NR 54
TC 17
Z9 18
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14303
EP 14330
DI 10.1007/s11042-018-6790-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700009
DA 2024-07-18
ER

PT J
AU Tiwari, M
   Lamba, SS
   Gupta, B
AF Tiwari, Mayank
   Lamba, Subir Singh
   Gupta, Bhupendra
TI A software supported image enhancement approach based on DCT and
   quantile dependent enhancement with a total control on enhancement
   level: DCT-Quantile
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform; Contrast enhancement; Linearly quantile
   separated histogram equalization; Greyscale images; Mean-shift problem
ID SOURCE-CAMERA IDENTIFICATION; HISTOGRAM EQUALIZATION; BRIGHTNESS
   PRESERVATION; PERFORMANCE
AB In many computer vision applications like medical imaging, pattern recognition etc., image enhancement is an important pre-processing requirement which is used to improve the efficiency of an application. A significantly large literature is available on image enhancement; unfortunately, most of these schemes have certain shortcomings for e.g. the lack of control over the contrast starching, noise enhancement and mean-shift' problem etc. To deal with the aforementioned problems, this study suggests an efficient method which is based on discrete cosine transformation (DCT) and quantile dependent sub-division of the histogram of given input image. In the proposed method, we apply DCT on the input image to get low-frequency component (LFC) and then use the quantile-based sub-division on the histogram of LFC. Finally, histogram equalization is performed on all these sub-histograms separately. The main advantage of quantile-based segmentation is that here entire intensity spectrum participates in the enhancement process, which provides a total control over the enhancement level. In the proposed method the high-frequency component remains untouched and hence the structural information of the input image and the noise in the input image remains unaffected by the image enhancement process.
C1 [Tiwari, Mayank; Lamba, Subir Singh; Gupta, Bhupendra] PDPM Indian Inst Informat Technol Design & Mfg, Dept Math, Jabalpur 482005, MP, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Tiwari, M (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Dept Math, Jabalpur 482005, MP, India.
EM mayanktiwariggits@gmail.com; subirs@gmail.com; gupta.bhupendra@gmail.com
RI Lamba, Subir Singh/ABD-5810-2020; Gupta, Bhupendra/ABD-4884-2020
OI Tiwari, Mayank/0000-0003-0347-0967
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gupta B, 2018, IEEE SIGNAL PROC LET, V25, P1340, DOI 10.1109/LSP.2018.2857223
   Gupta B, 2018, DIGIT INVEST, V24, P121, DOI 10.1016/j.diin.2018.02.003
   Gupta B, 2017, COMPUT ELECTR ENG, V62, P360, DOI 10.1016/j.compeleceng.2017.01.010
   Huang LD, 2015, IET IMAGE PROCESS, V9, P908, DOI 10.1049/iet-ipr.2015.0150
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   [冷璐 LENG Lu], 2010, [微电子学与计算机, Microelectronics & Computer], V27, P38
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Tiwari M, 2018, FORENSIC SCI INT, V285, P111, DOI 10.1016/j.forsciint.2018.02.005
   Tiwari M, 2015, IET IMAGE PROCESS, V9, P80, DOI 10.1049/iet-ipr.2013.0778
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 20
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16563
EP 16574
DI 10.1007/s11042-018-7056-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500037
DA 2024-07-18
ER

PT J
AU Wang, Y
   Pan, ZB
   Li, R
AF Wang, Yang
   Pan, Zhibin
   Li, Rui
TI A novel low bit rate side match vector quantization algorithm based on
   structed state codebook
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VQ; SMVQ; Image coding; Supporting codebook; Structed codebook
ID PARALLEL FRAMEWORK; SMVQ; COMPRESSION; INDEX
AB Side match vector quantization (SMVQ) is a widely used image compression algorithm for data hiding applications. Compared with conventional vector quantization (VQ) algorithm, a smaller and more powerful state codebook (SC) which is generated by utilizing the correlation in natural image is used in SMVQ to achieve low bit rate. However, the visual quality of reconstructed image by using SMVQ is significantly decreased. In this paper, a novel low bit rate coding algorithm named structured SMVQ (SSMVQ) is proposed. The size of SSMVQ's SC is flexible and the SC of SSMVQ is composed by a smaller SC of conventional SMVQ and a supporting codebook which is newly introduced in this paper. Experimental results show that the proposed structed SMVQ is able to achieve satisfactory PSNR when the bit rate is extremely low.
C1 [Wang, Yang; Pan, Zhibin; Li, Rui] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of the National Laboratory of Pattern Recognition
   (NLPR) [201800030]; Open Research Fund of Key Laboratory of Spectral
   Imaging Technology, Chinese Academy of Sciences [LSIT201606D]
FX This work is supported in part by the Open Project Program of the
   National Laboratory of Pattern Recognition (NLPR) (Grant No. 201800030),
   and the Open Research Fund of Key Laboratory of Spectral Imaging
   Technology, Chinese Academy of Sciences (Grant No. LSIT201606D).
CR Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chen CC, 2010, SIGNAL PROCESS, V90, P2141, DOI 10.1016/j.sigpro.2010.01.018
   DUNHAM MO, 1985, IEEE T COMMUN, V33, P83, DOI 10.1109/TCOM.1985.1096198
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   Hu YC, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.7.073110
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ma XX, 2015, IET IMAGE PROCESS, V9, P290, DOI 10.1049/iet-ipr.2014.0125
   Manohar K, 2017, MULTIMED TOOLS APPL, V4, P1
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Wang LF, 2017, MULTIMED TOOLS APPL, V76, P26225, DOI 10.1007/s11042-016-4108-5
   Wang YH, 2019, TOXICOL LETT, V300, P1, DOI 10.1016/j.toxlet.2018.10.003
   Wei HC, 2000, IEEE T CIRC SYST VID, V10, P51, DOI 10.1109/76.825858
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 17
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16965
EP 16977
DI 10.1007/s11042-018-7042-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500055
DA 2024-07-18
ER

PT J
AU Zhu, AC
   Wang, T
   Qiao, T
AF Zhu, Aichun
   Wang, Tian
   Qiao, Tong
TI Multiple human upper bodies detection via candidate-region convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Upper body detection; Convolutional neural network; Candidate regions
ID POSE; HISTOGRAMS
AB Upper body detection on images is a challenging task in practical application scenarios and shares all the difficulties of object detection. This paper focuses on the problems of the multiple upper bodies, including the diversity of appearances, the various object scales, and the frequent occlusions. To address these problems, we divide the upper body detection into two stages to form a Candidate-Region Convolutional Neural Network(CR-CNN). In the upper body candidate generation stage, a deep hierarchical model is proposed. This model is built by a graphical model that contains the appearance model and deformable model. The appearance model is built based on the feature maps in a CNN, and the deformable model is defined by each pair of connected parts to compute the relative spatial information in the graphical model. In the upper body candidate refining stage, the detected bounding boxes serve as the candidate regions and refined in the CR-CNN. Moreover, multiple convolutional features are introduced into the CR-CNN to provide the local information and contextual information. The proposed method is compared with the state of the art on the TV Human Interaction (TVHI) dataset and HollywoodHeads dataset. The experimental results demonstrate the effectiveness of the proposed method.
C1 [Zhu, Aichun] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Wang, Tian] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Qiao, Tong] Hangzhou Dianzi Univ, Sch Cyberspace, Hangzhou, Zhejiang, Peoples R China.
C3 Nanjing Tech University; Beihang University; Hangzhou Dianzi University
RP Zhu, AC (corresponding author), Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.; Wang, T (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
EM aichun.zhu@njtech.edu.cn; wangtian@buaa.edu.cn; tong.qiao@hdu.edu.cn
RI Wang, Tianyi/A-1441-2016
FU National Natural Science Foundation of China [61503017,61702150];
   Aeronautical Science Foundation of China [2016ZC51022]
FX This work is partially supported by the National Natural Science
   Foundation of China (61503017,61702150), the Aeronautical Science
   Foundation of China (2016ZC51022).
CR Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], ARXIV170807077
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, P 2 INT C LEARN REPR
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2014, CORR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 15 IAPR INT C MACH V
   [Anonymous], 2015 12 IEEE INT C A
   [Anonymous], 2009, P INT C COMP VIS ICC
   [Anonymous], 2012, BMVC
   [Anonymous], YOLO9000 BETTER FAST
   [Anonymous], 2015, IEEE INT C COMPUT VI, DOI DOI 10.1109/ICCV.2015.169
   Bishop C, 2007, RECOGNITION PATTERN
   Chen BY, 2017, IEEE IPCCC
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding M, 2016, IEEE T IMAGE PROCESS, V25, P776, DOI 10.1109/TIP.2015.2507445
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Ding XF, 2009, IEEE INT SYMP CIRC S, P1791, DOI 10.1109/ISCAS.2009.5118124
   Fan X., 2015, P IEEE C COMP VIS PA
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glauner PO, 2015, COMPUT SCI
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jia L, 2017, ADV HIGH-SPEED RAIL, P1, DOI 10.1007/978-981-10-4597-4
   JIANG H., 2008, IEEE C COMPUTER VISI, P1, DOI DOI 10.2118/115315-MS
   Kumar MP, 2009, IEEE I CONF COMP VIS, P552, DOI 10.1109/ICCV.2009.5459192
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li M, 2009, IEEE IMAGE PROC, P2545, DOI 10.1109/ICIP.2009.5414008
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, INT J CONTROL, V91, P2250, DOI 10.1080/00207179.2017.1337933
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tian TP, 2010, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2010.5540227
   Tsochantaridis Ioannis., 2004, PROC 21 INT C MACHIN, P104
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83
   Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519
   Xu RY, 2015, MULTIMED TOOLS APPL, V74, P729, DOI 10.1007/s11042-014-2177-x
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yoo H.-J., 2015, IEIE Transactions on Smart Processing and Computing, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhu AC, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043021
NR 56
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16077
EP 16096
DI 10.1007/s11042-018-6964-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500016
DA 2024-07-18
ER

PT J
AU Han, C
   Gao, GY
   Zhang, Y
AF Han, Cen
   Gao, Guangyu
   Zhang, Yu
TI Real-time small traffic sign detection with revised faster-RCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic signs; Small object detection; RCNN; OHEM
ID RECOGNITION
AB Traffic sign detection is a crucial step for automatic driving and Intelligent Transportation. Promising results have been achieved in the area of traffic sign detection, but most of them are limited to ideal environment, where the traffic signs are very clear and large. Actually, traffic sign detection is always realized based on object detection methods. However, existing object detection methods failed to detect most of the traffic signs, especially in surveillance videos or driving recorder videos. In fact, traffic signs, i.e. traffic lights, or distant road signs in driving recorded video, always cover less than 5% of the whole image in the view of camera. Therefore, in this paper, we dedicate an effort to propose a real-time small traffic sign detection approach based on revised Faster-RCNN. More specifically, firstly, we use a small region proposal generator to extract the characteristics of small traffic signs. That is to say, considering that the stride of generator is too large, we remove the pool4 layer of VGG-16 and adopt dilation for ResNet. Secondly, we combine the revised architecture of Faster-RCNN with Online Hard Examples Mining (OHEM) to make the system more robust to locate the region of small traffic signs. Finally, we conduct extensive experiments and empirical evaluations on several different videos to demonstrate the satisfying performance of our approach. i.e., the experimental results show our approach improve the mean average precision by 12.1% over the original object detection algorithm.
C1 [Han, Cen; Gao, Guangyu; Zhang, Yu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Gao, GY (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM mysayalhan@gmail.com; guangyugao@bit.edu.cn; brian.zhcn@gmail.com
FU National Natural Science Foundation of China [61401023]
FX This work was supported by the National Natural Science Foundation of
   China under Grant NO. 61401023.
CR [Anonymous], MATHEMATICS
   [Anonymous], ARXIV141265372
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2013, INTEGRATED RECOGNITI
   [Anonymous], 2012, P 20 ACM INT C MULTI
   Baró X, 2009, IEEE T INTELL TRANSP, V10, P113, DOI 10.1109/TITS.2008.2011702
   Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   David McAllester, 2008, COMPUTER VISION PATT, P1
   delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Kaixuan Xie, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P201, DOI 10.1007/978-3-319-48890-5_20
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Lam H, 2016, WINT SIMUL C PROC, P791, DOI 10.1109/WSC.2016.7822142
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mel BW, 1997, NEURAL COMPUT, V9, P777, DOI 10.1162/neco.1997.9.4.777
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sang JT, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3001594
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Takeki A, 2016, IEEE IMAGE PROC, P3977, DOI 10.1109/ICIP.2016.7533106
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Yang B., 2014, BIOMETRICS IJCB 2014, P1
   Zhao WL, 2013, IEEE T IMAGE PROCESS, V22, P980, DOI 10.1109/TIP.2012.2226043
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
NR 36
TC 52
Z9 61
U1 4
U2 95
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13263
EP 13278
DI 10.1007/s11042-018-6428-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900029
DA 2024-07-18
ER

PT J
AU Jia, YH
   Bai, L
   Liu, S
   Wang, P
   Guo, JL
   Xie, YX
AF Jia, Yuhua
   Bai, Liang
   Liu, Shuang
   Wang, Peng
   Guo, Jinlin
   Xie, Yuxiang
TI Semantically-enhanced kernel canonical correlation analysis: a
   multi-label cross-modal retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Kernel CCA; Multi-label information; Concept
   correlations
ID FEATURES; IMAGES
AB Aiming at measuring the inter-media semantic similarities, cross-modal retrieval tries to align heterogenous features to an intermediate common subspace in which they can be reasonably compared. This is based on the same understanding of the semantics which are represented by different modalities. However, the semantics can usually be reflected by multiple concepts since concepts co-occur in real-world rather than occur in isolation. This leads to a more challenging task of multi-label cross-modal retrieval in which multiple concepts are annotated as labels for images as an example. More importantly, the co-occurrence patterns of concepts result in correlated pairs of labels whose relationships need to be considered in an accurate cross-modal retrieval. In this paper, we propose multi-label kernel canonical correlation analysis (ml-KCCA), a novel approach for cross-modal retrieval which enhances kernel CCA with high-level semantic information reflected in multi-label annotations. By kernelizing correlation extraction from multi-label information, more complex non-linear correlations between different modalities can be measured in order to learn a discriminative subspace which is more suitable for cross-modal retrieval tasks. Extensive evaluations on public datasets have validated the improvements of our approach over the state-of-the-art cross-modal retrieval approaches including other CCA extensions.
C1 [Jia, Yuhua; Bai, Liang; Liu, Shuang; Guo, Jinlin; Xie, Yuxiang] Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha 410073, Hunan, Peoples R China.
   [Wang, Peng] Tsinghua Univ, Dept Comp Sci & Technol, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 National University of Defense Technology - China; Tsinghua University
RP Wang, P (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM jiayuhua11@outlook.com; xabpz@163.com; liushuangkd@163.com;
   pwang@tsinghua.edu.cn; gjlin99@gmail.com; yxxie@nudt.edu.cn
RI Wang, Peng/F-2018-2017
FU Natural Science Foundation of China [61571453, 61502264, 61405252];
   Natural Science Foundation of Hunan Province, China [14JJ3010]; National
   University of Defense Technology [ZK16-03-37]
FX This work is supported by the Natural Science Foundation of China under
   Grant No. 61571453, No. 61502264, and No. 61405252, Natural Science
   Foundation of Hunan Province, China under Grant No. 14JJ3010, Research
   Funding of National University of Defense Technology under grant No.
   ZK16-03-37.
CR [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], PAC RIM C MULT PCM
   [Anonymous], P INT M PSYCH SOC IM
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], P 2010 INT C BEHAV
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], ACM
   [Anonymous], J MACH LEARN RES
   [Anonymous], P INT C ART INT STAT
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   Bekkerman R, 2007, IEEE C COMPUTER VISI, P1
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Hwang SJ, 2010, PROC CVPR IEEE, P2971, DOI 10.1109/CVPR.2010.5540043
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jiang YG, 2012, IEEE T IMAGE PROCESS, V21, P3080, DOI 10.1109/TIP.2012.2188038
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Kennedy L.S., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P333
   Lai P L, 2000, Int J Neural Syst, V10, P365, DOI 10.1016/S0129-0657(00)00034-X
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Peng Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P251, DOI 10.1007/978-3-319-27671-7_21
   Qi G.J., 2007, P 15 ACM INT C MULTI, P17, DOI DOI 10.1145/1291233.1291245
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sang JT, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3001594
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Vinokourov Alexei, 2002, Adv. Neural Inf. Process. Syst., P1497
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang H, 2017, IET COMPUT VIS, V11, P181, DOI 10.1049/iet-cvi.2016.0148
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang P, 2017, NEUROCOMPUTING, V236, P39, DOI 10.1016/j.neucom.2016.08.107
   Wang P, 2016, COMPUT VIS IMAGE UND, V148, P181, DOI 10.1016/j.cviu.2015.09.014
   Wu F., 2013, P ACM INT C MULT, P877
   Wu F, 2007, P IEEE INT C IM PROC, P1465
   Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300
   Yao T, 2015, IEEE I CONF COMP VIS, P28, DOI 10.1109/ICCV.2015.12
   Yohan Jin, 2005, 13th Annual ACM International Conference on Multimedia, P706
   Yoshida K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1543-x
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
NR 49
TC 7
Z9 9
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13169
EP 13188
DI 10.1007/s11042-018-5767-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900024
DA 2024-07-18
ER

PT J
AU Pham, NT
   Lee, JW
   Kwon, GR
   Park, CS
AF Nam Thanh Pham
   Lee, Jong-Weon
   Kwon, Goo-Rak
   Park, Chun-Su
TI Efficient image splicing detection algorithm based on markov features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing; Markov features; DCT domain; Support vector machine
AB Image splicing is one of the most common methods for digital image tampering. In this paper, an efficient Markov features based algorithm is proposed for image splicing detection. The proposed algorithm first extracts two types of Markov features, coefficient-wise Markov features and block-wise Markov features in the discrete cosine transform (DCT) domain. The former are obtained by exploiting correlations between consecutive coefficients and the latter are computed by exploiting coefficient correlations between adjacent blocks. Then, a feature vector is obtained by combining these two Markov features and it is fed into support vector machine (SVM) for the classification of authentic and spliced images. The experimental results show that the proposed method not only achieves much higher detection accuracy but also reduces the total running time significantly in comparison with state-of-the-art methods.
C1 [Nam Thanh Pham] Sejong Univ, Dept Digital Contents, Seoul, South Korea.
   [Lee, Jong-Weon] Sejong Univ, Dept Software, Seoul, South Korea.
   [Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, Donggu, Gwangju, South Korea.
   [Park, Chun-Su] Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
C3 Sejong University; Sejong University; Chosun University; Sungkyunkwan
   University (SKKU)
RP Park, CS (corresponding author), Sungkyunkwan Univ, Dept Comp Educ, Seoul, South Korea.
EM cspk@skku.edu
RI Thanh Pham, Nam/HGV-2913-2022
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2017-2016-0-00312];
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [NRF-2016R1C1B1009682]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2017-2016-0-00312) supervised by the IITP (Institute for
   Information & communications Technology Promotion). This work was
   supported by Basic Science Research Program through the National
   Research Foundation of Korea (NRF) funded by the Ministry of Education,
   Science and Technology (NRF-2016R1C1B1009682).
CR Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Chen C, 2017, PROC CVPR IEEE, P1876, DOI 10.1109/CVPR.2017.203
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dong J, 2009, LECT NOTES COMPUT SC, V5450, P76, DOI 10.1007/978-3-642-04438-0_7
   Dong Jing., 2011, CASIA TAMPERED IMAGE
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Han JG, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.2.023031
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hsu CW, 2007, TECHNICAL REPORT, V1, P1
   Hsu YF, 2007, IEEE INT C MULT EXP, DOI [10. 1109/ICME. 2007. 4284578, DOI 10.1109/ICME.2007.4284578]
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kumar A, 2019, ADV INTELL SYST, V670, P17, DOI 10.1007/978-981-10-8971-8_2
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liang RZ, 2016, PROC INT C TOOLS ART, P299, DOI [10.1109/ICTAI.2016.50, 10.1109/ICTAI.2016.0053]
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Moghaddasi Z, 2014, SCI WORLD J, DOI 10.1155/2014/606570
   Ng T.T., 2004, ADVENT Technical Report
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Park CS, 2018, MULTIMED TOOLS APPL, V77, P16795, DOI 10.1007/s11042-017-5248-y
   Park CS, 2016, MULTIMED TOOLS APPL, V75, P16577, DOI 10.1007/s11042-016-3575-z
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang, 2016, ESANN 2017 P, P589
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wang W, 2009, IEEE INT C IM PROC I, DOI [10.1109/ICIP.2009.5413549, DOI 10.1109/ICIP.2009.5413549]
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zhang J, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P390, DOI 10.1109/ICICISYS.2009.5357642
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
NR 37
TC 18
Z9 19
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12405
EP 12419
DI 10.1007/s11042-018-6792-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900059
DA 2024-07-18
ER

PT J
AU Soulami, KB
   Saidi, MN
   Honnit, B
   Anibou, C
   Tamtaoui, A
AF Soulami, Khaoula Belhaj
   Saidi, Mohamed Nabil
   Honnit, Bouchra
   Anibou, Chaimae
   Tamtaoui, Ahmed
TI Detection of breast abnormalities in digital mammograms using the
   electromagnetism-like algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammograms; Early detection; Segmentation; Metaheuristics
ID AUTOMATIC MASS DETECTION; COMPUTER-AIDED DETECTION; OPTIMIZATION
AB The detection of abnormalities in the breast at an early stage can be so helpful for breast cancer treatment. Currently, mammography is the cheapest and the most efficient technique in terms of identifying the suspicious lesions in the breast. However, the interpretation of this screening remains so hard and could lead to inaccurate detection known as false positive and false negative. Dense breast mammograms particularly are difficult to read because they may contain abnormal structures that are similar to the normal breast tissue. In this paper, we introduce an effective method for the detection of the ambiguous areas in digital mammograms. After noise and artifacts removal from the images using 2D Median filtering and labeling, we isolate the abnormalities using the meta-heuristic algorithm Electromagnetism-like Optimization (EML). The segmentation was carried on the abnormal cases of two different databases Mini-Mias and DDSM. The accuracy detection rate achieves almost 85% for both databases and 91.07% for DDSM alone.
C1 [Soulami, Khaoula Belhaj; Honnit, Bouchra; Tamtaoui, Ahmed] Natl Inst Posts & Telecommun INPT, CEDOC 2TI, STRS, Rabat, Morocco.
   [Saidi, Mohamed Nabil] Natl Inst Statist & Appl Econ INSEA, Informat Syst Lab, SI2M, Rabat, Morocco.
   [Anibou, Chaimae] Univ Mohamed V Agdal, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP Soulami, KB (corresponding author), Natl Inst Posts & Telecommun INPT, CEDOC 2TI, STRS, Rabat, Morocco.
EM k.belhajsoulami@gmail.com
CR Abed AM, 2016, HEAT MASS TRANSFER, V52, P2621, DOI 10.1007/s00231-016-1769-6
   Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 1994, DIGITAL MAMMO, DOI DOI 10.1007/S11999-016-4732-4
   [Anonymous], 3 IEEE INT C ADV TEC
   [Anonymous], 2016 IE 28 INT C
   [Anonymous], ACTION2ACTIVITY RECO
   [Anonymous], P 30 AAAI C ART INT
   [Anonymous], 2015, P INT C TRENDS AUT C
   [Anonymous], 6 WSEAS INT C SYST S
   [Anonymous], APPL MATH
   [Anonymous], PATT REC ICPR 2016 2
   Chatterjee Abhijit, 2016, 2016 IEEE 21st International Mixed-Signal Testing Workshop (IMSTW). Proceedings, P1, DOI 10.1109/IMS3TW.2016.7524222
   Cuevas E, 2013, COMPUT MATH METHOD M, P1
   Cuevas E, 2012, INT J INNOV COMPUT I, V8, P8181
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Farahnakian M, 2015, P I MECH ENG B-J ENG, V229, P1933, DOI 10.1177/0954405414542489
   Geng Y., 2016, ARXIV160908417
   Jhang JY, 2009, AEU-INT J ELECTRON C, V63, P491, DOI 10.1016/j.aeue.2008.04.001
   Jiang J, 2007, COMPUT MED IMAG GRAP, V31, P49, DOI 10.1016/j.compmedimag.2006.09.011
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Miyajima H, 2015, J ARTIF INTELL SOFT, V5, P271, DOI 10.1515/jaiscr-2015-0035
   Neto OPS, 2017, MULTIMED TOOLS APPL, V76, P19263, DOI 10.1007/s11042-017-4710-1
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Rocha AMAC, 2009, OPTIM METHOD SOFTW, V24, P253, DOI 10.1080/10556780802525356
   Shang PJ, 2010, 2010 11TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY & HIGH DENSITY PACKAGING (ICEPT-HDP), P165, DOI 10.1109/ICEPT.2010.5582454
   Shrivastava A, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P366, DOI 10.1109/ICIVC.2017.7984579
   Soulami K. B., 2016, ADV UBIQUITOUS NETWO, P505
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Tan M, 2016, IEEE EMBS CONF BIO, P24, DOI 10.1109/IECBES.2016.7843408
   Tan M, 2015, PHYS MED BIOL, V60, P4413, DOI 10.1088/0031-9155/60/11/4413
   Tivatansakul S, 2016, 2016 18 INT C E HLTH, P1
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang HT, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0606-4
   Zhang CJ, 2013, EXPERT SYST APPL, V40, P5621, DOI 10.1016/j.eswa.2013.04.028
NR 38
TC 11
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12835
EP 12863
DI 10.1007/s11042-018-5934-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900009
DA 2024-07-18
ER

PT J
AU Turchi, T
   Fogli, D
   Malizia, A
AF Turchi, Tommaso
   Fogli, Daniela
   Malizia, Alessio
TI Fostering computational thinking through collaborative game-based
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational thinking; Gameplay; Tangible user interface;
   Constructionist video games
ID END-USER DEVELOPMENT; PARTICIPATION; ROBOTICS
AB Algorithms are more and more pervading our everyday life: from automatic checkouts in supermarkets and e-banking to booking a flight online. Understanding an algorithmic solution to a problem is a very relevant activity to improve end-users' involvement. To this end, adopting a meta-design approach may help to support end-users to appropriate the design skills necessary for contributing to system design, in new and engaging modalities. By acquiring Computational Thinking (CT) skills (e.g., algorithmic thinking, abstraction), end-users will be able to understand and trust algorithms, while at the same time participate in the design and development of systems evolving in accordance with their needs. In this work, we focus on two different ways of improving CT skills: playfulness and collaboration. We introduce a game-based system, TAPASPlay, to foster CT skills and we report the results of an exploratory study with 18 users; our hypothesis is that learning CT through gameplay is effective and we tested it by involving participants in game sessions providing playful experience and collaborative learning.
C1 [Turchi, Tommaso] Brunel Univ London, Dept Comp Sci, Uxbridge, Middx, England.
   [Fogli, Daniela] Univ Brescia, Dept Informat Engn, Brescia, Italy.
   [Malizia, Alessio] Univ Hertfordshire, Sch Creat Arts, User Experience Design, Hatfield, Herts, England.
   [Malizia, Alessio] Molde Univ Coll, Fac Logist, Molde, Norway.
C3 Brunel University; University of Brescia; University of Hertfordshire;
   Molde University College
RP Turchi, T (corresponding author), Brunel Univ London, Dept Comp Sci, Uxbridge, Middx, England.
EM tommaso.turchi@brunel.ac.uk; daniela.fogli@unibs.it;
   a.malizia@herts.ac.uk
RI Turchi, Tommaso/HMD-8690-2023; Malizia, Alessio/F-5452-2013
OI Turchi, Tommaso/0000-0001-6826-9688; Malizia,
   Alessio/0000-0002-2601-7009
FU University of Brescia; Brunel University London [DR-291-2016]
FX The authors would like to thank Federico Danesi and David Bell for their
   contribution to the development of the system presented in this paper.
   We would also like to thank Stanislao Lauria and Lesley Warren for their
   help in coordinating the study. We thank the University of Brescia and
   Brunel University London for supporting us in this collaboration with
   grant "Bando Tesi all'estero 2016-2017" DR-291-2016.
CR [Anonymous], 2012, 43 ACM TECHN S COMP, DOI DOI 10.1145/2157136.2157200
   [Anonymous], AERA 2012
   [Anonymous], 2007, QUANTITATIVE SOCIAL
   Atmatzidou S, 2016, ROBOT AUTON SYST, V75, P661, DOI 10.1016/j.robot.2015.10.008
   Barr TF, 2005, J MARKET EDUC, V27, P81, DOI 10.1177/0273475304273459
   Beckwith L, 2006, COMPUTER, V39, P97, DOI 10.1109/MC.2006.382
   Bers MU, 2014, COMPUT EDUC, V72, P145, DOI 10.1016/j.compedu.2013.10.020
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Bundy Alan., 2007, Journal of Scientific and Practical Computing
   Burnett M, 2009, LECT NOTES COMPUT SC, V5435, P15
   Cabitza F, 2017, MULTIMED TOOLS APPL, V76, P5221, DOI 10.1007/s11042-016-3511-2
   Cabitza F, 2014, J VISUAL LANG COMPUT, V25, P684, DOI 10.1016/j.jvlc.2014.10.014
   Cassell Justine., 1998, BARBIE MORTAL KOMBAT
   Cetin I, 2016, J EDUC COMPUT RES, V54, P997, DOI 10.1177/0735633116642774
   Coutaz J, 2016, IEEE PERVAS COMPUT, V15, P26, DOI 10.1109/MPRV.2016.24
   Danado Jose, 2012, Human-Centered Software Engineering. Proceedings of the 4th International Conference, HCSE 2012, P199, DOI 10.1007/978-3-642-34347-6_12
   Dorner C, 2007, 2007 IMPROVING INFOR
   Fischer CT, 2017, ON THE WAY TO COLLABORATIVE PSYCHOLOGICAL ASSESSMENT: THE SELECTED WORKS OF CONSTANCE T. FISCHER, P61
   Fischer G, 2017, Interactions, V25, P26, DOI DOI 10.1145/3170706
   Fischer G, 2006, HUM COM INT, V9, P427
   Fogli D, 2017, GHITALY CHITALY
   Fowler A., 2012, The Computer Games Journal, V1, P17
   Fowler Allan, 2011, P 6 INT C FDN DIG GA, P238, DOI DOI 10.1145/2159365.2159398
   Francese R, 2016, IEEE T MOBILE COMPUT, V15, P1033, DOI 10.1109/TMC.2015.2422295
   Grover S, 2015, COMPUT SCI EDUC, V25, P199, DOI 10.1080/08993408.2015.1033142
   Grund C.K., 2015, INFORMATIK, VP-246, P1279
   Herbert C. W., 2010, INTRO PROGRAMMING US
   Horn M.S., 2007, Proc. CHI2007 Ext. Abstr. San Jose, CA, P1965, DOI DOI 10.1145/1240866.1240933
   Houben S., 2017, Interactions, V24, P58, DOI 10.1145/3121348
   Huff C., 2002, SIGCSE Bulletin, V34, P112, DOI 10.1145/543812.543842
   Kafai Y., 1996, Constructionism in practice: Designing, thinking, and learning in a digital world
   Kafai YB, 2016, COMMUN ACM, V59, P26, DOI 10.1145/2955114
   Kazimoglu C, 2012, PROCEDIA COMPUT SCI, V9, P522, DOI 10.1016/j.procs.2012.04.056
   Kyu Han Koh, 2010, Proceedings 2010 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2010), P59, DOI 10.1109/VLHCC.2010.17
   Lee TY., 2014, International Journal of Child-Computer Interaction, V2, P26, DOI [10.1016/j.ijcci.2014.06.003, DOI 10.1016/J.IJCCI.2014.06.003]
   Lieberman Henry., 2006, HUMAN COMPUTER INTER
   Liu CC, 2011, COMPUT EDUC, V57, P1907, DOI 10.1016/j.compedu.2011.04.002
   Liu D, 2013, MIS QUART, V37, P111
   Lu James J., 2009, SIGCSE Bulletin, V41, P260, DOI 10.1145/1539024.1508959
   Lye SY, 2014, COMPUT HUM BEHAV, V41, P51, DOI 10.1016/j.chb.2014.09.012
   Malizia A, 2015, LECT NOTES COMPUTER
   Monteiro IT, 2017, J VISUAL LANG COMPUT, V40, P91, DOI 10.1016/j.jvlc.2017.01.005
   Moreno J, 2012, EDUC TECHNOL SOC, V15, P288
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Papert S., 1980, MINDSTORMS CHILDREN
   Price S, 2003, INTERACT COMPUT, V15, P169, DOI 10.1016/S0953-5438(03)00006-7
   Repenning A, 2016, S VIS LANG HUM CEN C, P218, DOI 10.1109/VLHCC.2016.7739688
   Repenning A, 2010, SIGCSE 10: PROCEEDINGS OF THE 41ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P265
   Repenning Alexander., 2000, AGENTSHEETS INTERACT
   Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020
   Scaffidi Christopher, 2017, End-User Development. 6th International Symposium, IS-EUD 2017. Proceedings: LNCS 10303, P183, DOI 10.1007/978-3-319-58735-6_13
   Shneiderman B., 2016, Interactions, V23, P24, DOI [DOI 10.1145/2977645, 10.1145/2977645]
   Shute VJ, 2017, EDUC RES REV-NETH, V22, P142, DOI 10.1016/j.edurev.2017.09.003
   Touretzky D S., 2013, Proceeding of the 44th ACM technical symposium on Computer science education, P609
   Turchi T, 2017, J VISUAL LANG COMPUT, V39, P66, DOI 10.1016/j.jvlc.2016.11.002
   Turchi T, 2016, S VIS LANG HUM CEN C, P232, DOI 10.1109/VLHCC.2016.7739692
   Tzafilkou K, 2017, EDUC INF TECHNOL, V22, P1853, DOI 10.1007/s10639-016-9519-4
   Voogt J, 2015, EDUC INF TECHNOL, V20, P715, DOI 10.1007/s10639-015-9412-6
   Wang DL, 2011, PROCEEDINGS OF IDC 2011: THE 10TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2011), P127
   Wang D, 2014, INT J PHOTOENERGY, V2014, DOI 10.1155/2014/846581
   Weintrop D, 2016, INT J GAME-BASED LEA, V6, P1, DOI 10.4018/IJGBL.2016010101
   Wing J. M., 2010, Computational thinking: What and why?
   Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215
   Wohlin C., 2000, EXPT SOFTWARE ENG IN
   Yadav A., 2014, ACM T COMPUT EDUC, V14, P5
   Yadav A, 2017, EDUC COMMUN TECHNOL, P205, DOI 10.1007/978-3-319-52691-1_13
NR 68
TC 33
Z9 38
U1 3
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13649
EP 13673
DI 10.1007/s11042-019-7229-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900046
OA hybrid
DA 2024-07-18
ER

PT J
AU Zheng, L
   Hu, RJ
AF Zheng, Lei
   Hu, Renjie
TI Robust and fast visual tracking for a ball and plate control system:
   design, implementation and experimental verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ball and plate system; Moving object detection; Path planning; Tracking
   Control
AB The ball and plate System (BPS) is a two-dimensional electromechanical system with multiple variables, non-linearity and strong coupling. The BPS control problem is to hold the rolling ball in a specific position on the plate by adjusting the plate inclination. Ball tracking is therefore the fundamental step in BPS control, which can largely influence the control effectiveness and efficiency. The segmented path planning based on the sequential thinning algorithm is one popular tracking technology. However, it suffers from high dependence on the operating environment, complex operation and slow speed. This paper innovatively proposes a robust and fast visual tracking solution for BPS. A novel hardware structure has been designed. The sensing camera is rigidly connected to the plate, which avoids the coordinate transformation and thus reduces the complexity. In path recognition, a parallel thinning algorithm is used to improve the processing speed. Additionally, in path planning, a window searching algorithm combining the slope order matching method is proposed to establish the linked list that describes the movement path. A cascaded structure of the BPS tracking controller is also designed. Experiments have shown the effectiveness of the whole system, exhibiting shorter travelling time, smaller tracking errors as well as better stability compared to conventional systems.
C1 [Zheng, Lei] Southeast Univ, Elect & Elect Expt Ctr, Nanjing 211189, Jiangsu, Peoples R China.
   [Hu, Renjie] Southeast Univ, Sch Elect Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Zheng, L (corresponding author), Southeast Univ, Elect & Elect Expt Ctr, Nanjing 211189, Jiangsu, Peoples R China.
EM 103007101@seu.edu.cn; hurenjie@seu.edu.cn
OI zheng, lei/0000-0002-2950-8305
CR [Anonymous], 2001, P 2 EUR WORKSH ADV V
   Bardyn J. J., 1984, C REC FORM INT ART P, V1, P557
   Bataineh B, 2011, PATTERN RECOGN LETT, V32, P1805, DOI 10.1016/j.patrec.2011.08.001
   CHUNG KL, 1995, COMPUT VIS IMAGE UND, V61, P278, DOI 10.1006/cviu.1995.1020
   Colmenares SG, 2012, C WORLD AUT C WAC
   Dong Y.X., 2014, Adv. Mat. Res, V989, P1959, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AMR.989-994.1959
   Duda RO, 1975, COMMUNICATIONS ASS C, V18, P120, DOI [10.1145/360666.360677, DOI 10.1145/360666.360677]
   Durus M, 2007, SIGNAL PROCESSING CO
   Fan JC, 2012, IEEE C EVOL COMPUTAT
   Fan XZ, 2004, FUZZY SET SYST, V144, P297, DOI 10.1016/S0165-0114(03)00135-0
   Giacobazzi R, 2008, SEFM 2008: SIXTH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND FORMAL METHODS, PROCEEDINGS, P7, DOI 10.1109/SEFM.2008.41
   Han Kyong-Won, 2014, Journal of Jilin University (Engineering and Technology Edition), V44, P718, DOI 10.13250/j.cnki.jdxbgxb201403023
   Jain A, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P760, DOI 10.1109/ICACEA.2015.7164804
   Kimme C, 1972, COMMUNICATIONS ASS C, V15, P11, DOI [10.1145/361237.361242, DOI 10.1145/361237.361242]
   Laizhen Li, 2014, Applied Mechanics and Materials, V530-531, P372, DOI 10.4028/www.scientific.net/AMM.530-531.372
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042
   Li YF, 2012, CHIN CONTR CONF, P7674
   Liu Yuangang, 2015, Geomatics and Information Science of Wuhan University, V40, P264, DOI 10.13203/j.whugis20130526
   MA JY, 2017, PROC SPIE 1, V420
   Ma Y., 2007, COMPUTER APPL, V27, P2544
   Sang J, 2012, ACM MULTIMEDIA, P18
   Sang JT, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/3001594
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Stocker AA, 2002, CIRC SYST ISCSA 2002, V2, P26
   [苏信 SU Xin], 2006, [计算机仿真, Computer Simulation], V23, P165
   Tan Guan-zheng, 2005, Journal of Central South University (Science and Technology), V36, P102
   Tu Y, 2017, J CLIN ONCOL, V35, DOI 10.1200/JCO.2017.35.15_suppl.e15597
   Wang Guoqiang, 2014, J ENG HEILONGJIANG U, V5, P64
   Wang L, 2017, J GASTRIC CANCER, V17, P295, DOI 10.5230/jgc.2017.17.e33
   Wang YK, 2014, ISA T, V53, P671, DOI 10.1016/j.isatra.2013.11.011
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhao Y-H, 2011, IND CONTROL APPL, V30, P12
   Zhu S, 2011, P 2011 CROSS STRAIT
   Zou JC, 2017, APPL MATH SER B, V32, P313, DOI 10.1007/s11766-017-3458-8
NR 35
TC 1
Z9 2
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13279
EP 13295
DI 10.1007/s11042-018-6430-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900030
DA 2024-07-18
ER

PT J
AU Jansi, R
   Amutha, R
AF Jansi, R.
   Amutha, R.
TI Sparse representation based classification scheme for human activity
   recognition using smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Classification; Sensors; Smartphone; Sparse
ID ACCELEROMETER; MULTISENSOR; CONTEXT; FACE
AB The availability of built-in sensors in mobile devices have paved a way for researchers to accurately determine human activities through these sensors. In this paper, we present a novel action recognition system based on sparse representation wherein, eight different human activities were classified. Our proposed classifier employs data of accelerometer, gyroscope, magnetometer and orientation sensor equipped in smartphones for recognizing human activities. Time-domain and frequency-domain features are derived from the acquired sensor data. We have introduced a novel algorithm for fusing the data from the four sensors using a sparse representation based technique that aid in achieving the best classification performance. In the proposed algorithm, if the majority of the sensors indicate a particular class as the output, then that specific class is assigned as the actual test class. However, if there is a disagreement between the classified output of different sensors, then a novel weighted fusion scheme is introduced to fuse the scores and the residue produced by different sensors. The weight used in fusion is chosen to be the standard deviation of the score vector. Thus, the features of excellent sensors are made to bestow more on to the result of action recognition. Finally, the action label is recognized based on an activity metric that maximizes the score while minimizing the residue. The performance analysis of the proposed system is performed using leave-one-subject-out approach. Performance evaluation metrics like recall, precision, specificity, F-score and accuracy are utilized in projecting the performance of the proposed system. It was shown that the proposed system attained a high overall accuracy of about 97.13%.
C1 [Jansi, R.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Jansi, R (corresponding author), SSN Coll Engn, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM jansir@ssn.edu.in
RI R, Jansi/ITT-3245-2023; Amutha, R./AAB-9399-2020
OI R, Jansi/0000-0001-9894-0006; 
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Akhavian R, 2016, AUTOMAT CONSTR, V71, P198, DOI 10.1016/j.autcon.2016.08.015
   Alam Mohammad A., 2013, Inclusive Society: Health and Wellbeing in the Community, and Care at Home. 11th International Conference on Smart Homes and Health Telematics, ICOST 2013. Proceedings. LNCS 7910, P134
   Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   Atallah L, 2011, IEEE T BIOMED CIRC S, V5, P320, DOI 10.1109/TBCAS.2011.2160540
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Baraniuk RG, 2010, P IEEE, V98, P906, DOI 10.1109/JPROC.2010.2047424
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Catal C, 2015, APPL SOFT COMPUT, V37, P1018, DOI 10.1016/j.asoc.2015.01.025
   Chen ZW, 2017, MULTIMED TOOLS APPL, V76, P17669, DOI 10.1007/s11042-015-2882-0
   Cheng H, 2014, MULTIMED TOOLS APPL, V70, P177, DOI 10.1007/s11042-012-1162-5
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   Figueiredo Isabel N., 2016, mUX: The Journal of Mobile User Experience, V5, DOI 10.1186/s13678-016-0004-1
   Fuentes D, 2012, EXPERT SYST APPL, V39, P2461, DOI 10.1016/j.eswa.2011.08.098
   Gao L, 2014, MED ENG PHYS, V36, P779, DOI 10.1016/j.medengphy.2014.02.012
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Huynh QT, 2015, J SENSORS, V2015, DOI 10.1155/2015/452078
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Jain A, 2015, PATTERN RECOGN LETT, V68, P351, DOI 10.1016/j.patrec.2015.07.004
   Jansi R, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P493, DOI 10.1109/WiSPNET.2017.8299805
   Jansi R, 2018, MULTIMED TOOLS APPL, V2018, P1
   Ordóñez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo XM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081738
   Miao F, 2015, SENSORS-BASEL, V15, P11465, DOI 10.3390/s150511465
   Mitchell E, 2013, SENSORS-BASEL, V13, P5317, DOI 10.3390/s130405317
   Moonon AU, 2015, SENS IMAGING, V16, DOI 10.1007/s11220-015-0125-0
   Preece SJ, 2009, IEEE T BIO-MED ENG, V56, P871, DOI 10.1109/TBME.2008.2006190
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Roy D, 2016, PATTERN RECOGN, V59, P55, DOI 10.1016/j.patcog.2016.03.011
   Seo JJ, 2017, IMAGE VISION COMPUT, V58, P76, DOI 10.1016/j.imavis.2016.06.002
   Seon-Woo Lee, 2002, IEEE Pervasive Computing, V1, P24, DOI 10.1109/MPRV.2002.1037719
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   Varkey JP, 2012, PERS UBIQUIT COMPUT, V16, P897, DOI 10.1007/s00779-011-0455-4
   Villalonga C, 2017, NEUROCOMPUTING, V250, P76, DOI 10.1016/j.neucom.2016.09.125
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wang SQ, 2015, DIGIT COMMUN NETW, V1, P20, DOI 10.1016/j.dcan.2015.02.006
   Xiao L, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/1550147716679668
   Xing XF, 2017, MULTIMED TOOLS APPL, V76, P2039, DOI 10.1007/s11042-015-3164-6
   Xu Y, 2015, NEUROCOMPUTING, V168, P566, DOI 10.1016/j.neucom.2015.05.070
   Xu Y, 2011, NEUROCOMPUTING, V74, P3946, DOI 10.1016/j.neucom.2011.08.011
   Yang AY, 2009, J AMB INTEL SMART EN, V1, P103, DOI 10.3233/AIS-2009-0016
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Yin L, 2014, MULTIMED TOOLS APPL, V72, P843, DOI 10.1007/s11042-013-1368-1
   Yun XP, 2012, IEEE T INSTRUM MEAS, V61, P2059, DOI 10.1109/TIM.2011.2179830
   Zhang M, 2013, IEEE J BIOMED HEALTH, V17, P553, DOI 10.1109/JBHI.2013.2253613
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao XM, 2014, NEURAL COMPUT APPL, V24, P1539, DOI 10.1007/s00521-013-1377-z
   Zualkernan I, 2017, COMPUT ELECTR ENG, V60, P1, DOI 10.1016/j.compeleceng.2017.05.004
NR 52
TC 14
Z9 15
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 11027
EP 11045
DI 10.1007/s11042-018-6662-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400066
DA 2024-07-18
ER

PT J
AU Lei, Y
   Zhou, XQ
   Xie, L
AF Lei, Yong
   Zhou, Xiaoqing
   Xie, Long
TI Emergency monitoring and disposal decision support system for sudden
   pollution accidents based on multimedia information system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sudden; Environmental accident; Emergency management; Monitoring system;
   Multimedia technology; Geographic information system; Early warning
   system
AB As the economy and society enter the period of rapid post-industrialization, the pressures on resources and the environment are becoming more obvious. Therefore, the environmental protection work faces more challenges. There are many important elements in the environmental emergency detection system, such as emergency monitoring data, information, and command transmission. In order to deal with all kinds of sudden environmental pollution accidents in a timely manner and to reduce the damage to the environment caused by accidents, we need to ensure the safety of the environment. Therefore, we must use scientific methods to manage sudden environmental pollution accidents. In this paper, we combine Internet technology, GIS technology and multimedia database technology, and establishes a decision support system for emergency monitoring and disposal based on multimedia information systems. Its basic hardware includes environmental risk source monitoring, emergency monitoring, command and dispatch, environmental emergency network and environmental emergency monitoring center construction. The software system includes basic software environment, environmental emergency monitoring and command information sharing platform, application software and unified portal. The entire system is integrated according to an organized organizational system, providing detection systems and early warning systems for sudden environmental pollution incident prevention and emergency response. The system we designed can collect and process relevant information in a very short time. The system can quickly handle emergency decision-making and minimize the adverse effects caused by sudden environmental pollution accidents. Experiment results show the well performance of the proposed system. The multimedia based user interface guarantees the user experience.
C1 [Lei, Yong; Zhou, Xiaoqing; Xie, Long] Pearl River Hydraul Res Inst, Room 2305,Tianshou Bldg,Tianshou Rd, Guangzhou 510000, Guangdong, Peoples R China.
RP Lei, Y (corresponding author), Pearl River Hydraul Res Inst, Room 2305,Tianshou Bldg,Tianshou Rd, Guangzhou 510000, Guangdong, Peoples R China.
EM leiyongPearl@hotmail.com
FU Special fund for science and technology development in 2016 of
   Department of science and technology of Guangdong Province
   [2016A020223007]
FX Special fund for science and technology development in 2016 of
   Department of science and technology of Guangdong Province under Grant
   No. 2016A020223007.
CR Gai KK, 2020, IEEE T CLOUD COMPUT, V8, P1212, DOI 10.1109/TCC.2016.2594172
   He BX, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P129, DOI 10.1109/ISAI.2016.0036
   Jeong HY, 2014, MULTIMED TOOLS APPL, V73, P887, DOI 10.1007/s11042-013-1445-5
   Khobragade MVB, 2015, IMAGE, V4, P155
   Lin E. C.-H., 2016, INT C FRONT COMP, P725, DOI [10.1007/978-981-10-3187-8_68, DOI 10.1007/978-981-10-3187-8_68]
   Lv ZH, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0475-8
   Maigrot C., 2016, MEDIAEVAL 2016 VERFI
   Panjanathan Rukmani, 2017, International Journal of High Performance Computing and Networking, V10, P23
   Pereira MHR, 2015, MULTIMED TOOLS APPL, V74, P10923, DOI 10.1007/s11042-014-2311-9
   Zhang F., 2016, REV IBERICA SISTEMAS, V22-27, P252
   Zhang Y, 2016, HUM ECOL RISK ASSESS, V22, P1552, DOI 10.1080/10807039.2016.1197769
   Zhu WW, 2015, IEEE MULTIMEDIA, V22, P96, DOI 10.1109/MMUL.2015.66
NR 12
TC 3
Z9 5
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 11047
EP 11071
DI 10.1007/s11042-018-6665-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400067
DA 2024-07-18
ER

PT J
AU Peng, YJ
   Wang, N
   Wang, YH
   Wang, ML
AF Peng, Yanjun
   Wang, Ning
   Wang, Yuanhong
   Wang, Meiling
TI Segmentation of dermoscopy image using adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin lesion; Image segmentation; Convolutional neural networks;
   Adversarial network
AB Skin lesion image segmentation task has many difficulties due to the hair occlusion or low contrast. Traditional methods based image quality are powerless when processing these kinds of skin images. In this paper, a segmentation architecture based adversarial networks is proposed. The architecture is consist of a segmentation network based U-net and a discrimination network linked by certain convolutional layers. Both two networks are trained alternately and at last segmentation network gets a high segmentation accuracy. We test our architecture on dataset PH2 and dataset obtained from Skin Lesion Analysis Toward Melanoma Detection challenge which was hosted by ISBI 2016 conference and we achieved segmentation average accuracy of 0.97, dice coefficient of 0.94 which outperform other existed segmentation network, including winner of ISBI 2016 challenge for skin melanoma segmentation.
C1 [Peng, Yanjun; Wang, Ning; Wang, Yuanhong; Wang, Meiling] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Shandong, Peoples R China.
   [Peng, Yanjun] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Shandong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao 266590, Shandong, Peoples R China.; Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Min Informat Technol, Qingdao 266590, Shandong, Peoples R China.
EM pengyanjuncn@163.com
FU National key research and development project of China [2016YFC0801406];
   Natural Science Foundation of Shandong Province [ZR2015FM013]; National
   Natural Science Foundation of China [61502279]; National key research
   and development project of the Shandong Province [2016GSF120012];
   Special Project Fund of Taishan Scholars of Shandong Province, Leading
   Talent Project of Shandong University of Science and Technology
FX This work is supported by the National key research and development
   project of China under Grant No.2016YFC0801406, the Natural Science
   Foundation of Shandong Province under Grant No. ZR2015FM013, the
   National Natural Science Foundation of China under Grant No. 61502279,
   the National key research and development project of the Shandong
   Province under Grant No. 2016GSF120012, and by Special Project Fund of
   Taishan Scholars of Shandong Province, Leading Talent Project of
   Shandong University of Science and Technology.
CR Abbas Q, 2011, BIOMED SIGNAL PROCES, V6, P395, DOI 10.1016/j.bspc.2011.01.003
   [Anonymous], 2015, COMPUT SCI
   [Anonymous], 2016, ARXIV161104076
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], GENET EVOL COMPUT WG
   [Anonymous], P 30 C NEURAL INFORM
   [Anonymous], INT C PATT REC
   [Anonymous], 2015, PROC CVPR IEEE
   Badri V, 2019, IEEE-CAA J AUTOMATIC, V6, P1179, DOI 10.1109/JAS.2017.7510667
   Celebi ME, 2008, SKIN RES TECHNOL, V14, P347, DOI 10.1111/j.1600-0846.2008.00301.x
   Celebi ME, 2007, COMPUT MED IMAG GRAP, V31, P362, DOI 10.1016/j.compmedimag.2007.01.003
   Chen L. C., 2015, Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs, P357, DOI [10.1080/17476938708814211, DOI 10.1080/17476938708814211]
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Mendonça T, 2013, IEEE ENG MED BIO, P5437
   MERMELSTEIN RJ, 1992, HEALTH PSYCHOL, V11, P371, DOI 10.1037/0278-6133.11.6.371
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schaefer G, 2011, COMPUT MED IMAG GRAP, V35, P99, DOI 10.1016/j.compmedimag.2010.08.004
   Sonderby C. K., 2016, ARXIV161004490
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Yuan Y, 2018, IEEE T SYST MAN CY-S, V48, P1885, DOI 10.1109/TSMC.2017.2704278
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou HY, 2010, IEEE ENG MED BIO, P1974, DOI 10.1109/IEMBS.2010.5627556
NR 27
TC 23
Z9 23
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10965
EP 10981
DI 10.1007/s11042-018-6523-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400063
DA 2024-07-18
ER

PT J
AU Li, H
   Li, WB
   Liu, SY
AF Li, Hong
   Li, Weibin
   Liu, Shuying
TI Pansharpening with support vector transform and semi-nonnegative matrix
   factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pansharpening; Panchromatic and multispectral images; Nonnegative matrix
   factorization (NMF); Support vector transform (SVT)
ID PAN-SHARPENING METHOD; MULTISPECTRAL IMAGES; FUSION; RESOLUTION; PARTS
AB This paper attempts to reduce the spectral distortion and enhance the spatial information of fused images. For this purpose, the author presented a novel pansharpening method based on support vector transform (SVT) and semi-nonnegative matrix factorization (semi-NMF). The proposed method involves three steps. In step one, SVT was performed on panchromatic and multispectral images. In step two, the low-frequency components were processed by semi-NMF-based fusion rule, while the high-frequency components were treated by the regional energy-weighted fusion rule. In step three, the fused images were reconstructed by the fused high-frequency and low-frequency components. After that, the proposed method was compared with other related methods through experiments on several datasets collected from QuickBird and GeoEye-1. The comparison shows that the proposed method outperforms the compared approaches. The research findings shed new light on the preservation of spatial and spectral information in image fusion.
C1 [Li, Hong; Li, Weibin; Liu, Shuying] XianYang Normal Univ, Sch Comp Sci, Xianyang, Shaanxi, Peoples R China.
C3 Xianyang Normal University
RP Li, H (corresponding author), XianYang Normal Univ, Sch Comp Sci, Xianyang, Shaanxi, Peoples R China.
EM honglishining@163.com
RI Li, Weibin/ABB-5097-2020
OI Li, Weibin/0000-0001-8970-0318
FU National Natural Science Foundation of China [81473559]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2017JM6086]; Science
   Basic Research Program in Shaanxi Province of China [16JK1823];
   Innovation Program in Shaanxi Province of China [2018KRM145]; Science
   Basic Research Program in Xianyang Normal University of China
   [XSYK18012]
FX The authors would like to thank the anonymous reviewers and the editor
   for suggesting various changes. And this work was supported by the
   National Natural Science Foundation of China (No. 81473559), the Natural
   Science Basic Research Plan in Shaanxi Province of China (No.
   2017JM6086), the Science Basic Research Program in Shaanxi Province of
   China (No. 16JK1823), the Innovation Program in Shaanxi Province of
   China (No. 2018KRM145), the Science Basic Research Program in Xianyang
   Normal University of China (No. XSYK18012).
CR Akul R, 2012, PROCEDIA ENGINEER, V30, P535, DOI 10.1016/j.proeng.2012.01.895
   Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   Alparone L, 2004, IEEE GEOSCI REMOTE S, V1, P313, DOI 10.1109/LGRS.2004.836784
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Garzelli A, 2006, INT J REMOTE SENS, V27, P3273, DOI 10.1080/01431160600554991
   Ghahremani M, 2016, IEEE T GEOSCI REMOTE, V54, P2194, DOI 10.1109/TGRS.2015.2497309
   Guo R, 2010, ELECTRON LETT, V46, P1399, DOI 10.1049/el.2010.1476
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Jiang C, 2014, IEEE J-STARS, V7, P1792, DOI 10.1109/JSTARS.2013.2283236
   Johnson BA, 2013, INT J REMOTE SENS, V34, P6969, DOI 10.1080/01431161.2013.810825
   Karathanassi V, 2007, INT J REMOTE SENS, V28, P2309, DOI 10.1080/01431160600606890
   Laben C. A., 2000, US Patent, Patent No. 6,011,875
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li H, 2016, IEEE J-STARS, V9, P5715, DOI 10.1109/JSTARS.2016.2584142
   Li Hong, 2016, Journal of Xidian University, V43, P193, DOI 10.3969/j.issn.1001-2400.2016.02.033
   Li ST, 2013, IEEE T GEOSCI REMOTE, V51, P4779, DOI 10.1109/TGRS.2012.2230332
   Li ST, 2011, IEEE T GEOSCI REMOTE, V49, P738, DOI 10.1109/TGRS.2010.2067219
   Li SZ, 2001, PROC CVPR IEEE, P207
   Liu Y, 2016, NEUROCOMPUTING, V173, P224, DOI 10.1016/j.neucom.2014.11.099
   Miao Qiguang, 2005, Journal of Computer Aided Design & Computer Graphics, V17, P2029
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Psjr CS.C. Sides, 1991, PHOTOGRAMMETRIC ENG, V57, P265
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Rong KX, 2014, IEEE J-STARS, V7, P4793, DOI 10.1109/JSTARS.2014.2347072
   Samat A, 2016, IEEE T GEOSCI REMOTE, V54, P6803, DOI 10.1109/TGRS.2016.2591066
   Shah VP, 2007, INT GEOSCI REMOTE SE, P310, DOI 10.1109/IGARSS.2007.4422792
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wang N, 2013, IEEE J-STARS, V6, P554, DOI 10.1109/JSTARS.2013.2242255
   Wang WQ, 2015, NEUROCOMPUTING, V155, P320, DOI 10.1016/j.neucom.2014.11.054
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang ZN, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P672
   Xu R, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.1757
   Yang SY, 2018, IEEE T NEUR NET LEAR, V29, P3647, DOI 10.1109/TNNLS.2017.2736011
   Yang SY, 2012, APPL SOFT COMPUT, V12, P228, DOI 10.1016/j.asoc.2011.08.050
   Yang SY, 2012, INFORM FUSION, V13, P177, DOI 10.1016/j.inffus.2010.09.003
   [YANG XiaoHui 杨晓慧], 2008, [自动化学报, Acta Automatica Sinica], V34, P274
   Yi YG, 2015, NEUROCOMPUTING, V149, P1021, DOI 10.1016/j.neucom.2014.07.031
   Yin HT, 2015, IEEE T GEOSCI REMOTE, V53, P5734, DOI 10.1109/TGRS.2015.2429691
   Yuhas R, 1992, P SUMM 4 JPL AIRB EA
   Zhang K, 2016, IEEE J-STARS, V9, P5740, DOI 10.1109/JSTARS.2015.2475754
   Zhang LF, 2011, IEEE GEOSCI REMOTE S, V8, P374, DOI 10.1109/LGRS.2010.2077272
   Zhang YX, 2014, SIGNAL PROCESS, V105, P84, DOI 10.1016/j.sigpro.2014.05.015
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 49
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7563
EP 7578
DI 10.1007/s11042-018-6499-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700051
DA 2024-07-18
ER

PT J
AU Mallik, B
   Sheikh-Akbari, A
   Kor, AL
AF Mallik, Bruhanth
   Sheikh-Akbari, Akbar
   Kor, Ah-Lian
TI Mixed-resolution HEVC based multiview video codec for low bitrate
   transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture 3D videos; Multiview video coding; Mixed-resolution video codec;
   HEVC; MV-HEVC; Low bitrate transmission
AB There has been increasing demand for multiview video transmission over band limited channel over past years and various techniques have been proposed to fulfil this need. In this paper, a High Efficiency Video Codec (HEVC) based spatial resolution scaling type of mixed resolution coding model, MRHEVC-MVC, for frame interleaved multiview videos is presented. However, enabling the HEVC to encode video with different frame resolutions is a challenge due to the coding tree partitioning used by the codec. This has been overcome by super-imposing the low resolution replica of each full resolution frame on their respective decoded picture buffer and setting the remaining space of the frame buffer to zero. The codec's reference frames structure is designed to efficiently encode frame interleaved multiview videos using a HEVC based mixed resolution codec. The proposed MRHEVC-MVC codec has been tested against the standard multiview extension of high efficiency video codec (MV-HEVC) for Balloon, Newspaper1, Undo_Dancer, Kendo and Poznan_Street standard multiview video sequences. Results show that the proposed codec gives significantly higher coding performance to that of the MV-HEVC codec at low bitrate both subjectively and objectively.
C1 [Mallik, Bruhanth; Sheikh-Akbari, Akbar; Kor, Ah-Lian] Leeds Beckett Univ, Sch Comp Creat Technol & Engn, Headingley Campus, Leeds LS6 3QS, W Yorkshire, England.
C3 Leeds Beckett University
RP Mallik, B (corresponding author), Leeds Beckett Univ, Sch Comp Creat Technol & Engn, Headingley Campus, Leeds LS6 3QS, W Yorkshire, England.
EM b.mallik6347@student.leedsbeckett.ac.uk
RI Sheikh-Akbari, Akbar/AAA-7302-2022
OI Sheikh-Akbari, Akbar/0000-0003-0677-7083; Kor,
   Ah-Lian/0000-0001-9514-3773
CR Aflaki P, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P267, DOI 10.1109/ISM.2014.11
   Akbari AS, 2015, COMM COM INF SC, V534, P182, DOI 10.1007/978-3-319-23276-8_16
   Akbari AS, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P109, DOI 10.1109/PCS.2012.6213298
   Aksay A., 2006, P 14 EUR SIGN PROC C, P1
   [Anonymous], 2016, ZETT ER TRENDS AN
   [Anonymous], 2010, 1449610 ISO IEC
   [Anonymous], 2016, 230082 ISO IEC
   Bjontegaard G., 2008, VCEGAI11
   Bjotegaard G., 2001, VCEGM33
   Bouyagoub S, 2010, ELECTRON LETT, V46, P345, DOI 10.1049/el.2010.2808
   Brust H., 2009, 3DTV C TRUE VIS CAPT
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Chung KL, 2016, J VIS COMMUN IMAGE R, V39, P65, DOI 10.1016/j.jvcir.2016.05.007
   Fehn Christoph, 2007, 3DTV Conference, 2007, P1
   Gunatilake P.D., 1994, SIGN PROC HDTV INT W, P173
   Iqbal MJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS (CYBERNETICSCOM), P1, DOI 10.1109/CyberneticsCom.2013.6865770
   Mallik B, 2016, 9 INT C DEV ES ENG D
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Said Hany, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P97
   Said H, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0164-7
   Sansli D.B., 2014, P 3DTV C TRUE VISION, P1
   Saygili G, 2011, IEEE T BROADCAST, V57, P593, DOI 10.1109/TBC.2011.2131450
   Schwarz H, 2013, HIGH EFFICIENCY VIDE, P49
   Senzaki K., 2010, 16WP3 ITU T, P1
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Zhang Y, 2006, INT CONF SIGN PROCES, P1405
   Zhang Y, 2009, ETRI J, V31, P151, DOI 10.4218/etrij.09.0108.0350
NR 32
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6701
EP 6720
DI 10.1007/s11042-018-6272-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700013
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Sitara, K
   Mehtre, BM
AF Sitara, K.
   Mehtre, B. M.
TI Automated camera sabotage detection for enhancing video surveillance
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera tampering; Camera sabotage; Video surveillance; Camera occlusion;
   Camera defocus; Camera displacement; Secure systems; Video forensics
AB Surveillance cameras are vital source of information in crime investigations. A surveillance video must be recorded with correct field of view and be of good quality, otherwise, it may not be suitable for investigation or analysis purposes. Perpetrators may tamper the recorded video or the physical device itself, in order to conceal their dubious activities. Generally, surveillance systems are unmanned due to limitations of manual monitoring. Automatic detection of camera tamper events is crucial for timely operator intervention. We propose a new method for detecting video camera tampering events like occlusion, defocus and displacement. The features used are edge information, frame count, foreground objects' coverage area and its static nature. Effectiveness of our method is tested through experimentation on public datasets. The results obtained are encouraging with high detection and low false alarm rates. The proposed method automatically detects routine problems with cameras like dirt on camera lens, fog and smoke.
C1 [Sitara, K.; Mehtre, B. M.] Inst Dev & Res Banking Technol, Ctr Excellence Cyber Secur, Hyderabad, India.
   [Sitara, K.] Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad, India.
C3 University of Hyderabad
RP Sitara, K (corresponding author), Inst Dev & Res Banking Technol, Ctr Excellence Cyber Secur, Hyderabad, India.; Sitara, K (corresponding author), Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad, India.
EM sitara.kk@gmail.com; bmmehtre@idrbt.ac.in
RI K, Sitara/AAW-2986-2020
OI K, Sitara/0000-0001-8242-8593
CR Ahmed SA, 2017, MULTIMED TOOLS APPL, V76, P13651, DOI 10.1007/s11042-016-3762-y
   Aksay A, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P558, DOI 10.1109/AVSS.2007.4425371
   [Anonymous], P 2012 C DES ARCH SI
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Ashby MPJ, 2017, EUR J CRIM POLICY RE, V23, P441, DOI 10.1007/s10610-017-9341-6
   Chun-Liang Tung, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012). Proceedings, P1760, DOI 10.1109/ICMLC.2012.6359641
   Comiskey PM, 2017, FORENSIC SCI INT, V276, P134, DOI 10.1016/j.forsciint.2017.04.016
   Daw-Tung Lin, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P383, DOI 10.1109/IIH-MSP.2012.99
   Ellwart D, 2012, LECT NOTES COMPUT SC, V7053, P45, DOI 10.1007/978-3-642-25261-7_4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzsimons J, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550028
   Gil-Jiménez P, 2007, LECT NOTES COMPUT SC, V4528, P222
   Huang DY, 2014, J VIS COMMUN IMAGE R, V25, P1865, DOI 10.1016/j.jvcir.2014.09.007
   Jerian M, 2007, FORENSIC SCI INT, V167, P207, DOI 10.1016/j.forsciint.2006.06.048
   Lavee G, 2007, MULTIMED TOOLS APPL, V35, P109, DOI 10.1007/s11042-007-0117-8
   Lee J, 2008, FORENSIC SCI INT, V177, P17, DOI 10.1016/j.forsciint.2007.10.008
   Li NN, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550113
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Ramstrand N, 2011, FORENSIC SCI INT, V212, P27, DOI 10.1016/j.forsciint.2011.05.002
   Ribnick E, 2006, P IEEE INT C VID SIG, P10
   Russo P, 2017, FORENSIC SCI INT, V271, P59, DOI 10.1016/j.forsciint.2016.12.023
   Saglam A, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P430, DOI 10.1109/AVSS.2009.29
   Shih-Hung Chen, 2013, 2013 Abstracts IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2013.6635119
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Sitara K., 2015, ADV INTELLIGENT SYST, P75
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Sulman N, 2008, INT C PATT RECOG, P1850
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Tsesmelis T, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P57, DOI 10.1109/AVSS.2013.6636616
   Yin HP, 2013, CHIN CONT DECIS CONF, P665
   Yuan-Kai Wang, 2011, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC 2011), P1520, DOI 10.1109/ICMLC.2011.6017032
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
NR 36
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5819
EP 5841
DI 10.1007/s11042-018-6165-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100040
DA 2024-07-18
ER

PT J
AU Szczuko, P
   Czyzewski, A
   Szczodrak, M
AF Szczuko, P.
   Czyzewski, A.
   Szczodrak, M.
TI Variable length sliding models for banking clients face biometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face biometry; Verification; Moving average
AB An experiment was organized in 100 bank branches to acquire biometric samples from nearly 5000 clients including face images. A procedure for creating face verification models based on continuously expanding database of biometric samples is proposed, implemented, and tested. The presented model applies to circumstances where it is possible to collect and to take into account new biometric samples after each positive verification of the user. Thus the model can evolve in time, and it can follow changes of user face characteristics, e.g. changes in complexion, variable amount of facial hair, arriving wrinkles, cheeks chubbiness appearance, etc., introduced as effects of changing lifestyle, sunbathing, gaining weight, aging or other processes. The variable length sliding models derived from the gathered experimental data are described in the paper.
C1 [Szczuko, P.; Czyzewski, A.; Szczodrak, M.] Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczuko, P (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Fac Elect Telecommun & Informat, Gdansk, Poland.
EM szczuko@multimed.org; andcz@multimed.org; szczodry@multimed.org
RI Szczuko, Piotr/AAB-4822-2020; Czyzewski, Andrzej/JXN-0946-2024
OI Szczuko, Piotr/0000-0003-3703-8734; Czyzewski,
   Andrzej/0000-0001-9159-8658
FU Polish National Center for Research and Development [PBS3/B3/26/2015]
FX This work was supported by the grant No. PBS3/B3/26/2015 entitled
   "Multimodal biometric system for bank client identity verification"
   co-financed by the Polish National Center for Research and Development.
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2011, Signal Processing and Communication Systems (ICSPCS), 2011 5th International Conference on, DOI [10.1109/IJCB.2011.6117600, DOI 10.1109/IJCB.2011.6117600]
   [Anonymous], 2013, CVPR
   Antipov G, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P191, DOI 10.1109/BTAS.2017.8272698
   Benlamoudi A., 2015, CVA, DOI [10.13140/RG.2.1.2027.4723, DOI 10.13140/RG.2.1.2027.4723]
   Berg T., 2012, BMVC
   Bolme DS, 2009, PROC CVPR IEEE, P2105, DOI 10.1109/CVPRW.2009.5206701
   Borade SN, 2016, MED C CONTR AUTOMAT, P1164, DOI 10.1109/MED.2016.7536065
   Bratoszewski P, 2017, SIG P ALGO ARCH ARR, P184, DOI 10.23919/SPA.2017.8166861
   Cao XD, 2013, IEEE I CONF COMP VIS, P3208, DOI 10.1109/ICCV.2013.398
   Çeliktutan O, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-13
   Czyzewski A., 2017, Multimedia Communications, Services and Security (Communications in Computer and Information Science), V785, P16, DOI [10.1007/978-3-319-69911-0, DOI 10.1007/978-3-319-69911-0]
   Goldberger J., 2004, P INT C NEUR INF PRO, V17, P513
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Klontz J., 2013, OPEN SOURCE BIOMETRI, P1
   Lanitis A., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P391, DOI 10.1109/AFGR.2000.840664
   Lech Michal, 2017, Elektronika, V58, P18, DOI 10.15199/13.2017.4.4
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380
   Ouloul I. M., 2015, 2015 5 INT C INF COM, P1, DOI DOI 10.1109/ICTA.2015.7426876
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Pavani SK, 2012, IEEE T INF FOREN SEC, V7, P932, DOI 10.1109/TIFS.2012.2186292
   Samine Hosseini S., 2012, Journal of Basic and Applied Scientific Research, V2, P9152
   Sun Y, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P4599
   Szczodrak M, 2017, FOUND COMPUT DECIS S, V42, P137, DOI 10.1515/fcds-2017-0006
   Szczuko P, 2019, J INTELL INF SYST, V52, P1, DOI 10.1007/s10844-017-0491-2
   TAO D, 2018, TIP, V27, P325, DOI DOI 10.1109/TIP.2017.2762588
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SW, 2013, EUR CON SFTWR MTNCE, P5, DOI 10.1109/CSMR.2013.11
   Weinberger K.Q., 2006, Advances in neural information processing systems, P1473
NR 30
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7749
EP 7766
DI 10.1007/s11042-018-6432-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700060
OA hybrid
DA 2024-07-18
ER

PT J
AU Zajic, G
   Gavrovska, A
   Reljin, I
   Reljin, B
AF Zajic, Goran
   Gavrovska, Ana
   Reljin, Irini
   Reljin, Branimir
TI A video hard cut detection using multifractal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Hard cut detection; Shot; Multifractals; Color; Texture
ID SHOT-BOUNDARY DETECTION; SEGMENTATION; EXTRACTION
AB Efficient management of video sequences is based on adequate video content description. This description can be used for various purposes in different applications, telecommunication services, video and multimedia systems. Video hard cut detection represents the foundation of temporal video segmentation. In this paper, a new video hard cut detection methodology is proposed using multifractal features. Transition between two shots can be described as color and texture differences within a decoded video sequence. In the proposed methodology we formed specific structures by measuring color differences between frames. The formed structures are used for hard cut candidate detection. This is followed by multifractal representation of texture changes by Holder exponents. The proposed methodology achieves high performance using more than 750,000 frames, extracted from forty different video sequences, classified by four well known genre groups. Moreover, the proposed hard cut detection achieves high performance regardless of high level video production or complex non-linear editing for different genre groups. This is confirmed by comparison between the proposed methodology and other recent work on hard cut detection.
C1 [Zajic, Goran] ICT Coll Vocat Studies, Zdravka Celara 16, Belgrade, Serbia.
   [Zajic, Goran; Gavrovska, Ana; Reljin, Irini; Reljin, Branimir] Univ Belgrade, Sch Elect Engn, Bulevar Kralja Alcksandra 73, Belgrade, Serbia.
C3 University of Belgrade
RP Zajic, G (corresponding author), ICT Coll Vocat Studies, Zdravka Celara 16, Belgrade, Serbia.; Zajic, G (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Alcksandra 73, Belgrade, Serbia.
EM gzajic@gmail.com; anaga777@gmail.com; irinitms@email.com; rebinb@etf.rs
RI Zajic, Goran/AAC-6964-2022
OI Zajic, Goran/0000-0002-3836-2061
CR Abd-Almageed W, 2008, IEEE IMAGE PROC, P3200, DOI 10.1109/ICIP.2008.4712476
   Adcock J, 2004, P TRECVID 2004 WORKS
   [Anonymous], 1999, FRACTAL GEOMETRY NAT
   [Anonymous], P TRECVID 2007 WORKS
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   Calic J, 2002, EURASIP J APPL SIG P, V2002, P561, DOI 10.1155/S1110865702000938
   Damnjanovic Uros, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1779
   Donate A, 2010, 1 INT WORKSH 3 DIM I, DOI [10. 1109/CVPRW. 2010. 5543811, DOI 10.1109/CVPRW.2010.5543811]
   Dutta D, 2016, MULTIMED TOOLS APPL, V75, P93, DOI 10.1007/s11042-014-2273-y
   El Khattabi Z., 2017, International Journal of Electrical and Computer Engineering, V7, P2565
   Falconer K., 2003, FRACTAL GEOMETRY MAT, V2, DOI DOI 10.1002/0470013850
   Grecos C, 2009, J REAL-TIME IMAGE PR, V4, P91, DOI 10.1007/s11554-008-0093-x
   Gunal E., 2011, J SOFTWARE ENG APPL, V4, P235, DOI DOI 10.4236/jsea.2011.44026
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Jacobs A, 2004, P TRECVID 2004 WORKS
   Kim TH, 2012, LECT NOTES COMPUT SC, V7202, P122, DOI 10.1007/978-3-642-31919-8_16
   Krulikovska L, 2012, WORLD ACAD SCI ENG T, V6, P633
   Lawrence S., 2004, Pattern Recognition and Image Analysis, V14, P109
   Le DD, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P706
   LI J, 2009, THE PROCEEDINGS OF T, P435, DOI DOI 10.1109/IAS.2009.16
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Liu X., 2016, INT J SIGNAL PROCESS, V9, P265, DOI [10.14257/ijsip.2016.9.4.25, DOI 10.14257/IJSIP.2016.9.4.25]
   Liu Z, 2007, P TRECVID 2007 WORKS
   Lopes R, 2009, MED IMAGE ANAL, V13, P634, DOI 10.1016/j.media.2009.05.003
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Mishra R, 2013, IEEE INT ADV COMPUT, P1201
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   Petersohn C, 2004, P TRECVID 2004 WORKS
   Petersohn C., 2010, Temporal Video Segmentation
   Primaux L, 2004, P TRECVID 2004 WORKS
   QUENOT GM, 2004, P TRECVID 2004 WORKS
   Reljin I, 2000, IEEE MEDITERR ELECT, P490
   Ren JC, 2009, IEEE T CIRC SYST VID, V19, P1234, DOI 10.1109/TCSVT.2009.2022707
   Richardson L.F., 1961, Gen. Syst. Yearb., V6, P139
   Song BC, 2001, J VIS COMMUN IMAGE R, V12, P364, DOI 10.1006/jvci.2001.0469
   Stojic T, 2006, PHYSICA A, V367, P494, DOI 10.1016/j.physa.2005.11.030
   Sun Xuemei, 2010, Proceedings of the 2010 International Conference on Computer and Information Application (ICCIA 2010), P56, DOI 10.1109/ICCIA.2010.6141536
   Tabii Y, 2014, ADV MULTIMEDIA INT J, V5, P1
   Turner M.J., 1998, FRACTAL GEOMETRY DIG
   VEHEL JL, 1996, INTRO MULTUFRACTAL A
   Wang Y, 2012, IEEE GLOB HIGH TECH
   Watkinson John, 2004, THE MPEG HDB, P366
   Yazici A, 2018, MULTIMED TOOLS APPL, V77, P2225, DOI 10.1007/s11042-017-4378-6
   Yuan J., 2007, P TRECVID 2007 WORKS
   Zaji GJ, 2011, TELFOR J, V3, P105
   Zajic G, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/62678
   Zajic GJ, 2015, 2015 23RD TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P724, DOI 10.1109/TELFOR.2015.7377569
   Zeinalpour-Tabrizi Z, 2010, LECT NOTES COMPUT SC, V6335, P128, DOI 10.1007/978-3-642-15470-6_14
   Zhao ZC, 2007, P TRECVID 2007WORKSH
NR 51
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6233
EP 6252
DI 10.1007/s11042-018-6420-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100058
DA 2024-07-18
ER

PT J
AU Zhao, F
   Si, WJ
   Dou, Z
   Wu, QD
AF Zhao, Feng
   Si, Weijian
   Dou, Zheng
   Wu, Qidi
TI Image compressive recovery based on dictionary learning from
   under-sampled measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Image recovery; Dictionary learning; Nonlocal
   technique; Iterative algorithm
ID SPARSITY; RECONSTRUCTION; ALGORITHM
AB Compressive sensing(CS) has attracted many attentions in recent years, which assumes that the signal can be exactly reconstruction from its only a few measurements when it is sparsity enough under a certain domain. In this paper, we address the image compressive recovery problem. Firstly, a specific adaptive dictionary learning method is adopted to represent the image more sparsely, which learns atoms in dictionary from the under-sampled measurement directly and shows some good performance in adapting to the compressed sensing framework. Secondly, by utilizing the nonlocal self-similarity in image, we also propose a novel nonlocal CS model with multiple regularizations to preserve the details in the reconstruction image, which are seen as the important information to human perception. In addition, to further improve the computational efficiency, an iterative algorithm is developed to solve the proposed model effectively. Extensive experiments on various benchmark images verify that, compared to the existing excellent methods, the proposed model shows superior and competitive performance.
C1 [Zhao, Feng; Si, Weijian; Dou, Zheng; Wu, Qidi] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Dou, Z (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM douzheng@hrbeu.edu.cn
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Charette Paul G., 2015, 2015 Photonics North, DOI 10.1109/PN.2015.7292530
   Chen G., 2012, FUTURE WIRELESS NETW, V1, P253
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P5249, DOI 10.1109/TIP.2014.2363616
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Egiazarian K, 2007, IEEE IMAGE PROC, P549
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254
   Li A., 2014, ADVANCES IN MECHANIC, V2014, P1
   Li A, 2016, CIRC SYST SIGNAL PR, V35, P2932, DOI 10.1007/s00034-015-0179-1
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Shihao Ji D, 2009, SIGNAL PROCESS, V57, P92
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Zhang J, 2012, IEEE J EM SEL TOP C, V2, P380, DOI 10.1109/JETCAS.2012.2220391
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 22
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5169
EP 5180
DI 10.1007/s11042-017-4559-3
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100005
DA 2024-07-18
ER

PT J
AU Chmiel, W
   Skalna, I
   Jedrusik, S
AF Chmiel, Wojciech
   Skalna, Iwona
   Jedrusik, Stanislaw
TI Intelligent route planning system based on interval computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Route optimisation; Video surveillance; Dynamic map; Interval
   arithmetic; Traffic image processing
ID PATH OPTIMIZATION; SPEED; ALGORITHM
AB We investigate the problem of vehicle route planning in a dynamic environment. In order to better reflect real-life situations, we assume that travel times are not known exactly, but bounded from below and from above, i.e., they are given as interval quantities. Accordingly, we develop algorithms for effective route replanning in a highly dynamic road network environment that combines traffic image processing with interval data for dynamic path optimisation. The developed algorithms are integrated into a larger system for traffic management. The efficiency of the proposed algorithms and their ability to support the dynamics of road traffic is verified using real data. The experimental research was also conducted using the microscopic, time-discrete, space-continuous traffic simulator.
C1 [Chmiel, Wojciech] AGH Univ Sci & Technol, Fac Elect Engn Automat Comp Sci & Biomed Engn, Krakow, Poland.
   [Skalna, Iwona; Jedrusik, Stanislaw] AGH Univ Sci & Technol, Fac Management, Krakow, Poland.
C3 AGH University of Krakow; AGH University of Krakow
RP Chmiel, W (corresponding author), AGH Univ Sci & Technol, Fac Elect Engn Automat Comp Sci & Biomed Engn, Krakow, Poland.
EM wch@agh.edu.pl; skalna@agh.edu.pl; jedrusik@zarz.agh.edu.pl
RI Skalna, Iwona/A-6570-2017
OI Skalna, Iwona/0000-0001-5707-7525; Chmiel, Wojciech/0000-0002-4773-9123
FU National Centre for Research and Development (NCBiR), Smart
   Infrastructure Road Innovation (RID) project
   [DZP/RID-I-68/14/NCBIR/2016]
FX This work has been co-financed by the National Centre for Research and
   Development (NCBiR), Smart Infrastructure Road Innovation (RID) project
   no. DZP/RID-I-68/14/NCBIR/2016.
CR Andonov, 2017, ADV GPU RES PRACTICE, P273, DOI [10.1016/B978-0-12-803738-6.00011-2, DOI 10.1016/B978-0-12-803738-6.00011-2]
   Angelelli E, 2016, TRANSPORT RES B-METH, V94, P1, DOI 10.1016/j.trb.2016.08.015
   [Anonymous], 2004, ALENEX/ANALC
   [Anonymous], 2004, Geoinformation und Mobilitat-von der Forschung zur praktischen Anwendung
   [Anonymous], 2004, MSRTR200424
   Arvanitakis I, 2017, IFAC PAPERSONLINE, V50, P12710, DOI 10.1016/j.ifacol.2017.08.2267
   Bader R, 2011, LECT NOTES COMPUT SC, V6595, P21, DOI 10.1007/978-3-642-19754-3_5
   Bast H, 2007, TRANSIT CONSTANT TIM
   Bast H, 2016, LECT NOTES COMPUT SC, V9220, P19, DOI 10.1007/978-3-319-49487-6_2
   Bellman R., 1957, Dynamic programming
   Buchhold V, 2018, 17 INT S EXPT ALG, V103, DOI DOI 10.4230/LIPICS.SEA.2018.27
   Chen M, 2017, TRANSPORT RES C-EMER, V82, P1, DOI 10.1016/j.trc.2017.06.007
   Chen P, 2018, EXPERT SYST APPL, V110, P20, DOI 10.1016/j.eswa.2018.05.022
   Chmiel W, 2016, MULTIMED TOOLS APPL, V75, P10529, DOI 10.1007/s11042-016-3367-5
   Chmiel W, 2015, COMM COM INF SC, V566, P195, DOI 10.1007/978-3-319-26404-2_16
   Del Grosso A., 1993, Smart Materials and Structures, V2, P103, DOI 10.1088/0964-1726/2/2/006
   Delling D, 2011, LECT NOTES COMPUT SC, V6630, P376
   Dib O, 2017, COMPUT OPER RES, V78, P420, DOI 10.1016/j.cor.2015.11.010
   Dinitz Y, 2017, J DISCRET ALGORITHMS, V42, P35, DOI 10.1016/j.jda.2017.01.001
   Flinsenberg I, 2004, THESIS
   Guzik V, 2017, PATH PLANNING FOR VEHICLES OPERATING IN UNCERTAIN 2D ENVIRONMENTS, P25, DOI 10.1016/B978-0-12-812305-8.00002-8
   Han J, 2018, INFORM SCIENCES, V450, P39, DOI 10.1016/j.ins.2018.03.035
   He R, 2002, TECH REP
   Holzer Martin., 2009, Journal of Experimental Algorithmics JEA, V13, P5
   Hu XB, 2017, TRANSPORT RES B-METH, V106, P411, DOI 10.1016/j.trb.2017.06.007
   Hu XB, 2016, EVOL COMPUT, V24, P319, DOI 10.1162/EVCO_a_00156
   Huang W, 2017, NEURAL NETWORKS, V90, P21, DOI 10.1016/j.neunet.2017.03.002
   Idri A, 2017, PROCEDIA COMPUT SCI, V109, P692, DOI 10.1016/j.procs.2017.05.379
   Jerrell M. E., 1997, Computational Economics, V10, P89, DOI 10.1023/A:1017987931447
   Jiang C, 2008, EUR J OPER RES, V188, P1, DOI 10.1016/j.ejor.2007.03.031
   Kampen EV, 2010, OPT SPAC REND DOCK U
   LUBY M, 1989, ALGORITHMICA, V4, P551, DOI 10.1007/BF01553908
   Ma ZL, 2017, TRANSPORT RES C-EMER, V74, P1, DOI 10.1016/j.trc.2016.11.008
   Marinakis Y, 2017, EUR J OPER RES, V261, P819, DOI 10.1016/j.ejor.2017.03.031
   Maue J, 2010, J EXP ALGORITHMICS, V14
   Miao CS, 2018, TRANSPORT RES C-EMER, V91, P353, DOI 10.1016/j.trc.2018.04.014
   Montemanni R, 2004, OPER RES LETT, V32, P225, DOI 10.1016/j.orl.2003.08.002
   Montemanni R, 2008, IDSIA0308
   Moore R., 1966, INTERVAL ANAL, V60
   Naghawi H., 2010, Journal of Transportation Safety Security, V2, P184, DOI DOI 10.1080/19439962.2010.488316
   Patle BK, 2018, DEF TECHNOL, V14, P691, DOI 10.1016/j.dt.2018.06.004
   Rahmani M, 2017, TRANSPORT RES C-EMER, V85, P628, DOI 10.1016/j.trc.2017.10.012
   Sanders P, 2005, LECT NOTES COMPUT SC, V3669, P568
   Sanders P, 2006, LECT NOTES COMPUT SC, V4168, P804
   Schultes D, 2008, THESIS
   Schultes D, 2007, LECT NOTES COMPUT SC, V4525, P66
   Schulz F, 1999, LECT NOTES COMPUT SC, V1668, P110
   Sevastjanov P., 2002, COMPUTER SCI POLITEC, V2, P45
   Sevastjanov P. V., 2003, TASK Quarterly, V7, P147
   Sever D, 2018, TRANSPORT RES C-EMER, V92, P42, DOI 10.1016/j.trc.2018.04.018
   Soong-Bong Lee, 2019, Journal of King Saud University - Engineering Sciences, V31, P314, DOI 10.1016/j.jksues.2017.12.001
   Stadtherr Mark A., 2007, International Journal of Reliability and Safety, V1, P465, DOI 10.1504/IJRS.2007.016260
   Szwed P, 2012, P FED C COMP SCI INF, P141
   Wagner D, 2003, LECT NOTES COMPUT SC, V2832, P776
   Yang CH, 2018, AUTOMAT CONSTR, V93, P214, DOI 10.1016/j.autcon.2018.05.024
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zeng XR, 2018, TRANSPORT RES C-EMER, V93, P148, DOI 10.1016/j.trc.2018.05.027
   Zhang Q, 2018, APPL SOFT COMPUTING
   Zhao YJ, 2018, KNOWL-BASED SYST, V158, P54, DOI 10.1016/j.knosys.2018.05.033
   Zhu S., 2004, THESIS
NR 60
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4693
EP 4721
DI 10.1007/s11042-018-6714-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200040
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, T
   Leng, JB
   Kong, LY
   Guo, S
   Bai, G
   Wang, K
AF Li, Tao
   Leng, Jiabing
   Kong, Lingyan
   Guo, Song
   Bai, Gang
   Wang, Kai
TI DCNR: deep cube CNN with random forest for hyperspectral image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HSI classification; Deep learning; CNN; Random forest; Spectral-spatial
   feature
ID CONVOLUTIONAL NEURAL-NETWORK
AB Hyperspectral Image (HSI) classification is one of the fundamental tasks in the field of remote sensing data analysis. CNN (Convolutional Neural Network) has been proven to be an effective deep learning model, which can extract high-level features directly from the raw data and thereby utilize rich information contained in HSI data. However, labor cost to label enough HIS data for training model is usually expensive, so that it is a strong demand of utilizing limited training data to get a satisfied classification accuracy. In this paper, we put forward a deep cube CNN model - DCNR, which is composed of a cube neighbor HSI pixels strategy, a deep CNN and a random forest classifier. In DCNR model, cubic samples, containing spectral-spatial information, are generated by putting each target pixel and its neighbors together. Then features with high representative ability, extracted by applying a specially designed cube CNN model on each cubic sample, are fed into the random forest classifier for the classification of the target pixel. Results show that DCNR model can achieve classification accuracy of 96.78%, 96.08% and 94.85% on KSC, IP and SA datasets respectively with 20% samples as training set, and 85.03%, 83.45 and 62.17% on KSC, IP and SA datasets respectively with only 1% samples as training set, significantly outperforming random forest and cube CNN models.
C1 [Li, Tao; Leng, Jiabing; Kong, Lingyan; Guo, Song; Bai, Gang; Wang, Kai] Nankai Univ, Coll Comp & Control Engn, Sino Canada Joint R&D Ctr Water & Environm Safety, Tianjin 300050, Peoples R China.
C3 Nankai University
RP Wang, K (corresponding author), Nankai Univ, Coll Comp & Control Engn, Sino Canada Joint R&D Ctr Water & Environm Safety, Tianjin 300050, Peoples R China.
EM wangk@nankai.edu.cn
OI Wang, Kai/0000-0001-5589-7060; Guo, Song/0000-0001-6841-753X
FU Natural Science Foundation of Tianjin [16JCYBJC15200]; Major Science and
   Technology Program of Big Data and Cloud Computing of Tianjin
   [15ZXDSGX00020]; Science and Technology Commission of Tianjin Binhai New
   Area [BHXQKJXM-PT-ZJSHJ-2017005]; National Key Research and Development
   Program of China [2016YFC0400709]; Fundamental Research Funds for the
   Central Universities
FX This study was funded by the Natural Science Foundation of Tianjin under
   Grant No. 16JCYBJC15200, the Major Science and Technology Program of Big
   Data and Cloud Computing of Tianjin No. 15ZXDSGX00020, the Science and
   Technology Commission of Tianjin Binhai New Area No.
   BHXQKJXM-PT-ZJSHJ-2017005, the National Key Research and Development
   Program of China (2016YFC0400709), and the Fundamental Research Funds
   for the Central Universities.
CR Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   AlZain MA, 2015, INT J CLOUD APPL COM, V5, P35, DOI 10.4018/IJCAC.2015070103
   [Anonymous], HDB RES MOD CRYPT SO
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE GEOSCI REMOTE S
   [Anonymous], ADV NEUR INFORM PROC
   [Anonymous], COMPUT SCI
   [Anonymous], 2009, INT C MACH LEARN ICM
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Berger J., 2010, Proceedings of the Python for Scientific Computing Conference (SciPy), number Scipy, P1
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Heaton JB, 2017, APPL STOCH MODEL BUS, V33, P3, DOI 10.1002/asmb.2209
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Jararweh Y, 2017, MULTIMED TOOLS APPL, P1
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Leng JB, 2016, PROC INT C TOOLS ART, P1027, DOI [10.1109/ICTAI.2016.155, 10.1109/ICTAI.2016.0158]
   Li J, 2015, IEEE T GEOSCI REMOTE, V53, P1592, DOI 10.1109/TGRS.2014.2345739
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li Y, 2016, VISUAL COMPUT, V32, P1525, DOI 10.1007/s00371-015-1137-4
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Qi C. R., 2017, IEEE P COMPUT VIS PA, V1, P4, DOI DOI 10.1109/CVPR.2017.16
   Quang D, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw226
   Simonyan K., 2014, 14091556 ARXIV
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Xia JS, 2014, IEEE GEOSCI REMOTE S, V11, P239, DOI 10.1109/LGRS.2013.2254108
   Xie L, 2017, IEEE GEOSCI REMOTE S, V14, P374, DOI 10.1109/LGRS.2016.2643686
   Yuan CS, 2017, CMC-COMPUT MATER CON, V53, P357
   Zeng SZ, 2017, INT J INTELL SYST, V32, P1136, DOI 10.1002/int.21886
   Zhang LF, 2012, IEEE T GEOSCI REMOTE, V50, P879, DOI 10.1109/TGRS.2011.2162339
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
NR 49
TC 25
Z9 26
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3411
EP 3433
DI 10.1007/s11042-018-5986-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600042
DA 2024-07-18
ER

PT J
AU Wang, CC
   Hung, JC
   Chen, SN
   Chang, HP
AF Wang, Chun-Chia
   Hung, Jason C.
   Chen, Shih-Nung
   Chang, Hsuan-Pu
TI Tracking students' visual attention on manga-based interactive e-book
   while reading: an eye-movement approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye tracking; Prior knowledge; Visual attention; Hypermedia system;
   Cognitive analysis
ID ARITHMETIC WORD-PROBLEMS; COGNITIVE-LOAD; PRIOR KNOWLEDGE;
   INDIVIDUAL-DIFFERENCES; ANNOTATION SYSTEM; COMPREHENSION; SCIENCE;
   ACHIEVEMENT; LEARNERS; LOOKING
AB This study employed an eye tracking technology to explore university students' visual attention and learning performance while learning Japanese using an interactive manga-based e-book. The developed e-book consisted of 8 pages accompanied by 13 annotations with both text and graphical formats. The subjects consisted of 60 students whose eye movements were tracked and recorded by the eye tracking system. These students came from the applied foreign language department in a northern university in Taiwan, of which 30 were assigned to high prior knowledge (PK) group and the other 30 were assigned to low PK group. Eye tracking measurements, including total contact time, number of fixations, latency of first fixation, and number of clicks on the defined regions of interest of the two groups were compared to indicate their visual attention. The results revealed that overall students spent more time on reading text and annotation than graphic information. The high PK students showed longer fixation durations on the texts, while the low PK students showed longer fixation durations on the graphics and annotations. Meanwhile, the low PK students used more clicks to look up underlined annotations whenever they didn't know words or phrases on the e-book. In addition, with respect to the latency of the first fixation, the graphic captured the attention faster than the text because of the size and its appeal to the students. Further analysis of saccade paths indicated that the low PK students showed more inter-scanning transitions not only between the text dialog and the annotation zone but also within annotation zone. Finally, the results of reading comprehension pretest and posttest found that there was a significant difference in learning outcomes between each PK group.
C1 [Wang, Chun-Chia] Chang Jung Christian Univ, Dept Comp Sci & Informat Engn, Tainan 71101, Taiwan.
   [Hung, Jason C.] Overseas Chinese Univ, Dept Informat Technol, Taichung 40721, Taiwan.
   [Chen, Shih-Nung] Asia Univ, Dept Informat Commun, Taichung 41354, Taiwan.
   [Chang, Hsuan-Pu] Tamkang Univ, Dept Informat & Lib Sci, New Taipei 25137, Taiwan.
C3 Chang Jung Christian University; Asia University Taiwan; Tamkang
   University
RP Hung, JC (corresponding author), Overseas Chinese Univ, Dept Informat Technol, Taichung 40721, Taiwan.
EM toshiwang@mail.cjcu.edu.tw; jhungc.hung@gmail.com; nung@asia.edu.tw;
   musicbubu@gmail.com
FU Department of International Cooperation and Science Education [MOST
   104-2511-S-149-001]; Ministry of Science and Technology of the Republic
   of China [MOST 104-2511-S-149-001]; Ministry of Education of the
   Republic of China
FX The author is grateful to the Department of International Cooperation
   and Science Education as well as the Ministry of Science and Technology
   of the Republic of China for their financial support to carry out this
   work, under Grant number: MOST 104-2511-S-149-001-. The author also wish
   to thank the Aim for the Top University (ATU) project of National Taiwan
   Normal University (NTNU), sponsored by the Ministry of Education of the
   Republic of China.
CR Adams J., 2001, International Journal of Art Design Education, V20, P133
   Alexander Patricia., 2000, HDB READING RES, V3, P285
   [Anonymous], 1988, Statistical power analysis for the behavioral sciences
   [Anonymous], J RES COMPUT ED
   [Anonymous], WORKSH P 21 INT C CO
   [Anonymous], J MEDIA ARTS CULTURE
   [Anonymous], AFTERSCHOOL MATTERS
   [Anonymous], WORKSH P 23 INT C CO
   [Anonymous], ASSESSING SCI UNDERS
   [Anonymous], WORKSH P 22 INT C CO
   [Anonymous], MULTIMEDIA LEARNING
   [Anonymous], STUDY EFFECTS INTERA
   [Anonymous], PIGS FLY ANIME AUTEU
   [Anonymous], JALT2012 C PROC 2013
   [Anonymous], INT J HUMANITIES
   [Anonymous], 19 ANN C COGN SCI SO
   [Anonymous], THESIS
   [Anonymous], 23 INT C COMP ED ICC
   [Anonymous], LANGUAGE
   [Anonymous], 2010, Cognitive Load Theory
   Black RW, 2005, J ADOLESC ADULT LIT, V49, P118, DOI 10.1598/JAAL.49.2.4
   Calvo MG, 2004, MOTIV EMOTION, V28, P221, DOI 10.1023/B:MOEM.0000040153.26156.ed
   Canham M, 2010, LEARN INSTR, V20, P155, DOI 10.1016/j.learninstruc.2009.02.014
   Cary Stephen., 2004, Going Graphic: Comics at Work in the Multilingual Classroom
   Chen YC, 2012, COMPUT EDUC, V58, P1094, DOI 10.1016/j.compedu.2011.12.017
   Chi MTH, 2012, EDUC PSYCHOL-US, V47, P177, DOI 10.1080/00461520.2012.695709
   Coiro J, 2011, J LIT RES, V43, P352, DOI 10.1177/1086296X11421979
   Cook M, 2008, INT J SCI EDUC, V30, P239, DOI 10.1080/09500690601187168
   Grant ER, 2003, PSYCHOL SCI, V14, P462, DOI 10.1111/1467-9280.02454
   Greene JA, 2010, COMPUT EDUC, V55, P1027, DOI 10.1016/j.compedu.2010.04.013
   HEGARTY M, 1995, J EDUC PSYCHOL, V87, P18, DOI 10.1037/0022-0663.87.1.18
   HEGARTY M, 1992, J EDUC PSYCHOL, V84, P76, DOI 10.1037/0022-0663.84.1.76
   Hewig J, 2008, J NONVERBAL BEHAV, V32, P67, DOI 10.1007/s10919-007-0043-5
   Higgins N., 1999, J READING PSYCHOL, V20, P1, DOI [10.1080/027027199278475, DOI 10.1080/027027199278475]
   Ho HNJ, 2014, INT J SCI MATH EDUC, V12, P525, DOI 10.1007/s10763-013-9489-6
   Humphrey K, 2009, BRIT J PSYCHOL, V100, P377, DOI 10.1348/000712608X344780
   Hwang WY, 2007, COMPUT EDUC, V48, P680, DOI 10.1016/j.compedu.2005.04.020
   Hwang WY, 2015, EDUC TECHNOL SOC, V18, P292
   Hwang WY, 2011, BRIT J EDUC TECHNOL, V42, P1016, DOI 10.1111/j.1467-8535.2010.01126.x
   Hwang WY, 2011, RECALL, V23, P160, DOI 10.1017/S0958344011000061
   Hwang WY, 2011, TURK ONLINE J EDUC T, V10, P234
   Hyönä J, 2002, J EDUC PSYCHOL, V94, P44, DOI 10.1037//0022-0663.94.1.44
   Jarodzka H, 2017, J EYE MOVEMENT RES, V10, DOI 10.16910/jemr.10.1.3
   Jarodzka H, 2010, LEARN INSTR, V20, P146, DOI 10.1016/j.learninstruc.2009.02.019
   JUST MA, 1985, PSYCHOL REV, V92, P137, DOI 10.1037/0033-295X.92.2.137
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Knoblich G, 2001, MEM COGNITION, V29, P1000, DOI 10.3758/BF03195762
   Korat O, 2004, J COMPUT ASSIST LEAR, V20, P257, DOI 10.1111/j.1365-2729.2004.00078.x
   Kristof R., 1995, INTERACTIVITY DESIGN
   Lai ML, 2013, EDUC RES REV-NETH, V10, P90, DOI 10.1016/j.edurev.2013.10.001
   Lin YT, 2016, IEEE T EDUC, V59, P175, DOI 10.1109/TE.2015.2487341
   Liu HC, 2008, J SCI EDUC TECHNOL, V17, P466, DOI 10.1007/s10956-008-9115-5
   Liversedge S.P., 1998, Eye Guidance in Reading and Scene Perception, P55, DOI [10.1016/B978-0-08-043361-5.X5000-7, DOI 10.1016/B978-008043361-5/50004-3]
   Mason L, 2013, J EXP EDUC, V81, P356, DOI 10.1080/00220973.2012.727885
   Mayer R.E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9780511816819.016, 10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369]
   Mayer RE, 2004, AM PSYCHOL, V59, P14, DOI 10.1037/0003-066X.59.1.14
   MAYER RE, 1994, J EDUC PSYCHOL, V86, P389, DOI 10.1037/0022-0663.86.3.389
   Mayer RE, 1997, EDUC PSYCHOL-US, V32, P1, DOI 10.1207/s15326985ep3201_1
   Mayer RE, 2011, Applying the Science of Learning
   Paas F, 2003, EDUC PSYCHOL, V38, P1, DOI 10.1207/S15326985EP3801_1
   PAAS FGWC, 1994, J EDUC PSYCHOL, V86, P122, DOI 10.1037/0022-0663.86.1.122
   Paivio A., 2006, Mind and Its Evolution: A Dual Coding Theoretical Approach
   Paivio A., 1986, Mental representations: A dual coding approach
   Peverly ST, 2013, APPL COGNITIVE PSYCH, V27, P115, DOI 10.1002/acp.2881
   Potter MC, 2014, ATTEN PERCEPT PSYCHO, V76, P270, DOI 10.3758/s13414-013-0605-z
   RAWLINS GJE, 1993, J AM SOC INFORM SCI, V44, P474, DOI 10.1002/(SICI)1097-4571(199309)44:8<474::AID-ASI6>3.0.CO;2-3
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rayner K, 2001, J EXP PSYCHOL-APPL, V7, P219, DOI 10.1037/1076-898X.7.3.219
   Rayner K, 2010, PSYCHON B REV, V17, P834, DOI 10.3758/PBR.17.6.834
   Rayner K, 2009, PSYCHOL SCI, V20, P6, DOI 10.1111/j.1467-9280.2008.02243.x
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Reingold E.M., 2011, OXFORD HDB EYE MOVEM, P528, DOI DOI 10.1093/OXFORDHB/9780199539789.013.0029
   Riley P., 2003, Learner autonomy in the foreign language classroom: teacher, learner, curriculum and assessment, P237
   Sadoski M, 2006, AM EDUC RES J, V43, P137, DOI 10.3102/00028312043001137
   Sanders M.S., 1987, Human factors in engineering and design, V6th
   She HC, 2009, COMPUT EDUC, V53, P1297, DOI 10.1016/j.compedu.2009.06.012
   Smith S J., 2010, EU-NATO Cooperation: A case of institutional fatigue? EU-NATO Cooperation: A case of institutional fatigue?, P1
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Thompson RA, 2003, TEACH PSYCHOL, V30, P96, DOI 10.1207/S15328023TOP3002_02
   Tsai J.-L., 2005, Research in Applied Psychology, V28, P91
   Tsai MJ, 2016, COMPUT EDUC, V98, P115, DOI 10.1016/j.compedu.2016.03.011
   Tsai MJ, 2012, COMPUT EDUC, V58, P375, DOI 10.1016/j.compedu.2011.07.012
   van Gog T, 2010, LEARN INSTR, V20, P95, DOI 10.1016/j.learninstruc.2009.02.009
   van Gog T, 2009, COMPUT HUM BEHAV, V25, P325, DOI 10.1016/j.chb.2008.12.021
   Wolfe P., 2010, Brain matters: Translating research into classroom practice, V2nd
   Yang FY, 2013, COMPUT EDUC, V62, P208, DOI 10.1016/j.compedu.2012.10.009
   Zheng HD, 2017, MYCOKEYS, P1, DOI 10.3897/mycokeys.26.14506
NR 87
TC 10
Z9 11
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4813
EP 4834
DI 10.1007/s11042-018-5754-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200046
DA 2024-07-18
ER

PT J
AU Frikha, M
   Fendri, E
   Hammami, M
AF Frikha, Mayssa
   Fendri, Emna
   Hammami, Mohamed
TI People search based on attributes description provided by an eyewitness
   for video surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People search; Attribute description; Semantic attributes; Interaction
   model; Appearance style rule database; Weighted appearance interaction
   graph
ID PERSON REIDENTIFICATION; CLASSIFICATION
AB People search based on attributes description presents a paramount task for several forensics and surveillance applications. The aim is to locate a suspect or to find a missing person in public areas. However, semantic attributes provide a natural interface for this system as they present human understandable properties. These features can cover the whole body characteristics by describing the worn bags, carried objects, clothes, accessories, etc. Detecting semantic attributes under uncontrolled acquisition conditions still remains a challenging task. Most of state-of-the-art approaches assume independence among attributes where each attribute classifier is trained independently based on low-level features extracted from training samples. In this paper, we propose a novel people search system based on attributes description that relies on several components. An interactive query verification algorithm is introduced to prevent search failure. In addition, an attribute classification method that relies on two steps is introduced. We start by selecting the most relevant features in attribute adaptive way. Then, we explored the interactions among attributes to predict a semantic trait by involving the independent attribute classifier and the other correlated attribute classifiers. Several experiments were conducted to validate the effectiveness of the proposed people search system on the challenging VIPeR, CUHK, and HDA+ datasets benchmark.
C1 [Frikha, Mayssa] Sfax Univ, MIRACL Fac Econ & Management, Sfax, Tunisia.
   [Fendri, Emna; Hammami, Mohamed] Sfax Univ, MIRACL Fac Sci, Sfax, Tunisia.
C3 Universite de Sfax; Multimedia, InfoRmation Systems & Advancing
   Computing Laboratory (MIRACL); Universite de Sfax; Faculty of Sciences
   Sfax; Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL)
RP Frikha, M (corresponding author), Sfax Univ, MIRACL Fac Econ & Management, Sfax, Tunisia.
EM frikha.mayssa@hotmail.fr
RI Emna, Fendri/AAC-9204-2020
OI Hammami, Mohamed/0000-0003-3580-0473; Emna, Fendri/0000-0002-2328-2616
CR Adjeroh Donald., 2010, Proc. IEEE International Workshop on Information Forensics and Security, P1
   Agrawal R., P 20 INT C VERY LARG
   Almudhahka N., 2016, 2016 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), P1
   An L, 2013, 2013 7 INT C DISTRIB, P1, DOI [10.1109/ICDSC.2013.6778216, DOI 10.1109/ICDSC.2013.6778216]
   [Anonymous], 2007, P IEEE INT WORKSH PE
   [Anonymous], ATTRIBUTE DISCOVERY
   [Anonymous], NEW APPEARANCE SIGNA
   [Anonymous], P INT C MULT RETR IC
   [Anonymous], PERSON RE IDENTIFICA
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ATTREL APPROACH PERS
   [Anonymous], ZERO SHOT LEARNING V
   [Anonymous], IMPROVE PEDESTRIAN A
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Antonie ML, 2004, LECT NOTES ARTIF INT, V3202, P27
   Breiman L., 2001, Mach. Learn., V45, P5
   Caruana R., 2006, ACM INT C P SER, P161, DOI DOI 10.1145/1143844.1143865
   Chen BC, 2013, IEEE T MULTIMEDIA, V15, P1163, DOI 10.1109/TMM.2013.2242460
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Denman S, 2017, ADV COMPUT VIS PATT, P267, DOI 10.1007/978-3-319-50673-9_12
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Figueira D., 2014, COMPUTER VISION ECCV, P241
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kovashka A, 2015, INT J COMPUT VISION, V115, P185, DOI 10.1007/s11263-015-0814-0
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lumini A, 2017, INFORM FUSION, V33, P71, DOI 10.1016/j.inffus.2016.05.003
   Martinel N, 2016, PATTERN RECOGN LETT, V71, P23, DOI 10.1016/j.patrec.2015.11.022
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Nambiar A, 2015, PATTERN RECOGN LETT, V68, P297, DOI 10.1016/j.patrec.2015.07.001
   Odone F, 2005, IEEE T IMAGE PROCESS, V14, P169, DOI 10.1109/TIP.2004.840701
   Provost F, 2001, MACH LEARN, V42, P203, DOI 10.1023/A:1007601015854
   Saghafi MA, 2014, IET COMPUT VIS, V8, P455, DOI 10.1049/iet-cvi.2013.0180
   Schmid C, 2001, PROC CVPR IEEE, P39
   Shih F., 2010, Image Processing and Pattern Recognition: Fundamentals and Techniques
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Ye M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P547, DOI 10.1145/2671188.2749347
NR 50
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2045
EP 2072
DI 10.1007/s11042-018-6245-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700035
DA 2024-07-18
ER

PT J
AU Krishnakumar, K
   Gandhi, SI
AF Krishnakumar, K.
   Gandhi, S. Indira
TI Video stitching using interacting multiple model based feature tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stitching; Video registration; Feature tracking; Kalman filter;
   Interacting multiple model
AB In this paper, we propose a novel video stitching algorithm for videos from multiple cameras using interacting multiple model feature tracking to maintain spatial-temporal consistency. Apart from image alignment challenges while stitching a video, inter frame consistency, video jitter due to moving object and camera movement also need to be addressed. To address these challenges, feature point detected in the initial frame is tracked in the subsequent frames to maintain spatial-temporal consistency and reduce computation complexity in feature point detection. Firstly, the feature points are detected using Features from Accelerated Segment Test algorithm. Secondly, using Binary Robust Invariant Scalable Keypoints descriptor values are obtained from detected feature points and matched using hamming distance. The outliers are removed by Random Sample Consensus Algorithm. Once, the first frame is stitched, feature points detected from first frame are tracked using kalman filter with interacting multiple model. The tracked feature points are descripted and homography between the frames are found. This will maintain the spatio-temporal consistency by reducing jitter effect between frames after stitching, and since the frames are neglected from feature point detection, computation complexity is reduced. From the experimental results, we observed that the execution time of the proposed method is less and the performance of structural similarity is better than the existing methods.
C1 [Krishnakumar, K.; Gandhi, S. Indira] Anna Univ, Madras Inst Technol, Dept Elect Engn, Chennai 600044, India.
C3 Anna University; Madras Institute of Technology; Anna University Chennai
RP Krishnakumar, K (corresponding author), Anna Univ, Madras Inst Technol, Dept Elect Engn, Chennai 600044, India.
EM kunakrishnakumar@gmail.com; indira@mitindia.edu
RI S, Indira Gandhi/AAC-4330-2022; K, Krishnakumar/AAB-5560-2019
OI K, Krishnakumar/0000-0003-2443-1553
CR Bar-Shalom Y, 1990, MULTITARGET MULTISEN, P391
   BLOM HAP, 1988, IEEE T AUTOMAT CONTR, V33, P780, DOI 10.1109/9.1299
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   El-Saban M, 2010, IEEE IMAGE PROC, P1193, DOI 10.1109/ICIP.2010.5651811
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guo H, 2016, IEEE T IMAGE PROCESS, V25, P5491, DOI 10.1109/TIP.2016.2607419
   Hamza A, 2015, IMAGE VISION COMPUT, V37, P20, DOI 10.1016/j.imavis.2015.02.002
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jia JY, 2008, IEEE T PATTERN ANAL, V30, P617, DOI 10.1109/TPAMI.2007.70729
   Jia JY, 2005, IEEE I CONF COMP VIS, P1651
   Jiang W, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301374
   Joshi H., 2013, INT J ADV RES COMPUT, V2
   Khan N, 2015, MACH VISION APPL, V26, P819, DOI 10.1007/s00138-015-0689-7
   Kirubarajan T, 2003, IEEE T AERO ELEC SYS, V39, P1452, DOI 10.1109/TAES.2003.1261143
   Kwon OS, 2010, IEEE T CONSUMER ELEC, V56
   LI G, 2016, SENSORS BASEL, V16, DOI DOI 10.3390/S16101601
   Li J, 2015, IEEE T CYBERNETICS, V45, P2707, DOI 10.1109/TCYB.2014.2381774
   Li J, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/59029
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Mills A, 2009, IMAGE VISION COMPUT, V27, P1593, DOI 10.1016/j.imavis.2009.03.004
   Perazzi F, 2015, COMPUT GRAPH FORUM, V34, P57, DOI 10.1111/cgf.12541
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   Song T, 2015, ELECTRON LETT, V51, P232, DOI 10.1049/el.2014.0981
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Welch G., 2001, P SIGGRAPH COURS, V8, P27599
   Xu W, 2013, MULTIMEDIA SYST, V19, P407, DOI 10.1007/s00530-013-0316-2
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
NR 38
TC 7
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1375
EP 1397
DI 10.1007/s11042-018-6116-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700007
DA 2024-07-18
ER

PT J
AU Li, P
   Liang, JL
   Shen, XB
   Zhao, MH
   Sui, LS
AF Li, Peng
   Liang, Junli
   Shen, Xubang
   Zhao, Minghua
   Sui, Liansheng
TI Textile fabric defect detection based on low-rank representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fabric defect detection; Eigen-value decomposition (EVD); Low-Rank
   Representation (LRR); Sparse matrix; Singular value decomposition (SVD);
   low-rank representation based on eigenvalue decomposition and blocked
   matrix (LRREB)
ID SPARSE; ALGORITHM; TEXTURE; IMAGES; DECOMPOSITION; REGULARITY;
   INSPECTION; FEATURES
AB In this paper, we propose a novel and robust fabric defect detection method based on the low-rank representation (LRR) technique. Due to the repeated texture structure we model a defects-free fabric image as a low-rank structure. In addition, because defects, if exist, change only the texture of fabric locally, we model them with a sparse structure. Based on the above idea, we represent a fabric image into the sum of a low-rank matrix which expresses fabric texture and a sparse matrix which expresses defects. Then, the LRR method is applied to obtain the corresponding decomposition. Especially, in order to make better use of low-rank structure characteristics we propose LRREB (low-rank representation based on eigenvalue decomposition and blocked matrix) method to improve LRR. LRREB is implemented by dividing a image into some corresponding blocked matrices to reduce dimensions and applying eigen-value decomposition (EVD) on blocked matrix instead of singular value decomposition (SVD) on original fabric image, which improves the accuracy and efficiency. No training samples are required in our methods. Experimental results show that the proposed fabric defect detection method is feasible, effective, and simple to be employed.
C1 [Li, Peng; Shen, Xubang] Xidian Univ, Sch Microelect, Xian, Shaanxi, Peoples R China.
   [Li, Peng; Zhao, Minghua; Sui, Liansheng] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
   [Liang, Junli] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
C3 Xidian University; Xi'an University of Technology; Northwestern
   Polytechnical University
RP Li, P (corresponding author), Xidian Univ, Sch Microelect, Xian, Shaanxi, Peoples R China.; Li, P (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian, Shaanxi, Peoples R China.
EM pengli@xaut.edu.cn
CR Abavisani M, 2018, INFORM FUSION, V39, P168, DOI 10.1016/j.inffus.2017.05.002
   Allili MS, 2014, IEEE T MULTIMEDIA, V16, P772, DOI 10.1109/TMM.2014.2298832
   [Anonymous], 2015, PROC CVPR IEEE
   Bai XL, 2014, IEEE T IND INFORM, V10, P2135, DOI 10.1109/TII.2014.2359416
   Basibüyük K, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P348, DOI 10.1109/ISCCSP.2008.4537248
   Bissi L, 2013, J VIS COMMUN IMAGE R, V24, P838, DOI 10.1016/j.jvcir.2013.05.011
   Bu HG, 2009, ENG APPL ARTIF INTEL, V22, P224, DOI 10.1016/j.engappai.2008.05.006
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Cao JJ, 2017, MULTIMED TOOLS APPL, V76, P4141, DOI 10.1007/s11042-015-3041-3
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chandra J. K., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P541, DOI 10.1109/RAICS.2011.6069371
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Feuillet V, 2012, NDT&E INT, V51, P58, DOI 10.1016/j.ndteint.2012.06.003
   Ghorai S, 2013, IEEE T INSTRUM MEAS, V62, P612, DOI 10.1109/TIM.2012.2218677
   Jianbing Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3481, DOI 10.1109/CVPR.2011.5995507
   Jiang J, 2012, IEEE T COMP PACK MAN, V2, P1536, DOI 10.1109/TCPMT.2012.2205149
   Kim JH, 2015, IEEE T IMAGE PROCESS, V24, P2658, DOI 10.1109/TIP.2015.2428933
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2002, IEEE T SYST MAN CY B, V32, P553, DOI 10.1109/TSMCB.2002.1033176
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Lee Y, 2014, IEEE T SEMICONDUCT M, V27, P223, DOI 10.1109/TSM.2014.2303473
   Li WC, 2011, IEEE T IND INFORM, V7, P136, DOI 10.1109/TII.2009.2034844
   Lin Z., 2009, Technical Report (No. UILU-ENG-09-2215
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu HX, 2010, IEEE T SEMICONDUCT M, V23, P141, DOI 10.1109/TSM.2009.2039185
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Mak K. L., 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P381, DOI 10.1109/ICGCS.2010.5543033
   Mak KL, 2009, IMAGE VISION COMPUT, V27, P1585, DOI 10.1016/j.imavis.2009.03.007
   Ngan HYT, 2008, PATTERN RECOGN, V41, P1878, DOI 10.1016/j.patcog.2007.11.014
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ngan HYT, 2010, PATTERN RECOGN, V43, P2132, DOI 10.1016/j.patcog.2009.12.001
   Ngan HYT, 2010, IEEE T AUTOM SCI ENG, V7, P58, DOI 10.1109/TASE.2008.2005418
   Pan Z, 2013, J LOW TEMP PHYS, V170, P436, DOI 10.1007/s10909-012-0671-y
   Patel VM, 2015, IEEE J-STSP, V9, P691, DOI 10.1109/JSTSP.2015.2402643
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Raheja JL, 2013, OPTIK, V124, P6469, DOI 10.1016/j.ijleo.2013.05.004
   Sezer OG, 2007, PATTERN RECOGN, V40, P121, DOI 10.1016/j.patcog.2006.05.023
   Shuyue Chen, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P857, DOI 10.1109/ICINFA.2010.5512449
   Tsai DM, 2013, IEEE T IND INFORM, V9, P122, DOI 10.1109/TII.2012.2209663
   Tsai DM, 2012, IEEE T IND INFORM, V8, P128, DOI 10.1109/TII.2011.2166797
   Wang CC, 2013, IEEE T SEMICONDUCT M, V26, P378, DOI 10.1109/TSM.2013.2261566
   Wang XS, 2012, IEEE T IMAGE PROCESS, V21, P3757, DOI 10.1109/TIP.2012.2194505
   Win M, 2015, IEEE T IND INFORM, V11, P642, DOI 10.1109/TII.2015.2417676
   Xie XH, 2007, IEEE T PATTERN ANAL, V29, P1454, DOI 10.1109/TPAMI.2007.1038
   Xu H, 2012, IEEE T INFORM THEORY, V58, P3047, DOI 10.1109/TIT.2011.2173156
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang X, 2013, LNCS, V8294, P475
   Yang X, 2013, LOCALITY DISCRIMINAT
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yin M, 2013, IEEE IMAGE PROC, P3770, DOI 10.1109/ICIP.2013.6738777
   Zhang TZ, 2013, IEEE I CONF COMP VIS, P281, DOI 10.1109/ICCV.2013.42
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang X, 2013, MATRIX ANAL APPL, P193
   ZHANG Xianda, 2013, MATRIX ANAL APPL, V2nd, P285
   Zhang Y, 2011, H SIN JAP OPT M BEIJ
   Zhang YH, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P652, DOI 10.1109/ICACC.2010.5486722
   Zhao YQ, 2015, IEEE T GEOSCI REMOTE, V53, P296, DOI 10.1109/TGRS.2014.2321557
   Zhu YY, 2014, PROC CVPR IEEE, P1542, DOI 10.1109/CVPR.2014.200
NR 63
TC 38
Z9 41
U1 2
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 99
EP 124
DI 10.1007/s11042-017-5263-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500006
DA 2024-07-18
ER

PT J
AU Simko, J
   Vrba, J
AF Simko, Jakub
   Vrba, Jakub
TI Screen recording segmentation to scenes for eye-tracking analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Video segmentation; Scenes; User interface; User
   experience studies; Eye-tracking
AB In usability studies involving eye-tracking, quantitative analysis of gaze data requires the information about so called scene occurrences. Scene ocurrences are time segments during which the application user interface remains more-less static, so gaze events (e.g., fixations) can be mapped to the particular areas of interest (user interface elements). The scene occurrences typically start and end by user interface changes such as page-to-page transitions, menu expansions, overlay propmts, etc. Normally, one would record such changes programmatically through application logging, yet in many studies, this is not possible. For example, in an early-prototype mobile-app testing, only a camera recording of a smart device screen is often available as evidence. In such cases, analysts must manually annotate the recordings. To reduce the need for manual annotation of scene occurrences, we present an image processing method for segmenting user interface video recordings. The method exploits specific properties of user interface recordings, which greatly differ from real world video shots (for which many segmentation methods exist). The core of our method lies in the use of SSIM and SIFT similarity metrics used on video frames (with several pre-processing and filtering procedures). The main advantage of our method is, that it requires no training data apart from single screenshot example for each scene (to which the recording frames are compared). The method is also able to work with user finger overlays, which are always present in mobile device recordings. We evaluate the accuracy of our method over recordings from several real-life studies and compare it with other image similarity techniques.
C1 [Simko, Jakub; Vrba, Jakub] Slovak Univ Technol Bratislava, Ilkovicova 2, Bratislava 84216, Slovakia.
C3 Slovak University of Technology Bratislava
RP Simko, J (corresponding author), Slovak Univ Technol Bratislava, Ilkovicova 2, Bratislava 84216, Slovakia.
EM jakub.simko@stuba.sk; kubo.vrba@gmail.com
RI Simko, Jakub/AAI-8565-2020
OI Simko, Jakub/0000-0003-0239-4237
FU Scientific Grant Agency of the Slovak Republic [VG 1/0646/15]; Slovak
   Research and Development Agency [APVV-15-0508]; Ministry of Education,
   Science, Research and Sport of the Slovak Republic within the Research
   and Development Operational Programme [ITMS 26240220084]; ERDF
FX This work was partially supported by the Scientific Grant Agency of the
   Slovak Republic, grant No. VG 1/0646/15, the Slovak Research and
   Development Agency under the contract No. APVV-15-0508 and was created
   with the support of the Ministry of Education, Science, Research and
   Sport of the Slovak Republic within the Research and Development
   Operational Programme for the project "University Science Park of STU
   Bratislava", ITMS 26240220084, co-funded by the ERDF.
CR [Anonymous], P 2016 ACM S DOC ENG
   [Anonymous], P 1 INT C INT INT TE
   [Anonymous], 2011, 22 INT JT C ART INT, DOI 10.5555/2283516.2283603
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   Ba Tu Truong, 2000, Proceedings ACM Multimedia 2000, P219, DOI 10.1145/354384.354481
   Banovic N, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P83
   Bao LF, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P673, DOI 10.1109/ICSE.2015.220
   Chang TH, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1535
   Dixon M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2231, DOI 10.1145/2556288.2556979
   Dixon M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1525
   Givens P, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P1165, DOI 10.1109/ICSE.2013.6606669
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Koch G., 2015, P ICML DEEP LEARN WO, V2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LubomirBourdev ShaiAvidan, 2011, P 24 ANN ACM S USER, P135, DOI DOI 10.1145/2047196.2047213.URL
   Mendi E, 2010, PROCEEDINGS OF THE 48TH ANNUAL SOUTHEAST REGIONAL CONFERENCE (ACM SE 10), P328, DOI 10.1145/1900008.1900096
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Tahaghoghi S., 2005, PROC 28 AUSTRALASIAN, P193
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   TONOMURA Y, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P131
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang RX, 2016, IEEE T IMAGE PROCESS, V25, P2117, DOI 10.1109/TIP.2016.2541318
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yeh T, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P183
NR 27
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2401
EP 2425
DI 10.1007/s11042-018-6369-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700049
DA 2024-07-18
ER

PT J
AU Song, SL
   Huang, HT
   Ruan, TX
AF Song, Shengli
   Huang, Haitao
   Ruan, Tongxiao
TI Abstractive text summarization using LSTM-CNN based deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text mining; Abstractive text summarization; Relation extraction; Deep
   learning
AB The Abstractive Text Summarization (ATS), which is the task of constructing summary sentences by merging facts from different source sentences and condensing them into a shorter representation while preserving information content and overall meaning. It is very difficult and time consuming for human beings to manually summarize large documents of text. In this paper, we propose an LSTM-CNN based ATS framework (ATSDL) that can construct new sentences by exploring more fine-grained fragments than sentences, namely, semantic phrases. Different from existing abstraction based approaches, ATSDL is composed of two main stages, the first of which extracts phrases from source sentences and the second generates text summaries using deep learning. Experimental results on the datasets CNN and DailyMail show that our ATSDL framework outperforms the state-of-the-art models in terms of both semantics and syntactic structure, and achieves competitive results on manual linguistic quality evaluation.
C1 [Song, Shengli] Xidian Univ, Software Engn Inst, Xian 710071, Shaanxi, Peoples R China.
   [Song, Shengli; Huang, Haitao; Ruan, Tongxiao] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University
RP Song, SL (corresponding author), Xidian Univ, Software Engn Inst, Xian 710071, Shaanxi, Peoples R China.; Song, SL (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM xidiansls@163.com
CR Angeli G., 2014, P 2014 C EMP METH NA, P1556, DOI DOI 10.3115/V1/D14-1164
   [Anonymous], ARXIV12012240
   [Anonymous], 2016, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N16-1012
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], 2003, P 2003 C N AM CHAPT
   [Anonymous], 2015, P 2015 C N AM CHAPT
   [Anonymous], 2015, ARXIV150601057
   [Anonymous], 2008, COLING 2008 P WORKSH, DOI DOI 10.3115/1613172.1613178
   [Anonymous], 2016, Abstractive text summarization using sequence-to-sequence rnns and beyond
   [Anonymous], EMNLP
   [Anonymous], 2015, CORR, DOI DOI 10.48550/ARXIV.1512.01712
   [Anonymous], 2015, ARXIV150601597
   [Anonymous], 2016, ARXIV160307252
   [Anonymous], 2015, ARXIV150900685, DOI DOI 10.18653/V1/D15-1044
   [Anonymous], 2016, ARXIV160306393
   Cao Z, 2016, ARXIV160400125
   Chen M., 2013, ARXIV13016770
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Nallapati R, 2017, AAAI CONF ARTIF INTE, P3075
   Ribeiro R, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P845
   Riedhammer K, 2010, SPEECH COMMUN, V52, P801, DOI 10.1016/j.specom.2010.06.002
   Wong K. F., 2008, P 22 INT C COMPUTATI, P985, DOI DOI 10.3115/1599081.1599205
   Yousefi-Azar M, 2017, EXPERT SYST APPL, V68, P93, DOI 10.1016/j.eswa.2016.10.017
   Zhang Y., 2017, Advances in Neural Information Processing Systems, P4172
   Zhou QY, 2018, ELECTRON COMMER RES, V18, P109, DOI 10.1007/s10660-017-9265-8
   Zhou QY, 2016, CLUSTER COMPUT, V19, P2109, DOI 10.1007/s10586-016-0655-9
   Zhou QY, 2016, CLUSTER COMPUT, V19, P1275, DOI 10.1007/s10586-016-0580-y
NR 27
TC 130
Z9 142
U1 1
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 857
EP 875
DI 10.1007/s11042-018-5749-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500049
DA 2024-07-18
ER

PT J
AU Meng, WZ
   Li, WJ
   Wong, DCS
AF Meng, Weizhi
   Li, Wenjuan
   Wong, Duncan S.
TI Enhancing touch behavioral authentication via cost-based intelligent
   mechanism on smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Behavioral biometrics; Touch dynamics; User authentication; Smartphone
   usability; Intelligent mechanism; Machine learning
ID USER AUTHENTICATION; ADVERSARY MODEL; MOBILE; IDENTIFICATION;
   VERIFICATION; SECURITY
AB Due to the popularity of smartphones, there is a great need to deploy appropriate authentication mechanisms to safeguard users' sensitive data. Touch dynamics-based authentication has been developed to verify smartphone users and detect imposters. These schemes usually employ machine learning techniques to detect behavioral anomalies by comparing current behavioral actions with the stored normal model. However, we notice that machine learning classifiers often have an unstable performance, which would greatly reduce the system usability, i.e., causing a high false rejection. In this work, we are motivated by this challenge and design a cost-based intelligent mechanism that can choose a less costly algorithm for user authentication. In the evaluation, we conduct a user study with a total of 60 users to investigate the performance of our mechanism with a lightweight touch gesture-based scheme on smartphones. Experimental results demonstrate that our approach can help achieve a relatively higher and more stable authentication accuracy, as compared to the use of a sole classifier.
C1 [Meng, Weizhi] Tech Univ Denmark, DTU Compute, Anker Engelunds Vej 1, Lyngby, Denmark.
   [Li, Wenjuan] City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
   [Wong, Duncan S.] Hong Kong Appl Sci & Technol, Res Inst, Shatin, Hong Kong, Peoples R China.
C3 Technical University of Denmark; City University of Hong Kong; Hong Kong
   Applied Science & Technology Research Institute Company Limited (ASTRI)
RP Meng, WZ (corresponding author), Tech Univ Denmark, DTU Compute, Anker Engelunds Vej 1, Lyngby, Denmark.
EM weme@dtu.dk; wenjuan.li@my.cityu.edu.hk
RI Li, Wenjuan/AAE-4027-2019; Meng, Weizhi/N-9638-2019
OI Li, Wenjuan/0000-0003-3745-5669; Meng, Weizhi/0000-0003-4384-5786
CR [Anonymous], WEKA WAIK ENV KNOWL
   [Anonymous], 2014, Proceedings of the 29th Annual ACM Symposium on Applied Computing
   Aviv AJ, 2010, 4 USENIX WORKSHOP OF, V10, P1
   Bergadano F., 2002, ACM Transactions on Information and Systems Security, V5, P367, DOI 10.1145/581271.581272
   Cahyani NDW, 2017, CONCURRENCY COMPUTAT, V29
   Chang L, 2015, SMARTPHONE USAGE SOA
   Clarke NL, 2007, INT J INF SECUR, V6, P1, DOI 10.1007/s10207-006-0006-6
   Clarke NL, 2005, COMPUT SECUR, V24, P519, DOI 10.1016/j.cose.2005.08.003
   D'Orazio Christian J., 2017, IEEE Internet of Things Journal, V4, P524, DOI 10.1109/JIOT.2016.2569094
   D'Orazio C, 2016, COMPUT SECUR, V56, P94, DOI 10.1016/j.cose.2015.06.009
   D'Orazio CJ, 2017, FUTURE GENER COMP SY, V74, P366, DOI 10.1016/j.future.2016.08.019
   Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164
   Dunphy P., Proceedings of the Sixth Symposium on Usable Privacy and Security (SOUPS '10), P1, DOI [10.1145/1837110.1837114, DOI 10.1145/1837110.1837114]
   Feng T, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P451, DOI 10.1109/THS.2012.6459891
   Fiorella D, 2010, J MULTIMODAL USER IN, V4, P3, DOI 10.1007/s12193-009-0034-4
   Florencio D., 2007, Proceedings of the 16th international conference on World Wide Web-WWW'07, P657, DOI DOI 10.1145/1242572.1242661
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Gaffney JE, 2001, P IEEE S SECUR PRIV, P50, DOI 10.1109/SECPRI.2001.924287
   Goel M, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P545
   Gong NZ, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P499, DOI 10.1145/2897845.2897908
   Gu G., 2006, ACM S INFORM COMPUTE, P90, DOI [10.1145/1128817.1128834, DOI 10.1145/1128817.1128834]
   Gunson N, 2011, INTERACT COMPUT, V23, P57, DOI 10.1016/j.intcom.2010.10.001
   IDC, 2017, SMARTPH OS MARK SHAR
   Karlson AK, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1647
   Keith M, 2007, INT J HUM-COMPUT ST, V65, P17, DOI 10.1016/j.ijhcs.2006.08.005
   Kim D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1093
   Kotthoff L, 2012, AI COMMUN, V25, P257, DOI 10.3233/AIC-2012-0533
   Lemos R, 2002, PASSWORDS WEAKEST LI
   Li J, 2018, COMPUT SECUR, V72, P1, DOI 10.1016/j.cose.2017.08.007
   Li J, 2017, IEEE SYST J, V11, P439, DOI 10.1109/JSYST.2015.2415835
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Meng WZ, 2017, COMPUT SECUR, V65, P213, DOI 10.1016/j.cose.2016.11.010
   Meng WZ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4818, DOI 10.1145/2858036.2858547
   Meng WZ, 2016, LECT NOTES COMPUT SC, V9696, P629, DOI 10.1007/978-3-319-39555-5_34
   Meng WZ, 2016, INF COMPUT SECUR, V24, P277, DOI 10.1108/ICS-12-2014-0078
   Meng WZ, 2015, IEEE COMMUN SURV TUT, V17, P1268, DOI 10.1109/COMST.2014.2386915
   Meng YX, 2011, ADV INTEL SOFT COMPU, V124, P573
   Millennial Media, 2012, MOB MIX MOB DEV IND
   Mobile and NCSA, 2012, REP CONS BEH PERC MO
   Numabe Yusuke, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P899, DOI 10.1109/ISCE.2009.5156942
   Pokharel S, 2017, COMPUT STAND INTER, V49, P71, DOI 10.1016/j.csi.2016.09.002
   Potharaju R, 2012, LECT NOTES COMPUT SC, V7159, P106, DOI 10.1007/978-3-642-28166-2_11
   Pusara M., 2004, P 2004 ACM WORKSHOP, P1, DOI DOI 10.1145/1029208.1029210
   Quick D, 2017, J NETW COMPUT APPL, V86, P24, DOI 10.1016/j.jnca.2016.11.018
   Ranjan J, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P361, DOI 10.1145/2968219.2971370
   Sae-Bae N, 2014, IEEE T INF FOREN SEC, V9, P568, DOI 10.1109/TIFS.2014.2302582
   Saevanee H, 2009, 2009 6TH IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, VOLS 1 AND 2, P1078
   Schaub F., 2012, Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia - MUM'12, P1
   Schmid NA, 2006, IEEE T INF FOREN SEC, V1, P154, DOI 10.1109/TIFS.2006.873603
   Shabtai A, 2010, IEEE SECUR PRIV, V8, P35, DOI 10.1109/MSP.2010.2
   Shahzad M, 2017, IEEE T MOBILE COMPUT, V16, P2726, DOI 10.1109/TMC.2016.2635643
   Sharma V, 2017, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON SECURITY AND PRIVACY IN WIRELESS AND MOBILE NETWORKS (WISEC 2017), P1, DOI 10.1145/3098243.3098262
   Smith-Creasey Max, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P104, DOI 10.1109/PST.2016.7906944
   Sommer R, 2010, P IEEE S SECUR PRIV, P305, DOI 10.1109/SP.2010.25
   Song YP, 2017, P IEEE S SECUR PRIV, P357, DOI 10.1109/SP.2017.54
   Tari F., 2006, Proceedings of the second symposium on Usable privacy and security, P56, DOI [DOI 10.1145/1143120.1143128, 10.1145/1143120.1143128.]
   Teh PinShen., 2015, Proceedings of the 13th International Conference on Advances in Mobile Computing and Multimedia, P108
   Temper M, 2015, PROCEEDINGS 2015 FIRST INTERNATIONAL CONFERENCE ON SOFTWARE SECURITY AND ASSURANCE (ICSSA 2015), P30, DOI 10.1109/ICSSA.2015.016
   Nguyen TV, 2017, COMPUT SECUR, V66, P115, DOI 10.1016/j.cose.2017.01.008
   Trewin S, 2012, 28TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2012), P159
   Van Thanh D, 2000, 11TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, PROCEEDINGS, P412, DOI 10.1109/DEXA.2000.875060
   Wallace R, 2012, IEEE T INF FOREN SEC, V7, P553, DOI 10.1109/TIFS.2012.2184095
   Yan J, 2004, IEEE SECUR PRIV, V2, P25, DOI 10.1109/MSP.2004.81
   Yuxin Meng, 2013, Information Security and Cryptology. 8th International Conference, Inscrypt 2012. Revised Selected Papers, P331, DOI 10.1007/978-3-642-38519-3_21
   Yuxin Meng, 2012, Proceedings of the 2012 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications (CIMSA), P108, DOI 10.1109/CIMSA.2012.6269608
   Zahid S, 2009, LECT NOTES COMPUT SC, V5758, P224, DOI 10.1007/978-3-642-04342-0_12
   Zhao X, 2014, IEEE T INF FOREN SEC, V9, DOI 10.1109/TIFS.2014.2350916
   Zheng N, 2014, I C NETWORK PROTOCOL, P221, DOI 10.1109/ICNP.2014.43
NR 70
TC 14
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30167
EP 30185
DI 10.1007/s11042-018-6094-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600001
DA 2024-07-18
ER

PT J
AU Yahia, S
   Ben Salem, Y
   Abdelkrim, MN
AF Yahia, Samah
   Ben Salem, Yassine
   Abdelkrim, Mohamed Naceur
TI Texture analysis of magnetic resonance brain images to assess multiple
   sclerosis lesions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MR images; Noise level; Intensity non-uniformity; DDP; GLCM; LBP;
   SVM
ID CLASSIFICATION; RECOGNITION; COOCCURRENCE
AB The novel contribution of this work is to introduce a new promising method for the analysis of textures: the Decimal Descriptor Patterns (DDP). Two best known methods of texture measures, always considered as references in image analysis are chosen for comparison: the Local Binary Patterns (LBP) and the Grey Level Co-occurrence Matrix (GLCM). We realized numerous experimentations for analyzing the brain Magnetic Resonance (MR) images in order to demonstrate the interest of our proposition. We used the 3D Brainweb database with two brain MR images sequences, and different levels of noise and intensity non-uniformity. This way accuracy of the three methods is tested in front on the image artifacts. Tests of classification are performed in the same conditions of work by means of the classifier multiclass Support Vector Machines (SVM). Experimental results demonstrate clearly the robustness and the stability of the proposed approach with respect to the noise level, intensity non-uniformity and to different T1- and T2- weighted MR images.
C1 [Yahia, Samah; Ben Salem, Yassine; Abdelkrim, Mohamed Naceur] Univ Gabes Tunisia, Natl Engn Sch Gabes ENIG, Res Lab Modeling Anal & Control Syst MACS, Gabes, Tunisia.
C3 Universite de Gabes
RP Yahia, S (corresponding author), Univ Gabes Tunisia, Natl Engn Sch Gabes ENIG, Res Lab Modeling Anal & Control Syst MACS, Gabes, Tunisia.
EM ysamah4@gmail.com; bensalemy73@yahoo.fr; naceur.abdelkrim@enig.rnu.tn
RI Samah, Yahia/KBC-7632-2024; Salem, Yassine Ben/X-8861-2019
OI Samah, Yahia/0000-0001-8680-1033; Salem, Yassine Ben/0000-0002-5191-4932
CR [Anonymous], INT C COMM COMP CONT
   [Anonymous], HDB FACE RECOGNITION
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Ben Salem Y, 2010, SIGNAL IMAGE VIDEO P, V4, P429, DOI 10.1007/s11760-009-0132-5
   Chang CW, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00066
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Chen WS, 2009, LECT NOTES COMPUT SC, V5558, P1122, DOI 10.1007/978-3-642-01793-3_113
   Cocosco C.A., 1997, NeuroImage
   Cuadra MB, 2002, LECT NOTES COMPUT SC, V2488, P290
   Deepa T, 2015, J ENG APPL SCI ASIAN, V10, P3621
   Eichkitz C, 2014, 76 EAGE C EXH, P2014
   Gao X, 2011, RETRIEVAL 3D MED IMA
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Haralick R.M., 1972, P S COMP IM PROC REC, V2, P12
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Michoux N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145497
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ortiz A, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/638563
   Patel SM, 2016, INT J INFORM, V6, P223
   Tsai F, 2007, LECT NOTES COMPUT SC, V4679, P429
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Yahia Samah, 2016, 2016 17th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA). Proceedings, P328, DOI 10.1109/STA.2016.7952047
   Yang ZY, 2018, CLUSTER COMPUT, V21, P1561, DOI 10.1007/s10586-018-2141-z
   Yazdania S, 2014, BRAIN TISSUE CLASSIF
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 30
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30769
EP 30789
DI 10.1007/s11042-018-6160-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600029
DA 2024-07-18
ER

PT J
AU Chen, JY
   Xu, RY
   Liu, LY
AF Chen, Jingying
   Xu, Ruyi
   Liu, Leyuan
TI Deep peak-neutral difference feature for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Facial-expression feature; Deep neutral
   network
ID SALIENCY
AB Facial expression recognition (FER) is important in vision-related applications. Deep neural networks demonstrate impressive performance for face recognition; however, it should be noted that this method relies heavily on a great deal of manually labeled training data, which is not available for facial expressions in real-world applications. Hence, we propose a powerful facial feature called deep peak-neutral difference (DPND) for FER. DPND is defined as the difference between two deep representations of the fully expressive (peak) and neutral facial expression frames. The difference tends to emphasize the facial parts that are changed in the transition from the neutral to the expressive face and to eliminate the face identity information retained in the fine-tuned deep neural network for facial expression, the network has been trained on large-scale face recognition dataset. Furthermore, unsupervised clustering and semi-supervised classification methods are presented to automatically acquire the neutral and peak frames from the expression sequence. The proposed facial expression feature achieved encouraging results on public databases, which suggests that it has strong potential to recognize facial expressions in real-world applications.
C1 [Chen, Jingying; Xu, Ruyi; Liu, Leyuan] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
C3 Central China Normal University
RP Liu, LY (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Hubei, Peoples R China.
EM chenjy@mail.ccnu.edu.cn; xuruyicv@163.com; lyliu@mail.ccnu.edu.cn
FU National Social Science Foundation of China [16BSH107]
FX This work was supported by the National Social Science Foundation of
   China (Grant no. 16BSH107).
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   An L, 2015, NEUROCOMPUTING, V149, P354, DOI 10.1016/j.neucom.2014.04.072
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Chen JY, 2016, COMPUTING, V98, P215, DOI 10.1007/s00607-014-0430-9
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   Dapogny Arnaud., 2017, IEEE Transactions on Affective Computing, P1, DOI DOI 10.1109/TAFFC.2017
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Lee SH, 2014, IEEE T AFFECT COMPUT, V5, P340, DOI 10.1109/TAFFC.2014.2346515
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li YF, 2015, IEEE T PATTERN ANAL, V37, P175, DOI 10.1109/TPAMI.2014.2299812
   Liu M., 2013, Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on, P1, DOI DOI 10.1109/FG.2013.6553734
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P366, DOI 10.1109/TCYB.2013.2256347
   Lu XQ, 2013, IEEE T CIRC SYST VID, V23, P2022, DOI 10.1109/TCSVT.2013.2244798
   Luo ZZ, 2016, COMM COM INF SC, V662, P119, DOI 10.1007/978-981-10-3002-4_10
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2014, IEEE-RAS INT C HUMAN, P1098, DOI 10.1109/HUMANOIDS.2014.7041505
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Scherer S., 2013, AUTOMATIC FACE GESTU, P1
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang Y, 2013, ARXIV
   Wang Z, 2012, 2012 IEEE INFORMATION THEORY WORKSHOP (ITW), P222, DOI [10.1109/ICNC.2012.6234551, 10.1109/ITW.2012.6404663]
   Wei-Lun Chao, 2015, Signal Processing, V117, P1, DOI 10.1016/j.sigpro.2015.04.007
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang X, 2015, MACH VISION APPL, V26, P467, DOI 10.1007/s00138-015-0677-y
   Zhao J, 2017, IEEE T CIRC SYST VID, P1
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
NR 47
TC 20
Z9 23
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29871
EP 29887
DI 10.1007/s11042-018-5909-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800039
DA 2024-07-18
ER

PT J
AU Ma, CC
   Zhang, JG
   Xu, SB
   Meng, WL
   Xi, RP
   Kumar, GH
   Zhang, XP
AF Ma, Chengcheng
   Zhang, Jiguang
   Xu, Shibiao
   Meng, Weiliang
   Xi, Runping
   Kumar, G. Hemantha
   Zhang, Xiaopeng
TI Accurate blind deblurring using salientpatch-based prior for large-size
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deblurring; SalientPatch; Kernel estimation; Segmentation; Large-size
AB The full-image based kernel estimation strategy is usually susceptible by the smooth and fine-scale background regions impacting and it is time-consuming for large-size image deblurring. Since not all the pixels in the blurred image are informative and it is frequent to restore human-interested objects in the foreground rather than background, we propose a novel concept "SalientPatch" to denote informative regions for better blur kernel estimation without user guidance by computing three cues (objectness probability, structure richness and local contrast). Although these cues are not new, it is innovative to integrate and complement each other in motion blur restoration. Experiments demonstrate that our SalientPatch-based deblurring algorithm can significantly speed up the kernel estimation and guarantee high-quality recovery for large-size blurry images as well.
C1 [Ma, Chengcheng; Xi, Runping] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Ma, Chengcheng] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Ma, Chengcheng; Xu, Shibiao; Meng, Weiliang; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Zhang, Jiguang; Kumar, G. Hemantha] Univ Mysore, Dept Comp Sci, Mysore, Karnataka, India.
C3 Northwestern Polytechnical University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Chinese Academy of
   Sciences; Institute of Automation, CAS; University of Mysore
RP Xu, SB; Zhang, XP (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM shibiao.xu@ia.ac.cn; xiaopeng.zhang@ia.ac.cn
FU National Natural Science Foundation of China [61620106003, 61671451,
   61572405, 61502490, 61571439, 61771026]; Open Projects Program of
   National Laboratory of Pattern Recognition [201600038]; Independent
   Research Project of National Laboratory of Pattern Recognition
   [Z-2018005, 6140001010207]
FX This work is supported in part by National Natural Science Foundation of
   China with Nos. 61620106003, 61671451, 61572405, 61502490, 61571439,
   61771026, in part by the Open Projects Program of National Laboratory of
   Pattern Recognition with No. 201600038, and in part by the Independent
   Research Project of National Laboratory of Pattern Recognition with No.
   Z-2018005 and Project 6140001010207.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2014, ECCV
   [Anonymous], 2014, FAST EDGE DETECTION
   [Anonymous], 2013, ICCV
   [Anonymous], 2012, P AS C COMP VIS
   Bloice MD, 2017, AUGMENTOR IMAGE AUGM
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45
   Hradis M., 2015, P BMVC, P1
   Hu Z, 2015, INT J COMPUT VISION, V115, P345, DOI 10.1007/s11263-015-0821-1
   Kotera Jan, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P59, DOI 10.1007/978-3-642-40246-3_8
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Sun X, 2017, 7 INT C INF SCI TECH
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Wang R., 2014, ARXIV PREPRINT ARXIV
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang Pingping, 2017, LEARNING UNCERTAIN C
   Zhang Q, 2018, VISUAL COMPUT, V34, P473, DOI 10.1007/s00371-017-1354-0
NR 29
TC 4
Z9 5
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28077
EP 28100
DI 10.1007/s11042-018-6009-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500015
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Sanyal, G
AF Mukherjee, Srilekha
   Sanyal, Goutam
TI A chaos based image steganographic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Brownian based scrambling; Peak signal to noise ratio
   (PSNR); Structural similarity index measure (SSIM); Cross-correlation
   coefficient
ID ENCRYPTION SCHEME; OPTIMIZATION; CAPACITY; MAP
AB This paper presents a steganographic technique using the theory of Brownian motion. In the beginning, the Brownian Based Scrambling procedure introduces traces of non linearity in the carrier medium so as to introduce one layer of security. A lighter pixel (in terms of its intensity) is presumed to experience a faster movement than the heavier ones. The above stated concept is based on the randomized scrambling strategy which is usually chaotic in nature. It actually reflects the strategy of chaos generation in the image medium. The 'key' is generated from the Brownian theories and is being utilized in the Power Modulus Scrambling strategy to increase the security level. In addition, the embedding technique, i.e. Pixel Insertion Methodology is also dependent on certain correlation factors of Brownian motion. The performance has been worked out to establish the efficacy of the algorithm. This whole procedure supports high embedding capacity. The experimental results show that the proposed technique performs better or at least at par with respect to many of the existing steganographic techniques. The results have been tested against various benchmarks, as illustrated in the section of experimental results. This approach can be used to provide an additional layer of protection to any system that communicates important data/information through any kind of globally accessed medium. Moreover, this approach serves its purpose of providing seamless security between sender and receiver without producing any distortion in the images. This explicit concept may be used in cyber-security for prevention of unauthorized access of information.
C1 [Mukherjee, Srilekha; Sanyal, Goutam] Natl Inst Technol, Dept CSE, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Mukherjee, S (corresponding author), Natl Inst Technol, Dept CSE, Durgapur, India.
EM srilekha.mukherjee3@gmail.com; nitgsanyal@gmail.com
RI SANYAL, GOUTAM/AAI-6613-2020; Mukherjee, Srilekha/ABA-7026-2020
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Almohammad A., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P215, DOI 10.1109/IPTA.2010.5586786
   Alsmirat MA, 2017, IMPACT DIGITAL FINGE, P1
   Amirtharajan Rengarajan, 2012, Journal of Applied Sciences, V12, P428, DOI 10.3923/jas.2012.428.439
   [Anonymous], INT J COMPUT INFORM
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2008, 5 IEEE INT WORKSH SI
   Banerjee I, 2015, INT J ELECTRON SECUR, V7, P345
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bhattacharyya S., 2012, INT J APPL INF SYST, V2, P42
   CHANDRAMOULI R, 2003, IWDW, P35
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Dukkipati A, 2012, APPL MATH COMPUT, V218, P11674, DOI 10.1016/j.amc.2012.05.052
   Duncan K, 2012, IEEE IMAGE PROC, P1093, DOI 10.1109/ICIP.2012.6467054
   El-Emam NN, 2015, COMPUT SECUR, V55, P21, DOI 10.1016/j.cose.2015.06.012
   Feng JH, 2017, MULTIMED TOOLS APPL, V76, P17405, DOI 10.1007/s11042-016-3907-z
   Ferzli R, 2010, P SPIE
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hansen BE, 2015, ECONOMET THEOR, V31, P337, DOI 10.1017/S0266466614000322
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kekre H, 2009, WORLD ACAD SCI ENG T, V27, P609
   Khan F, 2008, 4 IEEE GCC C EXH GUL
   Koo HI, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013020
   Lee MC, 2017, COMPUT SECUR, V69, P142, DOI 10.1016/j.cose.2016.12.009
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Malik F, 2011, J THEOR APPL INF TEC, V34
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Mukherjee Srilekha, 2017, International Journal of Computers and Applications, V39, P59, DOI 10.1080/1206212X.2016.1273624
   MUKHERJEE S, 2015, TENCON IEEE REGION, pN1582
   Mukherjee S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P406, DOI 10.1109/ICRCICN.2015.7434273
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Panjabi P, 2013, INT J COMPUTER APPL, V74, P36
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2009, IEEE AS PAC SERV COM, P1322
   Safarpour M, 2016, CAPACITY ENLARGEMENT
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P3469
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Wang YP, 2013, ADV INTELL SYST, V180, P101
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 50
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 27851
EP 27876
DI 10.1007/s11042-018-5996-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500006
DA 2024-07-18
ER

PT J
AU Shin, J
   Kim, M
   Paek, Y
   Ko, K
AF Shin, Jangseop
   Kim, MoonKwon
   Paek, Yunheung
   Ko, Kwangman
TI Developing a custom DSP for vision based human computer interaction
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Human computer interaction; Image recognition; Digital
   signal processor
AB As the computing power of modern devices become greater, computer vision is increasingly adopted as the means of human-computer interaction. The industry is struggling hard to bring computer vision into the mobile domain, but there are some difficulties mainly due to the computationally expansive nature of vision applications. On the other hand, there are various kinds of vision applications, which means using fixed hardware block will meet the performance criteria, but it will be possible to run only one application. To meet our needs, we can use another programmable component that is specialized for parallel processing and has domain specific instructions. In this paper, we introduce our work on the development of a low-power VLIW processor with vision-application specific parallel computation logic and a set of application-specific instructions, to improve the processor's performance while reducing the power consumption. Our VLIW processor accelerates by adding special instructions on the application's specific part in which processes heavy computation. We introduce our work on developing a custom DSP for vision system that includes designing the processor with Synopsys Processor Designer tool, and porting LLVM compiler. As the target, we ported a hand recognition application to our system, which we have constructed on Xilinx Zynq evaluation board. Even though our DSP was run at much lower frequency, it could run compute intensive part of the application four times faster than ARM processor, greatly speeding up the whole application.
C1 [Shin, Jangseop; Kim, MoonKwon; Paek, Yunheung] Seoul Natl Univ, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Ko, Kwangman] Sangji Univ, 83 Sangjidaegil, Wonjusi 220702, Gangwondo, South Korea.
C3 Seoul National University (SNU); Sangji University
RP Ko, K (corresponding author), Sangji Univ, 83 Sangjidaegil, Wonjusi 220702, Gangwondo, South Korea.
EM jsshin@sor.snu.ac.kr; mkkim@sor.snu.ac.kr; ypaek@sor.snu.ac.kr;
   kkman@sangji.ac.kr
FU National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [NRF-2017R1A2A1A17069478]; Brain Korea 21 Plus Project; Inter-University
   Semiconductor Research Center (ISRC); IDEC
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP)
   (NRF-2017R1A2A1A17069478), Brain Korea 21 Plus Project in 2018, IDEC,
   and Inter-University Semiconductor Research Center (ISRC). The ICT at
   Seoul National University provides research facilities for this study.
CR Barry B, 2015, IEEE MICRO, V35, P56, DOI 10.1109/MM.2015.10
   Bayazit M., 2009, P IAPR C MACH VIS AP, P9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gupta A, 2012, PROC TECH, V1, P98, DOI 10.1016/j.protcy.2012.10.013
   Kwon D, 2016, MULTIMED TOOLS APPL, P1
   Kyo S, 2009, HOT CHIPS, V21
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/CGO.2004.1281665
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Oh J, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.90
   Piao J-C, 2015, MULTIMED TOOLS APPL, P1
   SHI Y, 2006, IEEE 7 INT C EL PACK, P1
   Wang Y, 2016, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-48310-7
   Nguyen XT, 2012, IEEE INT SYMP SIGNAL, P286, DOI 10.1109/ISSPIT.2012.6621302
   Zynq X, 2015, 7000 ALL PROGRAMMABL
NR 14
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30051
EP 30065
DI 10.1007/s11042-018-6171-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800050
DA 2024-07-18
ER

PT J
AU Beulah, A
   Sharmila, TS
   Pramod, VK
AF Beulah, A.
   Sharmila, T. Sree
   Pramod, V. K.
TI Disc bulge diagnostic model in axial lumbar MR images using
   Intervertebral disc Descriptor (IdD)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disc bulge; Histogram of oriented gradients; Low back pain; Lumbar
   spine; MRI; Support vector machine
ID BACK-PAIN
AB One of the common types of lumbar disc disease is bulging which cause low back pain, tingling, and numbness. An automatic diagnostic system to detect the disc pathology would be helpful to the radiologist. A computer aided diagnostic system is proposed to identify the disc bulge in axial lumbar spine MR images. A new EM based segmentation method is applied to segment the Intervertebral Disc (IVD) from the axial slice of T2-weighted MRI. After segmentation, the features are extracted by executing Histogram of Oriented Gradients (HOG) and a novel feature descriptor called as Intervertebral disc Descriptor (IdD). The features obtained are trained by Support Vector Machine(SVM). In this work, T2-weighted axial slices of lumbar MR images for 93 patients are used for evaluation. The proposed framework is trained, tested and validated on 675 clinical axial MR images of 93 patients, in which 184 are normal, 55 are herniated, and 436 are bulged images. On applying the proposed system, an accuracy of 92.78% is obtained for classifying normal and bulge and compared with different classifiers such as k-nn, decision trees and feed forward neural network. This model produces high accuracy, sensitivity, specificity, and f-score to detect bulge in the MRI. The model built with SVM produces a better result when compared with k-nn, decision trees and feed forward neural network. Also, the same model can be applied to detect other disc pathologies such as desiccation and degeneration.
C1 [Beulah, A.] Sri Sivasubramaniya Nadar Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
   [Sharmila, T. Sree] Sri Sivasubramaniya Nadar Coll Engn, Dept Informat Technol, Madras, Tamil Nadu, India.
   [Pramod, V. K.] Trivandrum Med Coll, Dept Orthopaed, Thiruvananthapuram, Kerala, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Beulah, A (corresponding author), Sri Sivasubramaniya Nadar Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
EM beulaharul@ssn.edu.in; sreesharmilat@ssn.edu.in; pvalsalam@gmail.com
RI Beulah, A./Y-4433-2019; T., Sree Sharmila/ABC-3930-2021
OI T., Sree Sharmila/0000-0001-5744-9739; T, Sree
   Sharmila/0009-0009-1736-2669
CR Alomari RS, 2010, INT J COMPUT ASS RAD, V5, P287, DOI 10.1007/s11548-009-0396-9
   [Anonymous], 2017, INT C COMP COMM SIGN
   Castellano G, 2004, CLIN RADIOL, V59, P1061, DOI 10.1016/j.crad.2004.07.008
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Friedly J, 2010, PHYS MED REH CLIN N, V21, P659, DOI 10.1016/j.pmr.2010.08.002
   Ghosh S, 2011, IEEE ENG MED BIO, P5068, DOI 10.1109/IEMBS.2011.6091255
   Ghosh S, 2011, I S BIOMED IMAGING, P1179, DOI 10.1109/ISBI.2011.5872612
   Lateef H, 2009, CURR REV MUSCULOSKE, V2, P69, DOI 10.1007/s12178-008-9037-0
   Mulconrey Daniel S, 2006, Spine J, V6, P177, DOI 10.1016/j.spinee.2005.08.011
   Neubert A, 2013, J AM MED INFORM ASSN, V20, P1082, DOI 10.1136/amiajnl-2012-001547
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Remonda L, 1996, SCHWEIZ MED WSCHR, V126, P220
   Semelka RC, 2007, J MAGN RESON IMAGING, V25, P900, DOI 10.1002/jmri.20895
   Taimela S, 1997, SPINE, V22, P1132, DOI 10.1097/00007632-199705150-00013
   Tsai MD, 2002, COMPUT MED IMAG GRAP, V26, P369, DOI 10.1016/S0895-6111(02)00033-2
   Unal Y, 2015, APPL SOFT COMPUT, V33, P65, DOI 10.1016/j.asoc.2015.04.031
   Vos T, 2012, LANCET, V380, P2163, DOI 10.1016/S0140-6736(12)61729-2
NR 18
TC 9
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27215
EP 27230
DI 10.1007/s11042-018-5914-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500045
DA 2024-07-18
ER

PT J
AU Liu, ZQ
   Zhu, LG
AF Liu, Zhiqiang
   Zhu, Ligu
TI A novel retrieval method for remote sensing image based on statistical
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resolution remote sensing image retrieval; Non-subsampled Shearlet
   transform; Bessel K form; Statistical feature
ID WAVELET
AB With the increasing number of high-resolution remote sensing (HRRS) image technologies, there is an interest in seeking a way to retrieve images efficiently. In order to describe the images with abundant texture information more concisely and accurately, we propose a novel remote sensing image retrieval approach based on the statistical features of non-subsampled shearlet transform (NSST) coefficients, according to which we set up a model using Bessel K form (BKF). First, the remote sensing (RS) image is decomposed into several subbands of frequency and orientation using the non-subsampled shearlet transform. Then, we use the Bessel K distribution model is utilized to describe the coefficients of NSST high-frequency subband. Next, the BKF parameters are selected to serve as the texture feature to represent the characteristics of image, namely BKF statistical model feature (BSMF), and the feature vector of each image is created by combination with parameters at each high-pass subband. Both the experiment and theory indicate that the BKF distribution is highly matched with the statistical features of NSST coefficients within high-pass subbands. In our experiments, we applied the proposed method to two general RS image datasets- The UC Merced land use dataset and the Sydney dataset. The results show that our proposed method can achieve a more robust and commendable performance than the state-of-the-art approaches.
C1 [Liu, Zhiqiang; Zhu, Ligu] Commun Univ China, Sch Comp Sci, Beijing 100024, Peoples R China.
C3 Communication University of China
RP Liu, ZQ (corresponding author), Commun Univ China, Sch Comp Sci, Beijing 100024, Peoples R China.
EM zchxliu@126.com
FU National Natural Science Foundation of China [6137006]
FX This work was supported by the National Natural Science Foundation of
   China (No. 6137006).
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Allili MS, 2012, IEEE T IMAGE PROCESS, V21, P1452, DOI 10.1109/TIP.2011.2170701
   [Anonymous], GEOMATICS INF SCI WU
   [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], STAT CONTOURLET SUBB
   [Anonymous], 2009, INT J COMPUT SCI INF
   [Anonymous], 2015, P ICLR
   Ansari RA, 2015, REMOTE SENS LETT, V6, P982, DOI 10.1080/2150704X.2015.1093184
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736
   Bao Q, 2004, IEEE SYS MAN CYBERN, P1112
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Champion I, 2014, IEEE GEOSCI REMOTE S, V11, P5, DOI 10.1109/LGRS.2013.2244060
   Chaudhuri B, 2016, IEEE GEOSCI REMOTE S, V13, P987, DOI 10.1109/LGRS.2016.2558289
   de Ves E, 2014, PATTERN RECOGN, V47, P2925, DOI 10.1016/j.patcog.2014.03.004
   Du B, 2014, PATTERN RECOGN, V47, P344, DOI 10.1016/j.patcog.2013.07.005
   Du ZX, 2016, NEUROCOMPUTING, V207, P813, DOI 10.1016/j.neucom.2016.05.061
   Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Graña M, 2012, PATTERN RECOGN, V45, P3472, DOI 10.1016/j.patcog.2012.03.015
   Gueguen L, 2008, IEEE T KNOWL DATA EN, V20, P562, DOI 10.1109/TKDE.2007.190718
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hou B, 2012, IEEE J-STARS, V5, P809, DOI 10.1109/JSTARS.2012.2196680
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang J, 2013, INT J REMOTE SENS, V34, P5265, DOI 10.1080/01431161.2013.786195
   Jiang TB, 2017, J COMPUT SCI TECH-CH, V32, P726, DOI 10.1007/s11390-017-1754-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Pennec E., 2005, SIAM J MULTISCALE MO, V4, P2005
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li P, 2017, IEEE GEOSCI REMOTE S, V14, P464, DOI 10.1109/LGRS.2017.2651056
   Li YS, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090709
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Napoletano P, 2018, INT J REMOTE SENS, V39, P1343, DOI 10.1080/01431161.2017.1399472
   Özkan S, 2014, IEEE GEOSCI REMOTE S, V11, P1996, DOI 10.1109/LGRS.2014.2316143
   Rakvongthai Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1494, DOI 10.1016/j.image.2013.06.005
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Samal A, 2009, PATTERN RECOGN, V42, P2502, DOI 10.1016/j.patcog.2009.01.035
   Scott GJ, 2011, IEEE T GEOSCI REMOTE, V49, P1603, DOI 10.1109/TGRS.2010.2088404
   Shyu CR, 2007, IEEE T GEOSCI REMOTE, V45, P839, DOI 10.1109/TGRS.2006.890579
   Tobin KW, 2006, PHOTOGRAMM ENG REM S, V72, P531, DOI 10.14358/PERS.72.5.531
   Veganzones Miguel A., 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P426
   Velasco AV, 2013, OPT LETT, V38, P706, DOI 10.1364/OL.38.000706
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yang Y, 2013, IEEE T GEOSCI REMOTE, V51, P818, DOI 10.1109/TGRS.2012.2205158
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
   Zhou WX, 2015, REMOTE SENS LETT, V6, P775, DOI 10.1080/2150704X.2015.1074756
NR 53
TC 3
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24643
EP 24662
DI 10.1007/s11042-018-5649-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400004
DA 2024-07-18
ER

PT J
AU Moeinaddini, E
   Afsari, F
AF Moeinaddini, Elham
   Afsari, Fatemeh
TI Robust watermarking in DWT domain using SVD and opposition and
   dimensional based modified firefly algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; Discrete wavelet transform; Opposition and
   dimensional based modified firefly algorithm; Robustness; Imperceptible
ID IMAGE WATERMARKING; WAVELET TRANSFORM; SCHEME
AB The process of authenticating a digital image by embedding a watermark into it is called digital image watermarking, which protects the image from copyright infringement. This paper proposes an optimized watermarking scheme in the discrete wavelet transform (DWT) domain based on the singular value decomposition (SVD) using opposition and dimensional based modified firefly algorithm (ODFA).The host image is segmented into 8x8 non-overlapping blocks and the most suitable embedding blocks are selected for embedding. The selected blocks are then transformed into DWT domain and SVD is applied on LL1 sub-bands. Finally, the process of embedding the watermarked bits is optimized using ODFA, which applies the combination of imperceptibility and robustness as the objective function. The embedding algorithm possesses good similarity between the host and the watermarked images as well as the strong robustness against various image processing operations and attacks. Experimental results reveal that the proposed scheme has a higher degree of imperceptibility and robustness compare to related existing schemes.
C1 [Moeinaddini, Elham] Univ Jiroft, Dept Elect Engn, Jiroft, Iran.
   [Afsari, Fatemeh] Shahid Bahonar Univ Kerman, Dept Comp Engn, POB 76169-133,Afzalipoor Sq, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Afsari, F (corresponding author), Shahid Bahonar Univ Kerman, Dept Comp Engn, POB 76169-133,Afzalipoor Sq, Kerman, Iran.
EM el_moin@ujiroft.ac.ir; afsari@uk.ac.ir
RI Afsari, Fatemeh/AAL-1467-2021; Afsari, Fatemeh/IQW-6813-2023;
   Moeinaddini, Elham/JCO-7421-2023
OI Afsari, Fatemeh/0000-0003-4165-5233; Moeinaddini,
   Elham/0000-0001-5577-9339
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   [Anonymous], 2009, INT J COMPUT THEORY
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dong HL, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P310, DOI 10.1109/CyberC.2015.15
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ishtiaq M., 2010, ICIC Express Lett, V4, P1
   Kazemi B., 2017, PREDICTIVE MODEL BAS, P1
   Kazemivash B, 2017, MULTIMED TOOLS APPL, V76, P20499, DOI 10.1007/s11042-016-3962-5
   Lai CC, 2011, DIGIT SIGNAL PROCESS, V21, P522, DOI 10.1016/j.dsp.2011.01.017
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Lin TC, 2009, INFORM SCIENCES, V179, P3349, DOI 10.1016/j.ins.2009.05.022
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Maity SP, 2009, IEEE SIGNAL PROC LET, V16, P245, DOI 10.1109/LSP.2009.2014097
   Ming-Huwi Horng, 2010, 2010 Proceedings of 7th International Conference on Ubiquitous Intelligence & Computing and 7th International Conference on Autonomic & Trusted Computing (UIC/ATC 2010), P58, DOI 10.1109/UIC-ATC.2010.47
   ORuanaidh JJK, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P536, DOI 10.1109/ICIP.1997.647968
   PAL NR, 1989, IEE PROC-E, V136, P284, DOI 10.1049/ip-e.1989.0039
   Ramkumar M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P211, DOI 10.1109/ICIP.1999.822886
   Rivest R., 1992, MD5 MESSAGE DIGEST A
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Verma OP, 2016, EXPERT SYST APPL, V44, P168, DOI 10.1016/j.eswa.2015.08.054
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yang, 2008, NATURE INSPIRED META, P242
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Yudong Zhang, 2012, International Journal of Research and Reviews in Soft and Intelligent Computing, V2, P141
NR 29
TC 19
Z9 19
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26083
EP 26105
DI 10.1007/s11042-018-5838-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400063
DA 2024-07-18
ER

PT J
AU Oliva, D
   Hinojosa, S
   Abd Elaziz, M
   Ortega-Sánchez, N
AF Oliva, Diego
   Hinojosa, Salvador
   Abd Elaziz, Mohamed
   Ortega-Sanchez, Noe
TI Context based image segmentation using antlion optimization and sine
   cosine algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Antlion Optimization; Sine Cosine Algorithm; Multilevel Thresholding;
   Energy Curve
ID PARTICLE SWARM OPTIMIZATION; ARTIFICIAL BEE COLONY; MULTILEVEL; ENTROPY;
   PSO
AB Multilevel thresholding (MTH) is one of the most commonly used approaches to perform segmentation on images. However, as most methods are based on the histogram of the image to be segmented, MTH methods only consider the occurrence frequency of certain intensity level disregarding all spatial information. Contextual information can help to enhance the quality of the segmented image as it considers not only the value of the pixel but also its vicinity. The energy curve was designed to bring spatial information into a curve with the same properties as the histogram. In this paper, two recently proposed Evolutionary Computational Algorithms (ECAs) are coupled with two classical thresholding criteria to perform MTH over the energy curve. The selected ECAs are the Antlion Optimizer (ALO) and the Sine Cosine Algorithm (SCA). The proposed methods are evaluated intensively regarding quality, and a statistical analysis is presented to compare the results of the algorithms against similar approaches. Experimental evidence encourages the use ALO for MTH while it concludes that SCA does not outperform other ECAs form the state-of-the-art.
C1 [Oliva, Diego; Ortega-Sanchez, Noe] Univ Guadalajara, CUCEI, Div Elect & Comp, Ave Revoluc 1500, Guadalajara, Jal, Mexico.
   [Hinojosa, Salvador] Univ Complutense Madrid, Fac Informat, Dept Ingn Software & Inteligencia Artificial, E-28040 Madrid, Spain.
   [Abd Elaziz, Mohamed] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Abd Elaziz, Mohamed] Zagazig Univ, Dept Math, Fac Sci, Zagazig, Egypt.
C3 Universidad de Guadalajara; Complutense University of Madrid; Wuhan
   University of Technology; Egyptian Knowledge Bank (EKB); Zagazig
   University
RP Oliva, D (corresponding author), Univ Guadalajara, CUCEI, Div Elect & Comp, Ave Revoluc 1500, Guadalajara, Jal, Mexico.
EM diego.oliva@cucei.udg.mx; salvahin@ucm.es; abd_el_aziz_m@yahoo.com;
   noe.ortega@academicos.udg.mx
RI Oliva, Diego/A-3271-2016; Hinojosa, Salvador/P-1703-2018; ,
   mohamed/AAH-8886-2019
OI Oliva, Diego/0000-0001-8781-7993; Hinojosa,
   Salvador/0000-0001-9623-2022; , mohamed/0000-0002-7682-6269;
   Ortega-Sanchez, Noe/0000-0003-0949-2649
FU Mexican Government under the program for New Full Time Professors 2017
   of PRODEP; CONACYT [298283, 234148]
FX The first author acknowledges to Mexican Government for partially
   supporting this research under the program for New Full Time Professors
   2017 of PRODEP. The authors second and fourth acknowledge to CONACYT for
   the grants 298283 and 234148, respectively.
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Ali M, 2012, EUR J OPER RES, V217, P404, DOI 10.1016/j.ejor.2011.09.025
   [Anonymous], 2014, CUCKOO SEARCH FIREFL, DOI DOI 10.1007/978-3-319-02141-6
   [Anonymous], NEW METHOD GRAY LEVE
   [Anonymous], SINE COSINE OPTIMIZA
   [Anonymous], 1992, R. woods digital image processing
   [Anonymous], IEEE T MAN MACHCYB B
   [Anonymous], SYSTEM
   [Anonymous], COMPUT INTELL NEUROS
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], P 2015 4 INT C INF S
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cuevas E, 2010, EXPERT SYST APPL, V37, P5265, DOI 10.1016/j.eswa.2010.01.013
   David G., 1989, GENETIC ALGORITHMS S
   Dehshibi MM, 2017, MULTIMED TOOLS APPL, V76, P15951, DOI 10.1007/s11042-016-3891-3
   Dorigo M., 1999, Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406), P1470, DOI 10.1109/CEC.1999.782657
   Gao H, 2016, INFORM SCIENCES, V369, P500, DOI 10.1016/j.ins.2016.07.017
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   García S, 2009, J HEURISTICS, V15, P617, DOI 10.1007/s10732-008-9080-4
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Gupta E, 2016, COGENT ENG, V3, DOI 10.1080/23311916.2016.1151612
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Hussein WA, 2016, KNOWL-BASED SYST, V101, P114, DOI 10.1016/j.knosys.2016.03.010
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kumar S, 2013, MEMET COMPUT, V5, P323, DOI 10.1007/s12293-013-0123-5
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   Merrikh-Bayat F, 2015, APPL SOFT COMPUT, V33, P292, DOI 10.1016/j.asoc.2015.04.048
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Oliva D, 2015, EXPERT SYST APPL, V42, P5874, DOI 10.1016/j.eswa.2015.03.028
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Pare S, 2017, EXPERT SYST APPL, V87, P335, DOI 10.1016/j.eswa.2017.06.021
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Patra S, 2014, APPL SOFT COMPUT, V23, P122, DOI 10.1016/j.asoc.2014.06.016
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Socha K, 2008, EUR J OPER RES, V185, P1155, DOI 10.1016/j.ejor.2006.06.046
   Storn R., 1997, J GLOB OPTIM
   Suresh S, 2017, APPL SOFT COMPUT, V55, P503, DOI 10.1016/j.asoc.2017.02.005
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Zawbaa HM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150652
   Zhang J., 2014, MATH PROBL ENG, V2014, P10, DOI DOI 10.1016/J.IJEPES.2014.09.041
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zheng GP, 2015, STEM CELLS INT, V2015, DOI 10.1155/2015/989473
NR 59
TC 39
Z9 44
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25761
EP 25797
DI 10.1007/s11042-018-5815-x
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400049
DA 2024-07-18
ER

PT J
AU Xiao, ZY
   Wang, CH
   Jia, N
   Wu, JH
AF Xiao, Zhiyong
   Wang, Canhua
   Jia, Nan
   Wu, Jianhua
TI SAE-based classification of school-aged children with autism spectrum
   disorders using functional magnetic resonance imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stacked autoencoder; Classification; School-aged children; Autism
   spectrum disorder; Brain frequency
ID BRAIN; CONNECTIVITY; NETWORK; IDENTIFICATION; OSCILLATIONS; CORTEX
AB This paper employs a novel-deep learning method and brain frequencies to discriminate school-aged children with autism spectrum disorders (ASD) from typically developing (TD) school-aged children with functional magnetic resonance imaging (fMRI) data of 84 subjects from the ABIDE (Autism Brain Imaging Data Exchange) database. Firstly, the fMRI data were preprocessed, and then each subject's dataset was decomposed into 30 independent components (IC). Secondly, some key ICs were selected and inputted into a stacked autoencoder (SAE). The SAE was adopted for features subtraction and dimensionality reduction. Finally, a softmax classifier was used to discriminate the school-aged children with ASD from TD school-aged children. The average accuracy of the work was as high as 87.21% (average sensitivity = 92.86%, average specificity = 84.32%). The results of classification demonstrated that the proposed method may have the potential to automatically discriminate school-aged children with ASD from TD school-aged children. Attempts to use deep learning-based algorithms and brain frequencies to discriminate school-aged children with ASD from TD school-aged children should likely be a key step forward in auxiliary clinical utility.
C1 [Xiao, Zhiyong; Wang, Canhua] Nanchang Univ, Sch Mechatron Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Xiao, Zhiyong] Jiangxi Agr Univ, Sch Software, Nanchang 330045, Jiangxi, Peoples R China.
   [Wang, Canhua] Jiangxi Univ Tradit Chinese Med, Sch Comp, Nanchang 330004, Jiangxi, Peoples R China.
   [Jia, Nan; Wu, Jianhua] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University; Jiangxi Agricultural University; Jiangxi University
   of Traditional Chinese Medicine; Nanchang University
RP Wu, JH (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM zhyxiao@jxau.edu.cn; 390921890@qq.com; 729372337@qq.com; jhwu@ncu.edu.cn
RI Wu, Jianhua/AFL-8480-2022
OI Wu, Jianhua/0000-0002-4505-0568
FU Natural Science Foundation of China [61662047]
FX This study was supported by the Natural Science Foundation of China
   (Grant nos. 61662047). The authors would like to thank researchers and
   funding agencies that have contributed to ABIDE.
CR Anderson JS, 2011, BRAIN, V134, P3739, DOI 10.1093/brain/awr263
   [Anonymous], DEV BEHAV PEDIAT
   [Anonymous], 2013, Am Psychiatr Assoc, V51, P4189
   Assaf M, 2010, NEUROIMAGE, V53, P247, DOI 10.1016/j.neuroimage.2010.05.067
   Bajaj S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064466
   Baron-Cohen S, 2009, ANN NY ACAD SCI, V1156, P68, DOI 10.1111/j.1749-6632.2009.04467.x
   Barttfeld P, 2012, NEUROPSYCHOLOGIA, V50, P3653, DOI 10.1016/j.neuropsychologia.2012.09.047
   Belmonte MK, 2004, J NEUROSCI, V24, P9228, DOI 10.1523/JNEUROSCI.3340-04.2004
   Buzsáki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Chen H, 2016, PROG NEURO-PSYCHOPH, V64, P1, DOI 10.1016/j.pnpbp.2015.06.014
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Courchesne E, 2011, JAMA-J AM MED ASSOC, V306, P2001, DOI 10.1001/jama.2011.1638
   De Luca M, 2006, NEUROIMAGE, V29, P1359, DOI 10.1016/j.neuroimage.2005.08.035
   Di Martino A, 2008, BIOL PSYCHIAT, V64, P607, DOI 10.1016/j.biopsych.2008.03.008
   Di Martino A, 2011, BIOL PSYCHIAT, V69, P847, DOI 10.1016/j.biopsych.2010.10.029
   Goh S, 2014, JAMA PSYCHIAT, V71, P665, DOI 10.1001/jamapsychiatry.2014.179
   Han Y, 2011, NEUROIMAGE, V55, P287, DOI 10.1016/j.neuroimage.2010.11.059
   Hill EL, 2003, PHILOS T R SOC B, V358, P281, DOI 10.1098/rstb.2002.1209
   Hoptman MJ, 2010, SCHIZOPHR RES, V117, P13, DOI 10.1016/j.schres.2009.09.030
   Huys QJM, 2016, NAT NEUROSCI, V19, P404, DOI 10.1038/nn.4238
   Iidaka T, 2015, CORTEX, V63, P55, DOI 10.1016/j.cortex.2014.08.011
   Levy F, 2007, AUST NZ J PSYCHIAT, V41, P859, DOI 10.1080/00048670701634937
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Lord C., 1999, Autism diagnostic observation schedule
   Lynch CJ, 2013, BIOL PSYCHIAT, V74, P212, DOI 10.1016/j.biopsych.2012.12.013
   McKeown MJ, 1998, HUM BRAIN MAPP, V6, P368, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<368::AID-HBM7>3.0.CO;2-E
   Murdaugh DL, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050064
   Murillo L, 2016, AUST PSYCHOL, V51, P280, DOI 10.1111/ap.12226
   Orrù G, 2012, NEUROSCI BIOBEHAV R, V36, P1140, DOI 10.1016/j.neubiorev.2012.01.004
   Penttonen Markku, 2003, Thalamus & Related Systems, V2, P145, DOI 10.1017/S1472928803000074
   Ruparelia K, 2016, J CHILD NEUROL, V31, P1018, DOI 10.1177/0883073816635748
   Salvador R, 2008, NEUROIMAGE, V39, P279, DOI 10.1016/j.neuroimage.2007.08.018
   Siegel M, 2012, NAT REV NEUROSCI, V13, P121, DOI 10.1038/nrn3137
   Syed MA, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00459
   Uddin LQ, 2013, JAMA PSYCHIAT, V70, P869, DOI 10.1001/jamapsychiatry.2013.104
   Uddin LQ, 2011, BIOL PSYCHIAT, V70, P833, DOI 10.1016/j.biopsych.2011.07.014
   Velazquez JLP, 2009, INT J PSYCHOPHYSIOL, V73, P341, DOI 10.1016/j.ijpsycho.2009.05.009
   Wingate M, 2014, MMWR SURVEILL SUMM, V63
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang YD, 2016, INT C PAR DISTRIB SY, P1229, DOI [10.1109/ICPADS.2016.164, 10.1109/ICPADS.2016.0166]
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zuo XN, 2010, NEUROIMAGE, V49, P1432, DOI 10.1016/j.neuroimage.2009.09.037
NR 45
TC 15
Z9 16
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22809
EP 22820
DI 10.1007/s11042-018-5625-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500055
DA 2024-07-18
ER

PT J
AU Zhang, XB
   Sun, ZQ
   Li, Z
AF Zhang, Xiaobo
   Sun, Zhanquan
   Li, Zhao
TI Chinese materia medica resource images screening method study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE outlier detection; Chinese materia medica resource; feature extraction;
   deep learning; convolutional neural network; information loss
ID FEATURE-EXTRACTION; OUTLIER DETECTION
AB Chinese materia medica resource survey provides an important basis for the development of traditional Chinese Medicine (TCM) industry. During the Chinese materia medica resource survey process, millions of materia medica plant images are collected. The collected image dataset includes some images that are unqualified for image analysis, i.e. they can't be used to build medicinal plant classifier model. It is a burdensome work to identify the unqualified Chinese materia medica resource images manually. How to screen the unqualified images automatically is an important task of Chinese materia medica resource survey. Image recognition techniques developed quickly in recent years. Outlier detection is a kind of unsupervised method to find the unqualified images automatically. Lots of research work has been done on the topic. Extracted features and correlation metric play important roles on the outlier image detection result. For improving the image screening performance, a novel outlier detection method is proposed in this paper. Convolutional neural network (CNN) is used to extract the complicated features of Chinese materia medica resource images. Extended entropy is introduced into the calculation of information loss that is used to measure the distance between images. Based on the extracted image features and correlation metric, a novel outlier detection method based on clustering is proposed here. The efficiency of the screening method is illustrated with a practical example.
C1 [Zhang, Xiaobo] China Acad Chinese Med Sci, Natl Resource Ctr Chinese Mat Med, State Key Lab Breeding Base Dao Di Herbs, Beijing 100700, Peoples R China.
   [Sun, Zhanquan; Li, Zhao] Shandong Demonstrat Engn Technol Res Ctr E Govt B, Shandong Comp Sci Ctr, Shandong Prov Key Lab Comp Networks, Natl Supercomp Ctr Jinan, Jinan 250014, Shandong, Peoples R China.
   [Sun, Zhanquan; Li, Zhao] Shandong Engn Technol Res Ctr E Govt Big Data, Jinan 250014, Shandong, Peoples R China.
C3 China Academy of Chinese Medical Sciences; National Resource Center for
   Chinese Materia Medica, CACMS; Qilu University of Technology
RP Sun, ZQ (corresponding author), Shandong Demonstrat Engn Technol Res Ctr E Govt B, Shandong Comp Sci Ctr, Shandong Prov Key Lab Comp Networks, Natl Supercomp Ctr Jinan, Jinan 250014, Shandong, Peoples R China.; Sun, ZQ (corresponding author), Shandong Engn Technol Res Ctr E Govt Big Data, Jinan 250014, Shandong, Peoples R China.
EM sunzhq@sdas.org
FU Shandong science and technology development plan [2016GGC01061,
   2016GGX101029]; Natural Science Foundation of Shandong Province
   [ZR2015JL023, ZR2015FL025]
FX This work is partially supported by the Shandong science and technology
   development plan (Grant No. 2016GGC01061, 2016GGX101029), Natural
   Science Foundation of Shandong Province (Grant No. ZR2015JL023 and Grant
   No. ZR2015FL025).
CR Abid A, 2017, IET WIREL SENS SYST, V7, P83, DOI 10.1049/iet-wss.2016.0044
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ACM SIGMOD REC
   [Anonymous], CHIN J COMPUT
   Bakon M, 2017, IEEE J-STARS, V10, P2791, DOI 10.1109/JSTARS.2017.2686646
   Boriah S., 2008, P 2008 SIAM INT C DA, P243, DOI [10.1137/1.9781611972788.22, DOI 10.1137/1.9781611972788.22]
   Jin T, 2012, IEEE T GEOSCI REMOTE, V50, P4135, DOI 10.1109/TGRS.2012.2188803
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P3742, DOI 10.1109/TGRS.2013.2275613
   Kuncheva LI, 2014, IEEE T NEUR NET LEAR, V25, P69, DOI 10.1109/TNNLS.2013.2248094
   Lajevardi SM, 2010, IET IMAGE PROCESS, V4, P114, DOI 10.1049/iet-ipr.2009.0100
   Liang JZ, 2014, IET IMAGE PROCESS, V8, P528, DOI 10.1049/iet-ipr.2013.0006
   Lunga D, 2014, IEEE SIGNAL PROC MAG, V31, P55, DOI 10.1109/MSP.2013.2279894
   Niu ZX, 2011, LECT NOTES ARTIF INT, V7002, P380, DOI 10.1007/978-3-642-23881-9_50
   Rahmani M, 2017, IEEE T SIGNAL PROCES, V65, P1580, DOI 10.1109/TSP.2016.2645515
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang H, 2016, IEEE SIGNAL PROC LET, V23, P1736, DOI 10.1109/LSP.2016.2617340
   Tishby Naftali, 1999, P 37 ANN ALL C COMM
   Wang D, 2015, IEEE T KNOWL DATA EN, V27, P2743, DOI 10.1109/TKDE.2015.2426703
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zhou CE, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE AND EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P773, DOI 10.1109/ITME.2008.4743971
NR 21
TC 0
Z9 0
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22771
EP 22786
DI 10.1007/s11042-017-5501-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500053
DA 2024-07-18
ER

PT J
AU Zhu, J
   Chen, CW
AF Zhu, Jun
   Chen, Changwei
TI Image Recovery based on Local and Nonlocal Regularizations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Nonlocal low-rank regularization; Total variation;
   Weighted schatten-p norm; Alternating direction methods of multipliers
ID THRESHOLDING ALGORITHM; RECONSTRUCTION; SPARSITY; MINIMIZATION;
   RESTORATION; MRI
AB Recently, a nonlocal low-rank regularization based compressive sensing approach (NLR) which exploits structured sparsity of similar patches has shown the state-of-the-art performance in image recovery. However, NLR cannot efficiently preserve local structures because it ignores the relationship between pixels. In addition, the surrogate logdet function used in NLR cannot well approximate the rank. In this paper, a novel approach based on local and nonlocal regularizations toward exploiting the sparse-gradient property and nonlocal low-rank property (SGLR) has been proposed. Weighted schatten-p norm and l (q) norm have been used as better non-convex surrogate functions for the rank and l0 norm. In addition, an efficient iterative algorithm is developed to solve the resulting recovery problem. The experimental results have demonstrated that SGLR outperforms existing state-of-the-art CS algorithms.
C1 [Zhu, Jun] Jinling Inst Technol, Sch Comp Engn, Nanjing 211169, Jiangsu, Peoples R China.
   [Chen, Changwei] Nanjing Xiaozhuang Univ, Coll Comp & Informat Engn, Nanjing 210017, Jiangsu, Peoples R China.
C3 Jinling Institute of Technology; Nanjing Xiaozhuang University
RP Chen, CW (corresponding author), Nanjing Xiaozhuang Univ, Coll Comp & Informat Engn, Nanjing 210017, Jiangsu, Peoples R China.
EM chenchangwei8285@126.com
OI chen, changwei/0000-0002-9869-384X
FU Natural Science Fund for Colleges and Universities in Jiangsu Province
   [16KJB520014]; Doctor Initial Captional of Jinling Institute of
   Technology Nanjing [jit-b-201508]; Scientific Research Starting
   Foundation of Jinling Institute of Technology for Introducing Talents
   [jit-rcyj-201505]; Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) [30916014107]
FX This work was supported by the Natural Science Fund for Colleges and
   Universities in Jiangsu Province (Grant No. 16KJB520014), the Doctor
   Initial Captional of Jinling Institute of Technology Nanjing (No.
   jit-b-201508), the Scientific Research Starting Foundation of Jinling
   Institute of Technology for Introducing Talents (No. jit-rcyj-201505),
   and sponsored by the Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) (Grant No. 30916014107).
CR [Anonymous], 2014, PHD DISSERTATION NAN
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Egiazarian K, 2007, IEEE IMAGE PROC, P549
   Fazel M, 2003, P AMER CONTR CONF, P2156, DOI 10.1109/acc.2003.1243393
   Feng L, 2016, NEUROCOMPUTING, V216, P45, DOI 10.1016/j.neucom.2016.07.012
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Li W, 2010, INT C INT INF PROC B, P357
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Mohan K, 2010, P AMER CONTR CONF, P2953
   Nie F., 2012, AAAI, P655
   Qu XB, 2014, MED IMAGE ANAL, V18, P843, DOI 10.1016/j.media.2013.09.007
   Shu XB, 2010, LECT NOTES COMPUT SC, V6316, P393
   Wang J, 2015, PATTERN RECOGN, V48, P3135, DOI 10.1016/j.patcog.2015.01.024
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xie Y, 2016, IEEE T GEOSCI REMOTE, V54, P4642, DOI 10.1109/TGRS.2016.2547879
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2013, IEEE INT SYMP CIRC S, P2836
   Zhang J, 2012, IEEE DATA COMPR CONF, P287, DOI 10.1109/DCC.2012.71
   Zhang Y, 2011, J ELECTROMAGNET WAVE, V25, P1081, DOI 10.1163/156939311795762024
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhang YD, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/546814
   Zhao C, 2016, IEEE DATA COMPR CONF, P161, DOI 10.1109/DCC.2016.104
NR 29
TC 0
Z9 0
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22841
EP 22855
DI 10.1007/s11042-018-5935-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500057
DA 2024-07-18
ER

PT J
AU Li, CH
   Luo, GC
   Li, CB
AF Li, Chunhu
   Luo, Guangchun
   Li, Chunbao
TI A parallel image encryption algorithm based on chaotic Duffing
   oscillators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic Duffing oscillators; Chaotic cryptography; Image encryption;
   Parallel
ID MAPS; EQUATION; SYSTEMS
AB Image encryption has been a popular research field in recent decades. This paper presents a novel parallel image encryption algorithm, which is based on the chaotic duffing oscillators. Image encryption systems based on chaotic Duffing oscillators are show some better performances. In order to be more efficient and secure, we divided the plain-images (original-image) into several pieces. The speed of encryption and decryption is very fast. We use well-known ways to perform the security and performance analysis of the proposed image encryption scheme. The results of the fail-safe analysis are inspiring and it can be concluded that, the proposed scheme is efficient and secure.
C1 [Li, Chunhu; Luo, Guangchun; Li, Chunbao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Li, CH (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
EM lchh-tiger@163.com
OI Li, Chunbao/0000-0001-5891-417X
FU foundation of science and technology department of Sichuan province
   [2015SZ0231, 2015SZ0045]
FX This work is supported by the foundation of science and technology
   department of Sichuan province NO.2015SZ0231 and NO.2015SZ0045.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Ahmad B, 2008, NONLINEAR ANAL-REAL, V9, P1727, DOI 10.1016/j.nonrwa.2007.05.005
   Akhavan A, 2011, J FRANKLIN I, V348, P1797, DOI 10.1016/j.jfranklin.2011.05.001
   Akhshani A, 2006, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2006.312889
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bender CM, 1978, MATH GAZ, V63, P140
   Bruce S, 1995, APPL CRYPTOGRAPHY PR
   CARROLL TL, 1991, IEEE T CIRCUITS SYST, V38, P453, DOI 10.1109/31.75404
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dachselt F, 2001, IEEE T CIRCUITS-I, V48, P1498, DOI 10.1109/TCSI.2001.972857
   Deckard ND, 2016, TEACH SOCIOL, V44, P296, DOI 10.1177/0092055X16666513
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Elgendy Fatma, 2015, MULTIMED TOOLS APPL, V75, P1
   Harb AM, 2007, CHAOS SOLITON FRACT, V34, P639, DOI 10.1016/j.chaos.2006.03.119
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Jiang ZP, 2002, IEEE T CIRCUITS-I, V49, P244, DOI 10.1109/81.983872
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Loria A, 1998, IEEE T CIRCUITS-I, V45, P1252, DOI 10.1109/81.736558
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Matthews R. A. J., 1993, Cryptologia, V17, P187, DOI 10.1080/0161-119391867863
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mollaeefar M., 2017, MULTIMED TOOLS APPL, V76, P1
   NIJMEIJER H, 1995, IEEE T CIRCUITS-I, V42, P473, DOI 10.1109/81.404059
   OTT E, 1990, PHYS REV LETT, V64, P1196, DOI 10.1103/PhysRevLett.64.1196
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Smart N, 2010, FRAMEWORK, V116
   Stoyanov B, 2014, SCI WORLD J, V2014, P283
   Ueda Y., 1991, Chaos, Solitons and Fractals, V1, P199, DOI 10.1016/0960-0779(91)90032-5
   Wang W, 2016, WIRELESS COMMUNICATION AND SENSOR NETWORK, P711
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Yusufoglu E, 2006, APPL MATH COMPUT, V177, P572, DOI 10.1016/j.amc.2005.07.072
NR 37
TC 22
Z9 22
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19193
EP 19208
DI 10.1007/s11042-017-5391-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500014
DA 2024-07-18
ER

PT J
AU Mohamed, EA
   Yusoff, MZ
   Malik, AS
   Bahloul, MR
   Adam, DM
   Adam, IK
AF Mohamed, Eltaf Abdalsalam
   Yusoff, Mohd Zuki
   Malik, Aamir Saeed
   Bahloul, Mohammad Rida
   Adam, Dalia Mahmoud
   Adam, Ibrahim Khalil
TI Comparison of EEG signal decomposition methods in classification of
   motor-imagery BCI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer interface (BCI); Empirical mode decomposition (EMD);
   Electroencephalography (EEG); Intrinsic time-scale decomposition (ITD);
   Artificial neural network (ANN)
ID BRAIN-COMPUTER INTERFACE; LEFT HAND; COMMUNICATION; (DE)SYNCHRONIZATION;
   COMPONENTS; SELECTION; CORTEX; RHYTHM
AB A brain-computer interface (BCI) provides a link between the human brain and a computer. The task of discriminating four classes (left and right hands and feet) of motor imagery movements of a simple limb-based BCI is still challenging because most imaginary movements in the motor cortex have close spatial representations. We aimed to classify binary limb movements, rather than the direction of movement within one limb. We also investigated joint time-frequency methods to improve classification accuracies. Neither of these, to our knowledge, has been investigated previously in BCI. We recorded EEG data from eleven participants, and demonstrated the classification of four classes of simple-limb motor imagery with an accuracy of 91.46% using intrinsic time-scale decomposition and 88.99% using empirical mode decomposition. In binary classifications, we achieved average accuracies of 89.90% when classifying imaginary movements of left hand versus right hand, 93.1% for left hand versus right foot, 94.00% for left hand versus left foot, 83.82% for left foot versus right foot, 97.62% for right hand versus left foot, and 95.11% for right hand versus right foot. The results show that the binary classification performance is slightly better than that of four-class classification. Our results also show that there is no significant difference in terms of spatial distribution between left and right foot motor imagery movements. There is also no difference in classification performances involving left or right foot movement. This work demonstrates that binary and four-class movements of the left and right feet and hands can be classified using recorded EEG signals of the motor cortex, and an intrinsic time-scale decomposition (ITD) feature extraction method can be used for real time brain computer interface.
C1 [Mohamed, Eltaf Abdalsalam; Yusoff, Mohd Zuki; Malik, Aamir Saeed; Bahloul, Mohammad Rida] UTP, CISIR, Elect & Elect Engn Dept, Seri Iskandar 32610, Perak, Malaysia.
   [Adam, Dalia Mahmoud] Al Neelain Univ, Khartoum, Sudan.
   [Adam, Ibrahim Khalil] Univ Teknol PETRONAS, Mech Engn Dept, Ctr Automot Res & Elect Mobil, Seri Iskandar 32610, Perak, Malaysia.
C3 Universiti Teknologi Petronas
RP Mohamed, EA (corresponding author), UTP, CISIR, Elect & Elect Engn Dept, Seri Iskandar 32610, Perak, Malaysia.
EM eltaf55@yahoo.com; mzuki_yusoff@utp.edu.my; aamir_saeed@utp.edu.my;
   Nnmb2002@hotmail.com; d.daliamahmoud@yahoo.com;
   ibrahim_g02238@utp.edu.my
RI Bahloul, Mohammad R/B-6842-2017; Yusoff, Mohd Zuki/ABE-3628-2021; Malik,
   Aamir S/C-6904-2009
OI Malik, Aamir S/0000-0003-1085-3157
FU Ministry of Education Malaysia [0153CA-004]
FX The authors would like to thank the Universiti Teknologi PETRONAS for
   the Graduate Assistantship scheme (GA) given to the first author, the
   Ministry of Education Malaysia for providing Higher Institution Center
   of Excellence (HICoE) grant (cost center: 0153CA-004) and Centre for
   Intelligent Signal and Imaging Research (CISIR) for providing facilities
   and equipment. Also, we wish to thank the participants for their
   cooperation in the experiments.
CR Alkadhi H, 2000, AM J NEURORADIOL, V21, P1423
   [Anonymous], J NEURAL ENG
   [Anonymous], NEUROENG REHABIL
   [Anonymous], ARXIV160908417
   Aydemir O, 2014, J NEUROSCI METH, V229, P68, DOI 10.1016/j.jneumeth.2014.04.007
   Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051
   Brunner C, 2007, PATTERN RECOGN LETT, V28, P957, DOI 10.1016/j.patrec.2007.01.002
   Frei MG, 2007, P R SOC A, V463, P321, DOI 10.1098/rspa.2006.1761
   Galán F, 2008, CLIN NEUROPHYSIOL, V119, P2159, DOI 10.1016/j.clinph.2008.06.001
   Guo ZX, 2014, CONTROL ENG PRACT, V32, P64, DOI 10.1016/j.conengprac.2014.07.002
   Hari R, 1998, P NATL ACAD SCI USA, V95, P15061, DOI 10.1073/pnas.95.25.15061
   Huang DD, 2012, IEEE T NEUR SYS REH, V20, P379, DOI 10.1109/TNSRE.2012.2190299
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jeon Y, 2011, INT J IND ERGONOM, V41, P428, DOI 10.1016/j.ergon.2011.03.005
   Kevric J, 2017, BIOMED SIGNAL PROCES, V31, P398, DOI 10.1016/j.bspc.2016.09.007
   Krepki R, 2007, MULTIMED TOOLS APPL, V33, P73, DOI 10.1007/s11042-006-0094-3
   Kus R, 2012, IEEE T NEUR SYS REH, V20, P823, DOI 10.1109/TNSRE.2012.2214789
   Li AS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116429
   Li JH, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500135
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   Li YT, 2016, MULTIMED TOOLS APPL, V75, P7999, DOI 10.1007/s11042-015-2717-z
   Li YQ, 2010, IEEE T BIO-MED ENG, V57, P2495, DOI 10.1109/TBME.2010.2055564
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liang RZ, 2016, PROC INT C TOOLS ART, P299, DOI [10.1109/ICTAI.2016.50, 10.1109/ICTAI.2016.0053]
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01
   Martis RJ, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500238
   McFarland DJ, 2015, INT J PSYCHOPHYSIOL, V97, P271, DOI 10.1016/j.ijpsycho.2014.07.009
   McFarland DJ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/3/036007
   McFarland DJ, 1997, ELECTROEN CLIN NEURO, V103, P386, DOI 10.1016/S0013-4694(97)00022-2
   Morash V, 2008, CLIN NEUROPHYSIOL, V119, P2570, DOI 10.1016/j.clinph.2008.08.013
   Müller-Gerking J, 2000, CLIN NEUROPHYSIOL, V111, P1353, DOI 10.1016/S1388-2457(00)00345-X
   Naeem M, 2006, J NEURAL ENG, V3, P208, DOI 10.1088/1741-2560/3/3/003
   Neuper C, 2009, CLIN NEUROPHYSIOL, V120, P239, DOI 10.1016/j.clinph.2008.11.015
   Ortner R, 2011, IEEE T NEUR SYS REH, V19, P1, DOI 10.1109/TNSRE.2010.2076364
   Park C, 2013, IEEE T NEUR SYS REH, V21, P10, DOI 10.1109/TNSRE.2012.2229296
   Pfurtscheller G, 2008, EUR J NEUROSCI, V28, P1419, DOI 10.1111/j.1460-9568.2008.06441.x
   Pfurtscheller G, 1997, ELECTROEN CLIN NEURO, V103, P642, DOI 10.1016/S0013-4694(97)00080-1
   Pfurtscheller G, 2006, BRAIN RES, V1071, P145, DOI 10.1016/j.brainres.2005.11.083
   Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003
   Pfurtscheller G, 2009, Comput Intell Neurosci, P104180, DOI 10.1155/2009/104180
   Pfurtscheller G, 2001, VISION RES, V41, P1257, DOI 10.1016/S0042-6989(00)00235-2
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G, 1997, NEUROSCI LETT, V239, P65, DOI 10.1016/S0304-3940(97)00889-6
   Prieto A, 2016, NEUROCOMPUTING, V214, P242, DOI 10.1016/j.neucom.2016.06.014
   Scherer R, 2008, IEEE T BIO-MED ENG, V55, P675, DOI 10.1109/TBME.2007.903709
   Shenoy P, 2006, J NEURAL ENG, V3, pR13, DOI 10.1088/1741-2560/3/1/R02
   Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807
   Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Yi WX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102394
NR 50
TC 17
Z9 18
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21305
EP 21327
DI 10.1007/s11042-017-5586-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300044
DA 2024-07-18
ER

PT J
AU Jainish, GR
   Jiji, GW
   Infant, PA
AF Jainish, G. R.
   Jiji, G. Wiselin
   Infant, P. Alwin
TI Detection of Plaque in Coronary Artery in CMRI Images and 3D
   Visualization of Blood Flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Level set; Centerline Extraction; Vascular Structure; 3D
   Visualization; Coronary Artery
ID ACTIVE APPEARANCE MODELS; MANY-CORE PROCESSOR; SEGMENTATION; HEVC;
   FRAMEWORK
AB Detection of blocks in coronary arteries is becoming crucial interest for early detection of heart attacks. In this paper we propose a framework for detection of plaque in coronary arteries from cardio vascular magnetic resonance imaging(CMRI). It is a quantitative tool for the assessment of cardiovascular diseases. First, select a region of interest and segment the region of coronary artery using enhanced region based active contour (ERAC). Secondly the centreline extraction and lumen segmentation are integrated to extract the artery centreline using geometric moments and the vessel direction using Hessian matrix and segment the vessel lumen in each slice using ERAC. A boundary searching method is adapted to fine tune the segmented surface in each slice of CMRI image. Third, the soft plaques in the coronary artery are extracted by thresholding the segmented region. Finally a 3D visualization of blood flow in coronary artery is presented and the volume of blood flow is calculated. In the experiments we have employed 22 datasets of CMRI images. The experimental results show an average accuracy of 97.6% and with a mean and standard deviation of false discovery rate of 2.48 +/- 0.002.
C1 [Jainish, G. R.] Manonmaniam Sundaranar Univ, Tirunelveli, India.
   [Jiji, G. Wiselin] Dr Sivanthi Aditanar Coll Engn, Comp Sci & Engn Dept, Tiruchendur, India.
   [Infant, P. Alwin] Loyola Inst Technol & Sci, Dept Comp Sci & Engn, Kanyakumari, India.
C3 Manonmaniam Sundaranar University
RP Jainish, GR (corresponding author), Manonmaniam Sundaranar Univ, Tirunelveli, India.
EM jainish.gr@gmail.com; jijivevin@yahoo.co.in; alwininfant@hotmail.com
OI Infant, Alwin/0000-0003-4336-3162
CR Bouraoui B, 2008, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2008.4541182
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322
   Fang LY, 2017, BIOMED OPT EXPRESS, V8, P2732, DOI 10.1364/BOE.8.002732
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P4186, DOI 10.1109/TGRS.2015.2392755
   Fang LY, 2014, IEEE T GEOSCI REMOTE, V52, P7738, DOI 10.1109/TGRS.2014.2318058
   Felkel P, 2001, SPRING CONFERENCE ON COMPUTER GRAPHICS, PROCEEDINGS, P232, DOI 10.1109/SCCG.2001.945359
   Frangi AF, 2002, IEEE T MED IMAGING, V21, P1151, DOI 10.1109/TMI.2002.804426
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gonzalez RC, 2002, DIGITAL SIGNAL PROCE, V4th
   Jiji G. W., 2013, Journal of the Institution of Engineers (India) Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V94, P115, DOI 10.1007/s40031-013-0048-x
   Jiji GW, 2015, INT J BIOMED ENG TEC, V19, P118, DOI 10.1504/IJBET.2015.072932
   KOLLER TM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P864, DOI 10.1109/ICCV.1995.466846
   Lorenzo-Valdés M, 2002, LECT NOTES COMPUT SC, V2488, P642
   Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perperidis D, 2005, LECT NOTES COMPUT SC, V3750, P402, DOI 10.1007/11566489_50
   Tek H, 2008, MID J 2008 MICCAI WO
   Verdonck B, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P311, DOI 10.1109/ICIP.1996.560492
   Verdonck B, 1996, ACCURATE SEGMENTATIO, P311
   Wang C, 2008, MID J 2008 MICCAI WO
   Wink O, 2000, IEEE T MED IMAGING, V19, P337, DOI 10.1109/42.848184
   Xie X, 2016, MICR MECH SYST MEMS
   Xie X, 2017, MICR MECH SYST MEMS
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan C, 2013, DAT COMPR C DCC 2013
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zambal S, 2008, MID J 2008 MICCAI WO
   Zhuang X., 2008, P MED IM UND AN, P29
NR 34
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16965
EP 16984
DI 10.1007/s11042-017-5265-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300044
DA 2024-07-18
ER

PT J
AU Li, JJ
   Tao, JG
   Ding, L
   Gao, HB
   Deng, ZQ
   Luo, Y
   Li, ZD
AF Li, Jiajun
   Tao, Jianguo
   Ding, Liang
   Gao, Haibo
   Deng, Zongquan
   Luo, Yang
   Li, Zhandong
TI A new iterative synthetic data generation method for CNN based stroke
   gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stroke gesture recognition; Synthetic data generation; Iterative
   generation; Convolutional neural network
ID LINE
AB Training a stroke gesture classifier by using the state-of-the-art Convolutional Neural Network method requires a large sample size to achieve good performance. This becomes a serious problem when users want to add new gestures to the system because adding so many samples is time-consuming and expensive. In this paper, we propose an iterative synthetic data generation method to solve this problem. The method takes in one user-input template gesture which is modeled by Bezier curve and can generate thousands of samples for training. We propose two different modeling approaches so the method can be applied to both mono and multi-stroke gestures. By applying perturbation to the control points, we can obtain enough samples for training. The generation process is carried out in an iterative way, so the variability in different categories of stroke gestures can be balanced. The variability is measured by the dynamic time wrapping method. The proposed method is tested on our own dataset and two published datasets. Our method outperforms methods with fixed generation process and reaches high recognition accuracy.
C1 [Li, Jiajun; Tao, Jianguo; Ding, Liang; Gao, Haibo; Deng, Zongquan; Luo, Yang; Li, Zhandong] Harbin Inst Technol, State Key Lab Robot & Syst, 92 Xidazhi St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Li, JJ (corresponding author), Harbin Inst Technol, State Key Lab Robot & Syst, 92 Xidazhi St, Harbin 150001, Heilongjiang, Peoples R China.
EM lijiajunhit@gmail.com
RI Li, Jiajun/ABH-1814-2021; LUO, Yang/A-9935-2017
CR Abdulla WH, 2003, TENCON IEEE REGION, P1576
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2012, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/2207676.2208584
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 1996, P 5 INT WORKSH FRONT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ACM T INTEL SYST TEC
   [Anonymous], EL P MATH US INT WOR
   Anthony L., 2012, P GRAPHICS INTERFACE, P117
   Ballard L, 2007, IEEE T SYST MAN CY B, V37, P1107, DOI 10.1109/TSMCB.2007.903539
   Bertinetto L., 2016, Advances in neural information processing systems, P523
   Cano J., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P548
   Choe GM, 2015, MULTIMED TOOLS APPL, V74, P7195, DOI 10.1007/s11042-014-1960-z
   Chung M, 2014, MULTIMED TOOLS APPL, V72, P2769, DOI 10.1007/s11042-013-1576-8
   Delaye A, 2013, PATTERN RECOGN, V46, P117, DOI 10.1016/j.patcog.2012.07.015
   Elanwar R.I., 2013, 2 INT C NEW PAR EL I, P1
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Frank M, 2013, IEEE T INF FOREN SEC, V8, P136, DOI 10.1109/TIFS.2012.2225048
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodrich Michael A., 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Ha TM, 1997, IEEE T PATTERN ANAL, V19, P535, DOI 10.1109/34.589216
   Ho J, 2016, ADV NEUR IN, V29
   Keogh E. J., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P285, DOI 10.1145/347090.347153
   Lai YR, 2017, MULTIMED TOOLS APPL, V76, P1585, DOI 10.1007/s11042-015-3147-7
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li JJ, 2016, C HUM SYST INTERACT, P203, DOI 10.1109/HSI.2016.7529632
   Lin ZC, 2007, PATTERN RECOGN, V40, P2097, DOI 10.1016/j.patcog.2006.11.024
   Mantena G, 2013, INT CONF ACOUST SPEE, P8515, DOI 10.1109/ICASSP.2013.6639327
   Page Tom, 2014, International Journal of Human Factors and Ergonomics, V3, P65, DOI 10.1504/IJHFE.2014.062550
   Radford A., 2016, COMPUT SCI
   Romeu JM, 2006, INT C PATT RECOG, P1026
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taranta EM, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P873, DOI 10.1145/2984511.2984525
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Varga T, 2003, PROC INT CONF DOC, P618
   Varga Tamas., 2005, Conference of the International Graphonomics Society, P206
   Vatavu RD, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2522848.2522875
   Vatavu RD, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P273
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Wozniak M, 2014, INFORM FUSION, V16, P3, DOI 10.1016/j.inffus.2013.04.006
NR 45
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17181
EP 17205
DI 10.1007/s11042-017-5285-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300053
DA 2024-07-18
ER

PT J
AU Elrefaei, LA
   Hamid, DH
   Bayazed, AA
   Bushnak, SS
   Maasher, SY
AF Elrefaei, Lamiaa A.
   Hamid, Doaa H.
   Bayazed, Afnan A.
   Bushnak, Sara S.
   Maasher, Shaikhah Y.
TI Developing Iris Recognition System for Smartphone Security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Deep Sparse Filter; Hough transform; Iris recognition;
   Visible Light
AB Smartphones have become an important way to store sensitive information; therefore, users' privacy needs to be highly protected. This can be done by using the most reliable and accurate biometric identification system available today: iris recognition. This paper develops and tests an iris recognition system for smartphones. The system uses eye images that rely on visible wavelength; these images are acquired by the smartphone built-in camera. The development of the system passes through four main phases: the first phase is the iris segmentation phase, which is done in three steps to detect the iris region from the captured image, which contains the eye and part of the face using Haar Cascade Classifier training, pupil localization, and iris localization using a Circular Hough Transform. In the second phase, the system applies normalization using a Rubber Sheet model, which converts the iris image to a fixed size pattern. In the third phase, unique features are extracted from that pattern using a Deep Sparse Filtering algorithm. Finally, in the matching phase, seven different matching techniques are investigated to decide the most appropriate one the system will use to verify the user. Two types of testing are conducted: Offline and Online tests. The BIPLab database and a collected dataset are used to measure the accuracy of the system phases and to calculate the Equal Error Rate (EER) for the whole system. The average EER is 0.18 for the BIPLab database and 0.26 for the collected dataset.
C1 [Elrefaei, Lamiaa A.; Hamid, Doaa H.; Bayazed, Afnan A.; Bushnak, Sara S.; Maasher, Shaikhah Y.] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.
   [Elrefaei, Lamiaa A.] Benha Univ, Dept Elect Engn, Fac Engn Shoubra, Cairo, Egypt.
C3 King Abdulaziz University; Egyptian Knowledge Bank (EKB); Benha
   University
RP Elrefaei, LA (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Comp Sci, Jeddah, Saudi Arabia.; Elrefaei, LA (corresponding author), Benha Univ, Dept Elect Engn, Fac Engn Shoubra, Cairo, Egypt.
EM laelrefaei@kau.edu.sa; duaa_h_h@yahoo.com; abayazid2013@gmail.com;
   soso92sb@yahoo.com; sh.maasher@gmail.com
RI Elrefaei, Lamiaa/ABB-5716-2021; Elrefaei, Lamiaa/K-2232-2012
OI Elrefaei, Lamiaa/0000-0001-5781-2251; Elrefaei,
   Lamiaa/0000-0001-5781-2251
FU King Abdulaziz University, Jeddah [611-97-D1435]; DSR
FX This work was funded by the deanship of scientific research (DSR), King
   Abdulaziz University, Jeddah, under grant No. (611-97-D1435). The
   authors therefore, acknowledge with thanks DSR technical and financial
   support. Thanks also goes to the research laboratory at the University
   of Salerno, Italy for letting us use their BIPLab database [6], which
   helped us to complete this work and test it properly. The authors are
   grateful to the anonymous reviewers for their constructive suggestions
   to improve the quality of the paper. The authors are also grateful for
   all volunteers who contributed to collect our dataset and participated
   in the online test.
CR [Anonymous], 2013, INT J MODERN ENG RES
   [Anonymous], 2016, SAMSUNG GALAXY NOTE
   [Anonymous], J TEKNOL MKLM
   [Anonymous], 2014, IRISHIELDTM USB 2120
   Azizi A., 2009, INT J COMPUTER SCI I, V2, P1
   Chawla SK, 2011, P INT C ADV COMPUTIN
   Cherabit Noureddine, 2012, Sci. Technol, V2, P114, DOI [DOI 10.5923/J.SCIT.20120205.02, 10.5923/j.scit.20120205.02.]
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Chun-Guang Li, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P649, DOI 10.1109/ICPR.2010.164
   Djoumessi M, 2011, IRIS SEGMENTATION US
   Du Y., 2007, RETHINKING EFFECTIVE, DOI 10.1117/2.1200711.0815
   Gupta S, 2010, Int J App Pharm, V2, P1
   Jillela RR, 2015, PATTERN RECOGN LETT, V57, P4, DOI 10.1016/j.patrec.2014.09.014
   Jiquan N, 2015, INT J COMPUT SCI INF, V13, P73
   Jurman G., 2009, P ADV RANK NIPS 09 W, P22
   Kazakov T., 2011, THESIS
   Kelvin M, 2012, WHAT ARE BENIFITES A
   Lederer J, 2015, AAAI CONF ARTIF INTE, P3797
   Masek L., 2003, THESIS CITESEER
   Ngiam J., 2011, Advances in Neural Information Processing Systems, V24
   Omran SS, 2015, UKSIM INT CONF COMP, P66, DOI 10.1109/UKSim.2015.70
   OpenCV, 2014, CASC CLASS
   OpenCV, 2014, TEMPL MATCH
   OpenCV, 2014, CASC CLASS TRAIN
   Poh N, 2006, PATTERN RECOGN, V39, P223, DOI 10.1016/j.patcog.2005.06.011
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proença H, 2007, IEEE T PATTERN ANAL, V29, P607, DOI 10.1109/TPAMI.2007.1016
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Radu P, 2011, P INT C BIOM SPEC IN, P137
   Raja KB, 2015, PATTERN RECOGN LETT, V57, P33, DOI 10.1016/j.patrec.2014.09.006
   SINGH S., 2011, INT J ENG SCI RES, V02, P1
   Sirlantzis K, 2013, ELECT LETT COMPUT VI, V12, P54, DOI [10.5565/rev/elcvia.520, DOI 10.5565/REV/ELCVIA.520]
   Theiler J, 2006, PROC SPIE, V6233, DOI 10.1117/12.665994
   Trokielewicz M, 2015, PROC SPIE, V9662, DOI 10.1117/12.2205913
   Verma P., 2012, Int. J. Emerg. Technol. Adv. Eng, V2, P177
   Walia M, 2015, INT J ADV RES COMP S, V3, P13
   Wang L, 2009, BEHAV BIOMETRICS HUM, DOI [10.4018/978-1-60566-725-6, DOI 10.4018/978-1-60566-725-6]
   Zhu Y, 2000, INT C PATT RECOG, P801, DOI 10.1109/ICPR.2000.906197
NR 38
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14579
EP 14603
DI 10.1007/s11042-017-5049-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200005
DA 2024-07-18
ER

PT J
AU Lu, XK
   Guo, YY
   Liu, N
   Wan, LH
   Fang, T
AF Lu, Xiankai
   Guo, Yiyou
   Liu, Na
   Wan, Lihong
   Fang, Tao
TI Non-convex joint bilateral guided depth upsampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-convex joint bilateral upsampling; Guided depth map upsampling
ID OBJECT RETRIEVAL; OPTIMIZATION
AB Blurring depth edges and texture copy artifacts are challenging issues for guided depth map upsampling. They are caused by the inconsistency between depth edges and corresponding color edges. In this paper, we extend the well-known Joint Bilateral Upsampling (JBU) (Kopf et al. 2007) with a novel non-convex optimization framework for guided depth map upsampling, which is denoted as Non-Convex JBU (NCJBU). We show that the proposed NCJBU can well handle the edge inconsistency by making use of the property of both the guidance color image and the depth map. Through comprehensive experiments, we show that our NCJBU can preserve sharp depth edges and properly suppress texture copy artifacts. In addition, we present a data driven scheme to properly determine the parameter in our model such that fine details and sharp depth edges are well preserved even for a large upsampling factor (e.g., 8 x). Experimental results on both simulated and real data show the effectiveness of our method.
C1 [Lu, Xiankai; Guo, Yiyou; Liu, Na; Wan, Lihong; Fang, Tao] Automat Shanghai Jiao Tong Univ, 800 Dongchuan, Shanghai, Peoples R China.
RP Fang, T (corresponding author), Automat Shanghai Jiao Tong Univ, 800 Dongchuan, Shanghai, Peoples R China.
EM carrierlxk@sjtu.edu.cn; wuhee110@163.com; liuna.job@gmail.com;
   wanlihong917@sina.com; tfang@sjtu.edu.cn
RI fang, tao/IQU-3074-2023; Xiankai, Lu/W-5570-2019
FU National Key Basic Research and Development Program of China
   [2012CB719903]; Science Fund for Creative Research Groups of the
   National Natural Science Foundation of China [61221003]; National
   Natural Science Foundation of China [41071256, 41571402]; National
   Science Foundation of China Youth Program [41101386]
FX This work was supported by the National Key Basic Research and
   Development Program of China under Grant 2012CB719903, the Science Fund
   for Creative Research Groups of the National Natural Science Foundation
   of China under Grant 61221003, the National Natural Science Foundation
   of China under Grant 41071256, 41571402, the National Science Foundation
   of China Youth Program under Grant 41101386.
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P ADV NEUR INF PROC
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Ferstl D, 2015, IEEE I CONF COMP VIS, P513, DOI 10.1109/ICCV.2015.66
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Hahne U, 2011, COMPUT GRAPH FORUM, V30, P1887, DOI 10.1111/j.1467-8659.2011.02041.x
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huhle B, 2008, CVPRW, P1
   Jiang XL, 2017, NEUROCOMPUTING, V242, P1, DOI 10.1016/j.neucom.2017.01.080
   Kiechle M, 2013, IEEE I CONF COMP VIS, P1545, DOI 10.1109/ICCV.2013.195
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239453
   Liu W, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2612826
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizarro L, 2010, INT J COMPUT VISION, V90, P62, DOI 10.1007/s11263-010-0337-7
   Rajagopalan AN, 2008, LECT NOTES COMPUT SC, V5096, P304, DOI 10.1007/978-3-540-69321-5_31
   Tomasi C., 1998, IEEE INT C COMP VIS
   Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832
   Yan JC, 2015, IEEE T IMAGE PROCESS, V24, P994, DOI 10.1109/TIP.2014.2387386
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zimmer H, 2011, INT J COMPUT VISION, V93, P368, DOI 10.1007/s11263-011-0422-6
NR 31
TC 11
Z9 12
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15521
EP 15544
DI 10.1007/s11042-017-5131-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200048
DA 2024-07-18
ER

PT J
AU Zhou, JW
   Liu, F
   Cheng, LM
AF Zhou, Junwei
   Liu, Fang
   Cheng, Lee-Ming
TI Image authentication using distributed arithmetic coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Distributed arithmetic coding; Image authentication;
   Distributed source coding
ID FORENSICS; ROBUST
AB Image authentication using distributed arithmetic coding (DAC) is studied in this paper. The quantized random projections of the original image are compressed by a DAC encoder and the codeword is taken as the authentication data. With the help of a target image as side information, the DAC decoder could recover the projections. The authentication process is achieved by examining the Euclidean distance between the reconstructed projections and the side information. Compared with existing approaches, the proposed approach has a simpler structure without the help of an additional cryptographic hash function to verify the decoding result. Moreover, the authentication data is more compact with fewer size. Simulation results justify that the proposed approach achieves a comparable performance as existing schemes.
C1 [Zhou, Junwei] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Liu, Fang; Cheng, Lee-Ming] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Wuhan University of Technology; City University of Hong Kong
RP Zhou, JW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM junweizhou@whut.edu.cn; fangliu2@my.cityu.edu.hk; itlcheng@cityu.edu.hk
OI Cheng, Lee Ming/0000-0001-5501-8441; Zhou, Junwei/0000-0002-6094-1203
FU National Natural Science Foundation of China [61601337]; Fundamental
   Research Funds for the Central Universities [WUT: 2017IVB025,
   175210005]; National High-tech R&D Program of China (863 Program)
   [2015AA015403]; Science & Technology Pillar Program of Hubei Province
   [2014BAA146]; Key Natural Science Foundation of Hubei Province of China
   [2015CFA059, 2015CFA069]
FX The work described in this paper was supported in part by the National
   Natural Science Foundation of China (Grant No. 61601337), by the
   Fundamental Research Funds for the Central Universities (WUT:
   2017IVB025), by the National High-tech R&D Program of China (863
   Program) (Grant No. 2015AA015403), by the Science & Technology Pillar
   Program of Hubei Province (Grant No. 2014BAA146), by the Fundamental
   Research Funds for the Central Universities (Grant No. 175210005) and by
   the Key Natural Science Foundation of Hubei Province of China (Grant
   Nos. 2015CFA059, 2015CFA069).
CR Choi KC, 2016, MULTIMED TOOLS APPL, V75, P6621, DOI 10.1007/s11042-015-2596-3
   Computer Vision Group University of Granada, TEST IM MISC GRAY LE
   Cover T. M, 2006, Elements of Information Theory, V2nd
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Grangetto M, 2008, IEEE COMMUN LETT, V12, P575, DOI 10.1109/LCOMM.2008.080645
   Grangetto M, 2009, IEEE T SIGNAL PROCES, V57, P2245, DOI 10.1109/TSP.2009.2014280
   Hagag A, 2017, MULTIMED TOOLS APPL, V76, P23757, DOI 10.1007/s11042-016-4158-8
   Jia Y, 2015, MULTIMED TOOLS APPL, V74, P1777, DOI 10.1007/s11042-013-1718-z
   Kang LW, 2009, IEEE INT C IM PROC, P1277
   Keshtkarjahromi Y, 2014, IEEE DATA COMPR CONF, P382, DOI 10.1109/DCC.2014.24
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   Lin YC, 2012, IEEE T IMAGE PROCESS, V21, P273, DOI 10.1109/TIP.2011.2157515
   Liu H, 2016, MULTIMED TOOLS APPL, V75, P7681, DOI 10.1007/s11042-015-2688-0
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Ramalho M, 2012, EUR SIGNAL PR CONF, P554
   Ramalho M, 2011, IEEE IMAGE PROC, P1825, DOI 10.1109/ICIP.2011.6115820
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sutcu Y, 2008, IEEE INT SYMP INFO, P2297, DOI 10.1109/ISIT.2008.4595400
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Varodayan D, 2012, IEEE T IMAGE PROCESS, V21, P2630, DOI 10.1109/TIP.2011.2175936
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Yang H, 2018, MULTIMED TOOLS APPL, V77, P4453, DOI 10.1007/s11042-016-4245-x
   Yang YC, 2016, J INF SECUR APPL, V31, P75, DOI 10.1016/j.jisa.2016.09.001
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zhou JW, 2015, SIGNAL PROCESS, V116, P29, DOI 10.1016/j.sigpro.2015.04.013
NR 31
TC 0
Z9 0
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15505
EP 15520
DI 10.1007/s11042-017-5130-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200047
DA 2024-07-18
ER

PT J
AU Chen, WY
   Wang, M
   Kuo, YM
AF Chen, Wen-Yuan
   Wang, Mei
   Kuo, Yu-Ming
TI Finger recognition scheme using finger valley features and distance
   mapping techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger recognition; Finger valleys; Distance mapping; Triangular method;
   Palm detection
ID AUTHENTICATION; WAVELET
AB The gesture recognition in computer vision on life, work and the application of technology products occupy an important position. In this paper, we use the finger valleys, distance mapping and triangular method (FVDMTM) to precisely recognize the fingers. FVDMTM adopt three novel ideas: first, we use the finger valleys to distinguish each finger. It is robust against intentional deformation of the fingers. Second, we employ a distance mapping method effectively to detect the valleys between the fingers. Third: we use the center-of-gravity of the palm as the original point for angle calculation of each finger by the triangular method. This let us to get precise finger angles of the test image. The experimental results demonstrate that our scheme is an effective and correct method for finger recognition.
C1 [Chen, Wen-Yuan; Kuo, Yu-Ming] Natl Chin Yi Univ Technol, Dept Elect Engn, 57,Sec 2,Zhongshan Rd, Taichung 41170, Taiwan.
   [Wang, Mei] Xian Univ Sci & Technol, Coll Elect & Control Engn, 58 Yan Ta Rd, Xian 710054, Shaanxi, Peoples R China.
C3 National Chin-Yi University of Technology; Xi'an University of Science &
   Technology
RP Wang, M (corresponding author), Xian Univ Sci & Technol, Coll Elect & Control Engn, 58 Yan Ta Rd, Xian 710054, Shaanxi, Peoples R China.
EM cwy@ncut.edt.tw; wangm@xust.edu.cn; kuoym1115@gmail.com
FU National Science Council, Taiwan (R.O.C.) [NSC 101-2221-E-167-034-MY2];
   Key Scientific and Technological Project of Shaanxi Province, China
   [2016GY-040]
FX This work was partly supported by the National Science Council, Taiwan
   (R.O.C.) under contract NSC 101-2221-E-167-034-MY2, and the Key
   Scientific and Technological Project of Shaanxi Province (2016GY-040),
   China.
CR [Anonymous], CONCURRENCY COMPUTAT
   Badenas J, 2001, PATTERN RECOGN, V34, P661, DOI 10.1016/S0031-3203(00)00014-5
   Bronstein A. M., 2007, P 11 IEEE INT C COMP, P1, DOI [10.1109/ICCV.2007.4409076, 10.1109/iccv.2007.4409076, DOI 10.1109/ICCV.2007.4409076]
   Chen W-Y, 2013, 26 INT C IND ENG OTH
   Chen W-Y, 2010, 5 INT LIV TECHN C IL
   Chen WY, 2014, SENSORS-BASEL, V14, P10578, DOI 10.3390/s140610578
   Choi BD, 2008, IEEE T CONSUM ELECTR, V54, P981, DOI 10.1109/TCE.2008.4637576
   Hasuda Y, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P2065, DOI 10.1109/ISIE.2007.4374926
   Hong-xiang Duan, 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P139, DOI 10.1109/ICCSN.2011.6014236
   Jia DY, 2008, IEEE ASME INT C ADV, P1170, DOI 10.1109/AIM.2008.4601828
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HM, 2017, IEEE ACCESS, V5, P670, DOI 10.1109/ACCESS.2017.2648845
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Mazumdar D, 2013, 2013 1ST INTERNATIONAL CONFERENCE ON EMERGING TRENDS AND APPLICATIONS IN COMPUTER SCIENCE (ICETACS), P197, DOI 10.1109/ICETACS.2013.6691422
   Nanni L, 2008, PATTERN RECOGN LETT, V29, P343, DOI 10.1016/j.patrec.2007.10.010
   Prasad SM, 2011, SECUR COMMUN NETW, V4, P577, DOI 10.1002/sec.234
   Sriboonruang Y, 2004, 2004 IEEE SYMPOSIUM ON VIRTUAL ENVIRONMENTS, HUMAN-COMPUTRE INTERFACES AND MEASUREMENT SYSTEMS, P78, DOI 10.1109/VECIMS.2004.1397192
   Yoon Ho-Sub, 2006, SICE ICASE INT JOINT, P326
NR 19
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10899
EP 10920
DI 10.1007/s11042-017-5383-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900031
DA 2024-07-18
ER

PT J
AU Chen, Z
   Wang, Z
   Jia, CF
AF Chen, Zhe
   Wang, Zhi
   Jia, Chunfu
TI Semantic-integrated software watermarking with tamper-proofing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic software watermarking; Code obfuscation; Control flow
   obfuscation; Neural network
ID SYMBOLIC EXECUTION; PATH
AB The existing works of software watermarking have the intrinsic defects: watermarking is independent of program semantics and have weak strength and resilience to state-of-the-art reverse engineering such as symbolic execution, dynamic taint analysis and theorem proving. In this paper, we propose a semantic-integrated watermarking with tamper-proofing to mitigate such problems. This work chooses neural network as the "integrator" and skillfully integrates the watermarking and tamper-proofing module into program semantics. The difficult of reverse engineering or tampering with watermarked program is equal to extracting the rules from neural networks, which had be proven as a NP-hard problem. We have deployed our work in SPECint-2006 benchmarks to evaluate the overhead, strength and resilience. Experiment results show that our watermarking could effectively resist the state-of-the-art reverse engineering, and the introduced overhead is acceptable.
C1 [Chen, Zhe; Wang, Zhi; Jia, Chunfu] Nankai Univ, Coll Comp & Control Engn, Tianjin 300350, Peoples R China.
   [Wang, Zhi; Jia, Chunfu] Civil Aviat Univ China, Informat Secur Evaluat Ctr Civil Aviat, Tianjin 300300, Peoples R China.
   [Jia, Chunfu] Key Lab High Trusted Informat Syst Hebei Prov, Baoding 071002, Peoples R China.
C3 Nankai University; Civil Aviation University of China
RP Wang, Z (corresponding author), Nankai Univ, Coll Comp & Control Engn, Tianjin 300350, Peoples R China.; Wang, Z (corresponding author), Civil Aviat Univ China, Informat Secur Evaluat Ctr Civil Aviat, Tianjin 300300, Peoples R China.
EM zwang@nankai.edu.cn
FU 973 Program of China [2013CB834204]; National Natural Science Foundation
   of China [61300242, 61772291]; National Science Foundation of Tianjin
   [15JCQNJC41500, 17JCZDJC30500]; Open Project Foundation of Information
   Security Evaluation Center of Civil Aviation, Civil Aviation University
   of China [CAAC-ISECCA-201701, CAAC-ISECCA-201702]
FX This project is partly supported by 973 Program of China(Grant No.
   2013CB834204), the National Natural Science Foundation of China (No.
   61300242, No. 61772291), the National Science Foundation of Tianjin (No.
   15JCQNJC41500, No. 17JCZDJC30500), the Open Project Foundation of
   Information Security Evaluation Center of Civil Aviation, Civil Aviation
   University of China(NO. CAAC-ISECCA-201701, NO. CAAC-ISECCA-201702)
CR Akhunzada A, 2015, J NETW COMPUT APPL, V48, P44, DOI 10.1016/j.jnca.2014.10.009
   Alliance BS, 2016, BSA GLOB SOFTW SURV
   [Anonymous], 1989, MATH CONTROL SIGNAL, DOI DOI 10.1007/BF02551274
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Aucsmith D., 1996, Information Hiding. First International Workshop Proceedings, P317
   Brumley D, 2008, ADV INFORM SECUR, V36, P65
   Bugrara S., 2013, 2013 USENIX Annual Technical Conference, P199
   Cadar C, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2408776.2408795
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen HY, 2007, ACM SIGPLAN NOTICES, V42, P9, DOI 10.1145/1241761.1241762
   Chen XJ, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P3, DOI 10.1109/IAS.2009.327
   Collberg C, 2004, ACM SIGPLAN NOTICES, V39, P107, DOI 10.1145/996893.996856
   Collberg C., 1999, Conference Record of POPL '99. 26th ACM SIGPLAN-SIGACT. Symposium on Principles of Programming Languages, P311, DOI 10.1145/292540.292569
   Collberg CS, 2007, ACM T PROGR LANG SYS, V29, DOI 10.1145/1286821.1286826
   Cousot P, 2004, ACM SIGPLAN NOTICES, V39, P173, DOI 10.1145/982962.964016
   Davidson R.L., 1996, US Patent, Patent No. [5,559,884, 5559884]
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Godefroid Patrice, 2008, Network and Distributed Systems Security
   Golea M, 1996, TRAIN ART NEUR NETW
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jacob M, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P129
   Jin HX, 2003, LECT NOTES COMPUT SC, V2851, P352
   Kamel I, 2009, COMPUT SECUR, V28, P395, DOI 10.1016/j.cose.2009.01.007
   KING JC, 1976, COMMUN ACM, V19, P385, DOI 10.1145/360248.360252
   Ma H., 2014, INT C SECURITY PRIVA, P287
   Myles G., 2003, INT C INF SEC CRYPT, P274
   Nagra J., 2009, SURREPTITIOUS SOFTWA
   Oberhumer M, 2004, ULTIMATE PACKER EXEC
   Qu X, 2011, INT SYMP EMP SOFTWAR, P117, DOI 10.1109/ESEM.2011.20
   Sen K, 2007, P 22 IEEE ACM INT C, P571, DOI DOI 10.1145/1321631.1321746
   Sharif M. I., 2008, NDSS
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Song D, 2008, LECT NOTES COMPUT SC, V5352, P1, DOI 10.1007/978-3-540-89862-7_1
   Tickle AB, 1998, IEEE T NEURAL NETWOR, V9, P1057, DOI 10.1109/72.728352
   Towell Geoffrey G., 1993, MACHINE LEARNING
   Wang Z, 2011, LECT NOTES COMPUT SC, V6879, P210, DOI 10.1007/978-3-642-23822-2_12
   [王志 Wang Zhi], 2012, [计算机学报, Chinese Journal of Computers], V35, P693
   Wolf D, 2003, EASTER EGG ARCH
   Yu X., 2017, THESIS
   Yuqun Chen, 2002, Information Hiding. 5th International Workshop, IH 2002. Revised Papers (Lecture Notes in Computer Science Vol.2578), P400
   Zeng Junyuan., 2013, Proceedings of the 2013 ACM SIGSAC Conference on Computer Communications Security, CCS '13, P487
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zong N, 2014, 2014 THEORETICAL ASPECTS OF SOFTWARE ENGINEERING CONFERENCE (TASE), P114, DOI 10.1109/TASE.2014.19
NR 48
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11159
EP 11178
DI 10.1007/s11042-017-5373-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900044
DA 2024-07-18
ER

PT J
AU He, JR
   Xiong, NX
AF He, Jinrong
   Xiong, Naixue
TI An effective information detection method for social big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier detection; Decision graph; Local density; Discriminant distance;
   Outlier score; Social big data
ID OUTLIERS; SUPPORT
AB In data mining and knowledge discovery applications, outlier detection is a fundamental problem for robust machine learning and anomaly discovery. There are many successful outlier detection methods, including Local Outlier Factor (LOF), Angle-Based Outlier Factor (ABOF), Local Projection Score (LPS), etc. In this paper, we assume that outliers lie in lower density region and they are at relatively larger distance from any points with a higher local density. In order to identify such outliers quantitatively, the paper proposed a decision graph based outlier detection (DGOD) method. The DGOD method works by firstly calculating the decision graph score (DGS) for each sample, where the DGS is defined as ratio between discriminant distance and local density, next ranking samples according to their DGS values, and finally, returning samples with top-r largest DGS values as outliers. Experimental results on synthetic and real-world datasets have confirmed its effectiveness on outlier detection problems, and it is a general and effective information detection method, which is robust to data shape and dimensionality.
C1 [He, Jinrong] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Xiong, Naixue] Colorado Tech Univ, Sch Comp Sci, Colorado Springs, CO 80907 USA.
C3 Northwest A&F University - China; Colorado Technical University
RP He, JR (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.; Xiong, NX (corresponding author), Colorado Tech Univ, Sch Comp Sci, Colorado Springs, CO 80907 USA.
EM hejinrong@nwafu.edu.cn; xiongnaixue@gmail.com
RI He, Jinrong/R-9293-2019; xiong, naixue/M-4277-2019
OI He, Jinrong/0000-0003-4040-4766; xiong, naixue/0000-0002-0394-4635
FU Yangling Demonstration Zone Science and Technology Planning Project
   [2016NY-31]; Doctoral Starting up Foundation of Northwest AF University
   [2452015302]; National Natural Science Foundation of China [61602388]
FX The authors would like to thank all the anonymous reviewers and editors
   for their valuable comments and. Additionally, we would like to thank
   Bin Liu and Yaguang Jia who critically reviewed the study proposal. This
   work was supported in part by Yangling Demonstration Zone Science and
   Technology Planning Project under Grant 2016NY-31, Doctoral Starting up
   Foundation of Northwest A&F University under Grant 2452015302 and
   National Natural Science Foundation of China under Grants 61602388.
CR [Anonymous], 2012, OUTLIER ANAL
   [Anonymous], 1980, IDENTIFICATION OUTLI, DOI DOI 10.1007/978-94-015-3994-4
   [Anonymous], 1994, Multidimensional Scaling
   [Anonymous], 2015, ARXIV150104267
   Bagui S, 2015, INT J CLOUD APPL COM, V5, P36, DOI [10.4018/ijcac.2015040103, 10.4018/IJCAC.2015040103]
   Barnett V., 1984, OUTLIERS STAT DATA
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Du HZ, 2016, IEEE CONF COMPUT, DOI 10.1109/INFCOMW.2016.7562187
   Dufrenois F, 2015, IEEE T NEUR NET LEAR, V26, P982, DOI 10.1109/TNNLS.2014.2329534
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Ha J, 2014, KNOWL-BASED SYST, V63, P15, DOI 10.1016/j.knosys.2014.03.001
   Hamedani K, 2018, IEEE T IND INFORM, V14, P734, DOI 10.1109/TII.2017.2769106
   Hido S, 2011, KNOWL INF SYST, V26, P309, DOI 10.1007/s10115-010-0283-2
   Huang HM, 2013, J STAT COMPUT SIM, V83, P518, DOI 10.1080/00949655.2011.621124
   Jian Tang, 2002, Advances in Knowledge Discovery and Data Mining. 6th Pacific-Asia Conference, PAKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2336), P535
   Jiang SY, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P429, DOI 10.1109/FSKD.2008.244
   Jin W, 2006, LECT NOTES ARTIF INT, V3918, P577
   Johnson R.A., 2007, Applied multivariate statistial analysis, Vsixth
   Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392
   Kriegel H.-P., 2008, P 14 ACM SIGKDD INT, P444, DOI DOI 10.1145/1401890.1401946
   Liu HW, 2018, IEEE T SYST MAN CY-S, V48, P2451, DOI 10.1109/TSMC.2017.2718220
   Maimon O., 2005, The data mining and knowledge discovery handbook (1315-1329)
   Onderwater M., 2010, THESIS
   Ouf S, 2015, INT J CLOUD APPL COM, V5, P53, DOI [10.4018/ijcac.2015040104, 10.4018/IJCAC.2015040104]
   Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802
   Ramaswamy S, 2000, SIGMOD REC, V29, P427, DOI 10.1145/335191.335437
   Rehm F, 2007, SOFT COMPUT, V11, P489, DOI 10.1007/s00500-006-0112-4
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Shi Y, 2011, KNOWL INF SYST, V28, P709, DOI 10.1007/s10115-010-0323-y
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Wang XC, 2015, INFORM SYST, V48, P89, DOI 10.1016/j.is.2014.09.002
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   Zhang J, 2011, SOFT COMPUT, V15, P1195, DOI 10.1007/s00500-010-0575-1
   Zhang K, 2009, LECT NOTES ARTIF INT, V5476, P813, DOI 10.1007/978-3-642-01307-2_84
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zhang ZY, 2018, FUTURE GENER COMP SY, V86, P914, DOI 10.1016/j.future.2016.10.007
NR 41
TC 11
Z9 11
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11277
EP 11305
DI 10.1007/s11042-017-5523-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900050
DA 2024-07-18
ER

PT J
AU Yu, FH
   Chen, MJ
   Yu, BL
   Li, WP
   Ma, LH
   Gao, HM
AF Yu, Fahong
   Chen, Meijia
   Yu, Bolin
   Li, Wenping
   Ma, Longhua
   Gao, Huimin
TI Privacy preservation based on clustering perturbation algorithm for
   social network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Networks; Privacy preservation; Information loss; Perturbation
ID EFFICIENT
AB With a vigorous development of information release for social network, it is now an urgent question to protect sensitive information. The sensitive information concerned by the attackers may be usually located in a local group of large scale social networks and the operations of privacy protection are needed to minimize changes for overall structure of the network to maintain data availability. In this paper, a clustering perturbation algorithm to preserve privacy for social network was proposed considering preservation privacy of vertices properties and community structures simultaneously. The proposed algorithm introduced a strategy of exchanging attributes between vertices with same degree randomly to induce attackers to search for false targets and maintain whole structure of network. Furthermore, a perturbation strategy with tiny influences based on local clustering and modifying edges complementarily was adopted to decrease the risk of privacy disclosure considering minimum loss of network structure and data information. The experimental results showed that the proposed algorithm has more advantages over other existing state-of-the-art approaches in privacy preservation and effectiveness of social network.
C1 [Yu, Fahong; Li, Wenping; Gao, Huimin] Jiaxing Univ, Coll Math & Informat Engn, Jiaxing 434023, Zhejiang, Peoples R China.
   [Chen, Meijia] Jiaxing Univ, Ctr Econ Managing Expt, Jiaxing 434023, Zhejiang, Peoples R China.
   [Yu, Bolin] Shenzhen Inst Informat Technol, Sch Elect & Commun, Shenzhen 518172, Peoples R China.
   [Ma, Longhua] Zhejiang Univ, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
C3 Jiaxing University; Jiaxing University; Shenzhen Institute of
   Information Technology; Zhejiang University
RP Yu, FH (corresponding author), Jiaxing Univ, Coll Math & Informat Engn, Jiaxing 434023, Zhejiang, Peoples R China.
EM fhyu520@whu.edu.cn; mjchen1980@126.com; yubl@sziit.edu.cn;
   liwenping@hrbeu.edu.cn; lhmazju@163.com; hmgao@zjxu.edu.cn
RI Gao, Huimin/I-8253-2012
OI yu, fahong/0000-0002-9342-6419
FU Zhejiang Provincial Natural Science Foundation of China [LY16F020027,
   LY16F020026, LZ15F030004, LY15F030021]; National Nature Science
   Foundation of China [61703183, 61370185]; Humanity and Social Science
   Youth foundation of Ministry of Education of China [15YJCZH088]
FX This research is supported by the financial support from Zhejiang
   Provincial Natural Science Foundation of China under Grant No.
   LY16F020027, LY16F020026, LZ15F030004 and LY15F030021, National Nature
   Science Foundation of China under grant No. 61703183 and 61370185 and
   Humanity and Social Science Youth foundation of Ministry of Education of
   China under Grant no. 15YJCZH088. Furthermore, the original manuscript
   was helped by Wenping Li and Bolin Yu
CR [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], SECURE INTEGRATION I
   Bhagyashree V, 2016, INT J SCI RES, V6, P241
   Bi CJ, 2014, INT CONF CLOUD COMPU, P327, DOI 10.1109/CCIS.2014.7175753
   Campan A, 2013, PAC ASIA C KNOWL DIS, V8, P370
   Chaudhary P, 2016, 2016 IEEE 5TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS
   Deepajothi S, 2015, DATA MINING KNOWL EN, V7, P287
   Ford R, 2015, P DMIN, P403
   Fu Yan-Yan, 2014, Journal of Software, V25, P768
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta BB, 2017, TELECOMMUNICATION SY
   Li J, 2017, MULTIMEDIA TOOLS APP
   Li J, 2016, IEEE SYST J, V9, P248
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Mu CH, 2015, APPL SOFT COMPUT, V34, P485, DOI 10.1016/j.asoc.2015.05.034
   Sadhya D, 2016, COMPUT SECUR, V58, P160, DOI 10.1016/j.cose.2016.01.003
   Sapountzi A, 2016, FUT GEN COMPUT SYST
   Sihag VK, 2012, P INF TECHN, P267
   Tamersoy A, 2016, IEEE T INF TECHNOL B, V4, P413
   Vaghashia H, 2015, INT J COMPUT APPL, V19, P466
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang R, 2015, LECT NOTES COMPUT SC, V8949, P193, DOI DOI 10.1007/978-3-319-15943-0
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Yuan MX, 2013, IEEE T KNOWL DATA EN, V25, P633, DOI 10.1109/TKDE.2011.259
   Zhang S, 2017, CLUSTER COMPUT, V20, P1, DOI DOI 10.1007/s10586-016-0677-3
   Zhang Z, 2017, CYVOD NOVEL TRINITY
   Zhang Z, 2016, FUTURE GENER COMP SY, P1276
   Zhou B, 2014, KNOWL INF SYST, V7, P47
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 33
TC 14
Z9 16
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11241
EP 11258
DI 10.1007/s11042-017-5502-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900048
DA 2024-07-18
ER

PT J
AU Ahmad, W
   Karnick, H
   Hegde, RM
AF Ahmad, Waquar
   Karnick, Harish
   Hegde, Rajesh M.
TI Client-wise cohort set selection by combining speaker- and
   phoneme-specific I-vectors for speaker verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Speaker recognition; Cohort selection
ID SCORE NORMALIZATION; IDENTIFICATION; TUTORIAL
AB This work explores the use of phoneme level information in cohort selection to improve the performance of a speaker verification system. In speaker verification, cohort is used in score normalization to get a better performance. Score normalization is a technique to reduce the undesirable variation arising from acoustically mismatched conditions. Proper selection of cohort significantly improves speaker verification performance. In this paper, we investigate cohort selection based on a speaker model cluster under the i-vector framework that we call the i-vector model cluster (IMC). Two approaches for cohort selection are proposed. First approach utilizes speaker specific properties and called speaker specific cohort selection (SSCS). In this approach, speaker level information is used for cohort selection. The second approach is phoneme specific cohort selection (PSCS). This method improves cohort set selection by using phoneme level information. Phoneme level information is further employed in a late fusion approach that uses a majority voting method on normalized scores to improve the performance of the speaker verification system. Speaker verification experiments were conducted using the TIMIT, HINDI and YOHO databases. An equal error rate improvement of 19.01%, 14.61% and 19.4%is obtained for the proposed method compared to the standard ZT-Norm method for TIMIT, HINDI and YOHO datasets. Reasonable improvements in performance are also obtained in terms of minimum decision cost function (min DCF) and detection error trade-off (DET) curves.
C1 [Ahmad, Waquar] NIT Sikkim, Dept ECE, Ravangla 737139, Sikkim, India.
   [Karnick, Harish] IIT Kanpur, Dept Comp Sci & Engn, Kanpur 208016, Uttar Pradesh, India.
   [Hegde, Rajesh M.] IIT Kanpur, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Sikkim; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Kanpur; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Kanpur
RP Ahmad, W (corresponding author), NIT Sikkim, Dept ECE, Ravangla 737139, Sikkim, India.
EM waquar@nitsikkim.ac.in; hk@cse.iitk.ac.in; rhegde@iitk.ac.in
CR [Anonymous], 9 C SPEECH COMP
   [Anonymous], 2001, DATABASE INDIAN LANG
   [Anonymous], P OD SPEAK LANG REC
   [Anonymous], CRIM MONTREAL REPOR
   [Anonymous], 2012, INT CONF ACOUST SPEE
   Apsingekar VR, 2011, SPEECH COMMUN, V53, P110, DOI 10.1016/j.specom.2010.07.001
   Apsingekar VR, 2009, IEEE T AUDIO SPEECH, V17, P848, DOI 10.1109/TASL.2008.2010882
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   Bimbot F, 2004, EURASIP J APPL SIG P, V2004, P430, DOI 10.1155/S1110865704310024
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   CAMPBELL JP, 1995, INT CONF ACOUST SPEE, P341, DOI 10.1109/ICASSP.1995.479543
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Das Rohan Kumar, 2016, P INT C SIGN PROC CO, P1
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Eatock S, 1994, P ICASSP 1994, P133
   FIENBERG SE, 1970, ANN MATH STAT, V41, P907, DOI 10.1214/aoms/1177696968
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471
   Hosom J- P, 2016, uS Patent, Patent No. [9,230,550, 9230550]
   Hultzen I, 1964, TABLES TRANSITIONAL
   JIROUSEK R, 1995, COMPUT STAT DATA AN, V19, P177, DOI 10.1016/0167-9473(93)E0055-9
   Kenny P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2307
   Kinnunen T, REPORT MYSTERY COH A
   Kucera H, 1967, Computational analysis of present-day American English
   Martin A., 1997, PROC EURO SPEECH 97, V4, P1895
   Matejka P, 2011, INT CONF ACOUST SPEE, P4828
   Nagineni S, 2010, EUR SIGNAL PR CONF, P576
   Ramos-Castro D, 2007, PATTERN RECOGN LETT, V28, P90, DOI 10.1016/j.patrec.2006.06.008
   Reynolds D. A., 1997, EUROSPEECH
   Reynolds D.A., 2008, HDB SPEECH PROCESSIN, P763, DOI DOI 10.1007/978-3-540-49127-9_38
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   ROSENBERG AE, 1976, P IEEE, V64, P475, DOI 10.1109/PROC.1976.10156
   Sturim DE, 2005, INT CONF ACOUST SPEE, P741
   Vincent E, COMPUTER SPEECH LANG
   Young S.J., 1993, HTK HIDDEN MARKOV MO
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zeinali H, 2016, INTERSPEECH, P440, DOI 10.21437/Interspeech.2016-1174
NR 38
TC 2
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8273
EP 8294
DI 10.1007/s11042-017-4723-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800023
DA 2024-07-18
ER

PT J
AU Kashyap, KL
   Bajpai, MK
   Khanna, P
AF Kashyap, Kanchan Lata
   Bajpai, Manish Kumar
   Khanna, Pritee
TI An efficient algorithm for mass detection and shape analysis of
   different masses present in digital mammograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammography; Increased efficiency; Reduced computational time; Unsharp
   masking; Breast cancer; Wavelet technique; GLCM; GLRLM; FCM
ID AUTOMATED DETECTION; BREAST MASSES; CONTRAST ENHANCEMENT;
   CLASSIFICATION; SEGMENTATION; INFORMATION; DIAGNOSIS; FEATURES; LESIONS;
   SYSTEM
AB The present study introduces an efficient algorithm for automatic segmentation and detection of mass present in the mammograms. The problem of over and under-segmentation of low-contrast mammographic images has been solved by applying preprocessing on original mammograms. Subtraction operation performed between enhanced and enhanced inverted mammogram significantly highlights the suspicious mass region in mammograms. The segmentation accuracy of suspicious region has been improved by combining wavelet transform and fast fuzzy c-means clustering algorithm. The accuracy of mass segmentation has been quantified by means of Jaccard coefficients. Better sensitivity, specificity, accuracy, and area under the curve (AUC) are observed with support vector machine using radial basis kernel function. The proposed algorithm is validated on Mini-Mammographic Image Analysis Society (MIAS) and Digital Database for Screening Mammography (DDSM) datasets. Highest 91.76% sensitivity, 96.26% specificity, 95.46% accuracy, and 96.29% AUC on DDSM dataset and 94.63% sensitivity, 92.74% specificity, 92.02% accuracy, and 95.33% AUC on MIAS dataset are observed. Also, shape analysis of mass is performed by using moment invariant and Radon transform based features. The best results are obtained with Radon based features and achieved accuracies for round, oval, lobulated, and irregular shape of mass are 100%, 70%, 64%, and 96%, respectively.
C1 [Kashyap, Kanchan Lata; Bajpai, Manish Kumar; Khanna, Pritee] Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur 482005, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Kashyap, KL (corresponding author), Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur 482005, India.
EM kanchan.k@iiitdmj.ac.in; mkbajpai@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI Bajpai, Manish Kumar/K-7915-2015; Khanna, Pritee/V-5418-2019; Kashyap,
   Kanchan/AAG-3833-2019
OI Bajpai, Manish Kumar/0000-0003-2258-2390; Khanna,
   Pritee/0000-0003-0518-2133; Kashyap, Kanchan/0000-0003-0112-8711
CR [Anonymous], BREAST IM REP DAT SY
   Bellotti R, 2006, MED PHYS, V33, P3066, DOI 10.1118/1.2214177
   Bocchi L, 2007, MED ENG PHYS, V29, P691, DOI 10.1016/j.medengphy.2006.07.012
   Cao AZ, 2004, INT C PATT RECOG, P758, DOI 10.1109/ICPR.2004.1334639
   Cascio D, 2006, IEEE T NUCL SCI, V53, P2827, DOI 10.1109/TNS.2006.878003
   Che FN, 1996, IEEE C DIG MAMM, P13, DOI [10.1049/ic:19960496, DOI 10.1049/IC:19960496]
   CHEETHAM A H, 1969, Journal of Paleontology, V43, P1130
   Christoyianni I, 2000, IEEE SIGNAL PROC MAG, V17, P54, DOI 10.1109/79.814646
   Constantinidis AS, 1999, IEE CONF PUBL, P435, DOI 10.1049/cp:19990359
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   de Sampaio WB, 2015, EXPERT SYST APPL, V42, P8911, DOI 10.1016/j.eswa.2015.07.046
   Deans SR, 2007, The Radon transform and some of its applications
   do Nascimento MZ, 2013, EXPERT SYST APPL, V40, P6213, DOI 10.1016/j.eswa.2013.04.036
   Domínguez AR, 2009, PATTERN RECOGN, V42, P1138, DOI 10.1016/j.patcog.2008.08.006
   Ganesan Karthikeyan, 2013, IEEE Rev Biomed Eng, V6, P77, DOI 10.1109/RBME.2012.2232289
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUO ZM, 1995, MED PHYS, V22, P1569, DOI 10.1118/1.597626
   Jen CC, 2015, EXPERT SYST APPL, V42, P3048, DOI 10.1016/j.eswa.2014.11.061
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kom G, 2007, COMPUT BIOL MED, V37, P37, DOI 10.1016/j.compbiomed.2005.12.004
   Kupinski MA, 1998, IEEE T MED IMAGING, V17, P510, DOI 10.1109/42.730396
   Kurt B, 2014, COMPUT METH PROG BIO, V114, P349, DOI 10.1016/j.cmpb.2014.02.014
   Lladó X, 2009, COMPUT MED IMAG GRAP, V33, P415, DOI 10.1016/j.compmedimag.2009.03.007
   Martins LD, 2009, J SIGNAL PROCESS SYS, V55, P77, DOI 10.1007/s11265-008-0209-3
   Materka A, 1998, TEXTURE ANAL METHODS, P9
   Muramatsu C, 2016, COMPUT BIOL MED, V72, P43, DOI 10.1016/j.compbiomed.2016.03.007
   NG SL, 1992, COMPUT BIOMED RES, V25, P218, DOI 10.1016/0010-4809(92)90040-H
   Nguyen TA, 2005, P ANN INT IEEE EMBS, P3210, DOI 10.1109/IEMBS.2005.1617159
   Nunes AP, 2010, INT J SIGNAL IMAGING, V3, P40, DOI 10.1504/IJSISE.2010.034631
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Petrick N, 1996, IEEE T MED IMAGING, V15, P59, DOI 10.1109/42.481441
   Petrick N, 1996, MED PHYS, V23, P1685, DOI 10.1118/1.597756
   Rose C, 2006, LECT NOTES COMPUT SC, V4046, P376
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Surendiran B., 2012, International Journal of Medical Engineering and Informatics, V4, P36, DOI 10.1504/IJMEI.2012.045302
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Wang DF, 2009, NEUROCOMPUTING, V72, P3296, DOI 10.1016/j.neucom.2009.02.015
NR 46
TC 19
Z9 19
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9249
EP 9269
DI 10.1007/s11042-017-4751-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200004
DA 2024-07-18
ER

PT J
AU Kesavan, S
   Jayakumar, J
AF Kesavan, Selvaraj
   Jayakumar, J.
TI Effective client-driven three-level rate adaptation (TLRA) approach for
   adaptive HTTP streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive HTTP streaming; Conventional streaming; DASH; HLS; Rate
   adaptation; Quality of service; TLRA
ID H.264/AVC; QOS
AB Multimedia streaming allows consumers to view multimedia content anywhere. However, quality of service is a major concern amid heightened levels of network traffic caused by increasing user demand. Accordingly, media streaming technology is adopting a new paradigm: adaptive HTTP streaming (AHS). AHS is widely used for real-time streaming content delivery in the Internet environment. In streaming, selection of appropriate bitrate is crucial for adapting media rate to network variations and client processing capabilities while ensuring optimal service for the consumer. We evaluate a proposed client-driven three-level optimized rate adaptation algorithm for adaptive HTTP media streaming. In the first stage, the algorithm chooses a suitable starting bitrate close to the available channel capacity. Next, the algorithm monitors the client parameters in real time, precisely detecting network variations and choosing a likely available bit representation for the next download segment. The algorithm controls and minimizes the effects of buffer stalls and overflow resulting from the brief network variations occurring between consecutive segments. The proposed algorithm is implemented in Dynamic Adaptive Streaming over HTTP (DASH) player and its performance compared to that of commercially available Gstreamer-based HTTP Live Streaming (HLS) and DASH players which use conventional segment fetch time-based adaptation and throughput-based adaptation algorithms respectively. This evaluation uses a real-time cloud server client and test bed streaming setup. The resulting analysis shows that the client-driven three-level rate adaptation (TLRA) approach allows adaptive streaming clients to maximize use of end-to-end network capacity, delivering an ideal user experience by precisely predicting network variations and rapidly adapting to available bandwidth, minimizing rebuffering events and bitrate level changes.
C1 [Kesavan, Selvaraj; Jayakumar, J.] Karunya Univ, Dept Elect & Elect Engn, Coimbatore 641114, Tamil Nadu, India.
C3 Karunya Institute of Technology & Sciences
RP Kesavan, S (corresponding author), Karunya Univ, Dept Elect & Elect Engn, Coimbatore 641114, Tamil Nadu, India.
EM selvarajkesavan@gmail.com; jayakumar@karunya.edu
RI J, JAYAKUMAR/GNP-6444-2022
OI JAYARAJ, JAYAKUMAR/0000-0001-7099-0554
CR Allman M., 1999, IETF RFC 2581
   [Anonymous], ACM MMSYS 2011 SPECI
   [Anonymous], MULT FRAM SET AD HTT
   [Anonymous], 26247 TS 3GPP
   [Anonymous], 2014, 2300912014 ISO IEC
   [Anonymous], MED STREAM ENG DEPL
   [Anonymous], HTTP LIVE STREAMING
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], ADOBE HTTP DYNAMIC S
   [Anonymous], DUMMYNET PROJECT LIV
   [Anonymous], NETW PROT AN SET EXP
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], MULT BITR VID TRANSC
   [Anonymous], DASH PLAYBACK
   [Anonymous], 5104 RFC
   [Anonymous], USING FEC RATE ADAPT
   [Anonymous], 2008, 5348 RFC
   [Anonymous], AM WEB SERV EL CLOUD
   [Anonymous], 1997, TCP SLOW START CONGE
   [Anonymous], IEEE GLOB COMM C GLO
   [Anonymous], 2002, RFC 3390
   [Anonymous], 2003, 3448 RFC
   [Anonymous], 2013, P AS PAC SIGN INF PR
   Busse I, 1996, COMPUT COMMUN, V19, P49, DOI 10.1016/0140-3664(95)01038-6
   Fielding R., 1999, Tech. Rep
   Floyd S, 1993, IEEE ACM T NETWORK, V1, P397, DOI 10.1109/90.251892
   Huang TY, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P187, DOI 10.1145/2619239.2626296
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Liu CH, 2012, SIGNAL PROCESS-IMAGE, V27, P288, DOI 10.1016/j.image.2011.10.001
   Mulroy P, 2006, BT TECHNOL J, V24, P167, DOI 10.1007/s10550-006-0055-4
   Park J, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P222, DOI 10.1109/ICOIN.2015.7057886
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
NR 36
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8081
EP 8114
DI 10.1007/s11042-017-4705-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800015
DA 2024-07-18
ER

PT J
AU Kumar, P
   Saini, R
   Roy, PP
   Dogra, DP
AF Kumar, Pradeep
   Saini, Rajkumar
   Roy, Partha Pratim
   Dogra, Debi Prosad
TI A position and rotation invariant framework for sign language
   recognition (SLR) using Kinect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Depth sensors; Hidden Markov Model (HMM); Occluded
   gestures
AB Sign language is the only means of communication for speech and hearing impaired people. Using machine translation, Sign Language Recognition (SLR) systems provide medium of communication between speech and hearing impaired and others who have difficulty in understanding such languages. However, most of the SLR systems require the signer to sign in front of the capturing device/sensor. Such systems fail to recognize some gestures when the relative position of the signer is changed or when the body occlusion occurs due to position variations. In this paper, we present a robust position invariant SLR framework. A depth-sensor device (Kinect) has been used to obtain the signer's skeleton information. The framework is capable of recognizing occluded sign gestures and has been tested on a dataset of 2700 gestures. The recognition process has been performed using Hidden Markov Model (HMM) and the results show the efficiency of the proposed framework with an accuracy of 83.77% on occluded gestures.
C1 [Kumar, Pradeep; Saini, Rajkumar; Roy, Partha Pratim] IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar, Odisha, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bhubaneswar
RP Kumar, P (corresponding author), IIT Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM pradeep.iitr7@gmail.com; rajkr.dcs2014@iitr.ac.in; proy.fcs@iitr.ac.in;
   dpdogra@iitbbs.ac.in
RI Roy, Partha Pratim/GPF-4253-2022; Kumar, Pradeep/GQA-7930-2022; Roy,
   Partha Pratim/AAV-9061-2020; Roy, Partha Pratim/AAW-2994-2020; Kumar,
   Pradeep/GQV-5790-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2016, IEEE T PATTERN ANAL
   [Anonymous], 2015, Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on
   [Anonymous], 2017, J NETWORK COMPUTER A
   [Anonymous], 2010, ACM SIGGRAPH ASIA 20
   Athitsos V, 2003, PROC CVPR IEEE, P432
   Bianne-Bernard AL, 2011, IEEE T PATTERN ANAL, V33, P2066, DOI 10.1109/TPAMI.2011.22
   Chai X, 2013, C AUT FAC GEST REC
   de Campos T.E., 2006, IEEE C COMPUTER VISI, V1, P782
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Elliott R, 2011, SIGN LANGUAGE TRANSL
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Escobedo-Cardenas E, 2015, IEEE IMAGE PROC, P1240, DOI 10.1109/ICIP.2015.7350998
   González-Ortega D, 2014, COMPUT METH PROG BIO, V113, P620, DOI 10.1016/j.cmpb.2013.10.014
   Incertis IG, 2006, INT C PATT RECOG, P100
   Kaur B, MULTIMEDIA TOOLS APP
   Kumar P, 2016, MULTIMEDIA TOOLS APP
   Kumar  P., 2016, NEUROCOMPUTING
   Kumar P., 2016, IEEE SENSORS J
   Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18
   Lang S, 2012, LECT NOTES ARTIF INT, V7267, P394, DOI 10.1007/978-3-642-29347-4_46
   Lim KM, 2016, EXPERT SYST APPL, V54, P208, DOI 10.1016/j.eswa.2016.01.047
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Machida E, 2012, 2012 PROCEEDINGS OF SICE ANNUAL CONFERENCE (SICE), P2207
   Marin G, 2015, MULTIMEDIA TOOLS APP
   Martinez-Camarena M, 2015, IEEE IMAGE PROC, P2454, DOI 10.1109/ICIP.2015.7351243
   Miranda L., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P268, DOI 10.1109/SIBGRAPI.2012.44
   Monir S, 2012, INT CONF INTELL SYST, P404, DOI 10.1109/ISDA.2012.6416572
   Ong EJ, 2012, PROC CVPR IEEE, P2200, DOI 10.1109/CVPR.2012.6247928
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sun C, 2013, IEEE T CYBERNETICS, V43, P1418, DOI 10.1109/TCYB.2013.2265337
   Uebersax D, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130267
   Wu JX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P453
   Yang HD, 2015, SENSORS-BASEL, V15, P135, DOI 10.3390/s150100135
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
NR 46
TC 48
Z9 49
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8823
EP 8846
DI 10.1007/s11042-017-4776-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800047
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zheng, XH
   Chang, V
   Ye, SZ
   Tang, CM
AF Yang, Yang
   Zheng, Xianghan
   Chang, Victor
   Ye, Shaozhen
   Tang, Chunming
TI Lattice assumption based fuzzy information retrieval scheme support
   multi-user for secure multimedia cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secure multimedia cloud; Searchable encryption; Fuzzy keyword search;
   Multiple user; Lattice assumption
ID PUBLIC-KEY ENCRYPTION; KEYWORD SEARCH; PRIVACY
AB Multimedia cloud is novel computation paradigm which could leverage cloud infrastructure to store large quantity of multimedia documents and respond on the requests from customers. With the development of multimedia cloud, an increasing attention is paid to its privacy and security issues. Searchable encryption (SE) technology could protect the sensitive information of cloud storage data and at the same time allow keyword search query. Most of the available SE schemes are constructed using the bilinear map. However, both discrete logarithms and factorization are proved to be solved by quantum computer in a polynomial time. Thus, those schemes are not secure in quantum age. Moreover, majority SE schemes are limited in exact or fuzzy keyword search. They can not support the semantically keyword equivalent judgement. In order to solve those problems, we suggest a novel data retrieval scheme for multiple users based on the lattice based mechanism. The contribution of this paper is summarized in three aspects: lattice assumption based scheme to resist quantum attack, semantically keyword search to enable synonym query and broadcast encryption based mechanism to support multiple user system without sharing secret key. This scheme is a candidate for secure multimedia cloud even in quantum-era since the LWE problem is secure against quantum attack.
C1 [Yang, Yang; Zheng, Xianghan; Ye, Shaozhen] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Chang, Victor] Xian Jiaotong Liverpool Univ, IBSS, Suzhou, Peoples R China.
   [Yang, Yang; Tang, Chunming] Guangzhou Univ, Sch Math & Informat Sci, Key Lab Informat Secur, Guangzhou, Guangdong, Peoples R China.
C3 Fuzhou University; Xi'an Jiaotong-Liverpool University; Guangzhou
   University
RP Zheng, XH (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
EM xianghan.zheng@fzu.edu.cn
RI Chang, Victor/AAC-7582-2019
OI Chang, Victor/0000-0002-8012-5852
FU National Natural Science Foundation of China [61402112, 61472307,
   61472309, 61502106]; Fujian Major Project of Regional Industry
   [2014H4015]; Key Laboratory of Information Security, School Mathematics
   and Information Science, Guangzhou University [GDXXAQ2016-09]; Science
   and Technology Project of Fujian Education Department [JA12028]; Major
   Science and Technology Project of Fujian Province [2015H6013];
   Fundamental Research Funds for the Central Universities of China
   [ZYGX2014J061]; Natural Science Basic Research Plan in Shaanxi Province
   of China [2014JQ1027]; Basic Research Foundation of Xi'an University of
   Architecture and Technology [JC1416]
FX The authors are grateful to the anonymous editor and reviewers. This
   work is sponsored by National Natural Science Foundation of China
   (61402112, 61472307, 61472309, 61502106); Fujian Major Project of
   Regional Industry 2014H4015; Key Laboratory of Information Security,
   School Mathematics and Information Science, Guangzhou University (Grant
   No. GDXXAQ2016-09); Science and Technology Project of Fujian Education
   Department under Grant No. JA12028; Major Science and Technology Project
   of Fujian Province under Grant No. 2015H6013; Fundamental Research Funds
   for the Central Universities of China (ZYGX2014J061); Natural Science
   Basic Research Plan in Shaanxi Province of China (2014JQ1027); Basic
   Research Foundation of Xi'an University of Architecture and Technology
   (JC1416).
CR Agrawal S, 2010, LECT NOTES COMPUT SC, V6223, P98, DOI 10.1007/978-3-642-14623-7_6
   Agrawal S, 2010, LECT NOTES COMPUT SC, V6110, P553
   Alwen J., 2009, Proceedings of STACS, V09001, P75
   [Anonymous], 2013, INT J INFORM TECHNOL
   [Anonymous], 2012 INT C INF SEC I
   [Anonymous], 2009, INT ASS CRYPTOL RES
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   Baek J, 2008, LECT NOTES COMPUT SC, V5072, P1249, DOI 10.1007/978-3-540-69839-5_96
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Chang V, 2014, FUTURE GENER COMP SY, V37, P512, DOI 10.1016/j.future.2013.12.028
   Delerablée C, 2007, LECT NOTES COMPUT SC, V4833, P200
   Díaz-Sánchez D, 2014, TELECOMMUN SYST, V55, P315, DOI 10.1007/s11235-013-9783-1
   Ding MZ, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P526, DOI 10.1109/ICNIDC.2012.6418809
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Gentry C, 2010, LECT NOTES COMPUT SC, V6110, P506
   Goldwasser S., 2010, Proceedings of the 1st Symposium on Innovations in Computer Science, P230
   Gordon SD, 2010, LECT NOTES COMPUT SC, V6477, P395, DOI 10.1007/978-3-642-17373-8_23
   Hou CJ, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P336, DOI 10.1109/3PGCIC.2013.57
   Hu CY, 2012, COMM COM INF SC, V345, P568
   Hwang MS, 2014, INF TECHNOL CONTROL, V43, P277, DOI 10.5755/j01.itc.43.3.6429
   Li YB, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978575
   Peikert C, 2009, ACM S THEORY COMPUT, P333
   Troncoso-Pastoriza JR, 2013, IEEE SIGNAL PROC MAG, V30, P29, DOI 10.1109/MSP.2012.2228533
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Wang HG, 2014, IEEE COMMUN MAG, V52, P73, DOI 10.1109/MCOM.2014.6766088
   Xu P, 2013, IEEE T COMPUT, V62, P2266, DOI 10.1109/TC.2012.215
   Zhang B, 2011, J NETW COMPUT APPL, V34, P262, DOI 10.1016/j.jnca.2010.07.007
   Zhang Jiuling, 2012, Journal of Electronics (China), V29, P473, DOI 10.1007/s11767-012-0850-7
   Zheng XH, 2014, J INTERNET TECHNOL, V15, P1043, DOI 10.6138/JIT.2014.15.6.15
   Zhenhua Chen, 2012, Intelligence and Security Informatics. Proceedings Pacific Asia Workshop, PAISI 2012, P176, DOI 10.1007/978-3-642-30428-6_15
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 33
TC 31
Z9 32
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9927
EP 9941
DI 10.1007/s11042-017-4560-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200038
DA 2024-07-18
ER

PT J
AU Ullah, J
   Khan, A
   Jaffar, MA
AF Ullah, Javid
   Khan, Ahmad
   Jaffar, Muhammad Arfan
TI Motion cues and saliency based unconstrained video segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Moving object; Optical flow; Saliency; Recognition;
   Homography
ID OBJECT; MODEL
AB The segmentation of moving objects become challenging when the object motion is small, the shape of object changes, and there is global background motion in unconstrained videos. In this paper, we propose a fully automatic, efficient, fast and composite framework to segment the moving object on the basis of saliency, locality, color and motion cues. First, we propose a new saliency measure to predict the potential salient regions. In the second step, we use the RANSAC homography and optical flow to compensate the background motion and get reliable motion information, called motion cues. Furthermore, the saliency information and motion cues are combined to get the initial segmented object (seeded region). A refinement is performed to remove the unwanted noisy details and expand the seeded region to the whole object. Detailed experimentation is carried out on challenging video benchmarks to evaluate the performance of the proposed method. The results show that the proposed method is faster and performs better than state-of-the-art approaches.
C1 [Ullah, Javid; Jaffar, Muhammad Arfan] Natl Univ Comp & Emerging Sci, H-11-4, Islamabad, Pakistan.
   [Khan, Ahmad] COMSATS Inst Informat Technol, Dept Comp Sci, Abbottabad, Pakistan.
   [Jaffar, Muhammad Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Imam Mohammad Ibn Saud Islamic
   University (IMSIU)
RP Jaffar, MA (corresponding author), Natl Univ Comp & Emerging Sci, H-11-4, Islamabad, Pakistan.; Jaffar, MA (corresponding author), Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Riyadh, Saudi Arabia.
EM javid.fast@gmail.com; ahmadkhan@ciit.net.pk;
   arfan.jaffar@ccis.imamu.edu.sa
RI Khan, Ahmad/AAG-1269-2020; Jaffar, Arfan/GQB-2768-2022
OI Khan, Ahmad/0000-0002-6955-8876; 
CR [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS WORK
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2010, P BRIT MACH VIS C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], IEEE C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P EUR WORKSH ADV VID
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Bugeau A., 2007, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2007.383244, 10.1109/CVPR.2007.383244]
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Faktor A., 2014, P BRIT MACHINE VISIO
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fragkiadaki K, 2015, PROC CVPR IEEE, P4083, DOI 10.1109/CVPR.2015.7299035
   Gelgon M, 1997, PROC CVPR IEEE, P514, DOI 10.1109/CVPR.1997.609374
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Khan S, 2001, PROC CVPR IEEE, P746
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Liu Ce, 2009, THESIS
   López-Rubio E, 2011, INT J NEURAL SYST, V21, P225, DOI 10.1142/S012906571100281X
   López-Rubio E, 2011, COMPUT VIS IMAGE UND, V115, P735, DOI 10.1016/j.cviu.2011.01.007
   Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735
   Mahamud S., 2006, 2006 IEEE COMPUTER S, V1, P1154
   Matsuyama T., 2006, Systems and Computers in Japan, V37, P77, DOI 10.1002/scj.10166
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293
   Rahtu E., 2010, ECCV
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Sheikh Y, 2005, PROC CVPR IEEE, P74
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wang Y, 2005, PROC CVPR IEEE, P264
   Xu C, 2012, IEEE ICC
   Xu X., 2008, IEEE C COMPUTER VISI, P1
   Yin Pei., 2007, P IEEE C COMPUTER VI, P1, DOI DOI 10.1109/CVPR.2007.383008
   Yuen J, 2009, IEEE I CONF COMP VIS, P1451, DOI 10.1109/ICCV.2009.5459289
   Zhang G, 2007, AEROSP CONF PROC, P3929
NR 53
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7429
EP 7446
DI 10.1007/s11042-017-4655-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700046
DA 2024-07-18
ER

PT J
AU Alaoui-Fdili, O
   Coudoux, FX
   Fakhri, Y
   Corlay, P
   Aboutajdine, D
AF Alaoui-Fdili, Othmane
   Coudoux, Francois-Xavier
   Fakhri, Youssef
   Corlay, Patrick
   Aboutajdine, Driss
TI Energy-efficient joint video encoding and transmission framework for
   WVSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy-efficiency in WVSN; Cross-layer design; Energy consumption
   prediction; Video distortion prediction; Energy-efficient reliable
   routing
ID MULTIMEDIA SENSOR NETWORKS; SINGLE-PATH; WIRELESS; COMMUNICATION; TIME
AB In this paper, we propose an energy-efficient joint video encoding and transmission framework for network lifetime extension, under an end-to-end video quality constraint in the Wireless Video Sensor Networks (WVSN). This framework integrates an energy-efficient and adaptive intra-only video encoding scheme based on the H.264/AVC standard, that outputs two service differentiated macroblocks categories, namely the Region Of Interest and the Background. Empirical models describing the physical behavior of the measured energies and distortions, during the video encoding and transmission phases, are derived. These models enable the video source node to dynamically adapt its video encoder's configuration in order to meet the desired quality, while extending the network lifetime. An energy-efficient and reliable multipath multi-priority routing protocol is proposed to route the encoded streams to the sink, while considering the remaining energy, the congestion level as well as the packet loss rates of the intermediate nodes. Moreover, this protocol interacts with the application layer in order to bypass congestion situations and continuously feed it with current statistics. Through extensive numerical simulations, we demonstrate that the proposed framework does not only extend the video sensor lifetime by 54%, but it also performs significant end-to-end video quality enhancement of 35% in terms of Mean Squared Error (MSE) measurement.
C1 [Alaoui-Fdili, Othmane] Univ Cadi Ayyad, Ecole Super Technol Safi, Safi, Morocco.
   [Alaoui-Fdili, Othmane; Fakhri, Youssef; Aboutajdine, Driss] Univ Mohammed V Rabat, Fac Sci, LRIT CNRST 29, Rabat, Morocco.
   [Coudoux, Francois-Xavier; Corlay, Patrick] Univ Valenciennes & Hainaut Cambresis, Dept OAE, IEMN UMR 8520, Valenciennes, France.
   [Fakhri, Youssef] Ibn Tofail Univ, LARIT Networks & Telecommun Team, Kenitra, Morocco.
C3 Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences
   (INSIS); Universite Polytechnique Hauts-de-France; Universite de Lille;
   Ibn Tofail University of Kenitra
RP Alaoui-Fdili, O (corresponding author), Univ Cadi Ayyad, Ecole Super Technol Safi, Safi, Morocco.; Alaoui-Fdili, O (corresponding author), Univ Mohammed V Rabat, Fac Sci, LRIT CNRST 29, Rabat, Morocco.
EM othmane.alaoui.fdili@gmail.com
RI YOUSSEF, FAKHRI/AAA-8261-2020; aboutajdine, driss/AAP-9051-2020;
   Coudoux, Francois-Xavier/ACV-0828-2022; Alaoui-Fdili,
   Othmane/P-9377-2019
OI YOUSSEF, FAKHRI/0000-0002-5647-303X; Alaoui-Fdili,
   Othmane/0000-0003-1704-722X
FU National Center for Scientific and Technical Research (CNRST) of Morocco
   [G01/003]; Franco-Moroccan cooperation program in STICs for the research
   project "RECIF"
FX This research was supported by the excellence fellowships program of the
   National Center for Scientific and Technical Research (CNRST) of Morocco
   (G01/003) and the Franco-Moroccan cooperation program in STICs for the
   research project "RECIF".
CR Aghdasi HS, 2008, SENSORS-BASEL, V8, P4529, DOI 10.3390/s8074529
   Ahmad JJ, 2009, 2009 43RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1 AND 2, P629, DOI 10.1109/CISS.2009.5054795
   Akyildiz IF, 2007, WIRELESS MULTIMEDIA, V51
   Alaoui-Fdili O, 2013, EUR SIGN PROC C
   Alaoui-Fdili O, 2014, IEEE IMAGE PROC, P1189, DOI 10.1109/ICIP.2014.7025237
   Boluk PS, 2014, WIREL COMMUN MOB COM, V14, P1, DOI 10.1002/wcm.1218
   Costa DG, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-142
   Costa DG, 2012, J SENS ACTUAT NETW, V1, DOI 10.3390/jsan1010003
   Costa DG, 2011, SENSORS-BASEL, V11, P5439, DOI 10.3390/s110505439
   Dai R, 2012, IEEE T MULTIMEDIA, V14, P1469, DOI 10.1109/TMM.2012.2194992
   Felemban E, 2006, IEEE T MOBILE COMPUT, V5, P738, DOI 10.1109/TMC.2006.79
   Felemban E, 2014, AD HOC NETW, V23, P65, DOI 10.1016/j.adhoc.2014.06.003
   He YF, 2009, IEEE T CIRC SYST VID, V19, P704, DOI 10.1109/TCSVT.2009.2017411
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   He ZH, 2008, IEEE CIRC SYST MAG, V8, P25, DOI 10.1109/MCAS.2008.923007
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   *IEEE, 2002, 80211ED33 IEEE
   ITU-T RECOMMENDATION P, 1999, SUBJECTIVE VIDEO QUA
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   Lu XA, 2002, IEEE IMAGE PROC, P533
   Macit M, 2014, AD HOC NETW, V19, P132, DOI 10.1016/j.adhoc.2014.02.008
   Politis I, 2008, MOBILE NETW APPL, V13, P274, DOI 10.1007/s11036-008-0061-5
   Sahin D, 2014, AD HOC NETW, V22, P43, DOI 10.1016/j.adhoc.2014.05.005
   Shah GA, 2012, IEEE T MULTIMEDIA, V14, P1442, DOI 10.1109/TMM.2012.2196510
   Sobeih A, 2006, IEEE WIREL COMMUN, V13, P104, DOI 10.1109/MWC.2006.1678171
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Zhai F, 2006, IEEE T IMAGE PROCESS, V15, P40, DOI 10.1109/TIP.2005.860353
   Zou JN, 2011, IEEE T VEH TECHNOL, V60, P1182, DOI 10.1109/TVT.2011.2111425
NR 28
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4509
EP 4541
DI 10.1007/s11042-017-4904-6
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500027
DA 2024-07-18
ER

PT J
AU Guo, J
   Zhao, XW
   Yuan, X
   Li, YY
   Peng, Y
AF Guo, Jun
   Zhao, Xiaowei
   Yuan, Xuan
   Li, Yangyuan
   Peng, Yao
TI Discriminative unsupervised 2D dimensionality reduction with graph
   embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Similarity matrix; Spectral clustering; Global discriminant information
ID PRESERVING PROJECTIONS; FACE REPRESENTATION; 2-DIMENSIONAL PCA
AB Dimensionality reduction is a great challenge in high dimensional unlabelled data processing. The existing dimensionality reduction methods are prone to employing similarity matrix and spectral clustering algorithm. However, the noises in original data always make the similarity matrix unreliable and degrade the clustering performance. Besides, existing spectral clustering methods just focus on the local structures and ignore the global discriminative information, which may lead to overfitting in some cases. To address these issues, a novel unsupervised 2-dimensional dimensionality reduction method is proposed in this paper, which incorporates the similarity matrix learning and global discriminant information into the procedure of dimensionality reduction. Particularly, the number of the connected components in the learned similarity matrix is equal to cluster number. We compare the proposed method with several 2-dimensional unsupervised dimensionality reduction methods and evaluate the clustering performance by K-means on several benchmark data sets. The experimental results show that the proposed method outperforms the state-of-the-art methods.
C1 [Guo, Jun; Zhao, Xiaowei; Yuan, Xuan; Peng, Yao] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Li, Yangyuan] Budapest Univ Technol & Econ, Fac Elect Engn & Informat, H-1111 Budapest, Hungary.
C3 Northwest University Xi'an; Budapest University of Technology &
   Economics
RP Guo, J; Peng, Y (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Shaanxi, Peoples R China.
EM guojun@nwu.edu.cn; xiaoweizhao4@gmail.com; yuanxuan2017@gmail.com;
   wlqsb@hotmail.com; xyyiezi@163.com
RI Li, Yangyuan/ABA-6379-2022; yao, Yao/JED-9212-2023
OI yao, Yao/0000-0001-9569-6167
FU Natural Science Basic Research Plan in Shannxi Province of China
   [2017JM6056]; Designing inter-core Datapath for voltage frequency island
   mpSoC [15JK1726]
FX This work was jointly supported by Natural Science Basic Research Plan
   in Shannxi Province of China No. 2017JM6056, and Designing inter-core
   Datapath for voltage frequency island mpSoC No. 15JK1726.
CR [Anonymous], 2016, BMVC
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Boyd S., 2013, IEEE T AUTOMATIC CON, V51, P1859
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai D., 2010, KDD, P333
   Chang X, 2015, A CONVEX FORMULATION
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Dong XQ, 2010, THIRD INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2010), P443
   Du L, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P209, DOI 10.1145/2783258.2783345
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fan M, 2017, STRUCTURE REGULARIZE
   Gao L, 2015, IEEE C COMP VIS PATT
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   He XF, 2011, IEEE T PATTERN ANAL, V33, P2013, DOI 10.1109/TPAMI.2011.44
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Kadir SN, 2014, NEURAL COMPUT, V26, P2379, DOI 10.1162/NECO_a_00661
   Kambhatla N, 1997, NEURAL COMPUTATION
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Lakshmanan K. C., 2015, NEURAL COMPUT, V27, P1
   Luo M., 2016, IJCAI
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Manor LZ., 2005, Proceedings of the Advances in Neural Information Processing Systems, V27, P1601
   Mohar B., 1991, GRAPH THEORY COMBINA, V2, P871
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Niyogi X, 2004, ADV NEURAL INFORM PR, V16
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Song JK, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2964284.2964295
   Susan Shortreed., 2005, Proceedings of the Twenty-First Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-05), P534
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Woraratpanya K, 2015, 2015 7th International Conference on Information Technology and Electrical Engineering (ICITEE), P448, DOI 10.1109/ICITEED.2015.7408988
   Wu M., 2006, P C NEURAL INFORM PR, P1529
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhao X, 2017, NEURAL COMPUTATION
   Zhao Z, 2013, IEEE T KNOWL DATA EN, V25, P619, DOI 10.1109/TKDE.2011.222
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 50
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3189
EP 3207
DI 10.1007/s11042-017-5019-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600015
DA 2024-07-18
ER

PT J
AU Wang, L
   Gao, CQ
   Jian, J
   Tang, L
   Liu, J
AF Wang, Lan
   Gao, Chenqiang
   Jian, Jie
   Tang, Lin
   Liu, Jiang
TI Semantic feature based multi-spectral saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Multi-spectrum; Infrared images
ID VISUAL-ATTENTION; OBJECT DETECTION; MODEL
AB Saliency detection aims to locate the distinctive regions in images and can be extensively applied to many applications. Up to now, most of effort has put into visible images and the related methods usually encounter difficulty for images with complex background. In this paper, we propose a semantic feature based multi-spectral saliency detection method using the complementarity of infrared and visible images. We use the thermal infrared image to relieve the difficulty of visible images with complex background, while still utilizing the rich texture and color information in visible images. Specifically, we firstly uses the Convolutional Neural Network to extract high-level feature from superpixels obtained by segmenting visible and infrared images, and then the initial saliency maps of both spectrums are computed, respectively. After that, two initial saliency maps are fused via a Total Variation (TV) minimization model and finally the fused result is linearly combined with the enhanced foreground salient object map to obtain the final saliency detection result. Experiment results reveal that the proposed method outperforms the baseline methods.
C1 [Wang, Lan; Gao, Chenqiang; Jian, Jie; Tang, Lin; Liu, Jiang] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Gao, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
EM gaocq@cqupt.edu.cn
FU National Natural Science Foundation of China [61571071]; Wenfeng
   innovation and start-up project of Chongqing University of Posts and
   Telecommunications [WF201404]; National Social Science Foundation of
   China [15BGL2729]; Research Innovation Program for Postgraduate of
   Chongqing [CYS17222]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61571071), Wenfeng innovation and start-up project of
   Chongqing University of Posts and Telecommunications (No. WF201404), the
   National Social Science Foundation of China (No. 15BGL2729), the
   Research Innovation Program for Postgraduate of Chongqing (No.
   CYS17222). The authors also thank NVIDIA corporation for the donation of
   GTX 980 GPU.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], 2016, IEEE T PATTERN ANAL
   Bao L, 2015, MULTIMED TOOLS APPL, V74, P4045, DOI 10.1007/s11042-014-2043-x
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2234
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gao CQ, 2016, NEUROCOMPUTING, V212, P36, DOI 10.1016/j.neucom.2016.05.094
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han AL, 2017, MULTIMED TOOLS APPL, V76, P11037, DOI 10.1007/s11042-016-3463-6
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hiremath, 2008, International Journal of Image Processing, V2, P10
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang R, 2014, AAAI CONF ARTIF INTE, P2773
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang Q, 2013, COMPUT VIS IMAGE UND, V117, P1748, DOI 10.1016/j.cviu.2013.07.002
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yan Y., 2013, ACM International Conference on Multimedia, P537
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan Y, 2015, AAAI CONF ARTIF INTE, P3841
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yu J, 2014, INT WORKS EARTH OB
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 47
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3387
EP 3403
DI 10.1007/s11042-017-5152-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600027
DA 2024-07-18
ER

PT J
AU Wang, WN
   Mishra, KK
AF Wang, Weina
   Mishra, Krishn Kumar
TI A novel stock trading prediction and recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender; Information granule; Stock trading prediction; Fuzzy time
   series
ID FUZZY TIME-SERIES; FORECASTING ENROLLMENTS; MODELS; TAIEX; SEGMENTATION;
   INTERVALS; LENGTHS
AB The prices of the stock are influence by many factors and emerge extremely nonlinear structure. Therefore, the stock trading prediction and recommendation is an extremely challenging task. In this paper, a novel stock trading prediction and recommendation system is proposed in user-friendly form. The recommendation system can inform the user whether is to buy or sell the stocks in the next step. Information granulation is applied to transform raw time series into meaningful and interpretable granules, and the more effective non-uniform partitioning method for prediction is presented. The system first determines the intervals based on information granules, and then define the fuzzy sets and fuzzify the historical data. Third, construct fuzzy relationships and assign weights to each period. Finally, the prediction and recommendation is implemented. The experimental results show the proposed system yields better prediction performance, and increases profit-making opportunities.
C1 [Wang, Weina] Jilin Inst Chem Technol, Sch Sci, Jilin, Jilin, Peoples R China.
   [Mishra, Krishn Kumar] Univ Missouri, Dept Math & Comp Sci, Columbia, MO USA.
C3 Jilin Institute of Chemical Technology; University of Missouri System;
   University of Missouri Columbia
RP Wang, WN (corresponding author), Jilin Inst Chem Technol, Sch Sci, Jilin, Jilin, Peoples R China.
EM wangweina406@sina.com; kkm@mnnit.ac.in
RI Wang, Weina/ISR-9229-2023; Mishra, K.K/AAT-3083-2021
OI Wang, Weina/0000-0001-6773-7777; mishra, k.k./0000-0001-7557-5288
CR Chen SM, 2011, IEEE T FUZZY SYST, V19, P1, DOI 10.1109/TFUZZ.2010.2073712
   Chen SM, 1996, FUZZY SET SYST, V81, P311, DOI 10.1016/0165-0114(95)00220-0
   Fu T., 2006, DMIN, P3
   Huarng K, 2006, PHYSICA A, V363, P481, DOI 10.1016/j.physa.2005.08.014
   Huarng K, 2001, FUZZY SET SYST, V123, P387, DOI 10.1016/S0165-0114(00)00057-9
   Huarng KH, 2007, IEEE T SYST MAN CY B, V37, P836, DOI 10.1109/TSMCB.2006.890303
   Huarng KH, 2006, IEEE T SYST MAN CY B, V36, P328, DOI 10.1109/TSMCB.2005.857093
   Jiang J, 2007, I C WIREL COMM NETW, P5609
   Pedrycz W, 2013, Analysis and design of intelligent systems: A framework of granular computing
   Pedrycz W, 2015, KNOWL-BASED SYST, V80, P98, DOI 10.1016/j.knosys.2014.12.030
   Pedrycz W, 2013, APPL SOFT COMPUT, V13, P4209, DOI 10.1016/j.asoc.2013.06.017
   SONG Q, 1993, FUZZY SET SYST, V54, P1, DOI 10.1016/0165-0114(93)90355-L
   SONG Q, 1994, FUZZY SET SYST, V62, P1, DOI 10.1016/0165-0114(94)90067-1
   SONG Q, 1993, FUZZY SET SYST, V54, P269, DOI 10.1016/0165-0114(93)90372-O
   SULLIVAN J, 1994, FUZZY SET SYST, V64, P279, DOI 10.1016/0165-0114(94)90152-X
   Wang X, 2016, KNOWL-BASED SYST, V101, P100, DOI 10.1016/j.knosys.2016.03.012
   Wang ZJ, 2004, IEEE T SYST MAN CY B, V34, P1056, DOI 10.1109/TSMCB.2003.819486
   Weina Wang, 2015, ICIC Express Letters, V9, P2483
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   Yu HK, 2005, PHYSICA A, V349, P609, DOI 10.1016/j.physa.2004.11.006
   Yu HK, 2005, PHYSICA A, V346, P657, DOI 10.1016/j.physa.2004.07.024
   Yu THK, 2008, EXPERT SYST APPL, V34, P2945, DOI 10.1016/j.eswa.2007.05.016
   Yu THK, 2010, EXPERT SYST APPL, V37, P5529, DOI 10.1016/j.eswa.2010.03.063
NR 25
TC 6
Z9 7
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4203
EP 4215
DI 10.1007/s11042-017-4587-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500008
DA 2024-07-18
ER

PT J
AU Xing, L
   Dong, H
   Jiang, W
   Tang, KW
AF Xing, Ling
   Dong, Hao
   Jiang, Wei
   Tang, Kewei
TI Nonnegative matrix factorization by joint locality-constrained and
   <i>a""</i> <sub>2,1</sub>-norm regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonnegative matrix factorization; Local constraint; Clustering
ID SPARSE REPRESENTATION
AB Nonnegative matrix factorization has been widely applied recently. The nonnegativity constraints result in parts-based, sparse representations which can be more robust than global, non-sparse features. However, existing techniques could not accurately dominate the sparseness. To address this issue, we present a unified criterion, called Nonnegative Matrix Factorization by Joint Locality-constrained and a"" (2,1)-norm Regularization(NMF2L), which is designed to simultaneously perform nonnegative matrix factorization and locality constraint as well as to obtain the row sparsity. We reformulate the nonnegative local coordinate factorization problem and use a"" (2,1)-norm on the coefficient matrix to obtain row sparsity, which results in selecting relevant features. An efficient updating rule is proposed, and its convergence is theoretically guaranteed. Experiments on benchmark face datasets demonstrate the effectiveness of our presented method in comparison to the state-of-the-art methods.
C1 [Xing, Ling] Henan Univ Sci & Technol, Sch Informat Engn, Luoyang 471023, Peoples R China.
   [Dong, Hao; Jiang, Wei; Tang, Kewei] Liaoning Normal Univ, Sch Math, Dalian 116029, Peoples R China.
C3 Henan University of Science & Technology; Liaoning Normal University
RP Jiang, W (corresponding author), Liaoning Normal Univ, Sch Math, Dalian 116029, Peoples R China.
EM xinglinghaust@163.com; haodong@163.com; swxxjw@aliyun.com;
   tkwliaoning@gmail.com
FU Natural Science Foundation of Liaoning [2015020070]; Natural Science
   Foundation of China [61171109, 61175048]
FX We would like to thank all anonymous reviewers for their helpful
   comments. This work is supported by the Natural Science Foundation of
   Liaoning No. 2015020070, and the Natural Science Foundation of China No.
   61171109 and 61175048.
CR [Anonymous], 2011, IJCAI INT JOINT C AR
   [Anonymous], 21 AAAI C ART INT
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], MATH PROBL ENG
   [Anonymous], 2017, ACM T INTEL SYST TEC, DOI DOI 10.1145/2963105
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boyd S., 2004, CONVEX OPTIMIZATION
   Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P82
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chao YW, 2011, IEEE IMAGE PROC, P761, DOI 10.1109/ICIP.2011.6116666
   Chen Y, 2013, IEEE T IMAGE PROCESS, V22, P969, DOI 10.1109/TIP.2012.2224357
   Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Jiang W, 2016, INFORM SCIENCES, V340, P144, DOI 10.1016/j.ins.2015.12.038
   Kotsiantis S., 2011, ARTIF INTELL REV, V42, P157, DOI DOI 10.1007/S10462-011-9230-1
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Liu HF, 2012, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2012.6247851
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Luo M., 2016, INT JOINT C ART INT
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Qi H, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379796
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang R, 2015, IEEE T CYBERNETICS, V45, P1108, DOI 10.1109/TCYB.2014.2341575
   Wei CP, 2013, PATTERN RECOGN, V46, P1277, DOI 10.1016/j.patcog.2012.11.014
   Wei Xu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P202
   Wu Z., 2011, IJCAI Proceedings-International Joint Conference on Artificial Intelli- gence, P1378
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
NR 37
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3029
EP 3048
DI 10.1007/s11042-017-4970-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600007
DA 2024-07-18
ER

PT J
AU Yu, L
   Han, FJ
   Huang, SB
   Luo, YW
AF Yu, Li
   Han, Fangjian
   Huang, Shaobing
   Luo, Yiwen
TI A content-based goods image recommendation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Image content; Weighted representation model;
   Feature indexing
AB The information of e-commerce images varies and different users may focus on different contents of the same image for different purpose. So the research on recommendation by computers is becoming more and more important. But retrieval based only on keywords obviously falls short for massive numbers of resource images. In this paper, we focus on a recommendation system of goods images based on image content. Goods images have a relatively homogenous background and have a wide range of applications. The recommendation consists of three stages. First, the image is pre-processed by removing the background. Second, a weighted representation model is proposed to represent the image. The separated features are extracted and normalized, and then the weights of each feature are computed based on the samples browsed by the users. Third, a feature indexing scheme is put forward based on the proposed representation. A binary-tree is used for the indexing, and a binary-tree updating algorithm is also given. Finally, the recommended images are given by a features combination searching scheme. Experimental results on a real goods image database show that our algorithm can achieve high accuracy in recommending similar goods images with high speed.
C1 [Yu, Li; Han, Fangjian; Huang, Shaobing; Luo, Yiwen] Natl Univ Def Technol, Sch Elect Sci & Engn, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Yu, L (corresponding author), Natl Univ Def Technol, Sch Elect Sci & Engn, Changsha, Hunan, Peoples R China.
EM yuli@nudt.edu.cn
CR ADOMAVICIUS G, 2005, NEXT GENERATION RECO
   Akshita S, 2013, INT J COMPUTER APPL, V71
   Alber J, 1998, P 4 ANN INT COMP COM
   [Anonymous], 1990, SIGMOD, DOI DOI 10.1145/93597.98741
   Berger P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P326, DOI 10.1109/SmartCity.2015.92
   Castleman K. R., 1996, Digital Image Processing
   Celentano A, 1 EUR WORKSH CONT BA
   Di Ruberto C, 2009, IMAGE VISION COMPUT, V27, P1097, DOI 10.1016/j.imavis.2008.10.009
   Geng X, 2015, IEEE I CONF COMP VIS, P4274, DOI 10.1109/ICCV.2015.486
   Guntuku SC, 2016, IEEE T IMAGE PROCESS, V25, P3762, DOI 10.1109/TIP.2016.2576278
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kaufman L., 2009, FINDING GROUPS DATA
   Kim HI, 2016, INT CONF BIG DATA, P93, DOI 10.1109/BIGCOMP.2016.7425806
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Park DH, 2012, EXPERT SYST APPL, V39, P10059, DOI 10.1016/j.eswa.2012.02.038
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Poli G, 2010, FACE RECOGNITION, P381
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2015, APPL COMPUT HARMON A, V38, P161, DOI 10.1016/j.acha.2014.06.003
   WHITE DA, 1996, P 12 INT C DAT ENG N
   Yang LF, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P533, DOI 10.1109/CISP.2015.7407937
   Yoneya T, 2007, GENOME INFORM SER, V18, P267
   Yu L, 2006, OBJECT DETECTION BAS, V22, P348
   [No title captured]
NR 27
TC 12
Z9 12
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4155
EP 4169
DI 10.1007/s11042-017-4542-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500005
DA 2024-07-18
ER

PT J
AU Acharya, A
   Meher, S
AF Acharya, Aditya
   Meher, Sukadev
TI Composite high frequency predictive scheme for efficient 2-D up-scaling
   performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Up-scaling; Interpolation; Laplacian; Local processing; Global
   processing; Variance
ID WIENER-BASED INTERPOLATION; IMAGE INTERPOLATION; COMPRESSED DOMAIN; DCT;
   MODEL
AB This paper presents a new composite scheme to tackle the non-uniform blurring that arises because of image up-scaling. The image up-scaling results in undesirable blurring artifacts at the edge and fast changing regions due to high frequency (HF) and very high frequency (VHF) degradation. Most of the widely used interpolation schemes fail to predict the HF information in up-scaled image which consequently results in undesirable blurring. In order to overcome this problem, the proposed composite scheme is developed by combining a pre-processing and a post-processing operation to efficiently restore HF and VHF information in the up-scaled image. The pre-processing operation makes use of an iterative global sharpening scheme prior to image up-scaling to boost up the high frequency information so as to alleviate the extent of blurring in the up-scaled images. The post-processing scheme is operated on the up-scaled images to enhance and predict the HF information using a local statistics based local adaptive Laplacian filter. The appropriate fusion of pre-processing and post-processing operations results in more accurate prediction of HF in the up-scaled images. Experimental results reveal that the proposed composite scheme gives much less blurring in comparison to the standalone schemes and outperform most of the widely used interpolation schemes in terms of objective and subjective measures.
C1 [Acharya, Aditya] Silicon Inst Technol, Dept Elect & Commun Engn, Bhubaneswar 751024, Orissa, India.
   [Meher, Sukadev] Natl Inst Technol, Dept Elect & Commun Engn, Rourkela 769008, Odisha, India.
C3 Silicon Institute of Technology; National Institute of Technology (NIT
   System); National Institute of Technology Rourkela
RP Acharya, A (corresponding author), Silicon Inst Technol, Dept Elect & Commun Engn, Bhubaneswar 751024, Orissa, India.
EM 510EC308@nitrkl.ac.in; smeher@nitrkl.ac.in
RI Meher, Sukadev/AAW-2774-2020; Meher, Sukadev/O-4489-2017
OI Meher, Sukadev/0000-0003-4397-3139
CR Acharya A, 2013, P ANN IEEE INT C IND
   Acharya A, 2013, P IEEE INT C FUZZ SY
   Acharya A, 2015, P IEEE INT C EL EL S
   Acharya A, 2013, IJCA SPECIAL ISSUE E, P29
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], 2010, WORKSH REM SYS SRS 1
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Burger W., 2009, PRINCIPLES DIGITAL I, P231
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Cho MK, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2234736
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hung KW, 2013, INT CONF ACOUST SPEE, P1419, DOI 10.1109/ICASSP.2013.6637885
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Hung KW, 2010, IEEE IMAGE PROC, P3297, DOI 10.1109/ICIP.2010.5652082
   Ketan Tang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P66, DOI 10.1109/ICIG.2011.155
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee S. W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P177, DOI 10.1109/ICASSP.1993.319776
   Lehmann TM, 2001, IEEE T MED IMAGING, V20, P660, DOI 10.1109/42.932749
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Lim H, 2011, IEEE T CIRC SYST VID, V21, P879, DOI 10.1109/TCSVT.2011.2133250
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   Ren J, 2011, IEEE IMAGE PROC, P1177, DOI 10.1109/ICIP.2011.6115639
   Sajjad M., 2013, MULTIMED TOOLS APPL, V74, P8961
   SMIT T, 1990, IEEE T ACOUST SPEECH, V38, P1512, DOI 10.1109/29.60071
   Wong CS, 2010, EUR SIGNAL PR CONF, P309
   Wu ZY, 2010, IEEE SIGNAL PROC LET, V17, P827, DOI 10.1109/LSP.2010.2059700
   Yang S, 2008, IEEE T CONSUM ELECTR, V54, P1761, DOI 10.1109/TCE.2008.4711232
   Yaroslavsky L. P., 1996, Bioimaging, V4, P225, DOI 10.1002/1361-6374(199612)4:4<225::AID-BIO1>3.0.CO;2-G
   Ye W, 2011, IEEE T IMAGE PROCESS, V19, P2969
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 31
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2153
EP 2189
DI 10.1007/s11042-017-4346-1
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400030
DA 2024-07-18
ER

PT J
AU Lee, SK
   Kim, H
   Chung, AY
   Kim, H
AF Lee, Suk Kyu
   Kim, Hyunsoon
   Chung, Albert Yongjoon
   Kim, Hwangnam
TI Integrated approach of streaming 3d multimedia contents in real-time for
   mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile multimedia system; 3D Video; Video compression; Experimental
   evaluation
ID VIDEO; DISPLAY; IMAGE
AB It is popular to watch a 3D video through a 3D display nowadays. However, it is still difficult to enjoy the 3D multimedia contents with a mobile device even if a mobile device with a 3D display is currently introduced into the market. The main technological challenges for watching 3D contents via the mobile devices can be identified as the following: generating and streaming 3D contents. Generating 3D contents requires extra computational resources. Moreover, streaming 3D contents demands additional network bandwidth for receiving and transmitting the 3D data. To overcome these technological challenges, we propose ReMA, a novel 3D video streaming system in this paper. We devised a novel architecture for transmitter, receiver, and a distribution system to efficiently disseminate and generate 3D videos for the mobile devices. We implemented ReMA in a real test-bed and conducted a thorough empirical evaluation study to see the feasibility of streaming 3D contents for the mobile devices. Based on our empirical study, the resulting system presents a great promise in streaming 3D video in real-time to the mobile devices.
C1 [Lee, Suk Kyu] LG Elect Inc, Seoul, South Korea.
   [Kim, Hyunsoon; Chung, Albert Yongjoon; Kim, Hwangnam] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 LG Electronics; Korea University
RP Kim, H (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM skjl25@gmail.com; gustns2010@korea.ac.kr; aychung@korea.ac.kr;
   hnkim@korea.ac.kr
OI Kim, Hwangnam/0000-0003-4322-8518
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A01059151]; "Human
   Resources program in Energy Technology" of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP) from the Ministry of Trade,
   Industry & Energy, Republic of Korea [20154030200610]
FX This research was supported in part by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2015R1D1A1A01059151), and in part by "Human
   Resources program in Energy Technology" of the Korea Institute of Energy
   Technology Evaluation and Planning (KETEP) granted financial resource
   from the Ministry of Trade, Industry & Energy, Republic of Korea (No.
   20154030200610).
CR [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   Ribera RBI, 2012, COMPUT GRAPH FORUM, V31, P2213, DOI 10.1111/j.1467-8659.2012.03214.x
   Calagari K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P337, DOI 10.1145/2647868.2654899
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Chuohao Yeo, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P21
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Fattal D, 2013, NATURE, V495, P348, DOI 10.1038/nature11972
   FLACK J, 2007, P SPIE INT SOC OPT E, V6490, P502
   Algorri JF, 2014, J DISP TECHNOL, V10, P713, DOI 10.1109/JDT.2014.2313143
   Halle M., 2005, SIGGRAPH '05: ACM SIGGRAPH 2005 Courses, page, P104
   Kamolrat B, 2008, IEEE T CONSUM ELECTR, V54, P887, DOI 10.1109/TCE.2008.4560175
   Kunic S, 2011, ELMAR PROC, P127
   Lee SK, 2014, 33 IEEE INT PERF COM
   Lee SK, 2015, COMP REMA VC H 264
   Lee SK, 2016, MULTIMED TOOLS APPL, V75, P4615, DOI 10.1007/s11042-015-2495-7
   Lee SK, 2015, ACM T MULTIM COMPUT, V12, DOI 10.1145/2771438
   McVeigh JS, 1996, SIGNAL PROCESS-IMAGE, V9, P21, DOI 10.1016/S0923-5965(96)00005-7
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2009, IEEE IMAGE PROC, P741, DOI 10.1109/ICIP.2009.5414287
   Muller Karsten, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P34, DOI 10.1109/MMSP.2008.4665045
   Okamoto Y, 2011, INT J COMPUT VISION, V94, P12, DOI 10.1007/s11263-010-0383-1
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Puri R., 2002, P ANN ALLERTON C COM, V40, P586
   Saygili G, 2011, IEEE T BROADCAST, V57, P593, DOI 10.1109/TBC.2011.2131450
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sexton I, 1999, IEEE SIGNAL PROC MAG, V16, P85, DOI 10.1109/79.768575
   Sgardoni V, 2014, RAPTOR CODE AWARE LI
   Shi WD, 2011, J NETW COMPUT APPL, V34, P1078, DOI 10.1016/j.jnca.2010.06.005
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Vatolin D., 2009, Msu video quality measurement tool," ed
   Vetro A., 2008, P SPIE
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Xu Y, 2014, ANAL QOE MODELS BIT
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 34
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1811
EP 1842
DI 10.1007/s11042-016-4339-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400015
DA 2024-07-18
ER

PT J
AU Zakariah, M
   Khan, MK
   Malik, H
AF Zakariah, Mohammed
   Khan, Muhammad Khurram
   Malik, Hafiz
TI Digital multimedia audio forensics: past, present and future
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Audio authentication; Speech intelligibility;
   Environment detection; Microphone identification; Transcoding detection
ID ENVIRONMENT IDENTIFICATION; ENHANCEMENT; AUTHENTICITY; COMPRESSION;
   VIDEO
AB Digital audio forensics is used for a variety of applications ranging from authenticating audio files to link an audio recording to the acquisition device (e.g., microphone), and also linking to the acoustic environment in which the audio recording was made, and identifying traces of coding or transcoding. This survey paper provides an overview of the current state-of-the-art (SOA) in digital audio forensics and highlights some open research problems and future challenges in this active area of research. The paper categorizes the audio file analysis into container and content-based analysis in order to detect the authenticity of the file. Existing SOA, in audio forensics, is discussed based on both container and content-based analysis. The importance of this research topic has encouraged many researchers to contribute in this area; yet, further scopes are available to help researchers and readers expand the body of knowledge. The ultimate goal of this paper is to introduce all information on audio forensics and encourage researchers to solve the unanswered questions. Our survey paper would contribute to this critical research area, which has addressed many serious cases in the past, and help solve many more cases in the future by using advanced techniques with more accurate results.
C1 [Zakariah, Mohammed] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
   [Malik, Hafiz] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.
C3 King Saud University; King Saud University; University of Michigan
   System; University of Michigan
RP Khan, MK (corresponding author), King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
EM mzakariah@ksu.edu.sa; mkhurram@ksu.edu.sa; hafiz@umich.edu
RI KHAN, MUHAMMAD KHURRAM/E-4836-2014; Nusa, Nuhammad/JXY-5819-2024; Khan,
   Muhammad/IXN-8470-2023; Zakariah, Mohammed/AAX-4115-2021; Malik,
   Hafiz/AAE-6141-2020
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Malik,
   Hafiz/0000-0001-6006-3888
FU National Plan for Science, Technology and Innovation (MAARIFAH), King
   Abdulaziz City for Science and Technology, Kingdom of Saudi Arabia
   [12-INF2634-02]; Division Of Computer and Network Systems; Direct For
   Computer & Info Scie & Enginr [1440929] Funding Source: National Science
   Foundation
FX "This Project was funded by the National Plan for Science, Technology
   and Innovation (MAARIFAH), King Abdulaziz City for Science and
   Technology, Kingdom of Saudi Arabia, Award Number (12-INF2634-02)".
CR Alexander Anil, 2012, AUD ENG SOC C 46 INT
   [Anonymous], 2014, P 2 ACM WORKSHOP INF
   [Anonymous], 1978, DIGITAL PROCESSING S
   Balasubramaniyan VA, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P109, DOI 10.1145/1866307.1866320
   Bang KH, 2006, AUDIO ENG SOC CONVEN
   Bianchi T, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-10
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Brixen E. B., 2007, AUDIO ENG SOC CONVEN, V122
   Buchholz R, 2009, LECT NOTES COMPUT SC, V5806, P235, DOI 10.1007/978-3-642-04431-1_17
   Chaudhary Usman Amin, 2010, AUDIO ENG SOC CONVEN, V129
   Chen N, 2011, IET INFORM SECUR, V5, P19, DOI 10.1049/iet-ifs.2010.0097
   Cuccovillo L, 2013, IEEE INT WORKSH MULT, P177, DOI 10.1109/MMSP.2013.6659284
   D'Alessandro B, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P57
   Ding H, 2010, EURASIP J ADV SIG PR, V2010, P12
   Garcia-Romero D, 2010, INT CONF ACOUST SPEE, P1806, DOI 10.1109/ICASSP.2010.5495407
   Gerazov B, 2012, P INT CONF OPTIM EL, P1164, DOI 10.1109/OPTIM.2012.6231908
   Grigoras C, 2010, AUD ENG SOC C 39 INT
   Grigoras C, 2007, FORENSIC SCI INT, V167, P136, DOI 10.1016/j.forsciint.2006.06.033
   Grigoras C, 2009, J AUDIO ENG SOC, V57, P643
   Gupta S, 2012, IEEE MULTIMEDIA, V19, P50, DOI 10.1109/MMUL.2011.74
   Hatje U, 2005, AUD ENG SOC C 26 INT
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hicsonmez S., 2011, INF FOR SEC WIFS 201, P1
   Ikram S, 2010, IEEE INT CON MULTI, P106, DOI 10.1109/ICME.2010.5582981
   Jenner F, 2012, INT CONF ACOUST SPEE, P1737, DOI 10.1109/ICASSP.2012.6288234
   Ju FS, 2006, IEEE INT SYM MULTIM, P750
   KOENIG BE, 1990, J AUDIO ENG SOC, V38, P3
   Koenig BE, 2007, J AUDIO ENG SOC, V55, P352
   Koenig BE, 2012, J AUDIO ENG SOC, V60, P255
   Koenig BE, 2009, J AUDIO ENG SOC, V57, P662
   Korycki R, 2014, ARCH ACOUST, V39, P65, DOI 10.2478/aoa-2014-0007
   Korycki R, 2014, FORENSIC SCI INT, V238, P33, DOI 10.1016/j.forsciint.2014.02.008
   Kraetzer C., 2011, IS T SPIE ELECT IMAG
   Kraetzer C, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P63
   Kurniawan F., 2016, INT J ELECT COMPUT E, V6, P2211
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Luo D, 2015, DIGIT SIGNAL PROCESS, V37, P85, DOI 10.1016/j.dsp.2014.11.003
   Maher RC, 2010, STUD COMPUT INTELL, V282, P127
   Maher RC, 2009, IEEE SIGNAL PROC MAG, V26, P84, DOI 10.1109/MSP.2008.931080
   Malik H, 2013, IEEE T INF FOREN SEC, V8, P1827, DOI 10.1109/TIFS.2013.2280888
   Malik H, 2012, INT CONF ACOUST SPEE, P1833, DOI 10.1109/ICASSP.2012.6288258
   Malik H, 2010, INT CONF ACOUST SPEE, P1710, DOI 10.1109/ICASSP.2010.5495479
   Mansour MF, 2012, IEEE T MULTIMEDIA, V14, P1381, DOI 10.1109/TMM.2012.2197191
   Mansour MF, 2009, INT CONF ACOUST SPEE, P157, DOI 10.1109/ICASSP.2009.4959544
   MCAULAY RJ, 1980, IEEE T ACOUST SPEECH, V28, P137, DOI 10.1109/TASSP.1980.1163394
   Moon C.-B., 2014, UBIQUITOUS INFORM TE, V280, P35
   Muhammad G., 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P11, DOI 10.1109/ICDT.2010.10
   Rodríguez DPN, 2010, IEEE T INF FOREN SEC, V5, P534, DOI 10.1109/TIFS.2010.2051270
   Nikias C.L., 1993, PROC 15 ANN INT C IE, P319, DOI DOI 10.1109/IEMBS.1993.978564
   Olanrewaju R. F., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P830, DOI 10.1109/ICCCE.2012.6271333
   Owen T, 1996, J AUDIO ENG SOC, V44, P275
   Paliwal K, 2010, SPEECH COMMUN, V52, P450, DOI 10.1016/j.specom.2010.02.004
   Qiao M., 2013, Signal Processing, Communication and Computing (ICSPCC), 2013 IEEE International Conference on, P1
   Qiao M., 2010, P P 18 ACM INT C MUL, P1011
   Ratnam R, 2003, J ACOUST SOC AM, V114, P2877, DOI 10.1121/1.1616578
   Shanmugasundaram K., 2004, Proceedings. 20th Annual Computer Security Applications Conference, P316
   Sharma D, 2012, INT CONF ACOUST SPEE, P4477, DOI 10.1109/ICASSP.2012.6288914
   Soulodre GA, 2010, AUDIO ENG SOC CONVEN
   Takagi K, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P132, DOI 10.1109/MMSP.2006.285283
   Tsoukalas DE, 1997, IEEE T SPEECH AUDI P, V5, P497, DOI 10.1109/89.641296
   Weiss M., 1975, DTIC DOCUMENT
   Yang R, 2010, IS T SPIE ELECT IMAG
   Yang R, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344441
   Yang R, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P117
   Yang R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P21, DOI 10.1145/1411328.1411334
   Yiu K- K, 2003, INTERSPEECH
   Zhang Y, 2013, SPEECH COMMUN, V55, P1081, DOI 10.1016/j.specom.2013.06.014
   Zhao H, 2013, IEEE T INF FOREN SEC, V8, P1746, DOI 10.1109/TIFS.2013.2278843
   Zhao H, 2012, 2012 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P373, DOI 10.1109/SSP.2012.6319707
   Zhisheng Lv, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P427, DOI 10.1109/ChinaSIP.2013.6625375
   Zhou J., 2011, P 12 INTERSPEECH FLO, P2533
NR 72
TC 37
Z9 42
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1009
EP 1040
DI 10.1007/s11042-016-4277-2
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400043
DA 2024-07-18
ER

PT J
AU Pai, NS
   Hong, JH
   Chen, PY
   Wu, JK
AF Pai, Neng-Sheng
   Hong, Jiun-Hao
   Chen, Pi-Yun
   Wu, Jiun-Kai
TI Application of design of image tracking by combining SURF and TLD and
   SVM-based posture recognition system in robbery pre-alert system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image tracking; Foreground detection; Posture recognition; Speeded up
   robust features (SURF); Tracking-learning-detection (TLD); Support
   vector machine (SVM)
ID ALGORITHM
AB This paper describes the design of an image tracking system that combines Speeded Up Robust Features (SURF) and Tracking-Learning-Detection (TLD), with a posture recognition system that is based on the Support Vector Machine (SVM), and includes image tracking, foreground detection and posture recognition. Image tracking, which combines the SURF and the TLD algorithms, starts by detecting the postures of a specific person with SURF, before tracking the object using TLD. Foreground detection uses the Codebook background subtraction algorithm to acquire foreground images and mends them by post-processing. Lastly, posture recognition applies SVM to determine human body postures. This article embodies such a system by applying it in a robbery pre-alert system.
C1 [Pai, Neng-Sheng; Hong, Jiun-Hao; Chen, Pi-Yun; Wu, Jiun-Kai] Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 41170, Taiwan.
C3 National Chin-Yi University of Technology
RP Chen, PY (corresponding author), Natl Chin Yi Univ Technol, Dept Elect Engn, Taichung 41170, Taiwan.
EM chenby@ncut.edu.tw
RI Pai, NS/KVZ-1904-2024
CR [Anonymous], [No title captured]
   [Anonymous], 2011, LIBSVM: a library for support vector machines
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Camplani M, 2013, IEEE T CYBERNETICS, V43, P1560, DOI 10.1109/TCYB.2013.2271112
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee SW, 2005, P ANN INT IEEE EMBS, P6836
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Tsai TH, 2013, IEEE T CIRC SYST VID, V23, P15, DOI 10.1109/TCSVT.2012.2202193
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
NR 25
TC 1
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25321
EP 25342
DI 10.1007/s11042-017-4449-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300043
DA 2024-07-18
ER

PT J
AU Aishwarya, N
   Thangammal, CB
AF Aishwarya, N.
   Thangammal, C. Bennila
TI An image fusion framework using novel dictionary based sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imagefusion; Supervised dictionary learning; Sparse representation;
   K-SVD; OMP
ID PERFORMANCE; TRANSFORM; ALGORITHM
AB Image fusion is an important technique which aims to produce a synthetic result by leveraging the cross information available in the existing data. Sparse Representation (SR) is a powerful signal processing theory used in wide variety of applications like image denoising, compression and fusion. Construction of a proper dictionary with reduced computational efficiency is a major challenge in these applications. Owing to the above criterion, we propose a supervised dictionary learning approach for the fusion algorithm. Initially, gradient information is obtained for each patch of the training data set. Then, the edge strength and information content are measured for the gradient patches. A selection rule is finally employed to select the patches with better focus features for training the over complete dictionary. By the above process, the number of input patches for dictionary training is reduced to a greater extent. At the fusion step, the globally learned dictionary is used to represent the given set of source image patches. Experimental results with various source image pairs demonstrate that the proposed fusion framework gives better visual quality and competes with the existing methodologies quantitatively.
C1 [Aishwarya, N.] Anna Univ, RMD Engn Coll, Dept ECE, Madras, Tamil Nadu, India.
   [Thangammal, C. Bennila] Anna Univ, RMD Engn Coll, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University Chennai
RP Aishwarya, N (corresponding author), Anna Univ, RMD Engn Coll, Dept ECE, Madras, Tamil Nadu, India.
EM aishwarya8914@gmail.com
RI N, Aishwarya/HGD-4106-2022; aish, N.AISHWARYA/AAG-5520-2019; Thangammal,
   C Bennila/A-9270-2018
OI N, Aishwarya/0000-0003-4054-6801; Thangammal, C
   Bennila/0000-0002-2724-1678
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aishwarya N, 2013, P IEEE INT C COMM SI, P686
   Aslantas V., 2011, 4 INT C IM CRIM DET, P1, DOI [10.1049/ic.2011.0129, DOI 10.1049/IC.2011.0129]
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   James AP, 2014, INFORM FUSION, V19, P14
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   Li H, 2015, OPT COMMUN, V342, P1, DOI 10.1016/j.optcom.2014.12.048
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang J, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043019
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2012, INT C PATT RECOG, P376
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zheng Y, 2008, INFORM FUSION, V8, P177
NR 34
TC 13
Z9 14
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 21869
EP 21888
DI 10.1007/s11042-017-4583-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200003
DA 2024-07-18
ER

PT J
AU Ishikawa, S
   Laaksonen, J
AF Ishikawa, Satoru
   Laaksonen, Jorma
TI Uni- and multimodal methods for single- and multi-label recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal classification; Multi-label recognition; Multimodal Deep
   Boltzmann Machine; Support Vector Machine
AB The multimodal approach is becoming more and more attractive and common method in multimedia information retrieval and description. It often shows better content recognition results than using only unimodal methods, but depending on the used data, this is not always the case. Most of the current multimodal media content classification methods still depend on unimodal recognition results. For both uni- and multimodal approaches it is important to choose the best features and classification models. In addition, in the case of unimodal models, the final multimodal recognitions still need to be produced with an appropriate late fusion technique. In this article, we study several multi- and unimodal recognition methods, features for them and their combination techniques, in the application setup of concept detection in image-text data. We consider both single- and multi-label recognition tasks. As the image features, we use GoogLeNet deep convolutional neural network (DCNN) activation features and semantic concept or classeme vectors. For text features, we use simple binary vectors for tags and the word2vec embedding vectors. The Multimodal Deep Boltzmann Machine (DBM) model is used as the multimodal model and the Support Vector Machine (SVM) with both linear and non-linear radial basis function (RBF) kernels as the unimodal one. The experiments are performed with the MIRFLICKR-1M and the NUS-WIDE datasets. The results show that the two models have equally good performance in the single-label recognition task of the former database, while the Multimodal DBM produces clearly better results in the multi-label task of the latter database. Compared with the results in the literature, we exceed the state of the art in both datasets, mostly due to the use of DCNN features and semantic concept vectors based on them.
C1 [Ishikawa, Satoru; Laaksonen, Jorma] Aalto Univ, Dept Comp Sci, Sch Sci, POB 15400, FI-00076 Aalto, Finland.
C3 Aalto University
RP Ishikawa, S (corresponding author), Aalto Univ, Dept Comp Sci, Sch Sci, POB 15400, FI-00076 Aalto, Finland.
EM satoru.ishikawa@aalto.fi; jorma.laaksonen@aalto.fi
RI Laaksonen, Jorma/Q-1307-2016
OI Laaksonen, Jorma/0000-0001-7218-3131
FU Academy of Finland [251170]; Data to Intelligence D2I DIGILE SHOK
   program
FX This work has been funded by the grant 251170 of the Academy of Finland
   and the Data to Intelligence D2I DIGILE SHOK program. The calculations
   were performed using computer resources within the Aalto University
   School of Science "Science-IT" project.
CR [Anonymous], 2010, 2010 IEEE C COMP VIS
   [Anonymous], 2016, P 33 INT C MACHINE L
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2014, ICML
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV12124522 CORR
   [Anonymous], 2010, P NIPS
   [Anonymous], 2014, P WORK NOT P MEDIAEV
   [Anonymous], ACM T MULTIMEDIA COM
   [Anonymous], 2014, ARXIV14031840
   [Anonymous], P ECCV 2006
   [Anonymous], VLFEAT LIB COMPUTER
   [Anonymous], P 22 ACM INT C MULT
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2008, EMNLP
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   [Anonymous], ARXIV13013781 CORR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], IMAGE ANNOTATION TAG
   Bahrampour S, 2016, IEEE T IMAGE PROCESS, V25, P24, DOI 10.1109/TIP.2015.2496275
   Bhatia K, 2015, 29 ANN C NEURAL INFO, V28
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Boyd-Graber JordanL., 2009, Advances in neural information processing systems, P185
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Escalera S, 2016, J MACH LEARN RES, V17
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Habibian A, 2013, P 3 ACM C INT C MULT, P89, DOI DOI 10.1145/2461466.2461482
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2009, INT C NEURAL INF PRO, P1607
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huiskes M.J., 2008, MIR FLICKR RETRIEVAL
   Ishikawa S, 2016, INT WORK CONTENT MUL
   Kara S, 2012, INFORM SYST, V37, P294, DOI 10.1016/j.is.2011.09.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56
NR 43
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22405
EP 22423
DI 10.1007/s11042-017-4733-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200028
DA 2024-07-18
ER

PT J
AU Li, J
   Bao, H
   Han, XM
   Pan, F
   Pan, WG
   Zhang, FF
   Wang, D
AF Li, Jing
   Bao, Hong
   Han, Xiangmin
   Pan, Feng
   Pan, Weiguo
   Zhang, Feifei
   Wang, Di
TI Real-time self-driving car navigation and obstacle avoidance using
   mobile 3D laser scanner and GNSS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-driving; Autonomous vehicle; LiDAR; Satellite navigation; Vector
   field histogram; Path planning
ID VECTOR FIELD HISTOGRAM; ROBOT
AB Self-driving car navigation is currently attracting considerable research interests. The key problem is to guide the car to the destination in real-time with a safe and obstacle free path in real-world environments. We propose an innovative self-driving car navigation approach that incorporates a VFH (Vector Field Histogram) local path planner adapted for modern 3D laser scanners and a global path planner using satellite positioning and digital map along with a custom built PID controller (Proportional Integral Derivative controller). Since classical path planning methods such as VFH are often used on small robots with ultrasonic rangefinders or in simulation based environments, we applied the VFH method to a real self-driving car with two different LiDAR (Light Detection And Ranging) configurations. The quantitative results from extensive experiments indicate that the developed VFH method with the modern real-time 3D LiDAR generally outperform the conventional LIDAR in terms of efficiency, accuracy and reliability. In addition, the tracks produced by 3D LIDAR are more convergent, smooth and consistent than the other configuration. The maximum position deviation for the VFH with 3D LiDAR is 0.28 m and -0.16 m while the deviation for the other low-cost solution is 0.88 m and -0.49 m respectively. The global path planner can provide an accuracy of within 1 meter most of the time. The proposed approach is successfully implemented and tested on our self-driving car which took part in the national self-driving car competitions in recent years, and ranked No.3 and 4. in the future challenge 2014 self-driving car competition in China.
C1 [Li, Jing; Bao, Hong; Han, Xiangmin; Pan, Feng; Pan, Weiguo; Zhang, Feifei; Wang, Di] Beijing Union Univ, Beijing Key Lab Informat Serv Engn, Beijing, Peoples R China.
C3 Beijing Union University
RP Bao, H (corresponding author), Beijing Union Univ, Beijing Key Lab Informat Serv Engn, Beijing, Peoples R China.
EM baohongbuu@qq.com
RI Zhang, Feifei/A-3199-2015; Han, Xiangmin/GWU-5109-2022
OI Han, Xiangmin/0000-0002-6789-0568; Bao, Hong/0000-0002-4760-1570
FU National Natural Science Foundation of China [91420202, 41101436];
   Construction of Innovative Teams and Teacher Career Development for
   Universities and Colleges under Beijing Municipality [IDHT20140508];
   Scientific Research Foundation for the Returned Overseas Chinese
   Scholars, State Education Ministry
FX This work was partially funded by National Natural Science Foundation of
   China (Grant No. 91420202 and Grant No. 41101436) and Construction of
   Innovative Teams and Teacher Career Development for Universities and
   Colleges under Beijing Municipality (IDHT20140508). It was also
   partially funded by the Scientific Research Foundation for the Returned
   Overseas Chinese Scholars, State Education Ministry. We thank Beijing
   Key Laboratory of Information Service Engineering for providing the test
   vehicle.
CR [Anonymous], P AUSTR C ROB AUT AU
   [Anonymous], DYN SYST CONTR C
   [Anonymous], FEAT IB LUX 8 L IB L
   [Anonymous], HDL 32E US MAN PROGR
   [Anonymous], 2013, J MECH ENG AUTOMATIO
   [Anonymous], BOUND VALUE PRO 0110
   Babinec A, 2014, ROBOT AUTON SYST, V62, P1098, DOI 10.1016/j.robot.2014.05.003
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137
   Broggi A, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2477556
   Choi JW, 2016, IEEE T VEH TECHNOL, V65, P1868, DOI 10.1109/TVT.2015.2424933
   Choi S, 2014, IEEE INT CONF ROBOT, P3221, DOI 10.1109/ICRA.2014.6907322
   Kamil F, 2015, Adv Robot Autom, V4, P134, DOI DOI 10.4172/2168-9695.1000134
   Katrakazas C, 2015, TRANSPORT RES C-EMER, V60, P416, DOI 10.1016/j.trc.2015.09.011
   Kim B, 2016, IEEE SENS J, V16, P400, DOI 10.1109/JSEN.2015.2480742
   Kuwata Y, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1681, DOI 10.1109/IROS.2008.4651075
   Liu P., 2016, SOFT COMPUT, P1
   Liu P, 2014, IEEE GEOSCI REMOTE S, V11, P1931, DOI 10.1109/LGRS.2014.2314177
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Pepy Romain, 2006, 2006 2 INT C INF COM, V1, P781
   Qu PR, 2015, IEEE INT VEH SYM, P700, DOI 10.1109/IVS.2015.7225766
   Shim I, 2015, IEEE T INTELL TRANSP, V16, P1999, DOI 10.1109/TITS.2015.2389237
   Song YL, 2016, GENET MOL RES, V15, DOI 10.4238/gmr.15026298
   Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2505, DOI 10.1109/ROBOT.2000.846405
   Ulrich I, 1998, IEEE INT CONF ROBOT, P1572, DOI 10.1109/ROBOT.1998.677362
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Yim WJ, 2014, INT C CONTR AUTOMAT, P1037, DOI 10.1109/ICCAS.2014.6987943
NR 28
TC 41
Z9 42
U1 5
U2 145
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 23017
EP 23039
DI 10.1007/s11042-016-4211-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200058
DA 2024-07-18
ER

PT J
AU Lu, TC
   Chi, LP
   Wu, CH
   Chang, HP
AF Lu, Tzu-Chuen
   Chi, Li-Pin
   Wu, Chang-Han
   Chang, Hsung-Pin
TI Reversible data hiding in dual stego-images using frequency-based
   encoding strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple stego-images; Data embedding; Center-folding strategy;
   Frequency-based encoding
ID EXPANSION; WATERMARKING
AB Reversible data hiding methods can embed secret data into multimedia to prevent attacks from hackers. Reversible data hiding methods based on multiple stego-images have been proposed extensively in recent years. This type of method can embed large amounts of secret bits into several stego-images. However, data embedding may cause serious distortion of stego-images. To solve this problem, Lu et al. proposed a center-folding strategy to reduce secret digits to narrow down the distance between the original pixel and the stego pixel in 2015. Although the center-folding strategy works well, it can still be improved. In their proposed scheme, the maximum secret digit seriously damages the image quality of the stego-image. If the maximum secret digit occurs often, then the visual quality of the stego-image decreases quickly. In this paper, we propose a frequency-based encoding method to solve this problem. The secret digit that occurs most frequently is encoded as the minimum absolute digit, thereby decreasing the frequency and level of modification. Experimental results showed that the proposed method can achieve a greater peak signal-to-noise ratio value than previous methods, thereby confirming that the proposed method is effective.
C1 [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
   [Chi, Li-Pin; Wu, Chang-Han] Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 40722, Taiwan.
   [Chang, Hsung-Pin] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 40227, Taiwan.
C3 Chaoyang University of Technology; National Chung Hsing University
RP Lu, TC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung 41349, Taiwan.
EM tclu@cyut.edu.tw; cp531220@ms23.hinet.net; phd9712@cs.nchu.edu.tw;
   hpchang@cs.nchu.edu.tw
OI Lu, Tzu-Chuen/0000-0001-7305-4622; Chang, Hsung-Pin/0000-0002-2680-8556
FU Ministry of Science and Technology of the Republicof China, Taiwan [MOST
   105-2221-E-324 -020]
FX The authors would like to thank Mr. Ying-Hsuan Huang who give us great
   advice and technical support and the Ministry of Science and Technology
   of the Republicof China, Taiwan, for financially supporting this paper
   under Contract no MOST 105-2221-E-324 -020.
CR Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang CT, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/431037
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Lu TC, 2007, MULTIMEDIA SECURITY
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang SY, 2013, IET IMAGE PROCESS, V7, P805, DOI 10.1049/iet-ipr.2012.0521
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 16
TC 30
Z9 30
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23903
EP 23929
DI 10.1007/s11042-016-4135-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700036
DA 2024-07-18
ER

PT J
AU Bera, A
   Bhattacharjee, D
   Nasipuri, M
AF Bera, Asish
   Bhattacharjee, Debotosh
   Nasipuri, Mita
TI Finger contour profile based hand biometric recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Fingercontour profiles; Handgeometry; Identification;
   Randomforest; Verification
ID SHAPE; GEOMETRY; IDENTIFICATION; VERIFICATION; SYSTEM; IMAGE
AB This paper presents a contactless hand biometric system at unrestricted hand pose environment. A new preprocessing technique is proposed for defining the finger contour profiles (FCP). It mainly consists of simple grayscale image transformation, subtraction, and logical XOR operation. This hand prototyping method logically decomposes global hand contour into the left and right contour profiles of each finger. A set of twenty pose-invariant geometric features is extracted from the FCP and normalized global hand shape. Experiments are conducted on two publicly available hand databases namely, the Bosphorus and IIT Delhi (IITD) databases to validate the system using the kNN, minimum distance, and random forest (RF) classifiers. Satisfactory identification accuracy of 97.82 % using the RF classifier has been achieved for the Bosphorus database with 320 subjects; and in verification, 3.28 % equal error rate (EER) is reported. The kNN classifier has been found to produce good identification success of 95.22 % for the IITD database of 230 subjects; and 4.76 % EER is obtained in verification. The average execution time of this approach is lesser than 2 s, that implies its suitability in real-world applications.
C1 [Bera, Asish] Haldia Inst Technol, Dept Comp Sci & Engn, Haldia 721657, India.
   [Bhattacharjee, Debotosh; Nasipuri, Mita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 Haldia Institute of Technology; Jadavpur University
RP Bera, A (corresponding author), Haldia Inst Technol, Dept Comp Sci & Engn, Haldia 721657, India.
EM asish.bera@gmail.com; debotosh@ieee.org; mitanasipuri@gmail.com
RI Bhattacharjee, Debotosh/L-8521-2015; Bhattacharjee,
   Debotosh/Q-4065-2019; Bera, Asish/G-6169-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bera, Asish/0000-0002-4546-076X
CR Anitha ML, 2014, INT CONF DIGIT SIG, P574, DOI 10.1109/ICDSP.2014.6900730
   Böhme R, 2009, LECT NOTES COMPUT SC, V5718, P90
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chan FH, 2014, INT CONF MACH LEARN, P871, DOI 10.1109/ICMLC.2014.7009724
   Charfi N, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P261, DOI 10.1109/SOCPAR.2014.7008016
   Choras RS, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P1085
   de Santos-Sierra D., 2014, 2014 International Carnahan Conference on Security Technology (ICCST), P1
   de-Santos-Sierra A, 2011, SENSORS-BASEL, V11, P10143, DOI 10.3390/s111110143
   do Nascimento MVP, 2014, IEEE SYS MAN CYBERN, P423, DOI 10.1109/SMC.2014.6973944
   Duta N, 2009, PATTERN RECOGN, V42, P2797, DOI 10.1016/j.patcog.2009.02.007
   Dutagaci H, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2890986
   El-Alfy E.M., 2012, 5 INT C NEW TECHN MO, P1
   El-Sallam A, 2011, C IND ELECT APPL, P281, DOI 10.1109/ICIEA.2011.5975595
   Faundez-Zanuy M, 2014, COGN COMPUT, V6, P230, DOI 10.1007/s12559-013-9230-3
   Ferrer MA, 2014, INFORM SCIENCES, V268, P3, DOI 10.1016/j.ins.2013.10.011
   Hu RX, 2012, PATTERN RECOGN, V45, P3348, DOI 10.1016/j.patcog.2012.02.018
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Kang WX, 2014, IEEE T SYST MAN CY-S, V44, P1510, DOI 10.1109/TSMC.2014.2330551
   Kanhangad V., 2010, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, USA, P17, DOI DOI 10.1109/CVPRW.2010.5543236
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   Kumar A, 2006, PATTERN RECOGN LETT, V27, P1478, DOI 10.1016/j.patrec.2006.02.021
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Luque-Baena RM, 2013, EXPERT SYST APPL, V40, P3580, DOI 10.1016/j.eswa.2012.12.065
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   MILLER RP, 1971, Patent No. 3576538
   Morales A, 2015, PATTERN RECOGN LETT, V68, P183, DOI 10.1016/j.patrec.2015.09.011
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Pengfei Yu, 2010, 2010 3rd International Conference on Advanced Computer Theory and Engineering (ICACTE 2010), P260, DOI 10.1109/ICACTE.2010.5579795
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Ross A.A., 2006, Handbook of Multibiometrics, P37
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Shahin MK, 2008, CAIRO INT BIOM ENG, P1
   Sharma S, 2015, EXPERT SYST APPL, V42, P821, DOI 10.1016/j.eswa.2014.08.052
   Travieso CM, 2014, INFORM SCIENCES, V275, P45, DOI 10.1016/j.ins.2014.02.031
   Tsalakanidou F, 2007, PATTERN RECOGN LETT, V28, P2238, DOI 10.1016/j.patrec.2007.07.005
   Wang MH, 2012, EXPERT SYST APPL, V39, P7132, DOI 10.1016/j.eswa.2012.01.031
   Yörük E, 2006, IEEE T IMAGE PROCESS, V15, P1803, DOI 10.1109/TIP.2006.873439
NR 39
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21451
EP 21479
DI 10.1007/s11042-016-4075-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400050
DA 2024-07-18
ER

PT J
AU Bian, Y
   Tang, GM
   Gao, ZZ
   Wang, S
AF Bian, Yuan
   Tang, Guangming
   Gao, Zhanzhan
   Wang, Shuo
TI A distortion cost modification strategy for adaptive pentary
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pentarysteganography; Modificationdegreestrategy; Distortioncost;
   Multi-layered STCs
ID SPATIAL IMAGE STEGANOGRAPHY
AB In this paper, a pentary steganography scheme is proposed employing the multi-layered STCs, which takes the embedding interactions into consideration. First, based on the definition of local correlation for the four-neighborhood, we link the modification direction of the central pixel with that of its four-neighborhood. Secondly, a modification degree strategy (MDS) is proposed to adjust the costs of the pixels dynamically. And the cost of pixels is assigned utilizing the MDS, which divides the process of distortion calculation into two steps of initializing and updating distortion cost. Finally, the scheme is obtained incorporating the MDS with the existing adaptive scheme S-UNIWARD of pentary version. Experimental results show that the proposed scheme is capable of providing large capacity, and has a better performance than adaptive steganography scheme S-UNIWARD of pentary version in resisting the SRM and maxSRMd2 detection when the payload is larger than 0.5 bpp. Also, the strategy could be combined with other adaptive steganography schemes of pentary version. Besides, the proposed scheme outperforms some ternary adaptive schemes with both feature sets SRM and maxSRMd2 when the payload is from 0.05bpp to 0.5bpp.
C1 [Bian, Yuan; Gao, Zhanzhan; Wang, Shuo] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Tang, Guangming] Zhengzhou Informat Sci & Technol Inst, Dept Informat Secur, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Bian, Y (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM bianyuanlara@163.com
RI Bian, Yuan/JRX-6259-2023; TANG, Guang-Ming/E-5315-2013
OI Bian, Yuan/0009-0001-0809-4166; 
CR [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Filler T, 2010, INF FOR SEC WIES 201, P1
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Huang W, SCI CHIN INFORM SCI, P1
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Li Jian., 2016, Mobile Information Systems, P1, DOI [10.1155/2016/4502867, DOI 10.1007/S00170-016-9066-6, DOI 10.1155/2016/4502867]
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Sedighi V, 2015, IS T SPIE ELECT IMAG
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
NR 20
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20643
EP 20662
DI 10.1007/s11042-016-3986-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400012
DA 2024-07-18
ER

PT J
AU Matsui, Y
   Ito, K
   Aramaki, Y
   Fujimoto, A
   Ogawa, T
   Yamasaki, T
   Aizawa, K
AF Matsui, Yusuke
   Ito, Kota
   Aramaki, Yuji
   Fujimoto, Azuma
   Ogawa, Toru
   Yamasaki, Toshihiko
   Aizawa, Kiyoharu
TI Sketch-based manga retrieval using manga109 dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
ID SCALE
AB Manga (Japanese comics) are popular worldwide. However, current e-manga archives offer very limited search support, i.e., keyword-based search by title or author. To make the manga search experience more intuitive, efficient, and enjoyable, we propose a manga-specific image retrieval system. The proposed system consists of efficient margin labeling, edge orientation histogram feature description with screen tone removal, and approximate nearest-neighbor search using product quantization. For querying, the system provides a sketch-based interface. Based on the interface, two interactive reranking schemes are presented: relevance feedback and query retouch. For evaluation, we built a novel dataset of manga images, Manga109, which consists of 109 comic books of 21,142 pages drawn by professional manga artists. To the best of our knowledge, Manga109 is currently the biggest dataset of manga images available for research. Experimental results showed that the proposed framework is efficient and scalable (70 ms from 21,142 pages using a single computer with 204 MB RAM).
C1 [Matsui, Yusuke; Ito, Kota; Aramaki, Yuji; Fujimoto, Azuma; Ogawa, Toru] Univ Tokyo, Tokyo, Japan.
   [Yamasaki, Toshihiko] Univ Tokyo, Grad Sch Frontier Sci, Dept Frontier Informat, Tokyo, Japan.
   [Yamasaki, Toshihiko] Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Informat & Commun Engn, Tokyo, Japan.
   [Aizawa, Kiyoharu] Univ Tokyo, Dept Informat & Commun Engn, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo; University of Tokyo;
   University of Tokyo
RP Matsui, Y (corresponding author), Univ Tokyo, Tokyo, Japan.
EM matsui@hal.t.u-tokyo.ac.jp; ito@hal.t.u-tokyo.ac.jp;
   aramaki@hal.t.u-tokyo.ac.jp; fujimoto@hal.t.u-tokyo.ac.jp;
   t_ogawa@hal.t.u-tokyo.ac.jp; yamasaki@hal.t.u-tokyo.ac.jp;
   aizawa@hal.t.u-tokyo.ac.jp
FU Strategic Information and Communications RAMP;D Promotion Programme
   (SCOPE); JSPS KAKENHI [257696, 15K12025, 16H07411]; Grants-in-Aid for
   Scientific Research [15K12025, 16H07411] Funding Source: KAKEN
FX This work was supported by the Strategic Information and Communications
   R&D Promotion Programme (SCOPE) and JSPS KAKENHI Grant Number 257696,
   15K12025, and 16H07411.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], P BMVC
   [Anonymous], P CVPR
   [Anonymous], 2016, ARXIV160600185
   [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], 2013, P ICDAR
   [Anonymous], P CVPR
   Aramaki Y, 2014, P SIGGRAPH
   Babenko A, 2014, IEEE TPAMI
   Buttcher S., 2010, Information Retrieval-Implementing and Evaluating Search Engines
   Cao Y, 2011, P CVPR
   Cao Y, 2012, P SIGGRAPH AS
   Cao Y, 2014, P SIGGRAPH
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Chu WT, 2014, PROCEEDINGS MM
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Delalandre M, 2014, P DAS
   Eitz M, 2012, P SIGGRAPH
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Hoashi K, 2011, P MM
   Hu R, 2011, P ICIP
   Hu R, 2010, P ICIP
   Ito K, 2015, P EUR
   Jegou H, 2008, P ECCV
   Jegou H, 2009, P ICCV
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kazi RH, 2012, P CHI
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kopf J, 2012, P SIGGRAPH AS
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lin G., 2014, P CVPR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marchand-Mailet S, 1999, BINARY DIGITAL IMAGE
   Matsui Y, 2011, P SIGGRAPH
   Matsui Y., 2014, P ICIP
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Philbin J., 2008, P CVPR, P1
   Qu Y, 2008, P SIGGRAPH AS
   Qu Y, 2006, P SIGGRAPH
   Ren S, 2014, P ICMR
   Rigaud C, 2013, P ICDAR
   Rigaud C, 2015, INT J DOC ANAL RECOG, V18, P199, DOI 10.1007/s10032-015-0243-1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sato K, 2014, P SIGGRAPH AS TECHN
   Schneider RG, 2014, P SIGGRAPH AS
   Serra J., 1983, IMAGE ANAL MATH MORP
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Sun W, 2013, P ICDAR
   Sun WH, 2013, INT J DOC ANAL RECOG, V16, P331, DOI 10.1007/s10032-013-0199-y
   Sun X, 2013, P MM
   Sykora D, 2009, P EUR
   Tanaka T, 2007, P IJCAI
   Thanh-Nam Le, 2015, Graph-Based Representations in Pattern Recognition. 10th IAPR-TC-15 International Workshop, GbRPR 2015. Proceedings: LNCS 9069, P355, DOI 10.1007/978-3-319-18224-7_35
   Tseng KY, 2012, P MM
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2010, P MM
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang X, 2012, P CVPR
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zhou R, 2012, P MM
NR 73
TC 603
Z9 652
U1 5
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21811
EP 21838
DI 10.1007/s11042-016-4020-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400066
OA Green Submitted, hybrid
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Wang, BL
   Cao, Y
AF Wang, BeiLie
   Cao Ying
TI Liver medical image registration based on biomechanical model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT image registration; CUDA acceleration; Biological mechanics model;
   Level set
AB CT image registration technique is important in the medical image processing which also can be seen as signal processing. But the process of biological mechanics model of energy function is a tedious calculation and longer time-consuming, which cannot meet the requirements of clinical application. In order to solve this problem, through the level set method, this paper solves biological mechanics model of numerical solution of energy function, and the process of CUDA acceleration, so as to improve execution efficiency of medical image registration algorithm based on biological mechanics model and make it meet the clinical application of the real-time requirement. Experiments show that the method can be accurate and fast to abdominal CT image registration, and it also can satisfy the real-time requirement of the image registration clinically.
C1 [Wang, BeiLie; Cao Ying] Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Wang, BL (corresponding author), Northeastern Univ, Software Coll, Shenyang 110819, Liaoning, Peoples R China.
EM 133268682@qq.com
FU Northeastern University [N130317004]; Doctoral Research Fund for
   Liaoning province [20141011]
FX Research and application of pancreatic cancer early diagnosis algorithm
   based on dynamic biomechanical models, School Basic Scientific Research
   Business Expenses for Northeastern University (N130317004). Research on
   big data query technology in cloud environment and its application in
   medical big data, Doctoral Research Fund for Liaoning province
   (20141011).
CR Blume M, 2012, PHYS MED BIOL, V57, DOI 10.1088/0031-9155/57/24/8249
   Cao Guo-gang, 2008, Journal of Applied Sciences, V26, P274
   Gill S, 2012, MED IMAGE ANAL, V16, P662, DOI 10.1016/j.media.2010.07.008
   Michálek J, 2011, MICROSC MICROANAL, V17, P923, DOI 10.1017/S1431927611011937
   Persson PO, 2004, SIAM REV, V46, P329, DOI 10.1137/S0036144503429121
   Sher SO, 1988, COMMUN PHYS, V79, P12
   Wang YH, 2003, CHIN J MED IMAGING T, V19, P675
   Wang Zong-yue, 2007, Computer Engineering and Applications, V43, P71
NR 8
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19927
EP 19944
DI 10.1007/s11042-016-3828-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500036
DA 2024-07-18
ER

PT J
AU Wang, NN
AF Wang, Nana
TI Reversible watermarking for 2D vector maps based on <i>normalized</i>
   vertices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible water marking; RST invariance; Embedding distortion control;
   Capacity; Normalized vertex; 2D vector map
ID DIFFERENCE; SCHEME; IMAGE
AB For 2D vector maps, obtaining rotation, uniform scaling and translation (RST) invariance property, embedding distortion control and high capacity is a technically challenging task of existing reversible watermarking schemes. Using the idea of normalized vertices, we propose a method that not only tolerates RST transformations but also provides good invisibility and high capacity. In particular, we propose transforming the vertices to a new coordinate system, calculating a normalized vertex for each transformed vertex, and embedding watermarks into the normalized vertices using an improved quantization index modulation (IQIM) based reversible watermarking technique. While the embedding into each coordinate of every normalized vertex provides RST invariance property and high capacity, the selection of the embedding parameter ensures the control of the embedding distortions. Experimental results show that the proposed scheme provides good reversibility and is robust against RST attacks. The comparisons with existing reversible watermarking schemes show that this scheme provides embedding distortion control and higher capacity.
C1 [Wang, Nana] Jiangsu Normal Univ, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
C3 Jiangsu Normal University
RP Wang, NN (corresponding author), Jiangsu Normal Univ, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM wangnana_5@yahoo.com
RI wang, yan/GSE-6489-2022; lu, yuan/JZD-0832-2024; wang, na/HSF-2140-2023
FU National Natural Science Foundation of China [61602218]; University
   Science Research Project of Jiangsu Province [16KJB520011]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61602218) and University Science Research Project of
   Jiangsu Province (Grant No.16KJB520011).
CR Abubahia A, 2015, LECT NOTES COMPUT SC, V9097, P133, DOI 10.1007/978-3-319-19069-3_9
   [Anonymous], P 2014 INT C DAT SOF
   [Anonymous], 2005, P DOCT FOR CHIN
   [Anonymous], 2009, P INT C E BUS INF SY
   [Anonymous], 2016, INT J MULTIMED UBIQU
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Cao LJ, 2013, VISUAL COMPUT, V29, P231, DOI 10.1007/s00371-012-0732-x
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Gou HM, 2005, IEEE T SIGNAL PROCES, V53, P3988, DOI 10.1109/TSP.2005.855411
   Gu QL, 2013, DIGIT SIGNAL PROCESS, V23, P213, DOI 10.1016/j.dsp.2012.07.013
   Lafaye J, 2012, GEOINFORMATICA, V16, P245, DOI 10.1007/s10707-011-0133-8
   Lee SH, 2013, MULTIMED TOOLS APPL, V63, P757, DOI 10.1007/s11042-011-0894-y
   [李黎 LI Li], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P372
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Muttoo Sunil Kumar, 2012, Annals of GIS, V18, P135, DOI 10.1080/19475683.2011.640640
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Peng F, 2011, INT J DIGIT CRIME FO, V3, P53, DOI 10.4018/jdcf.2011010104
   [彭飞 Peng Fei], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1134
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Peng ZY, 2015, MULTIMED TOOLS APPL, V74, P11721, DOI 10.1007/s11042-014-2259-9
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Ren N, 2014, INT CONF GEOINFORM
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang NN, 2016, INT J DIGIT CRIME FO, V8, P1, DOI 10.4018/IJDCF.2016010101
   Wang NN, 2014, COMPUT AIDED DESIGN, V47, P108, DOI 10.1016/j.cad.2013.10.005
   Wang NN, 2013, MULTIMED TOOLS APPL, V67, P709, DOI 10.1007/s11042-012-1333-4
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P2109, DOI 10.1007/s11042-013-1744-x
   Yue ML, 2014, LECT NOTES COMPUT SC, V8709, P129, DOI 10.1007/978-3-319-11116-2_12
   Zhou Lu, 2009, Journal of Computer Applications, V29, P990, DOI 10.3724/SP.J.1087.2009.00990
NR 39
TC 8
Z9 9
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20935
EP 20953
DI 10.1007/s11042-016-3970-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400026
DA 2024-07-18
ER

PT J
AU Zhu, L
   Jeong, HY
AF Zhu, Li
   Jeong, Hwa Young
TI Research on an optimal selection method for sensor network node under
   high-speed mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-speed mobile; Sensor networks; Node; Optimal selection
AB The traditional selection methods for the selection of sensor network node under high-speed mobile environment is randomness, which cannot effectively use the multiple attributes of nodes, resulting in the irregular distribution of cluster head of nodes, and high energy consumption. An optimal selection method for sensor network node under the high-speed mobile environment based on EERNFS and Naive Bayesian Networks is proposed. By using EERNFS algorithm within each network intercept / sleep cycle, the sensor network node is made processing under high-speed mobile environment, to ensure the stable local connectivity and consistent collaboration intercepts, and reduces energy consumption. Naive Bayes algorithm is used to make optimization of general Bayesian classification method, and set the parameters. In the two-dimensional area, several sensor nodes are randomly placed, and the known two-dimensional area is divided. A certain node is selected arbitrarily in different regions to constitute the original set of Naive Bayes algorithm, and compute the training results and thresholds in the Bayesian system of node set at this moment. On the basis of the threshold, the optimal selection of sensor network node is achieved. Simulation results show that the proposed method not only has higher node coverage, but also the operating efficiency and energy consumption are better than the genetic method.
C1 [Zhu, Li] Jilin Agr Univ, Teaching & Management Ctr Informat, Changchun 130118, Jilin, Peoples R China.
   [Jeong, Hwa Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
C3 Jilin Agricultural University; Kyung Hee University
RP Zhu, L (corresponding author), Jilin Agr Univ, Teaching & Management Ctr Informat, Changchun 130118, Jilin, Peoples R China.
EM zhuli12003@163.com
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR [Anonymous], IEEE
   [Anonymous], IEEE
   [Anonymous], JIPS
   [Anonymous], IEEE
   Bas CU, 2013, IEEE T VEH TECHNOL, V62, P14, DOI 10.1109/TVT.2012.2215969
   Bouabana A, 2013, IEEE IND ELEC, P3877, DOI 10.1109/IECON.2013.6699754
   Cheng H, 2009, IEEE I CONF COMP VIS, P317, DOI 10.1109/ICCV.2009.5459267
   Cheng VW, 2012, IEEE T VEH TECHNOL, V61, P1610, DOI 10.1109/TVT.2012.2187467
   Chou H.-T., 2013, IEEE MTT S INT MICR, P1
   Clark D.A., 2010, OCEANS 2010 IEEESydney, P1
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Gosiewski Z, 2013, PROCEEDINGS OF THE 2013 14TH INTERNATIONAL CARPATHIAN CONTROL CONFERENCE (ICCC), P94
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Kapoor NK, 2012, IEEE IPCCC, P197, DOI 10.1109/PCCC.2012.6407705
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kumar AB., 2012, Design, synthesis and evaluation of novel diazirine photolabels with improved ambient light stability and fluorous-based enrichment capacity, P1, DOI DOI 10.1109/COMSNETS.2012.6151338
   Kumar M.N., 2014, The International Journal of Engineering and Science, V1, P1
   Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163
   Levy R, 2014, IEEE, P1
   Li GX, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1534, DOI 10.1109/ICEPT.2014.6922946
   Meti SA, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P1158, DOI 10.1109/IIC.2015.7150923
   Obeid S, 2015, 2015 Third International Conference on Technological Advances in Electrical, Electronics and Computer Engineering (TAEECE), P150, DOI 10.1109/TAEECE.2015.7113617
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
NR 24
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19635
EP 19647
DI 10.1007/s11042-015-3234-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500019
DA 2024-07-18
ER

PT J
AU Singh, S
   Rathore, VS
   Singh, R
   Singh, MK
AF Singh, Siddharth
   Rathore, Vivek Singh
   Singh, Rajiv
   Singh, Manoj Kumar
TI Hybrid semi-blind image watermarking in redundant wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Nonsubsampled contourlet transform; Singular value
   decomposition; Redundant discrete wavelet transform; Hybrid image
   watermarking
ID IMPERCEPTIBLE DUAL WATERMARKING; MULTIPLE WATERMARKING; ROBUST;
   TRANSFORM; SCHEME; AUTHENTICATION; RDWT
AB Image watermarking in wavelet domain has been found useful for copyright protection and rightful ownership. Classical wavelet transforms, like discrete wavelet transform (DWT), are shift sensitive and provide information in horizontal, vertical and diagonal directions only. Shift invariance and directional information are required for better reconstruction of images. In this work, we propose a semi-blind gray scale image watermarking technique in redundant wavelet domain. The primary focus of this research is to highlight the usefulness of redundant wavelet transforms in image watermarking. We have used nonsubsampled contourlet transform (NSCT) and redundant discrete wavelet transform (RDWT). These redundant transforms are shift invariant. Also, NSCT provides rich directional information. Thus, they overcome the shortcomings of DWT and are more useful in image watermarking. We have integrated singular value decomposition (SVD) in the proposed method. We use NSCT-RDWT-SVD decomposition for single and dual image watermarking. For single watermark embedding, cover images are sub-sampled followed by one level NSCT and RDWT decomposition. SVD has been applied on obtained RDWT coefficients. In the same way, image watermark has been processed and NSCT-RDWT-SVD decomposition has been applied on it. SVD coefficients of the cover image and watermark image have been combined using scaling factor. Inverse SVD-RDWT-NSCT operation together with reverse sub-sampling provides watermarked image. For extraction of the watermark, we follow the NSCT-RDWT-SVD decomposition and SVD coefficients have been separated by the same scaling factor that was used in embedding. In the dual watermarking, Arnold transform has been used for encryption of the text watermark and rest of the steps are similar to single watermarking. NSCT, RDWT and SVD improve the performance of the proposed method against geometrical and image processing attacks for single and dual image watermarking. Experiments have been carried over standard images and results have been shown for natural and medical images. Qualitative and quantitative evaluations in terms of peak signal to noise ratio (PSNR), correlation coefficient (CC), bit error rate (BER) and structural similarity index metric (SSIM) show that the proposed method is suitable for single and dual image watermarking, and outperforms existing methods.
C1 [Singh, Siddharth] VBS Purvanchal Univ, Dept Elect Engn, Jaunpur, Uttar Pradesh, India.
   [Rathore, Vivek Singh] Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
   [Singh, Rajiv] Banasthali Univ, Dept Comp Sci, Banasthali, Rajasthan, India.
   [Singh, Manoj Kumar] Banaras Hindu Univ, DST Ctr Interdisciplinary Math Sci, Varanasi, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; Banasthali Vidyapith; Banaras Hindu University (BHU)
RP Singh, R (corresponding author), Banasthali Univ, Dept Comp Sci, Banasthali, Rajasthan, India.
EM siddharthjnp@gmail.com; singhrathorevivek1@gmail.com;
   jkrajivsingh@gmail.com; mks_kjist@yahoo.co.in
RI Singh/AAK-2624-2020; Singh, Manoj Kumar/AAR-4499-2021; Singh,
   Rajiv/H-2377-2014
OI Singh, Manoj Kumar/0000-0001-5055-6128; Singh, Rajiv/0000-0003-4022-9945
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   [Anonymous], 2012, INT C EM TRENDS SCI, DOI DOI 10.1109/INCOSET.2012.6513904
   [Anonymous], 2015 ANN IEEE IND C
   [Anonymous], 2014, AM J ENG TECHNOLOGY
   [Anonymous], STAT SIGN PROC 2003
   [Anonymous], 2014, ARAB J GEOSCI
   [Anonymous], 2013, IOSR J COMPUTER ENG
   [Anonymous], 2011, INT J COMPUTER APPL
   [Anonymous], COMPUTER ENG INTELLI
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, CHOICE WAVELET WAVEL
   [Anonymous], HIGH CAPACITY DATA E
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Cao JG, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P277, DOI 10.1109/ICIP.2001.958478
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen J.M., 2013, Adv. Inf. Sci. Serv. Sci, V5, P629
   Cheung WN, 2000, TENCON IEEE REGION, pB374
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Das S, 2011, LECT NOTES COMPUT SC, V6744, P286
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Hien TD, 2006, SIGNAL PROCESS, V86, P2981, DOI 10.1016/j.sigpro.2005.12.003
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Khalighi S, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/540723
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Li LD, 2009, AEU-INT J ELECTRON C, V63, P123, DOI 10.1016/j.aeue.2007.11.007
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Parah SA, 2013, 2013 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P51, DOI 10.1109/MSPCT.2013.6782086
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Parah SA, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS, P57, DOI 10.1109/iNIS.2015.41
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Po DDY, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P262
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2016, MULTIMED TOOLS APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2014, INT J ELECTRON SECUR, V6, P285, DOI 10.1504/IJESDF.2014.065739
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P3557, DOI 10.1007/s11042-016-3885-1
   Sverdlov Alexander, 2005, 2005 13th European Signal Processing Conference, P1
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Zhenjun Tang, 2011, Journal of Multimedia, V6, P202, DOI 10.4304/jmm.6.2.202-206
NR 62
TC 36
Z9 38
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19113
EP 19137
DI 10.1007/s11042-017-4570-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800045
DA 2024-07-18
ER

PT J
AU Zheng, ZG
   Jeong, HY
   Huang, T
   Shu, JB
AF Zheng, Zhigao
   Jeong, Hwa-Young
   Huang, Tao
   Shu, Jiangbo
TI KDE based outlier detection on distributed data streams in multimedia
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel density estimation; Distributed; Data stream; Stream analysis;
   Exponential decay policy
ID DENSITY-ESTIMATION
AB Multimedia networks hold the promise of facilitating large-scale, real-time data processing in complex environments. Their foreseeable applications will help protect and monitor military, environmental, safety-critical, or domestic infrastructures and resources. Cloud infrastructures promise to provide high performance and cost effective solutions to large scale data processing problems. This paper focused on the outlier detection over distributed data stream in real time, proposed kernel density estimation (KDE) based outlier detection algorithm KDEDisStrOut in Storm, firstly formalized the problem of outlier detection using the kernel density estimation technique and update the transported data incrementally between the child node and the coordinator node which reduces the communication cost. Then the paper adopted the exponential decay policy to keep pace with the transient and evolving natures of stream data and changed the weight of different data in the sliding window adaptively made the data analysis more reasonable. Theoretical analysis and experiments on Storm with synthetic and real data show that the KDEDisStrOut algorithm is efficient and effective compared with existing outlier detection algorithms, and more suitable for data streams.
C1 [Zheng, Zhigao] Huazhong Univ Sci & Technol, Sch Comp & Technol, Wuhan 430079, Hubei, Peoples R China.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
   [Huang, Tao; Shu, Jiangbo] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Kyung Hee University;
   Central China Normal University
RP Huang, T (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan 430079, Hubei, Peoples R China.
EM zhengzhigao@hust.edu.cn; hyjeong@khu.ac.kr; tmht@hotmail.com;
   shujiangbo@mail.ccnu.edu.cn
OI Jeong, Hwa-Young/0000-0002-5017-934X
FU Key Projects in the National Science & Technology Pillar Program during
   the Twelfth Five-year Plan Period [2015BAK07B03]; National "Twelfth
   Five-Year" Plan for Science & Technology Support [2013BAH18F02]
FX This work is supported by the Key Projects in the National Science &
   Technology Pillar Program during the Twelfth Five-year Plan Period under
   Grant No. 2015BAK07B03, National "Twelfth Five-Year" Plan for Science &
   Technology Support under Grant No. 2013BAH18F02.
CR [Anonymous], 2004, P 30 INT C VER LARG
   [Anonymous], 2009, DEP ELECT ENG COMPUT
   Assent I, 2012, ANYOUT ANYTIME OUTLI
   Bifet A., 2011, Data stream mining: a practical approach
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Branch JW, 2013, KNOWL INF SYST, V34, P23, DOI 10.1007/s10115-011-0474-5
   Buchman SM, 2011, STAT METHODOL, V8, P18, DOI 10.1016/j.stamet.2009.07.002
   Buzzi-Ferraris G, 2011, COMPUT CHEM ENG, V35, P388, DOI 10.1016/j.compchemeng.2010.11.004
   Chen S, 2011, EVOL SYST, V2, P35, DOI 10.1007/s12530-010-9021-y
   Chen YX, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P133
   Cheon J., 2013, INT J ENG TECHNOLOGY, V5, P2685
   Crisan D, 2014, BERNOULLI, V20, P1879, DOI 10.3150/13-BEJ545
   Fernandez RaulCastro., 2014, P 8 ACM INT C DISTRI, P276
   Fingar P, 2010, DOT CLOUD 21 CENTURY
   Francia GA, 2014, CRISIS MANAGEMENT CO, P280, DOI [10.4018/978-1-4666-4707-7.ch012, DOI 10.4018/978-1-4666-4707-7.CH012]
   Gabel M, 2013, COMMUNICATION EFFICI
   Hatem SS, 2014, INT J ADV COMPUT SC, V5, P187
   Jia B, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/760248
   Juve G., 2010, ACM CROSSROADS CROSS, V16, P14, DOI [DOI 10.1145/1734160.1734166, 10.1145/1734160.1734166]
   Kleiminger W, 2011, STREAM PROCESSING CL
   Knorr E. M., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P392
   Legg PA, 2013, COMPUT MED IMAG GRAP, V37, P597, DOI 10.1016/j.compmedimag.2013.08.004
   Liu Peng, 2011, CLOUD COMPUTING
   Liu S, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/281707
   Liu Z, 2013, COMPUT ENG, V39, P178
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Massaro F, 2013, ASTROPHYS J SUPPL SE, V209, P1
   Milenkoski A, 2012, BENCHMARKING INTRUSI
   Papadimitriou S, 2003, PROC INT CONF DATA, P315, DOI 10.1109/ICDE.2003.1260802
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Saini A., 2014, INT J RES ASPECTS EN, V1, P69
   Scott DW, 2010, WIRES COMPUT STAT, V2, P497, DOI 10.1002/wics.103
   Vakali A, 2012, P 21 INT C COMP WORL
   Verde R, 2014, STUD CLASS DATA ANAL, P283, DOI 10.1007/978-3-319-06692-9__30
   Watson P, 2008, IBERGRID: 2ND IBERIAN GRID INFRASTRUCTURE CONFERENCE PROCEEDINGS, P3
   Yang F.X., 2012, THESIS XIAN NW U, P1
   Yu D, 2014, J COMPUT INF SYST, V10, P5481
   Zhang Y, 2010, IEEE COMMUN SURV TUT, V12, P159, DOI 10.1109/SURV.2010.021510.00088
NR 38
TC 27
Z9 29
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18027
EP 18045
DI 10.1007/s11042-016-3681-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800025
DA 2024-07-18
ER

PT J
AU Al-Maweri, NAAS
   Sabri, AQM
   Mansoor, AM
   Obaidellah, UH
   Faizal, ERM
   Lai, PCJ
AF Al-Maweri, Nasr Addin Ahmed Salem
   Sabri, Aznul Qalid Md
   Mansoor, Ali Mohammed
   Obaidellah, Unaizah Hanum
   Faizal, Erma Rahayu Mohd
   Lai, Joan P. C.
TI Metadata hiding for UAV video based on digital watermarking in DWT
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAV; Drones; Metadata hiding; Video watermarking; Copyright protection;
   Image scrambling
ID UNMANNED AERIAL VEHICLES
AB As the advent of the Unmanned Aerial Vehicles (UAVs) has been increased, the protection of the information within the transmitted or stored video has become a big challenge. Most known drone systems attach metadata of the recorded video in separate files or in the header of the video. Current techniques make the metadata unsecure and easy to get lost and removed as well as it occupies more storage and bandwidth. In this paper, an efficient method is proposed to hide the metadata of UAVs video using the technology of digital watermarking. Discrete Wavelet Transform (DWT) is used to implement the embedding of the information robustly. The middle frequencies coefficients reside on CH3 sub-band are utilized to hide the watermark bits. In addition, a new scrambling algorithm is proposed to secure the information before hiding. The adaption of the proposed video watermarking algorithm to hide the metadata of the UAV video is achieved. The experimental results prove the high performance of the proposed method. The method had unnoticeable impact on the video quality where the PSNR of 44 dB is attained. The experiments show that the method achieves high robustness under various attacks and provides enough capacity for metadata hiding of UAV video.
C1 [Al-Maweri, Nasr Addin Ahmed Salem; Sabri, Aznul Qalid Md; Mansoor, Ali Mohammed; Obaidellah, Unaizah Hanum; Faizal, Erma Rahayu Mohd] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
   [Lai, Joan P. C.] Univ Malaya, UM Ctr Innovat & Commercializat, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya
RP Al-Maweri, NAAS (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
EM senassr_maweri@yahoo.com
RI MD SABRI, AZNUL QALID/AGY-6106-2022; MOHD FAIZAL ABDULLAH, ERMA
   RAHAYU/B-8456-2010; Obaidellah, Unaizah/M-2068-2016; Lai,
   PC/O-4743-2018; Mansoor, Ali Mohammed/J-4151-2016
OI MD SABRI, AZNUL QALID/0000-0002-4758-5400; MOHD FAIZAL ABDULLAH, ERMA
   RAHAYU/0000-0002-3026-9428; Obaidellah, Unaizah/0000-0003-4822-2174;
   Lai, PC/0000-0002-8319-8459; Mansoor, Ali Mohammed/0000-0003-2443-6637
FU University of Malaya's Research Grant (UMRG) [RP030A-14AET]; Fundamental
   Research Grant (FRGS) [FP061-2014A]
FX This work is funded under the University of Malaya's Research Grant
   (UMRG), grant number RP030A-14AET and the Fundamental Research Grant
   (FRGS), grant number FP061-2014A.
CR Agilandeeswari L., 2015, MULTIMEDIA TOOLS APP
   Ahuja R, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1048, DOI 10.1109/CCAA.2015.7148559
   Al-Maweri NAAS, 2016, J COMPUT SCI
   Al-maweri NAAS, 2015, SECUR COMMUN NETW, V8, P4373, DOI 10.1002/sec.1371
   Alattar AM, 2003, IEEE T CIRC SYST VID, V13, P787, DOI 10.1109/TCSVT.2003.815958
   [Anonymous], 2016, IEEE LONG ISL SYST A
   [Anonymous], J NANOTECHNOL
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Gu K., 2012, J ELECT COMPUT ENG, V2012, P1
   Gupta M, 2015, INT J COMPUT INT SYS, V8, P364, DOI 10.1080/18756891.2015.1001958
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   Lilien LT, 2014, J NETW COMPUT APPL, V38, P3, DOI 10.1016/j.jnca.2013.05.003
   Liu S, 2015, INT J DISTRIB SENSOR
   Lowenthal M., 2015, Intelligence: From secrets to policy, V6th
   Marcinak MP, 2005, MIL COMM C
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Mohammed F, 2014, INT CONF UNMAN AIRCR, P267, DOI 10.1109/ICUAS.2014.6842265
   Mstafa RJ, 2015, MULTIMED TOOLS APPL
   Nex F, 2014, APPL GEOMAT, V6, P1, DOI 10.1007/s12518-013-0120-x
   Paganini P, 2014, PRIVACY SECURITY ISS
   Quaritsch M, 2010, ELEKTROTECH INFORMAT, V127, P56, DOI 10.1007/s00502-010-0717-2
   Rango A, 2006, ENVIRON PRAC, V8, P159, DOI 10.1017/S1466046606060224
   Saleem Y, 2015, J NETW COMPUT APPL, V50, P15, DOI 10.1016/j.jnca.2014.12.002
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 26
TC 5
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16239
EP 16261
DI 10.1007/s11042-016-3906-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100009
DA 2024-07-18
ER

PT J
AU Wang, QY
   Chen, DS
   Li, SR
   Wu, Q
   Zhang, Q
AF Wang, Qiaoyu
   Chen, Duansheng
   Li, Songru
   Wu, Qiong
   Zhang, Qun
TI An adaptive cartoon-like stylization for color video in real time
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cartoon-like stylization; Adaptive DoG; CUDA; Real time image rendering;
   GPU
AB The cartoon-like stylization of color video images is one of the major types of non-photorealistic rendering. It has broad applications in the entertainment industry due to its lively style, flexible form, and autonomous creation. Our video cartoonization framework consists of color space conversion, bilateral filtering, color quantization and edge detection. We use an adaptive difference of Gaussians filter to detect the edges- variance value of Gaussian filter is determined based on the gradient of each pixels, so that we can not only detect elaborate edges but also decrease the influence of noise. We also alter the target sharpness range in the color quantization to achieve a softer look. We implement two versions of our algorithm: serial on a CPU, and parallel on a GPU having the Computer Unified Device Architecture (CUDA). Only the CUDA GPU code is able to process video in real time, running 45 to 180 times faster than the CPU code.
C1 [Wang, Qiaoyu; Chen, Duansheng; Li, Songru; Wu, Qiong; Zhang, Qun] Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
C3 Huaqiao University
RP Chen, DS (corresponding author), Huaqiao Univ, Dept Comp Sci & Technol, Jimei Rd 668, Xiamen, Fujian, Peoples R China.
EM dschen.hqu@gmail.com
FU Natural Science Foundation of China [61370006]; Science and Technology
   Planning Project of Fujian Province, China [2015H0025]
FX This work was supported by the Natural Science Foundation of China (No.
   61370006) and the Science and Technology Planning Project of Fujian
   Province, China (No. 2015H0025).
CR Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dandan Che, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P640, DOI 10.1109/IASP.2010.5476191
   De Alencar J. B. O.  Jr., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P242, DOI 10.1109/SIBGRAPI.2013.41
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Farber R, 2011, CUDA APPLICATION DESIGN AND DEVELOPMENT, P1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kirk D., 2012, PROGRAMMING MASSIVEL, VSecond
   Knowlton K.C., 1964, Proceedings of the Spring Joint Computer Conference, P67
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Kyprianidis J. E., 2008, P EG UK THEOR PRACT, P51
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lu LW, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P680, DOI 10.1109/CISP.2013.6745252
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Rosin P., 2013, Image and Video-Based Artistic Stylisation, V42
   Sanders J, 2010, CUDA EXAMPLE INTRO G
   Shahcheraghi Zoya, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P343, DOI 10.1007/978-3-319-13168-9_38
   Shahcheraghi Z, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P37, DOI 10.1109/ICSIPA.2013.6707974
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
   Zhao HL, 2013, MULTIMED TOOLS APPL, V63, P647, DOI 10.1007/s11042-011-0890-2
NR 26
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16767
EP 16782
DI 10.1007/s11042-016-3951-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100032
DA 2024-07-18
ER

PT J
AU Zatloukal, P
   Bernas, M
AF Zatloukal, Petr
   Bernas, Martin
TI Optimized H.264 compression of sign language video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; H.264; HbbTV; Region-of-interest coding; Subjective
   quality; Intelligibility
AB In TV broadcasting deaf people are not able to get information from the audio content. In public television, some programs may be accompanied by a sign language interpreter as a part of the broadcasted signal. As a supplementary service, it would enable more programs to be accessible with a sign language interpreter to assist in comprehension. To be able to transmit such data flow separately, we define the parameters of compression of sign language interpreter image to ensure intelligibility and quality while maintaining low bitrate. This paper deals with specific video compression of Czech sign language interpreter based on regions of interest implemented to the x264 open source library. The results of this approach are verified in subjective tests with the deaf and hearing evaluators. The experiments examine the intelligibility of sign language expressions containing minimal pairs for different levels of image compression and also evaluate the subjective quality of the final image.
C1 [Zatloukal, Petr; Bernas, Martin] Czech Tech Univ, Fac Elect Engn, Dept Radio Engn, Tech 2, Prague 16627, Czech Republic.
C3 Czech Technical University Prague
RP Zatloukal, P (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Radio Engn, Tech 2, Prague 16627, Czech Republic.
EM zatlopet@fel.cvut.cz; bernas@fel.cvut.cz
FU Agency of Czech Technical University in Prague [SGS15/089/OHK3/1 T/13]
FX This work was supported by the Grant Agency of the Czech Technical
   University in Prague, grant No. SGS15/089/OHK3/1 T/13.
CR Agrafiotis D, 2006, SIGNAL PROCESS-IMAGE, V21, P531, DOI 10.1016/j.image.2006.02.003
   [Anonymous], 2008, RES SAMPL SURV DIS P
   Cavender A., 2006, Proceedings of the Sixth International ACM SIGACCESS Conference on Computers and Accessibility, P71, DOI [10.1145/1168987.1169001, DOI 10.1145/1168987.1169001]
   Ciaramello FM, 2011, IEEE T IMAGE PROCESS, V20, P3014, DOI 10.1109/TIP.2011.2132730
   Emmorey K, 2009, J DEAF STUD DEAF EDU, V14, P237, DOI 10.1093/deafed/enn037
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Laidler CH, 2010, THESIS
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Nakazono K, 2006, IEICE T INF SYST, VE89D, P1893, DOI 10.1093/ietisy/e89-d.6.1893
   Svachula Z., 2013, INT J SOFTWARE WEB S, V3, P44
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zatloukal P, 2014, 7 INT C MACH VIS ICM
NR 12
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16225
EP 16237
DI 10.1007/s11042-016-3905-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100008
DA 2024-07-18
ER

PT J
AU Liu, F
   Seipel, S
AF Liu, Fei
   Seipel, Stefan
TI On the precision of third person perspective augmented reality for
   target designation tasks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Third person perspective; Target designation;
   Precision study; Experiment
ID SYSTEM; INFORMATION; ART
AB The availability of powerful consumer-level smart devices and off-the-shelf software frameworks has tremendously popularized augmented reality (AR) applications. However, since the built-in cameras typically have rather limited field of view, it is usually preferable to position AR tools built upon these devices at a distance when large objects need to be tracked for augmentation. This arrangement makes it difficult or even impossible to physically interact with the augmented object. One solution is to adopt third person perspective (TPP) with which the smart device shows in real time the object to be interacted with, the AR information and the user herself, all captured by a remote camera. Through mental transformation between the user-centric coordinate space and the coordinate system of the remote camera, the user can directly interact with objects in the real world. To evaluate user performance under this cognitively demanding situation, we developed such an experimental TPP AR system and conducted experiments which required subjects to make markings on a whiteboard according to virtual marks displayed by the AR system. The same markings were also made manually with a ruler. We measured the precision of the markings as well as the time to accomplish the task. Our results show that although the AR approach was on average around half a centimeter less precise than the manual measurement, it was approximately three times as fast as the manual counterpart. Additionally, we also found that subjects could quickly adapt to the mental transformation between the two coordinate systems.
C1 [Liu, Fei; Seipel, Stefan] Univ Gavle, Dept Ind Dev IT & Land Management, S-80176 Gavle, Sweden.
   [Liu, Fei; Seipel, Stefan] Uppsala Univ, Ctr Image Anal, S-75105 Uppsala, Sweden.
C3 University of Gavle; Uppsala University
RP Liu, F (corresponding author), Univ Gavle, Dept Ind Dev IT & Land Management, S-80176 Gavle, Sweden.; Liu, F (corresponding author), Uppsala Univ, Ctr Image Anal, S-75105 Uppsala, Sweden.
EM feiliu@hig.se; ssl@hig.se
CR Ahn J, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-18
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bae Hyojoon., 2013, Visualization in Engineering, V1, P1, DOI DOI 10.1186/2213-7459-1-3
   Behzadan AH, 2015, ADV ENG INFORM, V29, P252, DOI 10.1016/j.aei.2015.03.005
   Bell B., 2002, P 15 ANN ACM S USER, P213
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chi HL, 2013, AUTOMAT CONSTR, V33, P116, DOI 10.1016/j.autcon.2012.12.017
   Côté S, 2013, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2013.6671788
   Daponte P, 2014, MEASUREMENT, V57, P53, DOI 10.1016/j.measurement.2014.07.009
   Dünser A, 2012, COMPUT GRAPH-UK, V36, P1084, DOI 10.1016/j.cag.2012.10.001
   Irizarry J, 2013, AUTOMAT CONSTR, V33, P11, DOI 10.1016/j.autcon.2012.09.002
   Kamat VR, 2007, J COMPUT CIVIL ENG, V21, P303, DOI 10.1061/(ASCE)0887-3801(2007)21:5(303)
   Keil J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P15, DOI 10.1109/ISMAR-AMH.2011.6093651
   Kurkovsky S., 2012, 2012 International Conference on Communications and Information Technology (ICCIT), P68, DOI 10.1109/ICCITechnol.2012.6285844
   Kwon OS, 2014, AUTOMAT CONSTR, V46, P74, DOI 10.1016/j.autcon.2014.05.005
   Marchal, 2008, P 3 INT C DIG INT ME
   Milgram P, 1999, MIXED REALITY, P5
   Mulloni A., 2010, Proc. MobileHCI, P161, DOI DOI 10.1145/1851600.1851629
   Mulloni Alessandro, 2011, P 13 INT C HUM COMP, P211
   Nakamura Ricardo, 2010, P 5 ACM SIGGRAPH S V, P43
   Olbrich M, 2013, VISUAL COMPUT, V29, P1093, DOI 10.1007/s00371-013-0840-2
   Rankohi S., 2013, Visualization in Engineering, V1, P9, DOI DOI 10.1186/2213-7459-1-9
   Rehrl K, 2014, J LOCAT BASED SERV, V8, P75, DOI 10.1080/17489725.2014.946975
   Salamin Patrick, 2006, Proceedings of the ACM symposium on Virtual reality software and technology, P27
   Schall G, 2013, PERS UBIQUIT COMPUT, V17, P1533, DOI 10.1007/s00779-012-0599-x
   Shin DH, 2008, AUTOMAT CONSTR, V17, P882, DOI 10.1016/j.autcon.2008.02.012
   Shin DH, 2009, AUTOMAT CONSTR, V18, P118, DOI 10.1016/j.autcon.2008.05.007
   Sukan M, 2012, INT SYM MIX AUGMENT, P217, DOI 10.1109/ISMAR.2012.6402560
   Tatzgern M, 2015, PERVASIVE MOB COMPUT, V18, P55, DOI 10.1016/j.pmcj.2014.08.010
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P21, DOI 10.1109/VR.2014.6802045
   Tönnis M, 2013, COMPUT GRAPH-UK, V37, P997, DOI 10.1016/j.cag.2013.09.002
   Van Krevelen D. W. F., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10/ggxxt5
   Veas E., 2010, Proc. GI, P193
   Wagner D, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P127, DOI 10.1109/ISWC.2003.1241402
   White J, 2014, P IEEE, V102, P120, DOI 10.1109/JPROC.2013.2295873
NR 35
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15279
EP 15296
DI 10.1007/s11042-016-3817-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, H
   Yang, YH
   Yang, EK
   Deng, C
AF Wang, Hao
   Yang, Yanhua
   Yang, Erkun
   Deng, Cheng
TI Exploring hybrid spatio-temporal convolutional networks for human action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Convolutional network; Spatio-temporal
   information; Approximate rank pooling; Weighted fusion
AB Convolutional neural networks have achieved great success in many computer vision tasks. However, it is still challenging for action recognition in videos due to the intrinsically complicated space-time correlation and computational difficult of videos. Existing methods usually neglect the fusion of long term spatio-temporal information. In this paper, we propose a novel hybrid spatio-temporal convolutional network for action recognition. Specifically, we integrate three different type of streams into the network: (1) the image stream utilizes still images to learn the appearance information; (2) the optical stream captures the motion information from optical flow frames; (3) the dynamic image stream explores the appearance information and motion information simultaneously from generated dynamic images. Finally, a weighted fusion strategy at the softmax layer is utilized to make the class decision. With the help of these three streams, we can take full advantage of the spatio-temporal information of the videos. Extensive experiments on two popular human action recognition datasets demonstrate the superiority of our proposed method when compared with several state-of-the-art approaches.
C1 [Wang, Hao; Yang, Yanhua; Yang, Erkun; Deng, Cheng] Xidian Univ, Dept Elect & Engn, Xian 710071, Peoples R China.
   [Deng, Cheng] Xidian Univ, State Key Lab Integrated Serv Networks ISN, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Deng, C (corresponding author), Xidian Univ, Dept Elect & Engn, Xian 710071, Peoples R China.; Deng, C (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks ISN, Xian 710071, Peoples R China.
EM hwang_3@stu.xidian.edu.cn; yanghuahua.xd@gmail.com;
   ekyang@stu.xidian.edu.cn; chdeng@mail.xidian.edu.cn
RI Zhang, Xiaoyu/JXR-6386-2024
OI Deng, Cheng/0000-0003-2620-3247
FU National Natural Science Foundation of China [61572388]
FX The authors would like to thank the Editor-in-Chief, the handling
   associate editor and all anonymous reviewers for their considerations
   and suggestions. This work was supported by the National Natural Science
   Foundation of China (61572388).
CR Alfaro A, 2016, PROC CVPR IEEE, P2688, DOI 10.1109/CVPR.2016.294
   [Anonymous], 2016, ARXIV160808851
   [Anonymous], 2016, ARXIV160800859
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollar P, 2005, VS PETS 2005
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2016, PROC CVPR IEEE, P1924, DOI 10.1109/CVPR.2016.212
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A, 2008, 2008 19 BRIT MACH VI
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li Z., 2016, ARXIV160701794
   Peng X, 2016, ARXIV14054506
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Salakhutdinov, 2015, ARXIV151104119
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Varol G, 2016, ARXIV160404994
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Wang YL, 2016, ARXIV16070641
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu Z., 2015, P 23 ACM INT C MULT, P461, DOI DOI 10.1145/2733373.2806222
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yang YH, 2016, SIGNAL PROCESS, V124, P36, DOI 10.1016/j.sigpro.2015.10.035
   Yang YM, 2018, IEEE T SYST MAN CY-S, V48, P1065, DOI 10.1109/TSMC.2016.2637279
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 49
TC 17
Z9 17
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15065
EP 15081
DI 10.1007/s11042-017-4514-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400029
DA 2024-07-18
ER

PT J
AU Chaabane, F
   Charfeddine, M
   Puech, W
   Ben Amar, C
AF Chaabane, Faten
   Charfeddine, Maha
   Puech, William
   Ben Amar, Chokri
TI A two-stage traitor tracing scheme for hierarchical fingerprints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia traitor tracing; Collusion secure fingerprint; Two-stage;
   Tardos; Boneh Shaw; Audio watermarking
ID COLLUSION; SECURITY
AB The multimedia traitor tracing field involves the embedding of a collusion secure fingerprint in the host signal to retrieve and prevent any multimedia content fraud. Trendy work aims at providing a tracing system which offers a good protection of the digital content and an efficient tracing process. These challenges depend on reducing the length of the embedded fingerprint and the complexity of the accusation process. Furthermore, addressing these issues becomes more and more relevant in media distribution applications involving an important number of users. In this paper, we propose a secure fingerprinting system based on a two-stage tracing strategy which combines two probabilistic tracing codes: Boneh Shaw with replication scheme and Tardos codes. This strategy is applied to a multilevel hierarchical fingerprint which is then embedded using a DCT-based audio watermarking technique. By taking the advantage of grouping users and applying a weight-based tracing process, the proposed fingerprinting system offers to reduce efficiently the computational costs of the tracing time. It has also a good robustness to different types of attacks. We have carried out different tests to evaluate the performance of the system in terms of robustness and imperceptibility. The experimental results show that the proposed fingerprinting system provides a suitable solution to the the infringement copyright problem in multimedia distribution platforms by reducing significantly the users' retrieval space and performing good detection results in a reduced time.
C1 [Chaabane, Faten; Charfeddine, Maha; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
   [Puech, William] Univ Montpellier II, CNRS, LIRMM Lab, UMR 5506, 161 Rue Ada, F-34392 Montpellier 05, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Centre
   National de la Recherche Scientifique (CNRS); Universite Paul-Valery;
   Universite Perpignan Via Domitia; Universite de Montpellier
RP Chaabane, F (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, BP 1173, Sfax 3038, Tunisia.
EM faten.chaabane@ieee.org; maha.charfeddine@gmail.com;
   william.puech@lirmm.fr; chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012; chaabane, faten/ABF-9660-2021;
   charfeddine, maha/AAC-7422-2021
OI charfeddine, maha/0000-0003-2996-4113; Puech,
   William/0000-0001-9383-2401
CR Akashi N., 2008, INT S INF THEOR ITS, P1
   Bhat KV, 2008, INFORM SYSTEMS SECUR, P235
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Boneh D, 1995, LECT NOTES COMPUT SC, V963, P452
   Cha BH, 2007, INT CONF ACOUST SPEE, P145
   Chaabane F., 2011, 2011 3rd International Conference on Next Generation Networks and Services (NGNS), P90, DOI 10.1109/NGNS.2011.6142556
   Chaabane F., 2015, NEURAL INFORM PROCES, P505
   Chaabane F, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P289
   Chaabane F, 2015, EUR SIGNAL PR CONF, P51, DOI 10.1109/EUSIPCO.2015.7362343
   Chaabane F, 2013, INT C INFORM ASSUR S, P85, DOI 10.1109/ISIAS.2013.6947738
   Charfeddine Maha, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P203
   Charteddine M., 2012, J MULTIMEDIA TOOLS A, V70, P1521
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Craver S, 2006, IEEE J SEL A, V16, P573
   Cvejic N, 2007, DIGITAL AUDIO WATERM
   Desoubeaux M., 2012, P SPIE, V8303
   Desoubeaux M., 2011, SPIE P, V7880
   El'Arbi M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1577, DOI 10.1109/ICME.2006.262846
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Eya Mezghani, 2013, IEEE EUROCON 2013, P1625, DOI 10.1109/EUROCON.2013.6625194
   Fernandez M, 2007, IET INFORM SECUR, V1, P83, DOI 10.1049/iet-ifs:20055145
   Fontaine C, 2011, THESIS U BRETAGNE OC
   Furon T, 2009, ARXIV09033480 CORR
   Hayashi N, 2007, LECT NOTES COMPUT SC, V4752, P28
   He S, 2007, IEEE T INF FOREN SEC, V2, P697, DOI 10.1109/TIFS.2007.908179
   Hong I, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P1946, DOI 10.1109/ISIE.2001.932010
   Keiler F, 2006, AUDIO ENG SOC CONVEN
   Koubaa M, 2006, IEEE INT SYM MULTIM, P161
   Koubaa M, 2012, MULTIMED TOOLS APPL, V56, P281, DOI 10.1007/s11042-010-0626-8
   Kumar N. M., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P1277, DOI 10.1109/ICRTIT.2011.5972280
   Kuribayashi M, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P752, DOI 10.1109/MMSP.2008.4665174
   Laarhoven T, 2011, ARXIV11073441 CORR
   Lanxun W, 2007, 8 INT C EL MEAS INST
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Maha C, 2010, SIGMAP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATION, P139
   Mathon B, 2013, IEEE T INF FOREN SEC, V8, P1038, DOI 10.1109/TIFS.2013.2260158
   Meerwald P, 2012, IEEE T INF FOREN SEC, V7, P1168, DOI 10.1109/TIFS.2012.2195655
   Nematollahi M. A., 2012, 2012 6th Asia Modelling Symposium (AMS 2012), P109, DOI 10.1109/AMS.2012.54
   Neubauer C., 1998, 105 AES CONV SAN FRA
   Nuida K, 2007, LECT NOTES COMPUT SC, V4851, P80
   Peikert C, 2003, SIAM PROC S, P472
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qureshi A, 2015, EXPERT SYST APPL, V42, P1391, DOI 10.1016/j.eswa.2014.08.053
   Saharan B.S., 2014, Chinese Journal of Biology, V2014, P1, DOI DOI 10.1155/2014/802984
   Skoric B., 2007, IACR CRYPTOLOGY EPRI, V2007, P41
   Tardos G., 2003, Proceedings of the 35th Annual ACM Symposium on Theory of Computing, P116, DOI DOI 10.1145/780542.780561
   Tassa T, 2005, J CRYPTOL, V18, P167, DOI [10.1007/s00145-004-0214-z, 10.1007/S00145-004-0214-z]
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   Wagner N.R., 1983, P 1983 S SECURITY PR, P18
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014
   Wang ZJ, 2004, EURASIP J APPL SIG P, V2004, P2153, DOI 10.1155/S1110865704312151
   Wu XW, 2012, P 4 INT S CYB SAF SE, V7672, P352
   Xie FC, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P101
   Xu XJ, 2007, LECT NOTES ARTIF INT, V4578, P136
NR 55
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14405
EP 14435
DI 10.1007/s11042-016-3749-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800032
DA 2024-07-18
ER

PT J
AU Liu, K
   Sun, ZX
   Song, MF
   Li, B
AF Liu, Kai
   Sun, Zhengxing
   Song, Mofei
   Li, Bo
TI Iterative samples labeling for sketch recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Online metric learning; Semi-supervised clustering;
   Iterative annotation
ID IMAGE; SIMILARITY; SHAPE
AB Sketch recognition is an important issue in human-computer interaction, especially in sketch-based interface. To provide a scalable and flexible tool for user-centered sketch recognition, this paper proposes an iterative sketch collection annotation method for classifier-training by interleaving online metric learning, semi-supervised clustering and user intervention. It can discover the categories of the collections iteratively by combing online metric learning with semi-supervised clustering, and put the user intervention into the loop of each iteration. The features of our methods lie in three aspects. Firstly, the unlabeled collections are annotated with less effort in a group by group form. Secondly, users can annotate the collections flexibly and freely to define the sketch recognition personally for different applications. Finally, the scalable collection can be annotated efficiently by combining the dynamically processing and online learning. The extensive experimental results prove the effectiveness of our proposed method.
C1 [Liu, Kai; Sun, Zhengxing; Song, Mofei; Li, Bo] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM liukaics@hotmail.com; szx@nju.edu.cn; Mofeisong@nju.edu.cn;
   billleelh@gmail.com
RI Sun, Zhengxing/A-7411-2011; liu, qi/KFA-4047-2024; Liu,
   Kai/IST-6808-2023; yuan, liping/JPK-7584-2023
OI Song, Mofei/0000-0002-9912-1560
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; Innovation Fund of State Key Laboratory for Novel Software
   Technology [ZZKT2013A12]
FX This work is supported by the National High Technology Research and
   Development Program of China (Project No. 2007AA01Z334), National
   Natural Science Foundation of China (Project No. 61321491 and 61272219),
   Innovation Fund of State Key Laboratory for Novel Software Technology
   (Project No. ZZKT2013A12).
CR [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], 2008, P 2008 SIAM INT C DA
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2011, P 19 ACM INT C MULTI
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Bellet A., 2013, arXiv
   Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Eitz M., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2335395
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Fu ZY, 2015, MULTIMED TOOLS APPL, V74, P3739, DOI 10.1007/s11042-013-1796-y
   Galleguillos C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2665, DOI 10.1109/CVPR.2011.5995527
   Galleguillos C, 2014, INT J COMPUT VISION, V108, P115, DOI 10.1007/s11263-013-0679-z
   Galleguillos C, 2010, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2010.5540223
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Kapoor A, 2010, INT J COMPUT VISION, V88, P169, DOI 10.1007/s11263-009-0268-3
   Kriegel H.-P., 2008, P 14 ACM SIGKDD INT, P444, DOI DOI 10.1145/1401890.1401946
   Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523
   Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237
   Li X, 2013, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2013.116
   [李琰 Li Yan], 2013, [电源学报, Journal of  Power Supply], P1
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Liu K, 2015, LECT NOTES COMPUT SC, V9314, P55, DOI 10.1007/978-3-319-24075-6_6
   Liu W, 2015, AAAI CONF ARTIF INTE, P2792
   Lu ZM, 2010, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON ASIAN AND PACIFIC COASTS, VOL 3, P1
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Sun ZX, 2005, LECT NOTES COMPUT SC, V3610, P655
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8
   Wang HX, 2014, PROC CVPR IEEE, P4106, DOI 10.1109/CVPR.2014.523
   Wigness M, 2014, IEEE WINT CONF APPL, P247, DOI 10.1109/WACV.2014.6836093
   Xia H, 2014, IEEE T PATTERN ANAL, V36, P536, DOI 10.1109/TPAMI.2013.149
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang LN, 2014, IEEE T CIRC SYST VID, V24, P346, DOI 10.1109/TCSVT.2013.2276172
   Zhou C. J., 2007, P 24 INT C MACH LEAR, P1159, DOI DOI 10.1145/1273496.1273642
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 43
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12819
EP 12852
DI 10.1007/s11042-016-3700-z
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200029
DA 2024-07-18
ER

PT J
AU Han, W
   Chu, J
   Wang, LF
   Pan, CH
AF Han, Wei
   Chu, Jun
   Wang, Lingfeng
   Pan, Chunhong
TI Edge-directed single image super-resolution via cross-resolution
   sharpening function learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Gradient magnitude transformation; Linear
   transformation function
ID LIMITS
AB Edge-directed single image super-resolution methods have been paid more attentions due to their sharp edge preserving in the recovered high-resolution image. Their core is the high-resolution gradient estimation. In this paper, we propose a novel cross-resolution gradient sharpening function learning to obtain the high-resolution gradient. The main idea of cross-resolution learning is to learn a sharpening function from low-resolution, and use it in high-resolution. Specifically, a blurred low-resolution image is first constructed by performing bicubic down-sampling and up-sampling operations sequentially. The gradient sharpening function considered as a linear transform is learned from blurred low-resolution gradient to the input low-resolution image gradient. After that, the high-resolution gradient is estimated by applying the learned gradient sharpening function to the initial blurred gradient obtained from the bicubic up-sampled of the low-resolution image. Finally, edge-directed single image super-resolution reconstruction is performed to obtain the sharpened high-resolution image. Extensive experiments demonstrate the effectiveness of our method in comparison with the state-of-the-art approaches.
C1 [Han, Wei; Chu, Jun] Nanchang Hangkong Univ, Inst Comp Vis, Nanchang, Jiangxi, Peoples R China.
   [Han, Wei; Chu, Jun] Nanchang Hangkong Univ, Key Laborator Jiangxi Prov Image Proc & Pattern R, Nanchang, Jiangxi, Peoples R China.
   [Wang, Lingfeng; Pan, Chunhong] Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China.
C3 Nanchang Hangkong University; Nanchang Hangkong University; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Chu, J (corresponding author), Nanchang Hangkong Univ, Inst Comp Vis, Nanchang, Jiangxi, Peoples R China.; Chu, J (corresponding author), Nanchang Hangkong Univ, Key Laborator Jiangxi Prov Image Proc & Pattern R, Nanchang, Jiangxi, Peoples R China.
EM jerry123456@126.com; chujun99602@163.com; lfwang@nlpr.ia.ac.cn;
   chpan@nlpr.ia.ac.cn
FU National Natural Science Foundation of China [61263046, 61403376,
   61175025]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant Nos. 61263046, 61403376 and 61175025).
CR [Anonymous], ACM T GRAPH
   [Anonymous], ACM T GRAPHICS SIGGR
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai S., 2007, Computer Vision and Pattern Recognition, P1
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Kim K. I., 2008, EXAMPLE BASED LEARNI
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Morse BS, 2001, PROC CVPR IEEE, P333
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Yang J, 2008, PROC CVPR IEEE, P173
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
NR 20
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11143
EP 11155
DI 10.1007/s11042-016-3656-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400048
DA 2024-07-18
ER

PT J
AU He, L
   Tan, JQ
   Huo, X
   Xie, CJ
AF He, Lei
   Tan, Jieqing
   Huo, Xing
   Xie, Chengjun
TI A novel super-resolution image and video reconstruction approach based
   on Newton-Thiele's rational kernel in sparse principal component
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Newton-thiele; Super-resolution; Linear minimum mean square-error
   estimation; Sparse principal component analysis
ID HALLUCINATION; REMOVAL
AB In this paper, we propose a new image and video sequences reconstruction approach, where the Newton-Thiele's vector valued rational interpolation is combined with the sparse principal component analysis. Through observation of the degraded model, the reconstruction scheme is performed by two steps. Firstly, the sparse principal component analysis and the linear minimum mean square-error estimation method are used to remove the noise from the degraded image. And then, the Newton-Thiele's vector valued rational interpolation is used to magnify the denoising result, by which the details and texture regions of image can be well preserved. By using this novel reconstruction model by Newton-Thiele's rational kernel in sparse principal component analysis, the final reconstructed results not only have good visual effect, but also have rich texture details. In order to show the effectiveness and robustness of the proposed method, we have done plenty of experiments on images and video sequences, and the experimental results show that the proposed method can produce better high-quality resolution results, as compared with the state-of-the-art methods.
C1 [He, Lei; Tan, Jieqing; Huo, Xing] Hefei Univ Technol, Sch Comp & Informat, Sch Math, Hefei 230009, Peoples R China.
   [Xie, Chengjun] Chinese Acad Sci, Inst Intelligent Machines, Hefei, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS
RP He, L (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Sch Math, Hefei 230009, Peoples R China.
EM hlei80@163.com
RI Tan, Jie/IVV-5250-2023
FU National Natural Science Foundation of China [61472466, 61502141,
   61070227]; NSFC-Guangdong Joint Foundation [U1135003]; Anhui Provincial
   Natural Science Foundation [1508085QF128]; Fundamental Research Funds
   for the Central Universities [JZ2015HGXJ0175]
FX The authors would like to thank the referees for their valuable comments
   and constructive suggestions which greatly help improve the clarity of
   the paper. This work is supported by the National Natural Science
   Foundation of China under Grant Nos. 61472466, 61502141, and 61070227,
   the NSFC-Guangdong Joint Foundation (Key Project) under Grant No.
   U1135003, the Anhui Provincial Natural Science Foundation under Grant
   No. 1508085QF128, and the Fundamental Research Funds for the Central
   Universities under Grant No. JZ2015HGXJ0175.
CR [Anonymous], P 3 CHIN JAP SEM NUM
   [Anonymous], J CHIN U
   Bai T, 2014, SIGNAL PROCESS, V102, P247, DOI 10.1016/j.sigpro.2014.03.023
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   GRAVESMORRIS PR, 1983, NUMER MATH, V42, P331, DOI 10.1007/BF01389578
   He L, 2015, SIGNAL PROCESS-IMAGE, V31, P86, DOI 10.1016/j.image.2014.12.003
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Hu M, 2006, J COMPUT APPL MATH, V195, P46, DOI 10.1016/j.cam.2005.07.011
   Huo X, 2014, MULTIMED TOOLS APPL, V71, P451, DOI 10.1007/s11042-013-1523-8
   Jiang JJ, 2014, MULTIMED TOOLS APPL, V72, P2573, DOI 10.1007/s11042-013-1567-9
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu P, 2013, OPT LASER ENG, V51, P873, DOI 10.1016/j.optlaseng.2013.02.001
   Meng DY, 2012, PATTERN RECOGN, V45, P487, DOI 10.1016/j.patcog.2011.07.009
   Sajjad M, 2014, MULTIMED TOOLS APPL, V72, P2063, DOI 10.1007/s11042-012-1325-4
   Shahar O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3353, DOI 10.1109/CVPR.2011.5995360
   Sun J, 2003, PROC CVPR IEEE, P729
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tan JQ, 2000, MATH COMPUT, V69, P1521
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Wan BK, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P46, DOI 10.1109/CIMSA.2009.5069916
   Wang Q, 2005, IEEE I CONF COMP VIS, P709
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   ZASS R., 2006, ADV NEURAL INFORM PR, P1561
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 31
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9463
EP 9483
DI 10.1007/s11042-016-3557-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300016
DA 2024-07-18
ER

PT J
AU Lee, CF
   Weng, CY
   Chen, KC
AF Lee, Chin-Feng
   Weng, Chi-Yao
   Chen, Kai-Chin
TI An efficient reversible data hiding with reduplicated exploiting
   modification direction using image interpolation and edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Exploiting modification direction; Image
   interpolation; Edge detection
AB Data hiding is a technique that embeds a cluster of secret messages into the original image. The image with secret messages can be distributed on the Internet while the message embedded would not be easily discovered by a third party. In this way, the secret message can be well protected. At the same time, an image might be made with complex and smooth textures. If changes are made on complex textures, it is less easy for human eyes to discern the differences in the image; but if changes are made on smooth textures, the changes are easier to be discerned by human eyes. This paper proposes a data hiding method based on reduplicated exploiting modification direction (REMD), image interpolation, and canny edge detection. It aims at fulfilling two goals. First, conduct difference-embedding on the image's feature information, distribute the image, and use image interpolation to accomplish reversibility. Second, check the pixels that are located at the edge and insert different data payload according to the application demands. This allows users to flexibly adjust data payload embedded into the image's edge pixels according to their practical conditions, effectively considering both the image quality and payload. The experimental results demonstrate that the proposed method can achieve the data payload of 3.01bpp, so this is a reversible hiding technique with a very high embedding capacity. In the mean time, the average image quality is kept at an acceptable level, about 33 +/- 1 dB.
C1 [Lee, Chin-Feng; Chen, Kai-Chin] Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
   [Weng, Chi-Yao] Natl Pingtung Univ, Dept Comp Sci, Pingtung 90003, Taiwan.
C3 Chaoyang University of Technology; National Pingtung University
RP Weng, CY (corresponding author), Natl Pingtung Univ, Dept Comp Sci, Pingtung 90003, Taiwan.
EM cyweng@mail.nptu.edu.tw
RI Lee, Cheng-Chi/AGH-0724-2022
OI Lee, Cheng-Chi/0000-0002-8918-1703
FU Ministry of Science and Technology, Taiwan [MOST 104-2221-E-324-013]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Contract MOST 104-2221-E-324-013.
CR Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kuo WC, 2010, P 2010 TAIW AC NETW
   Lee C., 2015, INT J NETW SECURITY, V17, P607
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee CF, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P825, DOI 10.1109/APSCC.2008.50
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Sun HM, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2423636.2423639
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P247, DOI 10.1109/83.366474
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 21
TC 20
Z9 21
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9993
EP 10016
DI 10.1007/s11042-016-3591-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300040
DA 2024-07-18
ER

PT J
AU Rani, PI
   Muneeswaran, K
AF Rani, P. Ithaya
   Muneeswaran, K.
TI Recognize the facial emotion in video sequences using eye and mouth
   temporal Gabor features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gabor wavelet; Multiclass adaboost; Detection of face; Detection of
   facial components
ID EXPRESSION RECOGNITION
AB Machine analysis of facial emotion recognition is a challenging and innovative research topic in Human-Computer Intelligent Interaction (HCII) nowadays. The eye and mouth regions are the most important components for facial emotion recognition. Most of the existing approaches have not utilized the eye and mouth temporal features for high recognition rate. This paper proposes a novel approach for recognizing the facial emotions using eye and mouth temporal features with high recognition rate. The local features are extracted in each frame by using Gabor Wavelet with selected scale and orientations. This feature is passed to ensemble classifier for detecting the location of face region. From the signature of the face region, the eye and the mouth regions are detected using ensemble classifier. Blocks of temporal features are extracted from the signature of the eye and the mouth regions in the consecutive frames. In each block, the eye and mouth temporal features are normalized by Z-score normalization technique and encoded into binary pattern features. Concatenate the eye and mouth encoded temporal features to generate the enhanced temporal feature. Multi-class Adaboost is used to select and classify the discriminative temporal features for recognizing the facial emotion. The developed methods are deployed on the RML and CK databases, and they exhibit significant performance improvement owing to their temporal features when compared with the existing techniques.
C1 [Rani, P. Ithaya; Muneeswaran, K.] Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Amathur Post 626005, Sivakasi, India.
C3 Mepco Schlenk Engineering College
RP Rani, PI (corresponding author), Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Amathur Post 626005, Sivakasi, India.
EM muhilrani@gmail.com
RI K, Muneeswaran/T-1550-2019
CR [Anonymous], 2014, IEEE T CYBERNETICS
   [Anonymous], 2011, NIPS
   [Anonymous], IEEE INT C AUT FAC G
   Cohn JF, 2010, IEEE SIGNAL PROC MAG, V27, P128, DOI 10.1109/MSP.2010.938102
   DAUGMAN J, 2003, INT J WAVELETS MULTI
   Ekman P, 1978, FACIAL ACTION CODING
   Fakhreddine K., 2008, INT J SMART SENS INT, V1, P23
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fasel F, 2003, PATTERN RECOGNITION
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Guruswami V, 1999, P C COMP LEARN THEOR, P102
   Inan T, 2012, IEEE T INF FOREN SEC, V7, P577, DOI 10.1109/TIFS.2012.2186293
   Jerome F, 2000, ANN STAT
   Ji Y, 2010, CBMI 8 INT WORKSH CO
   Ji Y, 2012, PATTERN RECOGN LETT, V33, P1373, DOI 10.1016/j.patrec.2012.03.006
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Muneeswaran K, 2006, PATTERN RECOGN LETT, V27, P755, DOI 10.1016/j.patrec.2005.11.002
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tie Y, 2013, IEEE T CIRC SYST VID, V23, P142, DOI 10.1109/TCSVT.2012.2203210
   Vezhnevets A., 2005, GRAPHICON
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P659, DOI 10.1109/TMM.2008.921734
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Xiang T, 2008, PATTERN RECOGN, V41, P204, DOI 10.1016/j.patcog.2007.04.021
   Xiaoyang T, 2007, FUSING GABOR LBP FEA, P235
   Yang P, 2009, PATTERN RECOGN LETT, V30, P132, DOI 10.1016/j.patrec.2008.03.014
   Yun T, 2013, PATTERN RECOGN, V46, P529, DOI 10.1016/j.patcog.2012.08.002
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
NR 32
TC 5
Z9 5
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10017
EP 10040
DI 10.1007/s11042-016-3592-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300041
DA 2024-07-18
ER

PT J
AU Ding, SH
   Li, G
   Li, Y
   Li, XF
   Zhai, Q
   Champion, AC
   Zhu, JD
   Xuan, D
   Zheng, YF
AF Ding, Sihao
   Li, Gang
   Li, Ying
   Li, Xinfeng
   Zhai, Qiang
   Champion, Adam C.
   Zhu, Junda
   Xuan, Dong
   Zheng, Yuan F.
TI SurvSurf: human retrieval on large surveillance video data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video analysis; Surveillance; MapReduce
ID OBJECT; IMAGES; MOTION
AB The volume of surveillance videos is increasing rapidly, where humans are the major objects of interest. Rapid human retrieval in surveillance videos is therefore desirable and applicable to a broad spectrum of applications. Existing big data processing tools thatmainly target textual data cannot be applied directly for timely processing of large video data due to three main challenges: videos are more data-intensive than textual data; visual operations have higher computational complexity than textual operations; and traditional segmentation may damage video data's continuous semantics. In this paper, we design SurvSurf, a human retrieval system on large surveillance video data that exploits characteristics of these data and big data processing tools. We propose using motion information contained in videos for video data segmentation. The basic data unit after segmentation is called M-clip. M-clips help remove redundant video contents and reduce data volumes. We use the MapReduce framework to process M-clips in parallel for human detection and appearance/motion feature extraction. We further accelerate vision algorithms by processing only sub-areas with significant motion vectors rather than entire frames. In addition, we design a distributed data store called V-BigTable to structuralizeM-clips' semantic information. VBigTable enables efficient retrieval on a huge amount of M-clips. We implement the system on Hadoop and HBase. Experimental results show that our system outperforms basic solutions by one order of magnitude in computational time with satisfactory human retrieval accuracy.
C1 [Ding, Sihao; Li, Gang; Li, Ying; Li, Xinfeng; Zhai, Qiang; Champion, Adam C.; Zhu, Junda; Xuan, Dong; Zheng, Yuan F.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Ding, SH (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
EM ding.189@osu.edu; lgang@cse.ohio-state.edu; liyi@ece.osu.edu;
   lixinf@cse.ohio-state.edu; zhaiq@cse.ohio-state.edu;
   champion@cse.ohio-state.edu; jdzhu@umac.mo; xuan@cse.ohio-state.edu;
   zheng@ece.osu.edu
RI zheng, yuan/JCN-7781-2023
FU Macau Science and Technology Development Fund [FDCT 023/2013/A1];
   University of Macau Research Council
FX Dr. Junda Zhu's research was supported in part by The Macau Science and
   Technology Development Fund under Grant FDCT 023/2013/A1, and University
   of Macau Research Council under Multi Year Research Grant.
CR [Anonymous], 2012, THE DIGITAL UNIVERSE IN 2020 Executive Summary: Big Data, Bigger Digital Shadows, and Biggest Growth in the Far East
   Araujo Andre, 2015, 2015 IEEE International Conference on Image Processing (ICIP). Proceedings, P1519, DOI 10.1109/ICIP.2015.7351054
   Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Candan KS, 2011, IEEE MULTIMEDIA, V18, P64, DOI 10.1109/MMUL.2010.70
   Chang F, 2008, ACM T COMPUT SYST, V26, DOI 10.1145/1365815.1365816
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Bruyne S, 2008, SIGNAL PROCESS-IMAGE, V23, P473, DOI 10.1016/j.image.2008.04.012
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Duan LY, 2014, IEEE MULTIMEDIA, V21, P30, DOI 10.1109/MMUL.2013.66
   Efros A., 2012, WHAT MAKES BIG VISUA
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Fernandez-Beltran R, 2016, PATTERN RECOGN, V51, P72, DOI 10.1016/j.patcog.2015.09.007
   Heikkinen Arto, 2013, 2013 IEEE 24th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), P3497, DOI 10.1109/PIMRC.2013.6666755
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang T, 2014, IEEE COMPUTER SOC, V7
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1026, DOI 10.1109/TCSVT.2014.2358022
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mullins J, 2006, RING OF STEEL
   Over Paul., 2014, TRECVID 2014 - An overview of the goals, tasks, data, evaluation mechanisms and metrics, TRECVID 2014, NIST
   Ozer IB, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P274, DOI 10.1109/ICIP.2001.958104
   Riggs M, 2013, INTENSE SMOG IS MAKI
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   White B., 2010, MDMKDD, P9
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zaharia Matei, 2010, 2 USENIX WORKSHOP HO
   Zaharia Matei, 2008, OSDI, V8, P7
NR 34
TC 10
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6521
EP 6549
DI 10.1007/s11042-016-3307-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400020
DA 2024-07-18
ER

PT J
AU Hsieh, CY
   Lin, WY
AF Hsieh, Chung-Yang
   Lin, Wei-Yang
TI Video-based human action and hand gesture recognition by fusing factored
   matrices of dual tensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Gesture recognition; Canonical correlation analysis;
   Tensor; Fusing factored matrices
ID FEATURES
AB In this paper, we present a novel approach for human action and gesture recognition using dual-complementary tensors. In particular, the proposed method constructs a compact and yet discriminative representation by normalizing the input video volume into dual tensors. One tensor is obtained from the raw video volume data and the other one is obtained from the histogram of oriented gradients (HOG) features. Each tensor is converted to factored matrices and the similarity between factored matrices is evaluated using canonical correlation analysis (CCA). We, furthermore, propose an information fusion method to combine the resulting similarity scores. The proposed fusion strategy can effectively enhance discriminability between different action categories and lead to better recognition accuracy. We have conducted several experiments on two publicly available databases (UCF sports and Cambridge-Gesture). The results show that our proposed method achieves comparable recognition accuracy as the state-of-the-art methods.
C1 [Hsieh, Chung-Yang; Lin, Wei-Yang] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM k40964096@gmail.com; wylin@cs.ccu.edu.tw
CR [Anonymous], 2009, BMVC
   [Anonymous], COMPUTER VISION PATT
   Atmosukarto I, 2015, IEEE WINT CONF APPL, P899, DOI 10.1109/WACV.2015.124
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Geest R, 2014, IEEE IMAGE PROC, P5771, DOI 10.1109/ICIP.2014.7026167
   Deng XY, 2013, NEUROCOMPUTING, V99, P144, DOI 10.1016/j.neucom.2012.06.011
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Dollar P., PIOTRS COMPUTER VISI
   Dyana A, 2010, IEEE T CIRC SYST VID, V20, P1080, DOI 10.1109/TCSVT.2010.2051367
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Harandi MT, 2013, PATTERN RECOGN LETT, V34, P1906, DOI 10.1016/j.patrec.2013.01.008
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Iosifidis A, 2013, IEEE T CIRC SYST VID, V23, P1968, DOI 10.1109/TCSVT.2013.2269774
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   Jones S, 2012, PATTERN RECOGN LETT, V33, P446, DOI 10.1016/j.patrec.2011.05.001
   Kam Lai, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P185, DOI 10.1109/SSIAI.2012.6202484
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li HJ, 2010, IEEE T CIRC SYST VID, V20, P351, DOI 10.1109/TCSVT.2009.2035833
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Lui YM, 2012, J MACH LEARN RES, V13, P3297
   Lui YM, 2012, IEEE T CIRC SYST VID, V22, P930, DOI 10.1109/TCSVT.2011.2181452
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Ma AJ, 2013, IEEE T CIRC SYST VID, V23, P1447, DOI 10.1109/TCSVT.2013.2248494
   Minhas R, 2012, IEEE T CIRC SYST VID, V22, P1529, DOI 10.1109/TCSVT.2011.2177182
   Nagendar G., 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P479, DOI 10.1007/978-3-642-37431-9_37
   O'Hara S, 2012, PROC CVPR IEEE, P1210, DOI 10.1109/CVPR.2012.6247803
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Rodriguez M. D., 2008, IEEE C COMPUTER VISI, P1
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Scherer S, 2012, J MULTIMODAL USER IN, V6, P117, DOI 10.1007/s12193-012-0093-9
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shi F, 2013, PROC CVPR IEEE, P2595, DOI 10.1109/CVPR.2013.335
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Song Y, 2011, IEEE T CIRC SYST VID, V21, P1193, DOI 10.1109/TCSVT.2011.2130230
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527
   Yuan CF, 2013, PROC CVPR IEEE, P423, DOI 10.1109/CVPR.2013.61
   Yui Man Lui, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P97, DOI 10.1109/FG.2011.5771378
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
NR 51
TC 7
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7575
EP 7594
DI 10.1007/s11042-016-3407-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800001
DA 2024-07-18
ER

PT J
AU Kuo, YH
   Gao, YT
   Zhang, X
   Chen, J
AF Kuo, Yonghong
   Gao, Yatian
   Zhang, Xin
   Chen, Jian
TI A new multiple frames decoding and frame wise measurement for compressed
   video sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed video sensing; Low sampling; Sampling rate allocation;
   Scrambling measurements
ID IMAGE/VIDEO CODING METHOD
AB Compressed sensing (CS) breaks the limit of Nyquist sampling rate and provides a new method for information sampling. Compressed video sensing (CVS) introduces CS into video codec and decreases the burden of encoding. For three-dimensional video data, the cubebased CVS scheme is an intuitive method in that CS measurements can span the entire spatial and temporal extent of a video sequence. Unfortunately, the measuring of multiple frames in video cubes simultaneously requires complex calculation and expensive spatial costs, which is largely considered impractical to implement in a real device. In this paper, a novel compressed video sensing scheme that is exactly suitable for wireless multimedia sensor networks is proposed by changing the method of processing multiple frames in video cubes. At the encoder, sampling rate redistribution (SRR) algorithm increases the measurements contained in the first and last frames so that they can assist to reconstruct intermediate frames. At the decoder, all measurements are scrambled by global measurement scrambling (GMS) algorithm to make them similar to measurements of the global CS acquisition. The experimental results show that the proposed scheme effectively improves the decoding performance on the premise of realizable hardware devices.
C1 [Kuo, Yonghong; Gao, Yatian; Zhang, Xin; Chen, Jian] Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Kuo, YH (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian 710071, Peoples R China.
EM yhkuo@mail.xidian.edu.cn
RI KUO, Yong-Hong/M-9078-2015
FU National Science Foundation China [61440056, 61540046]; 111 Project of
   China [B08038]
FX This work was supported by the National Science Foundation China under
   grant 61440056 and 61540046, and the 111 Project of China (B08038).
CR [Anonymous], SPIE J ELECT IMAGING
   [Anonymous], 2009, THESIS
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan TF, 2006, HDB MATH MODELS COMP
   Coluccia G, 2012, IEEE J EM SEL TOP C, V2, P340, DOI 10.1109/JETCAS.2012.2214891
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673
   Jiang H, 2012, BELL LABS TECH J, V16, P149, DOI 10.1002/bltj.20539
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Li CB, 2013, IEEE T BROADCAST, V59, P197, DOI 10.1109/TBC.2012.2226509
   Li CB, 2011, 2011 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2077, DOI 10.1109/WCNC.2011.5779474
   Lorintiu O, 2014, IEEE IMAGE PROC, P1317, DOI 10.1109/ICIP.2014.7025263
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Markus L, 2015, IEEE T WIREL COMMUN, V14, P1536
   PEACEMAN DW, 1955, J SOC IND APPL MATH, V3, P28, DOI 10.1137/0103003
   Powell M.J.D., 1969, Optimization, P283
   Reddy D, 2008, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2008.4711731
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Zhang YF, 2008, IEEE INT SYMP CIRC S, P1830, DOI 10.1109/ISCAS.2008.4541796
   Zhang YF, 2008, INT CONF ACOUST SPEE, P1361
NR 25
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7321
EP 7339
DI 10.1007/s11042-016-3390-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400054
DA 2024-07-18
ER

PT J
AU Leng, L
   Teoh, ABJ
   Li, M
AF Leng, Lu
   Teoh, Andrew Beng Jin
   Li, Ming
TI Simplified 2DPalmHash code for secure palmprint verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Simplified 2D PalmHash Code; Cancelable palmprint; Secure palmprint
   verification
ID PRIVACY
AB 2DPalmHash Code (2DPHC) was proposed as a cancelable code for secure palmprint verification. In order to relieve the vertical and horizontal dislocation problems, palmprint codes, including 2DPHC, need to be shifted both in horizontal and vertical directions and matched repeatedly, which leads to high computational complexity. However, according to our analysis, horizontal-shift matching can be ignored. Therefore, the multiple-shift matching of 2DPHC can be greatly simplified. Simplified 2DPHC (S2DPHC) has threefold advantages: (1) reduces matching complexity; (2) enhances changeability performance; (3) improves verification performance. Furthermore, the superiorities of S2DPHC over 2DPHC in terms of changeability and verification performances are validated via rigorously analysis and extensive experimentation.
C1 [Leng, Lu; Li, Ming] Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Jiangxi, Peoples R China.
   [Leng, Lu; Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul 120749, South Korea.
   [Leng, Lu] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 Nanchang Hangkong University; Yonsei University; West Virginia
   University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul 120749, South Korea.
EM bjteoh@yonsei.ac.kr
RI Teoh, Andrew Beng Jin/F-4422-2010
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484
FU Basic Science Research Program through the National Research Foundation
   (NRF) of Korea - Ministry of Science, ICT and Future Planning
   [2013006574]; National Natural Science Foundation of China [61305010,
   61262019]; Institute of BioMed-IT, Energy-IT and Smart-IT Technology
   (BEST); Brain Korea 21 Plus Program, Yonsei University [2014-11-0007];
   Science and Technology Project of Education Department of Jiangxi
   Province [GJJ150715]; Voyage Project of Jiangxi Province [201450]; Open
   Foundation of Key Laboratory of Jiangxi Province for Image Processing
   and Pattern Recognition [TX201604002]
FX The authors would like to thank Biometric Research Center at Hong Kong
   Polytechnic University for providing us with the palmprint database.
   This work was supported by Basic Science Research Program through the
   National Research Foundation (NRF) of Korea funded by Ministry of
   Science, ICT and Future Planning (2013006574), National Natural Science
   Foundation of China (61305010, 61262019), Institute of BioMed-IT,
   Energy-IT and Smart-IT Technology (BEST), a Brain Korea 21 Plus Program,
   Yonsei University (2014-11-0007), Science and Technology Project of
   Education Department of Jiangxi Province(GJJ150715), Voyage Project of
   Jiangxi Province (201450), and Open Foundation of Key Laboratory of
   Jiangxi Province for Image Processing and Pattern Recognition
   (TX201604002).
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], SCI RES ESS
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Cheung KH, 2005, CISST '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY: COMPUTER GRAPHICS, P40
   Cheung KH, 2005, LECT NOTES ARTIF INT, V3683, P1168
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hammami M, 2014, MULTIMED TOOLS APPL, V68, P1023, DOI 10.1007/s11042-012-1109-x
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   JIN A.T.B., 2010, Scholarpedia, V5, P9201
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kong A, 2008, PATTERN RECOGN, V41, P1329, DOI 10.1016/j.patcog.2007.09.002
   Kong A, 2006, PATTERN RECOGN, V39, P1359, DOI 10.1016/j.patcog.2005.10.025
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Leng L, 2013, P 6 INT C IM SIGN PR, P1694
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, COMM COM INF SC, V186, P122
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Li HJ, 2010, INFORM SCIENCES, V180, P3876, DOI 10.1016/j.ins.2010.06.040
   Meraoumia A, 2015, MULTIMED TOOLS APPL, V74, P955, DOI 10.1007/s11042-013-1706-3
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tamrakar D, 2016, MULTIMED TOOLS APPL, V75, P5777, DOI 10.1007/s11042-015-2541-5
   Teoh ABJ, 2005, PATTERN RECOGN LETT, V26, P1454, DOI 10.1016/j.patrec.2004.11.021
   Teoh A, 2006, INFORM PROCESS LETT, V100, P145, DOI 10.1016/j.ipl.2006.06.010
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Wang YJ, 2011, IEEE T SYST MAN CY B, V41, P840, DOI 10.1109/TSMCB.2010.2098439
   Wang Y, 2010, IEEE T SYST MAN CY B, V40, P1280, DOI 10.1109/TSMCB.2009.2037131
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
NR 37
TC 22
Z9 22
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8373
EP 8398
DI 10.1007/s11042-016-3458-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800034
DA 2024-07-18
ER

PT J
AU Xiang, D
   Wang, ZL
AF Xiang, Dao
   Wang, Zilei
TI Salient object detection via saliency bias and diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object detection; Saliency bias; Saliency diffusion; Region
   pairwise similarity
ID VISUAL-ATTENTION
AB Salient object detection aims to identify both spatial locations and scales of the salient object in an image. However, previous saliency detection methods generally fail in detecting the whole objects, especially when the salient objects are actually composed of heterogeneous parts. In this work, we propose a saliency bias and diffusion method to effectively detect the complete spatial support of salient objects. We first introduce a novel saliency-aware feature to bias the objectness detection for saliency detection on a given image and incorporate the saliency clues explicitly in refining the saliency map. Then, we propose a saliency diffusion method to fuse the saliency confidences of different parts from the same object for discovering the whole salient object, which uses the learned visual similarities among object regions to propagate the saliency values across them. Benefiting from such bias and diffusion strategy, the performance of salient object detection is significantly improved, as shown in the comprehensive experimental evaluations on four benchmark data sets, including MSRA-1000, SOD, SED, and THUS-10000.
C1 [Xiang, Dao; Wang, Zilei] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Wang, ZL (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
EM zlwang@ustc.edu.cn
FU National Natural Science Foundation of China [61203256, 61233003];
   Natural Science Foundation of Anhui Province [1408085MF112]; Fundamental
   Research Funds for the Central Universities [WK350000002, WK3490000001]
FX This work is supported partially by the National Natural Science
   Foundation of China under Grant 61203256 and 61233003, Natural Science
   Foundation of Anhui Province (1408085MF112), and the Fundamental
   Research Funds for the Central Universities (WK350000002 and
   WK3490000001).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Al-Azawi M, 2014, MULTIMED TOOLS APPL, P1
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alpert S, 2007, IMAGE SEGMENTATION P, P1
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2008, P INT C NEUR INF PRO
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], P IEEE C COMP VIS PA
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bao L, 2015, MULT TOOLS APPL, P1
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Desai C., 2009, IEEE Electrical Power Energy Conference (EPEC), P1, DOI [10.1109/EPEC.2009.5420888, DOI 10.1109/EPEC.2009.5420888]
   Ding M, 2010, VISUAL COMPUT, V26, P721, DOI 10.1007/s00371-010-0448-8
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu H, 2007, P 15 INT C MULT
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu B, 2014, MULTIMED TOOLS APPL, V73, P1053, DOI 10.1007/s11042-013-1530-9
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
NR 42
TC 3
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6209
EP 6228
DI 10.1007/s11042-016-3310-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400007
DA 2024-07-18
ER

PT J
AU Zhao, CY
   Wang, JQ
   Lu, HQ
AF Zhao, Chaoyang
   Wang, Jinqiao
   Lu, Hanqing
TI Learning discriminative context models for concurrent collective
   activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity classification; Context information; Max-margin learning
AB Collective activity classification is the task to identify activities with multiple persons participation, which often involves the context information like person relationships and person interactions. Most existing approaches assume that all individuals in a single image share the same activity label. However, in many cases, multiple activities co-exist and serve as context cues for each other in real-world scenarios. Based on this observation, in this paper, a unified discriminative learning framework of multiple context models is proposed for concurrent collective activity recognition. Firstly, both the intra-class and inter-class behaviour interactions among persons in a scenario are considered. Besides, the scenario where activities happen also provides additional context information for recognizing specific collective activities. Finally, we jointly model the multiple context cues (intra-class, inter-class and global-context) with a max-margin leaning framework. A greedy forward search method is utilized to label the activities in the testing scenes. Experimental results demonstrate the superiority of our approach in activity recognition.
C1 [Zhao, Chaoyang; Wang, Jinqiao; Lu, Hanqing] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Zhao, CY (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM chaoyang.zhao@nlpr.ia.ac.cn; jqwang@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn
FU 863 Program [2014AA015104]; National Natural Science Foundation of China
   [61273034, 61332016]
FX This work was supported by 863 Program 2014AA015104, and National
   Natural Science Foundation of China 61273034, and 61332016.
CR Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14
   [Anonymous], 2010, Advances in neural information processing systems
   [Anonymous], COMPUT VIS PATT RECO, DOI DOI 10.1109/CVPR.2009.5206557
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2012, Trends and Topics in Computer Vision
   [Anonymous], 2013, CVPR
   [Anonymous], 2003, NIPS
   Antic B, 2014, EUR C COMP VIS ECCV
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x
   Fu Wei., 2015, Proceedings of the 7th International Conference on Internet Multimedia Computing and Service, page, P9
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427
   Jain A, 2010, LECT NOTES COMPUT SC, V6314, P199, DOI 10.1007/978-3-642-15561-1_15
   Kjellström H, 2008, LECT NOTES COMPUT SC, V5303, P336, DOI 10.1007/978-3-540-88688-4_25
   Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821
   Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228
   Li R, 2013, PROC CVPR IEEE, P1241, DOI 10.1109/CVPR.2013.164
   Odashima S, 2012, EUR C COMP VIS ECCV
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Savarese S, 2009, 2009 IEEE 12 INT C C, P1282
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Tsochantaridis I., 2004, ICML, P104
   Wang JQ, 2014, MULTIMED TOOLS APPL, V70, P799, DOI 10.1007/s11042-011-0866-2
   Wongun C, 2013, UNDERSTANDING COLLEC
   Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707
   Yao Bangpeng, 2010, CVPR
   YAO BP, 2010, PROC CVPR IEEE, P17, DOI DOI 10.1109/CVPR.2010.5540235
   Zhao CY, 2014, INT C PATT RECOG, P648, DOI 10.1109/ICPR.2014.122
NR 33
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7401
EP 7420
DI 10.1007/s11042-016-3393-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400058
DA 2024-07-18
ER

PT J
AU Bu, SH
   Zhao, Y
   Wan, G
   Li, K
   Cheng, G
   Liu, ZB
AF Bu, Shuhui
   Zhao, Yong
   Wan, Gang
   Li, Ke
   Cheng, Gong
   Liu, Zhenbao
TI Semi-direct tracking and mapping with RGB-D camera for MAV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB-D SLAM; Localization; Tracking; Mapping; Reconstruction; Real-time
ID HIGH-LEVEL FEATURE; EFFICIENT; FRAMEWORK; FUSION
AB In this paper we present a novel semi-direct tracking and mapping (SDTAM) approach for RGB-D cameras which inherits the advantages of both direct and feature based methods, and consequently it achieves high efficiency, accuracy, and robustness. The input RGB-D frames are tracked with a direct method and keyframes are refined by minimizing a proposed measurement residual function which takes both geometric and depth information into account. A local optimization is performed to refine the local map while global optimization detects and corrects loops with the appearance based bag of words and a co-visibility weighted pose graph. Our method has higher accuracy on both trajectory tracking and surface reconstruction compared to state-of-the-art frame-to-frame or frame-model approaches. We test our system in challenging sequences with motion blur, fast pure rotation, and large moving objects, the results demonstrate it can still successfully obtain results with high accuracy. Furthermore, the proposed approach achieves real-time speed which only uses part of the CPU computation power, and it can be applied to embedded devices such as phones, tablets, or micro aerial vehicles (MAVs).
C1 [Bu, Shuhui; Zhao, Yong; Cheng, Gong; Liu, Zhenbao] Northwestern Polytech Univ, Xian 710072, Peoples R China.
   [Wan, Gang; Li, Ke] Informat Engn Univ, Zhengzhou 450000, Peoples R China.
C3 Northwestern Polytechnical University; PLA Information Engineering
   University
RP Bu, SH (corresponding author), Northwestern Polytech Univ, Xian 710072, Peoples R China.
EM bushuhui@nwpu.edu.cn; zd5945@126.com; liuzhenbao@nwpu.edu.cn
RI Li, Ke/HZM-6170-2023; Cheng, Gong/I-9551-2019
OI Li, Ke/0000-0002-7873-1554; Cheng, Gong/0000-0001-5030-0683
FU National Natural Science Foundation of China [61202185, 61473231,
   61573284]; Fundamental Research Funds for the Central Universities
   [310201401-(JCQ01009,JCQ01012)]; Open Projects Program of National
   Laboratory of Pattern Recognition (NLPR)
FX This work is partly supported by grants from National Natural Science
   Foundation of China (61202185, 61473231, 61573284), the Fundamental
   Research Funds for the Central Universities (310201401-(JCQ01009,
   JCQ01012)), Open Projects Program of National Laboratory of Pattern
   Recognition (NLPR).
CR [Anonymous], 2012, IMU
   [Anonymous], 2015, IEEE MTT S INT MICR
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bu SH, 2015, COMPUT GRAPH-UK, V46, P117, DOI 10.1016/j.cag.2014.09.007
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Bu SH, 2014, IEEE MULTIMEDIA, V21, P38, DOI 10.1109/MMUL.2014.52
   Bu SH, 2014, VISUAL COMPUT, V30, P867, DOI 10.1007/s00371-014-0970-1
   Bylow E., 2013, RGB D WORKSH ADV REA
   Cheng CF, 2013, EVID-BASED COMPL ALT, V2013, DOI [10.1155/2013/613950, 10.1155/2013/958025]
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Engel J, 2012, IEEE INT C INT ROBOT, P2815, DOI 10.1109/IROS.2012.6385458
   Gálvez-López D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525
   Glocker B, 2015, IEEE T VIS COMPUT GR, V21, P571, DOI 10.1109/TVCG.2014.2360403
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843
   Grisetti G, 2011, G2O GEN FRAMEWORK GR
   Grzonka S, 2009, IEEE INT CONF ROBOT, P1679
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T CYBERNETICS, V45, P1692, DOI 10.1109/TCYB.2014.2358647
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2014, ISPRS J PHOTOGRAMM, V89, P37, DOI 10.1016/j.isprsjprs.2013.12.011
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Lee SO, 2014, IEEE INT C INT ROBOT, P2749, DOI 10.1109/IROS.2014.6942938
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu L., 2013, 23 INT JOINT C ART I
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Segal AV, 2009, GEN ICP, DOI DOI 10.15607/RSS.2009.V.021
   Selig JM, 2004, NATO SCI SER II MATH, V136, P101
   Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321
   Steinbrücker F, 2014, IEEE INT CONF ROBOT, P2021, DOI 10.1109/ICRA.2014.6907127
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517
   Stückler J, 2014, J VIS COMMUN IMAGE R, V25, P137, DOI 10.1016/j.jvcir.2013.02.008
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Whelan T., 2012, Kintinuous: Spatially extended kinectfusion, P7
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008
   Wu C., 2007, Siftgpu: A gpu implementation of david lowe's scale invariant feature transform (sift)
   Yu J, 2014, INFORM SCIENCES, V281, P674, DOI 10.1016/j.ins.2014.01.025
NR 51
TC 11
Z9 11
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4445
EP 4469
DI 10.1007/s11042-016-3524-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200061
DA 2024-07-18
ER

PT J
AU Celentano, A
AF Celentano, Augusto
TI Interactive web-based hypermedia coordination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design space; Event based synchronization; HTML5; Interactive
   hypermedia; Media coordination; Spine; User interaction
ID MULTIMEDIA PRESENTATIONS; SYNCHRONIZATION; DOCUMENTS; MODEL;
   ENVIRONMENT; CONTEXT
AB This paper discusses the interactive coordination of hypermedia documents' components in the world wide web environment, proposing a design space based on discrete events transmission between linked media and on an extension of the concept of spine introduced by the IEEE 1599 standard for music description. The elements of the design space draw from the early hypermedia models the basic concepts of anchor and link, framing them in the world wide web technology, and integrate the user interaction into dynamic media behavior in a coherent and seamless way. The paper describes the components and operations defined in the design space, giving a rationale for them. Several examples are discussed which represent the typical patterns of dynamic media synchronization and user interaction found in current hypermedia applications. Guidelines for the implementation in the standard HTML5/CSS/Javascript environment are also discussed.
C1 [Celentano, Augusto] Univ Ca Foscari Venezia, DAIS, Venice, Italy.
C3 Universita Ca Foscari Venezia
RP Celentano, A (corresponding author), Univ Ca Foscari Venezia, DAIS, Venice, Italy.
EM auce@dais.unive.it
RI Celentano, Andrea/JFJ-2728-2023; Celentano, Andrea/J-6190-2012
OI Celentano, Andrea/0000-0002-7104-2983; Celentano,
   Augusto/0000-0002-8574-4935
CR Baggi Denis L., 2009, Journal of Multimedia, V4, P3
   Bailey B., 1998, Proceedings ACM Multimedia 98, P257, DOI 10.1145/290747.290779
   Barate A., 2006, INTELLIGENT MUSIC IN
   Barate A, 2009, ELPUB2009, P29
   Barry C., 2001, IEEE Multimedia, V8, P52, DOI 10.1109/93.917971
   Bertino E, 1998, IEEE T KNOWL DATA EN, V10, P612, DOI 10.1109/69.706060
   BIEBER M, 1995, COMMUN ACM, V38, P26, DOI 10.1145/208344.208345
   Buchanan M. C., 1992, Proceeding of the ACM Conference on Hypertext, P262, DOI 10.1145/168466.171513
   Bulterman DCA, 1998, COMPUT NETWORKS ISDN, V30, P519, DOI 10.1016/S0169-7552(98)00128-7
   Bulterman DCA, 2007, MULTIMEDIA SYST, V12, P423, DOI 10.1007/s00530-006-0065-6
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Campbell A, 1992, PECHERIES FRANCAISES, P1
   Celentano A, 2003, INT J SOFTW ENG KNOW, V13, P419, DOI 10.1142/S0218194003001354
   Celentano A, 2013, P INT C DISTR MULT S, P3
   Celentano A, 2006, MULTIMED TOOLS APPL, V29, P7, DOI 10.1007/s11042-006-7811-9
   Gaggi O, 2005, MULTIMED TOOLS APPL, V27, P53, DOI 10.1007/s11042-005-2714-8
   Gaggi O, 2011, P INT C DISTR MULT S, P114
   Gaggi O, 2011, MULTIMEDIA SYST, V17, P487, DOI 10.1007/s00530-011-0233-1
   GINIGE A, 1995, IEEE MULTIMEDIA, V2, P24, DOI 10.1109/93.482293
   GOODMAN D, 1990, COMPLETE HYPERCARD 2
   HALASZ F, 1994, COMMUN ACM, V37, P30, DOI 10.1145/175235.175237
   Halasz F. G., 2001, ACM Journal of Computer Documentation, V25, P71, DOI 10.1145/507317.507321
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   Hardman L., 2000, New Review of Hypermedia and Multimedia, V6, P89, DOI 10.1080/13614560008914719
   Hardman L., 1999, Hypertext '99. Returning to our Diverse Roots. The 10th ACM Conference on Hypertext and Hypermedia, P189, DOI 10.1145/294469.294515
   Hardman L, 1998, THESIS
   HIRZALLA N, 1995, IEEE MULTIMEDIA, V2, P24, DOI 10.1109/93.410508
   Huang CM, 1998, IEEE MULTIMEDIA, V5, P44, DOI 10.1109/93.735868
   Huang CM, 1998, MULTIMEDIA SYST, V6, P316, DOI 10.1007/s005300050096
   Huang CM, 1999, COMPUT J, V42, P112, DOI 10.1093/comjnl/42.2.112
   Hustedde S.F., 1996, DEV ASYMETRIX TOOLBO
   Kappe F., 1993, Journal of Educational Multimedia and Hypermedia, V2, P39
   King P., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P355, DOI 10.1007/BFb0053283
   Kirsh D, 1997, INSTR SCI, V25, P79, DOI 10.1023/A:1002915430871
   Lab MM, 1981, INTERACTIVE MOVIE MA
   Liao WJ, 1998, MULTIMEDIA SYST, V6, P196, DOI 10.1007/s005300050088
   Little T., 1993, Multimedia System, V1, P87
   Little T. D. C., 1991, IEEE Data Eng. Bull., V14, P26
   Mantovani A, 2012, THESIS
   Mirbel I, 2000, VLDB J, V9, P111, DOI 10.1007/PL00010674
   Nelson Theodor Holm, 1965, Proceedings of the 1965 20th National Conference. ACM'65, P84, DOI [DOI 10.1145/800197.806036(CIT.ONP.169, 10.1145/800197.806036, DOI 10.1145/800197.806036]
   Ossenbruggen Jaccovan., 2001, The 10th International World Wide Web Conference on World Wide Web (WWW10), Hong Kong, P479
   PRABHAKARAN B, 1994, MULTIMEDIA SYSTEMS, V2, P53
   Sadallah M, 2014, MULTIMED TOOLS APPL, V70, P869, DOI 10.1007/s11042-012-1177-y
   Sauer S, 2001, IEEE SYMPOSIA ON HUMAN-CENTRIC COMPUTING LANGUAGES AND ENVIRONMENTS, PROCEEDINGS, P248, DOI 10.1109/HCC.2001.995271
   van Ossenbruggen J., 2003, Proceedings of the Twelfth International Conference on World Wide Web, May 2003, P384
   van Rossum G., 1993, Proceedings ACM Multimedia 93, P183, DOI 10.1145/166266.166287
   Wang Z., 2007, WUANG U J NAT SCI, V6, P1019
   YANKELOVICH N, 1988, COMPUTER, V21, P81, DOI 10.1109/2.222120
   Zucker F. D., 2007, ACM INTERACTIONS, V14, P41
NR 50
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5511
EP 5538
DI 10.1007/s11042-016-3790-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500038
DA 2024-07-18
ER

PT J
AU Chen, BB
   King, CT
   Li, XC
   Guo, DH
AF Chen, Benbin
   King, Chung-Ta
   Li, Xiaochao
   Guo, Donghui
TI A high quality compiler tool for application-specific instruction-set
   processors with library and parallel supports
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Application-specific instruction-set processor; Multimedia application;
   Retargeting compiler; Library support; OpenMP parallel specification
ID DESIGN
AB Developing a high quality compiler tool for application-specific instruction- set processors (ASIPs) including DSP for multimedia application is challenging. The specialization in ASIPs often calls for extensions at the high-level languages to allow the designers to exploit the specialized capabilities. This in turn requires the frontend of the compiler to handle the new syntax and carry the intentions of the designers across to the compiler backend implementations. The backend implementations also require extra efforts for optimized uses of the specialize features of ASIPs. Meanwhile, because of the diversity of the application, it is necessary to make full use of the compiler to complete supports and to make up some shortages of ASIP processors, the corresponding library functions are increased to support of certain operations, such as floating point arithmetic that may not be supported in ASIPs. With the development of the embedded parallelism, the advanced ASIP compilers need the support of parallelism for future application. This paper describes the High-performance C Compiler (HCC) and its specific implementation for an industrial ASIP and its family processors. HCC is a C language compiler extended and retargeted from GCC. A compiler extension framework is proposed processing programming syntax extensions of standard ANSI C for the ASIPs. With target-specific implementation, the adding optimized arithmetic functions library and chips definition file (CDF) as well as the header files for corresponding ASIPs, HCC compiler could be enhanced for the processing capabilities of target processors. Finally, this paper describes a new compiler static allocation and scheduling scheme for loop parallelization based on the OpenMP specification to improve the load imbalance. We have conducted analysis and extensive experiments to verify the correctness and effectiveness of the HCC compiler with the presented ideas. The results show that HCC compiler has a stable performance with excellent codes quality and it has been used in market.
C1 [Chen, Benbin; Li, Xiaochao; Guo, Donghui] Xiamen Univ, Dept Elect Engn, Xiamen 361005, Peoples R China.
   [Chen, Benbin] Xiamen Univ Technol, Sch Elect Engn & Automat, Fujian 361024, Peoples R China.
   [King, Chung-Ta] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 Xiamen University; Xiamen University of Technology; National Tsing Hua
   University
RP Guo, DH (corresponding author), Xiamen Univ, Dept Elect Engn, Xiamen 361005, Peoples R China.
EM benbin.chen@stu.xmu.edu.cn; dhguo@xmu.edu.cn
RI Guo, Donghui/AAN-1098-2020
OI Li, Xiaochao/0000-0001-7469-7064
FU Natural Science Foundation of China [61274133]; Xiamen University;
   holtek semiconductor Inc.
FX Foundation item: The Natural Science Foundation of China (No.:
   61274133). Authors are grateful to the Department of Electronic
   Engineering, Xiamen University and holtek semiconductor Inc. for the
   supports to carry out this work and thanks for all team members'
   assistances.
CR Antani L, 2007, TRICORE PORT GCC AN
   Ayguadé E, 2009, IEEE T PARALL DISTR, V20, P404, DOI 10.1109/TPDS.2008.105
   Chen BB, 2014, PROC INT CONF ANTI, P30
   Cuadrado LS, 2007, IEEE SOFTWARE, V24, P48, DOI 10.1109/MS.2007.135
   Desai NP, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P467, DOI 10.1109/IADCC.2009.4809056
   Feese S, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0015-9
   Guyer SZ, 2005, P IEEE, V93, P342, DOI 10.1109/JPROC.2004.840489
   Hada Ryuji, 2008, WSEAS Transactions on Computers, V7, P1515
   Hsu PY, 2014, J INF SCI ENG, V30, P107
   Kim PS, 2013, J INF PROCESS SYST, V9, P425, DOI 10.3745/JIPS.2013.9.3.425
   Leupers R, 2005, IEE P-COMPUT DIG T, V152, P209, DOI 10.1049/ip-cdt:20045075
   Malkawi M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-3
   Mozgovoy M., 2013, HUMAN CTR COMPUTING, V3, P1
   Nilsson, 1998, PORT GNU C COMP CRIS
   Oh J.-S., 2014, J CONVERGENCE, V5, P8
   Ozturk O, 2013, IEEE T COMPUT, V62, P268, DOI 10.1109/TC.2011.229
   Panduranga HT, 2013, J INF PROCESS SYST, V9, P499, DOI 10.3745/JIPS.2013.9.3.499
   Pei XH, 2010, PORT GCC GODS PROC
   Povazan I, 2013, RETARGETABLE C COMPI, P48
   Ren Kun, 2008, Journal of Zhejiang University, V42, P553
   Seng JS, 2003, INTERACT-7 2003: SEVENTH WORKSHOP ON INTERACTION BETWEEN COMPILERS AND COMPUTER ARCHITECTURES, PROCEEDINGS, P51, DOI 10.1109/INTERA.2003.1192355
   Trienekens R, 2009, PORTING GCC COMPILER
   TZEN TH, 1993, IEEE T PARALL DISTR, V4, P87, DOI 10.1109/71.205655
   Wagner J, 2001, IEEE T COMPUT AID D, V20, P1302, DOI 10.1109/43.959859
   Yang X., 2013, J CONVERG, V4, P11
   Zaidi SMA, 2014, J INF PROCESS SYST, V10, P176, DOI 10.3745/JIPS.03.0002
NR 26
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5905
EP 5926
DI 10.1007/s11042-015-2653-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500055
DA 2024-07-18
ER

PT J
AU Liapis, A
   Katsanos, C
   Sotiropoulos, DG
   Karousos, N
   Xenos, M
AF Liapis, Alexandros
   Katsanos, Christos
   Sotiropoulos, Dimitris G.
   Karousos, Nikos
   Xenos, Michalis
TI Stress in interactive applications: analysis of the valence-arousal
   space based on physiological signals and self-reported data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human computer interaction; Emotional experience evaluation; Interactive
   multimedia environments; Galvanic skin response; Affect grid; Valence;
   Arousal
ID HUMAN-COMPUTER INTERACTION; SKIN-CONDUCTANCE; EMOTION; PLEASURE;
   SCIENCE; EVENTS
AB Measuring users' emotional reaction to interactive multimedia and hypermedia is important. One particularly popular self-reported method for emotion assessment is the Valence-Arousal (VA) Scale: a 9x9 affective grid. This paper aims to identify specific stress region(s) in the VA space by combining self-reported ratings (pairs of VA) and physiological signals (skin conductance). To this end, 31 healthy volunteers participated in an experiment by performing five stressful interaction tasks while their skin conductance was monitored. The selected interaction tasks were most frequently listed as stressful by a separate group of 15 interviewees. After each task, participants expressed their perceived emotional experience using the VA rating space. Our findings show which regions in the VA rating space may reliably indicate self-reported stress that is in alignment with one's measured skin conductance while using interactive applications. One additional important contribution of this work is the proposed approach for the empirical identification of affect regions in the VA space based on physiological signals.
C1 [Liapis, Alexandros; Katsanos, Christos; Sotiropoulos, Dimitris G.; Karousos, Nikos; Xenos, Michalis] Hellen Open Univ, Sch Sci & Technol, Parodos Aristotelous 18, Patras 26335, Greece.
   [Katsanos, Christos; Karousos, Nikos] Technol Educ Inst Western Greece, M Alexandrou 1, Patras 26334, Greece.
C3 Hellenic Open University; Western Greece University of Applied Sciences
   (TEI of Western Greece)
RP Liapis, A (corresponding author), Hellen Open Univ, Sch Sci & Technol, Parodos Aristotelous 18, Patras 26335, Greece.
EM aliapis@eap.gr
RI Sotiropoulos, Dimitris G./HMV-9796-2023
OI Sotiropoulos, Dimitris G./0000-0002-6597-0185; Liapis,
   Alexandros/0000-0002-0299-5051
CR Anderson NB, 1998, ANN NY ACAD SCI, V840, P563, DOI 10.1111/j.1749-6632.1998.tb09595.x
   [Anonymous], 2014, EVID BASED COMPLEMEN, DOI DOI 10.1109/iww-BCI.2014.6782577
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   BAUM A, 1990, HEALTH PSYCHOL, V9, P653, DOI 10.1037/0278-6133.9.6.653
   Benedek M, 2010, J NEUROSCI METH, V190, P80, DOI 10.1016/j.jneumeth.2010.04.028
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Boucsein W, 1992, ELECTRODERMAL ACTIVI
   BRANTLEY PJ, 1987, J BEHAV MED, V10, P61, DOI 10.1007/BF00845128
   CACIOPPO JT, 1990, AM PSYCHOL, V45, P16, DOI 10.1037/0003-066X.45.1.16
   Calhoun BH, 2012, P IEEE, V100, P91, DOI 10.1109/JPROC.2011.2161240
   CAMPBELL JD, 1991, J PERS, V59, P473, DOI 10.1111/j.1467-6494.1991.tb00257.x
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chauncey A, 2010, LECT NOTES COMPUT SC, V6094, P369
   Chung S, 2015, INSTR SCI, V43, P545, DOI 10.1007/s11251-015-9352-y
   de Santos Sierra A., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P364, DOI 10.1109/IIHMSP.2010.95
   Deaver CM, 2003, BEHAV MODIF, V27, P578, DOI 10.1177/0145445503255571
   Diamond David M., 2007, Neural Plasticity, V2007, P1, DOI 10.1155/2007/60803
   Drachen A., 2010, Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games, P49, DOI DOI 10.1145/1836135.1836143
   EICH E, 1994, J EXP PSYCHOL GEN, V123, P201, DOI 10.1037/0096-3445.123.2.201
   Endsley M. R., 1988, Proceedings of the IEEE 1988 National Aerospace and Electronics Conference: NAECON 1988 (Cat. No.88CH2596-5), P789, DOI 10.1109/NAECON.1988.195097
   Ganglbauer E, 2009, P MOB HCI
   HART S G, 1988, P139
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Hernandez J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P51, DOI 10.1145/2556288.2557165
   Hernandez J, 2011, LECT NOTES COMPUT SC, V6974, P125, DOI 10.1007/978-3-642-24600-5_16
   JAMES W, 1994, PSYCHOL REV, V101, P205, DOI 10.1037/0033-295X.101.2.205
   JENSEN AR, 1966, ACTA PSYCHOL, V25, P36, DOI 10.1016/0001-6918(66)90004-7
   Katsanos C, 2014, INT J HUM-COMPUT INT, V30, P237, DOI 10.1080/10447318.2013.849547
   Killgore WDS, 1998, PSYCHOL REP, V83, P639, DOI 10.2466/pr0.1998.83.2.639
   Kivikangas JM, 2011, J GAMING VIRTUAL WOR, V3, P181, DOI 10.1386/jgvw.3.3.181_1
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Law ELC, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P719
   Lazar D.J., 2010, Research Methods in Human-Computer Interaction
   Liapis A, 2015, LECT NOTES COMPUT SC, V9296, P255, DOI 10.1007/978-3-319-22701-6_18
   Liapis Alexandros, 2015, P INT C BIANN C IT S, P174, DOI [10.1145/2808435, DOI 10.1145/2808435]
   Lin T., 2005, Proc. of the 17th Australia Conference on Computer-Human interaction, V122, P1
   Lin T, 2008, INTERACT COMPUT, V20, P364, DOI 10.1016/j.intcom.2007.12.002
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Lunn D, 2010, P 2010 INT CROSS DIS
   Lv HR, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1089, DOI 10.1109/ICME.2008.4607628
   Mahlke S, 2008, LECT NOTES COMPUT SC, V4868, P51, DOI 10.1007/978-3-540-85099-1_5
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Mead KML, 2007, EUR J COGN PSYCHOL, V19, P59, DOI 10.1080/09541440600591999
   Peter C, 2006, INTERACT COMPUT, V18, P139, DOI 10.1016/j.intcom.2005.10.006
   Picard R.W., 2000, Affective Computing
   Ritz T, 2005, PSYCHOPHYSIOLOGY, V42, P568, DOI 10.1111/j.1469-8986.2005.00312.x
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell YI, 2012, PERCEPT MOTOR SKILL, V114, P125, DOI 10.2466/03.28.PMS.114.1.125-136
   SCHACHTER S, 1962, PSYCHOL REV, V69, P379, DOI 10.1037/h0046234
   Scheirer J, 2001, FRUSTRATING USER PUR
   Strain Amber Chauncey, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P59, DOI 10.1007/978-3-642-30950-2_8
   Tsui WH, 2013, IEEE ENG MED BIO, P2870, DOI 10.1109/EMBC.2013.6610139
   Vermeeren Arnold POS, 2010, P 6 NORD C HUM COMP, P521, DOI [DOI 10.1145/1868914.1868973, 10.1145/1868914, DOI 10.1145/1868914]
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P4679, DOI 10.1007/s11042-013-1830-0
   Wang SF, 2014, MULTIMED TOOLS APPL, V72, P1257, DOI 10.1007/s11042-013-1450-8
   Ward RD, 2004, INTERACT COMPUT, V16, P707, DOI 10.1016/j.intcom.2004.06.002
   Wilson GM, 2000, BCS CONFERENCE S, P327
NR 59
TC 16
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5051
EP 5071
DI 10.1007/s11042-016-3637-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500017
DA 2024-07-18
ER

PT J
AU Vanattenhoven, J
   Geerts, D
AF Vanattenhoven, Jeroen
   Geerts, David
TI Social experiences within the home using second screen TV applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social interaction; Sociability; Second screen; HbbTV; User experience;
   Television
ID TELEVISION; ATTENTION
AB Today, using second screen devices while watching TV is quite common, whether related to what happens on TV or not. One area of research looks at using second screen devices to support social interaction. While most research in this area focuses on supporting social interaction between remote viewers, in this article, we focus on social interaction between collocated viewers, using second screen applications that were designed for a specific TV program. We present the results of five studies that were carried out in three different phases of a user-centered design cycle ( analysis, design and evaluation) and report on the social interaction that occurs when groups of viewers use such applications in the home and on the factors that have an influence on this social experience. Based on these findings we formulate a number of guidelines for the design of social second screen applications. We found that most participants valued such applications because of the increased interactivity and the social experience. Furthermore, applications that incorporate some form of competition are especially compelling. However, care needs to be taken when introducing competitive elements into an application and when choosing a suitable TV genre.
C1 [Vanattenhoven, Jeroen; Geerts, David] Katholieke Univ Leuven, iMinds, Meaningful Interact Lab Mintlab, Pk Str 45, B-3000 Leuven, Belgium.
C3 IMEC; KU Leuven
RP Vanattenhoven, J (corresponding author), Katholieke Univ Leuven, iMinds, Meaningful Interact Lab Mintlab, Pk Str 45, B-3000 Leuven, Belgium.
EM jeroen.vanattenhoven@kuleuven.be; david.geerts@kuleuven.be
OI Geerts, David/0000-0003-3933-9266
FU European Commission [ICT PSP-325209]
FX The research leading to these results was carried out in the TV-RING
   project under the European Commission (EC) grant agreement ICT
   PSP-325209. We would like to thank all partners in the TV-Ring project.
   Special thanks to the Dutch Public Broadcaster NPO of the TV-RING
   consortium with whom we have conducted this research.
CR Abreu Jorge., 2013, PROCS 11 EUROPEAN C, P5, DOI DOI 10.1145/2465958.2465970
   Almeida P, 2012, P 10 EUR C INT TV VI, P175, DOI DOI 10.1145/2325616.2325651
   Almeida P, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P95, DOI 10.4108/icst.intetain.2015.259548
   Anstead Edward., 2014, P ACM INT C INTERACT, P103, DOI [10.1145/2602299, DOI 10.1145/2602299]
   Basapur S., 2012, P 10 EUROPEAN C INTE, P87, DOI [10.1145/2325616.2325636, DOI 10.1145/2325616.2325636]
   Brown A., 2014, Proceedings of Human Factors in Computing Systems Conference Extended Abstracts (CHI EA '14). ACM Press, P665
   Cesar P., 2011, 2011 IEEE Consumer Communications and Networking Conference (CCNC 2011), P347, DOI 10.1109/CCNC.2011.5766487
   Cesar P, 2008, LECT NOTES COMPUT SC, V5066, P168, DOI 10.1007/978-3-540-69478-6_22
   D'heer E., 2012, Proceedings of the 10th European conference on Interactive tv and video, P195, DOI DOI 10.1145/2325616.2325654
   De Kort Yvonne AW, 2007, P PRESENCE, P1
   De Meulenaere J., 2015, The Journal of Media Innovations, V2, P6, DOI [10.5617/jmi.v2i2.909, DOI 10.5617/JMI.V2I2.909]
   Doughty M., 2012, P 10 EUR C INT TV VI, P79, DOI [DOI 10.1145/2325616.2325635, 10.1145/2325616.2325635]
   Dowell J, 2015, PERS UBIQUIT COMPUT, V19, P1215, DOI 10.1007/s00779-015-0867-7
   Ducheneaut N, 2008, INT J HUM-COMPUT INT, V24, P136, DOI 10.1080/10447310701821426
   Geerts D., 2014, INT C INTERACTIVE EX, P95, DOI [10.1145/2602299.2602312, DOI 10.1145/2602299.2602312]
   Geerts D., 2008, P UXTV 2008, P71, DOI DOI 10.1145/1453805.1453822
   Geerts D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P595
   Greer CF, 2015, CONVERGENCE-US, V21, P244, DOI 10.1177/1354856514541928
   Harboe G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1
   Holmes M.E., 2012, S EYE TRACKING RES A, P397, DOI DOI 10.1145/2168556.2168646
   Holz Christian., 2015, P ACM INT C INTERACT, P93, DOI DOI 10.1145/2745197.2745210
   Jin Yichao., 2013, P 21 ACM INT C MULTI, P435
   Krämer NC, 2015, COMPUT HUM BEHAV, V51, P255, DOI 10.1016/j.chb.2015.05.005
   Leenheer R, 2015, P ACM INT C INT EXP, P143
   Lull J., 1980, Human communication research, V6, P197, DOI DOI 10.1111/J.1468-2958.1980.TB00140.X
   McGill M, 2015, PERS UBIQUIT COMPUT, V19, P743, DOI 10.1007/s00779-015-0860-1
   Murray J.H., 2012, P 10 EUROPEAN C INTE, P223, DOI [10.1145/2325616, DOI 10.1145/2325616]
   Nandakumar A.Murray., 2014, P 2014 INT C INTERAC, P3
   Neate T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3103, DOI 10.1145/2702123.2702278
   Palviainen J, 2013, P 12 INT C MOB UB MU
   Sanders E., 2008, CoDesign, V4, P5, DOI DOI 10.1080/15710880701875068
   Schirra S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2441, DOI 10.1145/2556288.2557070
   Silva P, 2015, P ACM INT C INT EXP, P167, DOI DOI 10.1145/2745197.2755519
   Simmel G, 1949, AM J SOCIOL, V55, P254, DOI 10.1086/220534
   Van Cauwenberge A, 2014, COMPUT HUM BEHAV, V38, P100, DOI 10.1016/j.chb.2014.05.021
   Vanattenhoven J, 2012, P 3 INT WORKSH FUT T, P12
   Vanattenhoven J., 2015, P ACM INT C INT EXP, P73, DOI [DOI 10.1145/2745197.2745208, 10.1145/2745197.2745208]
   Vatavu RD, 2015, PERS UBIQUIT COMPUT, V19, P781, DOI 10.1007/s00779-015-0862-z
   Wu Y, 2013, IEEE T MULTIMEDIA, V15, P821, DOI 10.1109/TMM.2013.2240670
NR 39
TC 8
Z9 11
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5661
EP 5689
DI 10.1007/s11042-016-3646-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500043
DA 2024-07-18
ER

PT J
AU Bitar, AW
   Darazi, R
   Couchot, JF
   Couturier, R
AF Bitar, Ahmad W.
   Darazi, Rony
   Couchot, Jean-Francois
   Couturier, Raphael
TI Blind digital watermarking in PDF documents using Spread Transform
   Dither Modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital Watermarking; Portable Document Format; Quantization Index
   Modulation; Spread Transform Dither Modulation; Transparency; Robustness
AB In this paper, a blind digital watermarking scheme for Portable Document Format (PDF) documents is proposed. The proposed method is based on a variant Quantization Index Modulation (QIM) method called Spread Transform Dither Modulation (STDM). Each bit of the secret message is embedded into a group of characters, more specifically in their x-coordinate values. The method exhibits experiments of two opposite objectives: transparency and robustness, and is motivated to present an acceptable distortion value that shows sufficient robustness under high density noises attacks while preserving sufficient transparency.
C1 [Bitar, Ahmad W.; Darazi, Rony] Univ Antonine, Hadat Baabda, Lebanon.
   [Couchot, Jean-Francois] Univ Franche Comte, Dept Comp Sci DISC, FEMTO ST Inst UMR CNRS 6174, Belfort, France.
   [Couturier, Raphael] Univ Franche Comte, Belfort, France.
   [Bitar, Ahmad W.] SONDRA Cent Supelec, 3 Rue Joliot Curie, F-91190 Gif Sur Yvette, France.
C3 Universite de Franche-Comte; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Universite de Franche-Comte; Universite
   Paris Saclay
RP Bitar, AW (corresponding author), Univ Antonine, Hadat Baabda, Lebanon.; Bitar, AW (corresponding author), SONDRA Cent Supelec, 3 Rue Joliot Curie, F-91190 Gif Sur Yvette, France.
EM ahmad.bitar@supelec.fr; rony.darazi@ua.edu.lb;
   jean-francois.couchot@univ-fcomte.fr; raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Couchot, Jean-François/H-5876-2019
OI Couturier, Raphaël/0000-0003-1490-9592; Couchot,
   Jean-François/0000-0001-6437-5598
CR Alizadeh F, 2012, USING STEGANOGRAPHY, P1
   [Anonymous], 2008, DOCUMENT MANAGEMENT
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen B, 1999, P SOC PHOTO-OPT INS, V3845, P43, DOI 10.1117/12.371232
   Cox IJ., 2007, DIGITAL WATERMARKING
   Darazi R, 2010, INT CONF ACOUST SPEE, P1742, DOI 10.1109/ICASSP.2010.5495455
   Lee IS, 2010, SIGNAL PROCESS, V90, P557, DOI 10.1016/j.sigpro.2009.07.022
   Lin HF, 2013, INT J INNOV COMPUT I, V9, P1
   POR L.Y., 2008, 7 WSEAS INT C APPL C
   Wan WB, 2013, IEEE IMAGE PROC, P4522, DOI 10.1109/ICIP.2013.6738931
   Wang C, 2008, IEEE POW ENER SOC GE, P4050
NR 11
TC 16
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 143
EP 161
DI 10.1007/s11042-015-3034-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000008
DA 2024-07-18
ER

PT J
AU Huang, YH
   Yao, HX
   Zhao, SC
   Zhang, YH
AF Huang, Yinghao
   Yao, Hongxun
   Zhao, Sicheng
   Zhang, Yanhao
TI Towards more efficient and flexible face image deblurring using robust
   salient face landmark detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face image deblurring; Robust landmark detection; Image restoration
ID SPARSE REPRESENTATION; SINGLE; RESTORATION; CAMERA
AB Recent years have witnessed great progress in image deblurring. However, as an important application case, the deblurring of face images has not been well studied. Most existing face deblurring methods rely on exemplar set construction and candidate matching, which not only cost much computation time but also are vulnerable to possible complex or exaggerated face variations. To address the aforementioned problems, we propose a novel face deblurring method by integrating classical L (0) deblurring approach with face landmark detection. A carefully tailored landmark detector is used to detect the main face contours. Then the detected contours are used as salient edges to guide the blind image deconvolution. Extensive experimental results demonstrate that the proposed method can better handle various complex face poses, shapes and expressions while greatly reducing computation time, as compared with existing state-of-the-art approaches.
C1 [Huang, Yinghao; Yao, Hongxun; Zhao, Sicheng; Zhang, Yanhao] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Peoples R China.
EM yinghaohuang91@gmail.com; h.yao@hit.edu.cn; zsc@hit.edu.cn;
   yhzhang@hit.edu.cn
FU National Science Foundation of China [61472103]; Key Program Grant of
   National Science Foundation of China [61133003]
FX This work was supported in part by the National Science Foundation of
   China No. 61472103, and Key Program Grant of National Science Foundation
   of China No. 61133003.
CR [Anonymous], 2011, CVPR
   [Anonymous], 2014, CVPR
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cho HJ, 2012, LECT NOTES COMPUT SC, V7576, P524, DOI 10.1007/978-3-642-33715-4_38
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Edwards G. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P137, DOI 10.1109/ICCV.1999.791209
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45
   HaCohen Y, 2013, IEEE I CONF COMP VIS, P2384, DOI 10.1109/ICCV.2013.296
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432
   Joshi N, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587834
   Kazemi V, 2011, BMVC, P27
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Nishiyama M, 2011, IEEE T PATTERN ANAL, V33, P838, DOI 10.1109/TPAMI.2010.203
   Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Sun LH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P1
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512
   Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
NR 32
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 123
EP 142
DI 10.1007/s11042-015-3009-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000007
DA 2024-07-18
ER

PT J
AU Qi, F
   Zhao, DB
   Liu, SH
   Fan, XP
AF Qi, Feng
   Zhao, Debin
   Liu, Shaohui
   Fan, Xiaopeng
TI 3D visual saliency detection model with generated disparity map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D visual attention; Binocular vision; Depth perception; Saliency fusion
ID ATTENTION; CONTRAST; IMAGE
AB Due to the remarkable distinction between human monocular vision and binocular vision, stereoscopic visual attention becomes an emerging question in the study of 3D applications. Some of existing 3D visual saliency detection models take advantage of ground-truth disparity map to compute center-surround differences of the depth features with high computational cost. In some 3D applications, the ground-truth disparity map may not be always available. In this paper, an efficient and simple 3D visual saliency detection model is proposed without using ground-truth disparity map. The proposed model is based on a band-pass filtering method which coincides with the visual perceptual process in human visual system. Firstly, the monocular luminance, color and texture features are extracted from the left view's image; the binocular depth feature is extracted from the two views' disparity map. Then, all the feature maps are filtered to generate three types of saliency maps, i.e., 2D saliency map, texture saliency map and depth saliency map. Subsequently, the three saliency maps are fused to one 3D saliency map by a linear pooling strategy. Finally, the final 3D visual saliency map is enhanced by the center-bias factor. Experimental results on a public eye tracking database show that the proposed model achieves better detection performance with low computational cost among the existing 3D visual saliency detection models.
C1 [Qi, Feng; Zhao, Debin; Liu, Shaohui; Fan, Xiaopeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Qi, F (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM fqi@jdl.ac.cn
RI Liu, Shaohui/AAC-3092-2019; Liu, shaohui/HKE-1383-2023; Zhao,
   Debin/JEP-0204-2023
OI Liu, Shaohui/0000-0002-1810-5412; 
FU Major State Basic Research Development Program of China 973 Program
   [2015CB351804]; National Science Foundation of China (NSFC) [61272386,
   61472101, 61390513]
FX This work was supported in part by the Major State Basic Research
   Development Program of China 973 Program under Grant 2015CB351804 and in
   part by the National Science Foundation of China (NSFC) under Grant
   61272386, 61472101 and 61390513.
CR ANDERSON SJ, 1985, VISION RES, V25, P1147, DOI 10.1016/0042-6989(85)90104-X
   [Anonymous], 2010, P CVPR
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], [No title captured]
   [Anonymous], P 4 ACM C MULT SYST
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2010, IMAGE VISION COMPUT, V28, P1130, DOI 10.1016/j.imavis.2009.10.006
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P88, DOI 10.1109/CRV.2005.13
   Chamaret C, 2010, IEEE IMAGE PROC, P1077, DOI 10.1109/ICIP.2010.5651381
   Chamaret C, 2010, P SOC PHOTO-OPT INS, V7524, DOI 10.1117/12.837532
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cho SH, 2014, LECT NOTES COMPUT SC, V8827, P778, DOI 10.1007/978-3-319-12568-8_94
   Ciptadi A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.112
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gautier J, 2012, COGN COMPUT, V4, P141, DOI 10.1007/s12559-012-9138-3
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Häkkinen J, 2010, PROC SPIE, V7524, DOI 10.1117/12.838857
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jung YJ, 2012, P SPIE ELECT IMAGING
   Khaustova D, 2014, PROC SPIE, V9014, DOI 10.1117/12.2037954
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Maki A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P734, DOI 10.1109/ICPR.1996.547661
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Ouerhani N, 2000, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2000.905356
   Potapova Ekaterina, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P132, DOI 10.1007/978-3-642-23968-7_14
   Robertson A.R., 1977, Color Res. Appl., V2, P7, DOI [10.1002/j.1520-6378.1977.tb00104.x, DOI 10.1002/J.1520-6378.1977.TB00104.X]
   Roe AW, 2007, J NEUROSCI, V27, P11820, DOI 10.1523/JNEUROSCI.4164-07.2007
   Rosenholtz R, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870080
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Xing P., 2013, Visual Communications and Image Processing (VCIP), 2013, P1
   Yan JC, 2010, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2010.5652280
   Zhang L., 2013, P ICIP
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2010, LECT NOTES COMPUT SC, V5916, P314, DOI 10.1007/978-3-642-11301-7_33
   Zuo W., 2013, CVPR
NR 46
TC 15
Z9 17
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 3087
EP 3103
DI 10.1007/s11042-015-3229-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000067
DA 2024-07-18
ER

PT J
AU Sun, ZQ
   Zhu, YS
   Xing, XM
   Luo, GB
   Liu, XY
AF Sun, Ziqiang
   Zhu, Yuesheng
   Xing, Xiaomei
   Luo, Guibo
   Liu, Xiyao
TI A near-duplicate 3D video detection algorithm by using hypercomplex
   representations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate 3D video detection; Video fingerprint; Quaternion;
   Hypercomplex representation
ID COPY DETECTION; ROBUST; DIBR
AB Copyright protection is still a crucial open issue in the 3D video industry with the development of 3DTV coupled with the increasing 3D video spread over the internet. In this paper a novel video fingerprinting is proposed for near-duplicate 3D video detection. Instead of generating fingerprints from the color frames and the depth maps separately, the proposed algorithm processes them in a holistic manner. The hypercomplex representation developed from the RGB and depth components is used to represent the 3D contents as quaternion frames and a novel quaternion centroid of the spatio-temporal gradient orientations is exploited to generate 3D video fingerprints based on these quaternion frames. Comprehensive experiments are conducted to evaluate the performance of the proposed method, and the results show that the proposed near-duplicate 3D video detection algorithm outperforms the state-of-the-art approaches in terms of robustness and discrimination. And the proposed fingerprints are also more compact than the existing approaches.
C1 [Sun, Ziqiang; Zhu, Yuesheng; Xing, Xiaomei; Luo, Guibo; Liu, Xiyao] Peking Univ, Inst Big Data Technol, Shenzhen Grad Sch, Commun & Informat Secur Lab, Beijing, Peoples R China.
C3 Peking University
RP Zhu, YS (corresponding author), Peking Univ, Inst Big Data Technol, Shenzhen Grad Sch, Commun & Informat Secur Lab, Beijing, Peoples R China.
EM sunzq87@gmail.com; zhuys@pkusz.edu.cn
RI liu, xiyao/GSE-0791-2022
FU Shenzhen Engineering Laboratory of Broadband Wireless Network Security;
   Science and Technology Development Fund of Macao [SARFDCT056/2012/A2];
   UM Multi-year Research Grant [MYRG144 (Y1-L2) - FST11 - ZLM]; Next
   Generation of Information Technology Industry Development Special Fund
   of Shenzhen [XXH-YY20130329010018]
FX This work was supported by Shenzhen Engineering Laboratory of Broadband
   Wireless Network Security, the Science and Technology Development Fund
   of Macao SARFDCT056/2012/A2, UM Multi-year Research Grant MYRG144
   (Y1-L2) - FST11 - ZLM, and the Next Generation of Information Technology
   Industry Development Special Fund of Shenzhen XXH-YY20130329010018.
CR Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Ghouti Lahouari, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3794, DOI 10.1109/ICASSP.2014.6854311
   Hamilton W. R., 1848, Transactions of the Royal Irish Academy, V21, P199
   Hampapur A, 2002, P SOC PHOTO-OPT INS, V4676, P194
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khodabakhshi N, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422963
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Laradji IH, 2013, IEEE IMAGE PROC, P4402, DOI 10.1109/ICIP.2013.6738907
   Le Bihan N, 2004, SIGNAL PROCESS, V84, P1177, DOI 10.1016/j.sigpro.2004.04.001
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2009, IEEE T CIRC SYST VID, V19, P1379, DOI 10.1109/TCSVT.2009.2022801
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Liu Z., 2010, Proc. of the international conference on Multimedia information retrieval (MIR'10), P119
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mehta S, 2014, IEEE IMAGE PROC, P4797, DOI 10.1109/ICIP.2014.7025972
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mohan R, 1998, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.1998.679686
   Ramachandra Vikas, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P81, DOI 10.1109/3DTV.2008.4547813
   Robinson J. J., 1981, Paper, 32nd Annual Meeting of the European Association for Animal Production
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schwarz H., 2010, MPEG2010N11274 ISO
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Sun ZQ, 2013, KSII T INTERNET INF, V7, P2754, DOI 10.3837/tiis.2013.11.012
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 32
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1055
EP 1071
DI 10.1007/s11042-015-3086-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000046
DA 2024-07-18
ER

PT J
AU Saldana, J
AF Saldana, Jose
TI On the effectiveness of an optimization method for the traffic of
   TCP-based multiplayer online games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic optimization; Online games; MMORPG; Header compression;
   Multiplexing; Subjective quality
ID INTERNET; PERSPECTIVE; NETWORK
AB This paper studies the feasibility of using an optimization method, based on multiplexing and header compression, for the traffic of Massively Multiplayer Online Role Playing Games (MMORPGs) using TCP at the Transport Layer. Different scenarios where a number of flows share a common network path are identified. The adaptation of the multiplexing method is explained, and a formula of the savings is devised. The header compression ratio is obtained using real traces of a popular game and a statistical model of its traffic is used to obtain the bandwidth saving as a function of the number of players and the multiplexing period. The obtained savings can be up to 60 % for IPv4 and 70 % for IPv6. A Mean Opinion Score model from the literature is employed to calculate the limits of the multiplexing period that can be used without harming the user experience. The interactions between multiplexed and non-multiplexed flows, sharing a bottleneck with different kinds of background traffic, are studied through simulations. As a result of the tests, some limits for the multiplexing period are recommended: the unfairness between players can be low if the value of the multiplexing period is kept under 10 or 20 ms. TCP background flows using SACK (Selective Acknowledgment) and Reno yield better results, in terms of fairness, than Tahoe and New Reno. When UDP is used for background traffic, high values of the multiplexing period may stress the unfairness between flows if network congestion is severe.
C1 [Saldana, Jose] Univ Zaragoza, Aragon Inst Engn Res I3A, EINA, L2-05,Ada Byron Bldg, Zaragoza 50018, Spain.
C3 University of Zaragoza
RP Saldana, J (corresponding author), Univ Zaragoza, Aragon Inst Engn Res I3A, EINA, L2-05,Ada Byron Bldg, Zaragoza 50018, Spain.
EM jsaldana@unizar.es
RI Saldana, Jose/K-6595-2014
OI Saldana, Jose/0000-0002-6977-6363
FU European Social Fund; Government of Aragon; TAMA Project, Government of
   Aragon
FX This work has been partially financed by the European Social Fund in
   collaboration with the Government of Aragon; and TAMA Project,
   Government of Aragon.
CR [Anonymous], 2011, P 4 INT ICST C SIM T
   [Anonymous], 1999, 2507 RFC
   [Anonymous], 2015, 7540 RFC
   [Anonymous], P ACM SIGCHI INT C A
   [Anonymous], PREDICTING PERCEIVED
   [Anonymous], 1990, 1144 RFC
   [Anonymous], AUSTR TEL NETW APPL
   [Anonymous], G107 ITUT
   Avallone S, 2004, INT CONF QUANT EVAL, P316
   Batool SH, 2010, INFORM DEV, V26, P141, DOI 10.1177/0266666910366650
   Bauer D., 2002, Proceedings of NetGames, Association for Computer Machinery, P36, DOI DOI 10.1145/566500.566506
   Cameron P, 1994, 1692 RFC
   CASNER S, 1999, 2508 RFC
   Chambers C., 2005, 5 ACM SIGCOMM C INT, P1
   Che XH, 2012, J NETW COMPUT APPL, V35, P240, DOI 10.1016/j.jnca.2011.08.005
   Chen KT, 2006, COMPUT NETW, V50, P3002, DOI 10.1016/j.comnet.2005.11.005
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Cooperative Association for Internet Data Analysis, NASA AM INT EXCH PAC
   De Vleeschauwer B., 2005, ACM SIGCOMM Workshop on Network and System Support for Games, P1
   Ertekin E, 2004, IEEE COMMUN MAG, V42, P106, DOI 10.1109/MCOM.2004.1362553
   Feng WC, 2005, IEEE ACM T NETWORK, V13, P488, DOI 10.1109/TNET.2005.850221
   Francis B, 2012, DISTR COMP SYST WORK, p[230, 222], DOI [10.1109/ICDCSW.2012.29, DOI 10.1109/ICDCSW.2012.29]
   Fritsch Tobias., 2005, NETGAMES 05, P1
   Furuholt Bjorn, 2008, International Information and Library Review, V40, P129, DOI 10.1016/j.iilr.2008.02.001
   Griwodz C, 2006, P INT WORKS NETW OP, DOI [10.1145/1378191.1378193, DOI 10.1145/1378191.1378193]
   GUROL M, 2007, TELEMAT INFORM, V24, P59, DOI DOI 10.1016/J.TELE.2005.12.004
   Huawei, 2012, SMARTPH SOL WHIT PAP
   Issariyakul T., 2011, Introduction to network simulator NS2
   Kaiser A, 2009, P IEEE GLOB TEL C GL, DOI [10.1109/GLOCOM.2009.5426032, DOI 10.1109/GLOCOM.2009.5426032]
   KIHL M, 2010, INT C ULTR TEL CONTR, P218, DOI DOI 10.1109/ICUMT.2010.5676634
   KOREN T, 2003, 3545 RFC
   Majewski C., 2006, P INT NETW C INC 06, P113
   Marfia G, 2010, COMPUT NETW, V54, P2327, DOI 10.1016/j.comnet.2010.02.014
   MAUVE M, 2002, P 1 WORKSH NETW SYST, P25, DOI DOI 10.1145/566500.566504
   Miller JL, 2010, IEEE 9 ANN WORKSH NE, DOI [10.1109/NETGAMES.2010.5679578, DOI 10.1109/NETGAMES.2010.5679578]
   Newzoo, FREE GLOB TREND REP
   Oliveira M., 2003, NETWORK SYSTEM SUPPO, P185
   Pereira RM, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P53, DOI 10.1109/ICDT.2009.17
   Perkins C., 2003, RTP : Audio and Video for the Internet
   Radhakrishnan Sivasankar., 2011, ACM CoNEXT
   Ratti S, 2010, IEEE INTERNET COMPUT, V14, P60, DOI 10.1109/MIC.2010.57
   Ries M, 2008, INT CONF SYST SIGNAL, P181, DOI 10.1109/IWSSIP.2008.4604397
   Saldana J., 2014, TUNNELING C IN PRESS
   Saldana J, 2014, MULTIMED TOOLS APPL, V71, P1823, DOI 10.1007/s11042-012-1309-4
   Saldana J, 2013, IEEE COMMUN MAG, V51, P127, DOI 10.1109/MCOM.2013.6658664
   Saldana J, 2012, COMPUT NETW, V56, P1893, DOI 10.1016/j.comnet.2012.02.004
   Saldana J, 2011, IEEE COMMUN MAG, V49, P190, DOI 10.1109/MCOM.2011.6069728
   Saldana J, 2011, IEEE COMMUN LETT, V15, P1132, DOI 10.1109/LCOMM.2011.080811.111160
   Sandlund K, 2010, RFC 5795
   Suznjevic M, 2009, P 8 ANN WORKSH NETW, DOI 10.1109/NETGAMES.2009.5446235
   Suznjevic M, 2014, INT J COMPUT GAMES T, V2014, DOI 10.1155/2014/602403
   Suznjevic M, 2013, MULTIMEDIA SYST, V19, P231, DOI 10.1007/s00530-012-0269-x
   Suznjevic M, 2013, MULTIMEDIA SYST, V19, P199, DOI 10.1007/s00530-012-0270-4
   Suznjevic M, 2009, MULTIMED TOOLS APPL, V45, P191, DOI 10.1007/s11042-009-0300-1
   Svoboda P, 2007, P ICC 07 URB CHAMP, DOI [10.1109/ICC.2007.270, DOI 10.1109/ICC.2007.270]
   Thompson B., 2005, 4170 RFC
   Wu CC, 2009, MULTIMED TOOLS APPL, V45, P7, DOI 10.1007/s11042-009-0297-5
   Zhuang X., 2007, CMUCS07158
   Zorzi M, 1999, IEEE PERS COMMUN, V6, P32, DOI 10.1109/98.799618
NR 59
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17333
EP 17374
DI 10.1007/s11042-015-3001-y
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Selvakumar, K
   Jerome, J
   Rajamani, K
AF Selvakumar, K.
   Jerome, Jovitha
   Rajamani, Kumar
TI Robust face identification using DTCWT and PCA subspace based sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face identification; Illumination normalization; Partial occlusion;
   Dual-tree complex wavelet transform; Principal component analysis;
   Sparse representation
ID RECOGNITION
AB This paper presents a robust method for recognizing human faces with varying illumination as well as partial occlusion. In the proposed approach, a dual-tree complex wavelet transform (DTCWT) is employed to normalize the illumination variation in the logarithm domain. In order to minimize the variations under different lighting conditions, appropriate low frequency DTCWT subbands are truncated and the rest of the directional subbands are used to reconstruct the stable invariant face. Using the fundamental concept that patterns from a single object class lie in a linear subspace, we develop class specific dictionaries using principal component analysis (PCA) based subspace learning on illumination invariant faces. By representing the pre-processed probe image against each dictionary using l (1) regularization into PCA reconstruction, target face and sparse noises are effectively factorized. Then, identification decision is made in favor of a class with minimum reconstruction error. Evaluations on challenging probe images demonstrate that the proposed method performs favorably against several state of the art methods.
C1 [Selvakumar, K.; Jerome, Jovitha] PSG Coll Technol, Dept Instrumentat & Control Engn, Coimbatore 641004, Tamil Nadu, India.
   [Rajamani, Kumar] Robert Bosch Engn & Business Solut Ltd, Bangalore, Karnataka, India.
C3 PSG College Technology; Bosch
RP Selvakumar, K (corresponding author), PSG Coll Technol, Dept Instrumentat & Control Engn, Coimbatore 641004, Tamil Nadu, India.
EM kskumareee@gmail.com
RI Karuppusamy, Selvakumar/W-8269-2019; k, selvakumar/T-6970-2019
OI Karuppusamy, Selvakumar/0000-0001-9556-6944; k,
   selvakumar/0000-0003-0580-158X
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   Bonnen K, 2013, IEEE T INF FOREN SEC, V8, P239, DOI 10.1109/TIFS.2012.2226580
   Cai S., MATLAB IMPLEMENTATIO
   Chellappa R, 2012, PATTERN RECOGN LETT, V33, P1849, DOI 10.1016/j.patrec.2011.11.020
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goh YZ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P421, DOI 10.1109/CISP.2008.335
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   Horn B.K.P, 1986, Robot Vision
   Hu HF, 2011, COMPUT VIS IMAGE UND, V115, P1384, DOI 10.1016/j.cviu.2011.06.004
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Liu CC, 2009, IEEE T IMAGE PROCESS, V18, P2593, DOI 10.1109/TIP.2009.2027361
   Luan X, 2014, PATTERN RECOGN, V47, P495, DOI 10.1016/j.patcog.2013.06.031
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Martinez A. M., 1998, THE AR FACE DATABASE
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nabatchian A, 2011, PATTERN RECOGN, V44, P2576, DOI 10.1016/j.patcog.2011.03.012
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
NR 31
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16073
EP 16092
DI 10.1007/s11042-015-2914-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700054
DA 2024-07-18
ER

PT J
AU Shin, K
   Kim, D
   Chung, K
AF Shin, Kwangmu
   Kim, Daekeun
   Chung, Kidong
TI Visual stereo matching combined with intuitive transition of pixel
   values
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Visual processing; Algorithms; Stereo matching; Pixel values
ID COST AGGREGATION
AB The objective of stereo matching is to find the corresponding pixels from similar two or more images. However, it is difficult problem to get precise and consistent disparity under a variety of real world situations. In other words, the color values of stereo images are easily influenced by radiometric factors such as illumination direction, illumination color, and camera exposure. Therefore, conventional stereo matching methods can have low performances under radiometric conditions. In this paper, we propose a novel stereo matching approach that is robust in controlling various radiometric variations such as local and global radiometric variations. We designed a hybrid stereo matching approach using transition of pixel values and data fitting. Transition of pixel values is utilized for the coarse stereo matching stage, and polynomial curve fitting is used for the fine stereo matching stage. Experimental results show that the proposed method has better performances compared to the stereo matching algorithms of comparison group under severely different radiometric conditions between stereo images. Consequentially, we demonstrate that the proposed method is less sensitive to various radiometric variations, and shows an outstanding performance in computational complexity.
C1 [Shin, Kwangmu; Kim, Daekeun; Chung, Kidong] Pusan Natl Univ, Dept Comp Engn, Mt 30, Busan 46241, South Korea.
C3 Pusan National University
RP Shin, K (corresponding author), Pusan Natl Univ, Dept Comp Engn, Mt 30, Busan 46241, South Korea.
EM sin@pusan.ac.kr
CR [Anonymous], P COMP VIS WINT WORK
   [Anonymous], 2013, WERTUNG THEORIEN INS, DOI DOI 10.HTTP://WWW.10.1109/CVPR.2001.990462
   [Anonymous], J CONVERG
   [Anonymous], 2006, BMVC
   [Anonymous], J CONVERGENCE
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Chaudhary A, 2012, J INF PROCESS SYST, V8, P399, DOI 10.3745/JIPS.2012.8.3.399
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Heo Y., 2008, Proceedings of the International Conference on Computer Vision and Pattern Recognition, P1, DOI 10.1109/CVPR.2008.4587697
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Iqbal M, 2010, INT CONF COMPUT AUTO, P334, DOI 10.1109/ICCAE.2010.5451536
   Jung IL, 2013, IEEE T MULTIMEDIA, V15, P56, DOI 10.1109/TMM.2012.2225041
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Malhotra R, 2012, J INF PROCESS SYST, V8, P241, DOI 10.3745/JIPS.2012.8.2.241
   MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029
   Mattoccia S, 2008, IEEE T IMAGE PROCESS, V17, P528, DOI 10.1109/TIP.2008.919362
   Miled W, 2009, IEEE T IMAGE PROCESS, V18, P813, DOI 10.1109/TIP.2008.2011386
   Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416
   Na I, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P1175
   Ohkawara T, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-11
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R., 2011, Computer Vision: Applications and Algorithms
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Veksler O, 2003, PROC CVPR IEEE, P556
   Xia Hu, 2010, Proceedings of the 2010 IEEE 10th International Conference on Computer and Information Technology (CIT 2010), P1388, DOI 10.1109/CIT.2010.248
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang K, 2009, IEEE INT CON MULTI, P93, DOI 10.1109/ICME.2009.5202444
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhou XZ, 2012, IEEE IMAGE PROC, P2989, DOI 10.1109/ICIP.2012.6467528
NR 35
TC 4
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15381
EP 15403
DI 10.1007/s11042-015-2962-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700017
OA hybrid
DA 2024-07-18
ER

PT J
AU Uddin, J
   Jeong, IK
   Kang, M
   Kim, CH
   Kim, JM
AF Uddin, Jia
   Jeong, In-Kyu
   Kang, Myeongsu
   Kim, Cheol-Hong
   Kim, Jong-Myon
TI Accelerating IP routing algorithm using graphics processing unit for
   high speed multimedia communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bellman-Ford algorithm; IP routing; Graphics processing unit; Clustering
   computing
AB This paper presents a Graphics Processing Unit (GPU)-based implementation of a Bellman-Ford (BF) routing algorithm using NVIDIA's Compute Unified Device Architecture (CUDA). In the proposed GPU-based approach, multiple threads run concurrently over numerous streaming processors in the GPU to dynamically update routing information. Instead of computing the individual vertex distances one-by-one, a number of threads concurrently update a larger number of vertex distances, and an individual vertex distance is represented in a single thread. This paper compares the performance of the GPU-based approach to an equivalent CPU implementation while varying the number of vertices. Experimental results show that the proposed GPU-based approach outperforms the equivalent sequential CPU implementation in terms of execution time by exploiting the massive parallelism inherent in the BF routing algorithm. In addition, the reduction in energy consumption (about 99 %) achieved by using the GPU is reflective of the overall merits of deploying GPUs across the entire landscape of IP routing for emerging multimedia communications.
C1 [Uddin, Jia; Jeong, In-Kyu; Kang, Myeongsu; Kim, Jong-Myon] Univ Ulsan, Sch Elect Engn, Bldg 7,Room 308,93 Daehak Ro Mugeo Dong, Ulsan 680749, South Korea.
   [Kim, Cheol-Hong] Chonnam Natl Univ, Sch Elect & Comp Engn, Gwangju, South Korea.
C3 University of Ulsan; Chonnam National University
RP Kim, JM (corresponding author), Univ Ulsan, Sch Elect Engn, Bldg 7,Room 308,93 Daehak Ro Mugeo Dong, Ulsan 680749, South Korea.
EM engrjiauddin@gmail.com; jeonginkeyu@gmail.com; ilmareboy@gmail.com;
   cheolhong@gmail.com; jongmyon.kim@gmail.com
OI Uddin, Jia/0000-0002-3403-4095
FU Research Funds of Hyundai Heavy Industries for University of Ulsan
FX This work was supported by 2014 Research Funds of Hyundai Heavy
   Industries for University of Ulsan.
CR [Anonymous], J CONVERGENCE
   Bellman R., 1958, Q APPL MATH, V16, P87
   Bhattacharya A., 2012, HUMAN CENTRIC COMPUT, V2, P1, DOI DOI 10.1186/2192-1962-2-7
   Chang KD, 2010, J INF PROCESS SYST, V6, P129, DOI 10.3745/JIPS.2010.6.2.129
   Chao JS, 2011, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.2011.6116299
   Chikkagoudar S, 2013, BMC RES NOTE
   Choi HJ, 2013, J SUPERCOMPUT, V65, P886, DOI 10.1007/s11227-013-0870-6
   Chorianopoulos K., 2013, HUMANCENTRIC COMPUT, V3, P1
   Gong CY, 2011, J INF PROCESS SYST, V7, P63, DOI 10.3745/JIPS.2011.7.1.063
   Harvey JP, 2009, THESIS, P1
   Huang JW, 2008, ADV MULTIMED, V2008, DOI 10.1155/2008/720685
   Kang K, 2011, DES AUT TEST EUR C E, P1
   Lalami ME, 2011, IEEE INT C HIGH PERF, P179
   Luebke D, 2008, I S BIOMED IMAGING, P836, DOI 10.1109/ISBI.2008.4541126
   Mu S, 2010, IEEE DES AUT TEST EU, P93
   Nie DH, 2009, J INF PROCESS SYST, V5, P105, DOI 10.3745/JIPS.2009.5.2.105
   NVIDIA, 2013, CUDA PROGR GUID CUDA
   Sharma M.J., 2012, HUMAN CTR COMPUTING, V2, P1
   Shi L, 2012, IEEE T COMPUT, V61, P1
   Tian Y, 2011, J INT COUNC ELECT EN, V1, P116
   Truong T., 2012, J CONVERGENCE, V3, P1
   Udayan JD, 2013, J CONVERGENCE, V4, P6
   Zhang Y, 2011, IEEE DES AUT C NEW Y, P1044
NR 23
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15365
EP 15379
DI 10.1007/s11042-014-2013-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700016
DA 2024-07-18
ER

PT J
AU Wang, LP
   Zhou, SB
   Karim, A
AF Wang, Liping
   Zhou, Shangbo
   Karim, Awudu
TI Super-resolution image reconstruction method using homotopy
   regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Total variation; Partial differential equation;
   Homotopy regularization
ID TIKHONOV REGULARIZATION; INVERSION; TOMOGRAPHY; EQUATION
AB In this paper, we present a homotopy regularization based on fractional order total variation for image super-resolution. This regularization function of the proposed method is composed of three parts: fractional order TV regularization term, homotopy data fidelity term and traditional data fidelity. And the overall function is minimized using the gradient descent flow. For super-resolution reconstruction, the proposed approach makes full use of characteristics of fractional calculus and homotopy method, avoiding effectively the jaggies when reconstructing an image. Fractional calculus can significantly improve high frequency component of a signal, while the low frequency part is strengthened accordingly. Homotopy method can achieve convergence quickly in a nonlocal area.
C1 [Wang, Liping; Zhou, Shangbo; Karim, Awudu] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.
   [Wang, Liping; Zhou, Shangbo; Karim, Awudu] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University; Chongqing University
RP Zhou, SB (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, Chongqing 400030, Peoples R China.; Zhou, SB (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM shbzhou@cqu.edu.cn
RI Awudu, Karim/GSI-9518-2022
OI Awudu, Karim/0000-0002-8108-6218
FU National Natural Science Foundation of China [60873200]
FX This work was supported by National Natural Science Foundation of China
   under Grant No. 60873200. The authors also thank sincerely the anonymous
   referee for his or her valuable comments, which helped in improving
   substantially the manuscript.
CR AMUNDSEN L, 1991, GEOPHYSICS, V56, P1027, DOI 10.1190/1.1443111
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   BERKHOUT AJ, 1984, GEOPHYSICS, V49, P1881, DOI 10.1190/1.1441601
   BUNKS C, 1995, GEOPHYSICS, V60, P1457, DOI 10.1190/1.1443880
   Chen MJ, 2011, J REAL-TIME IMAGE PR, V6, P281, DOI 10.1007/s11554-010-0170-9
   Chunduru RK, 1997, GEOPHYSICS, V62, P1196, DOI 10.1190/1.1444220
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   FAN QB, 2015, J SIGNAL PROCESS, V114, P131, DOI DOI 10.1016/J.SIGPRO.2015.02.021
   Fan WR, 2010, FLOW MEAS INSTRUM, V21, P277, DOI 10.1016/j.flowmeasinst.2010.02.007
   Feng XC, 2009, VARIATIONAL METHOD P
   Gang L, 2014, J COMPUT MATH APPL, V67, P2015
   Gao H, 2010, OPT EXPRESS, V18, P2894, DOI 10.1364/OE.18.002894
   HAN B, 1994, APPL MATH COMPUT, V60, P139, DOI 10.1016/0096-3003(94)90100-7
   Han B, 1997, APPL MATH COMPUT, V81, P97, DOI 10.1016/0096-3003(95)00304-5
   JinZheng L, 2014, J OPTIC OPTICS, V125, P2497
   Lei J, 2009, MEASUREMENT, V42, P368, DOI 10.1016/j.measurement.2008.07.003
   LIU J, 1993, SIAM J SCI COMPUT, V14, P389, DOI 10.1137/0914024
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   MCAULAY AD, 1986, GEOPHYSICS, V51, P1789, DOI 10.1190/1.1442225
   Ren ZM, 2013, SIGNAL PROCESS, V93, P2408, DOI 10.1016/j.sigpro.2013.02.015
   Ren ZM, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.023006
   Rieder A, 1997, NUMER MATH, V75, P501, DOI 10.1007/s002110050250
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saleck FM, 1993, 63 ANN INT MTY SOC E, P688
   Shen JH, 2003, PHYSICA D, V175, P241, DOI 10.1016/S0167-2789(02)00734-0
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   VASCO DW, 1994, GEOPHYS J INT, V119, P809, DOI 10.1111/j.1365-246X.1994.tb04019.x
   Wenfei J, 2014, J VIS COMMUN IMAGE R, V29, P125
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeng W, 2011, J APPL MATH, V3, P447
   ZHAO HS, 1994, GEOPHYSICS, V59, P1868, DOI 10.1190/1.1443574
   Zhou L, 2014, MULTIMED TOOLS APPL, V71, P1879, DOI 10.1007/s11042-012-1311-x
NR 34
TC 5
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15993
EP 16016
DI 10.1007/s11042-015-2910-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700050
DA 2024-07-18
ER

PT J
AU Wang, Y
   Yu, LL
   Xie, HQ
   Lei, T
   Guo, Z
   Qi, M
   Lv, GY
   Fan, YY
   Niu, YL
AF Wang, Yi
   Yu, Liangliang
   Xie, Houqi
   Lei, Tao
   Guo, Zhe
   Qi, Min
   Lv, Guoyun
   Fan, Yangyu
   Niu, Yilong
TI Line detection algorithm based on adaptive gradient threshold and
   weighted mean shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Line detection; Weighted mean shift; Adaptive gradient threshold;
   Omni-direction searching
ID PROBABILISTIC HOUGH TRANSFORM; FALSE DETECTION CONTROL; SEGMENT
   DETECTOR; TRACKING; SPACE
AB Line detection is a classical problem in computer vision and image processing, and it is widely used as a basic method. Most of existing line detection algorithms are based on edge information, whose discontinuity limited the detection result. Meanwhile, some other algorithms only use gradient magnitudes, and neglect the function of gradient directions. In this paper, an adaptive gradient threshold and omni-direction line growing method based on line detection with weighted mean shift procedure and 2D slice sampling strategy (referred to as LSWMSAllDir) is proposed. It makes full use of the magnitudes and directions of the gradient to detect lines in the image. Experiments on synthetic data and real scene image data showed that the improve algorithm was the most accurate when compared with Progressive Probabilistic Hough Transform (PPHT), line segment detector (LSD), parameter free edge drawing (EDPF) and original line segment detection using weighted mean shift (LSWMS) algorithms.
C1 [Wang, Yi; Yu, Liangliang; Xie, Houqi; Guo, Zhe; Qi, Min; Lv, Guoyun; Fan, Yangyu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Lei, Tao] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Lei, Tao] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
   [Niu, Yilong] Northwestern Polytech Univ, Sch Marine Sci & Technol, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Shaanxi University of Science & Technology; Northwestern
   Polytechnical University
RP Niu, YL (corresponding author), Northwestern Polytech Univ, Sch Marine Sci & Technol, Xian 710072, Shaanxi, Peoples R China.
EM wangyi79@nwpu.edu.cn; yuliangliang@mail.nwpu.edu.cn; jxfcxhq@163.com;
   leitaoly@163.com; guozhe@nwpu.edu.cn; drqimin@nwpu.edu.cn;
   lvguoyun101@nwpu.edu.cn; fan_yangyu@nwpu.edu.cn; yilong_niu@nwpu.edu.cn
RI wang, yi/KBB-3614-2024
OI Wang, Yi/0000-0002-7743-1779
FU National Nature Science Foundation of China [61461025, 61402371];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2015JM6317, 2013JQ8039]; Fundamental Research Funds for the Central
   Universities [3102014JCQ01060]; NPU Foundation for Fundamental Research
   [JCY20130130]; Seed Foundation of Innovation and Creation for Graduate
   Students in NPU [Z2016024, Z2016121]
FX This work was supported by the National Nature Science Foundation of
   China (Grant Nos. 61461025, 61402371); Natural Science Basic Research
   Plan in Shaanxi Province of China (Grant No. 2015JM6317, 2013JQ8039);
   Fundamental Research Funds for the Central Universities (Grant No.
   3102014JCQ01060); NPU Foundation for Fundamental Research (Grant No.
   JCY20130130); The Seed Foundation of Innovation and Creation for
   Graduate Students in NPU (Grant No. Z2016024, Z2016121).
CR Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   BENTZVI D, 1990, PATTERN RECOGN LETT, V11, P167, DOI 10.1016/0167-8655(90)90002-J
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   Franti P., 1998, Joint Conference on Intelligent Systems 1999 (JCIS'98), P433
   Galambos C, 2001, IEE P-VIS IMAGE SIGN, V148, P158, DOI 10.1049/ip-vis:20010354
   Grompone R, 2007, IEEE GEOSCIENCE REMO
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964
   Karnieli A, 1996, PHOTOGRAMM ENG REM S, V62, P525
   Lee H J, 2001, INT SOC OPTICS PHOTO, p2e44
   LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   Meksen T.M., 2006, Proc. of the 6th WSEAS Int. Conf. Signal Processing, P202
   Nieto M, 2011, PATTERN ANAL APPL, V14, P149, DOI 10.1007/s10044-011-0211-4
   Panagiotakis C, 2015, IEEE J-STARS, V8, P3, DOI 10.1109/JSTARS.2014.2363080
   San DK, 2010, SCIENCE, V38, P1063
   Siyu Guo, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P47, DOI 10.1049/cp:20080281
   Soto-Pinto C, 2013, COMPUT GEOSCI-UK, V57, P93, DOI 10.1016/j.cageo.2013.03.019
   Strzodka R, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P188, DOI 10.1109/ICIAP.2003.1234048
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Voon LFCLY, 1997, P SOC PHOTO-OPT INS, V3029, P140, DOI 10.1117/12.271236
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yang C, 2004, 18 C NEUR INF PROC S, P13
NR 30
TC 3
Z9 5
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16665
EP 16682
DI 10.1007/s11042-016-3835-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700079
DA 2024-07-18
ER

PT J
AU Yang, GL
   Zhang, YD
   Yang, JQ
   Ji, GL
   Dong, ZC
   Wang, SH
   Feng, CM
   Wang, Q
AF Yang, Gelan
   Zhang, Yudong
   Yang, Jiquan
   Ji, Genlin
   Dong, Zhengchao
   Wang, Shuihua
   Feng, Chunmei
   Wang, Qiong
TI Automated classification of brain images using wavelet-energy and
   biogeography-based optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Pattern recognition; Support vector machine; Magnetic
   resonance imaging; Biogeography-based optimization
ID SUPPORT VECTOR MACHINE; MRI; ENTROPY; PARAMETERS; TRANSFORM; ALGORITHM;
   DIAGNOSIS; TUMOR
AB It is very important to early detect abnormal brains, in order to save social and hospital resources. The wavelet-energy was a successful feature descriptor that achieved excellent performances in various applications; hence, we proposed a novel wavelet-energy based approach for automated classification of MR brain images as normal or abnormal. SVM was used as the classifier, and biogeography-based optimization (BBO) was introduced to optimize the weights of the SVM. The results based on a 5 x 5-fold cross validation showed the performance of the proposed BBO-KSVM was superior to BP-NN, KSVM, and PSO-KSVM in terms of sensitivity and accuracy. The study offered a new means to detect abnormal brains with excellent performance.
C1 [Yang, Gelan] Hunan City Univ, Sch Informat Sci & Engn, Yiyang 413000, Peoples R China.
   [Zhang, Yudong; Ji, Genlin; Wang, Shuihua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Yudong; Yang, Jiquan; Feng, Chunmei; Wang, Qiong] Jiangsu Key Lab 3D Printing Equipment & Mfg, Nanjing 210042, Jiangsu, Peoples R China.
   [Dong, Zhengchao] Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.
   [Dong, Zhengchao] Columbia Univ, MRI Unit, New York, NY 10032 USA.
   [Dong, Zhengchao] New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
C3 Hunan City University; Nanjing Normal University; Columbia University;
   Columbia University; New York State Psychiatry Institute
RP Zhang, YD (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Zhang, YD (corresponding author), Jiangsu Key Lab 3D Printing Equipment & Mfg, Nanjing 210042, Jiangsu, Peoples R China.
EM zhangyudong@njnu.edu.cn
RI Wang, shuihua/G-7326-2016; Zhang, Yudong/I-7633-2013
OI Wang, shuihua/0000-0003-4713-2791; Yang, Gelan/0000-0002-2472-3436;
   Zhang, Yudong/0000-0002-4870-1493; Xiu, Haohua/0000-0002-7821-125X
FU NSFC [610011024, 61273243, 51407095]; Program of Natural Science
   Research of Jiangsu Higher Education Institutions [13KJB460011,
   14KJB520021]; Jiangsu Key Laboratory of 3D Printing Equipment and
   Manufacturing [BM2013006]; Key Supporting Science and Technology Program
   (Industry) of Jiangsu Province [BE2012201, BE2014009-3, BE2013012-2];
   Special Funds for Scientific and Technological Achievement
   Transformation Project in Jiangsu Province [BA2013058]; Nanjing Normal
   University Research Foundation for Talented Scholars [2013119XGQ0061,
   2014119XGQ0080]; Science Research Foundation of Hunan Provincial
   Education Department [12B023]
FX This paper was supported by NSFC (610011024, 61273243, 51407095),
   Program of Natural Science Research of Jiangsu Higher Education
   Institutions (13KJB460011, 14KJB520021), Jiangsu Key Laboratory of 3D
   Printing Equipment and Manufacturing (BM2013006), Key Supporting Science
   and Technology Program (Industry) of Jiangsu Province (BE2012201,
   BE2014009-3, BE2013012-2), Special Funds for Scientific and
   Technological Achievement Transformation Project in Jiangsu Province
   (BA2013058), Nanjing Normal University Research Foundation for Talented
   Scholars (2013119XGQ0061, 2014119XGQ0080), and Science Research
   Foundation of Hunan Provincial Education Department (12B023).
CR Bafroui HH, 2014, NEUROCOMPUTING, V133, P437, DOI 10.1016/j.neucom.2013.12.018
   Cai ML, 2014, MULTIMED TOOLS APPL, V70, P1333, DOI 10.1007/s11042-013-1749-5
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   Cheng J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076400
   Choudhary R, 2009, BIOSYST ENG, V102, P115, DOI 10.1016/j.biosystemseng.2008.09.028
   Christy AA, 2014, INT J ELEC POWER, V62, P344, DOI 10.1016/j.ijepes.2014.04.054
   Dai Y, 2013, INT J MED ROBOT COMP, V9, P433, DOI 10.1002/rcs.1477
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Dong ZC, 2014, NMR BIOMED, V27, P1325, DOI 10.1002/nbm.3193
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Fang LT, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/513849
   Goh S, 2014, JAMA PSYCHIAT, V71, P665, DOI 10.1001/jamapsychiatry.2014.179
   Guo DL, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/420482
   Guo WA, 2014, ENG OPTIMIZ, V46, P1465, DOI 10.1080/0305215X.2013.854349
   Kalbkhani H, 2013, BIOMED SIGNAL PROCES, V8, P909, DOI 10.1016/j.bspc.2013.09.001
   Lee SH, 2013, IEICE ELECTRON EXPR, V10, DOI 10.1587/elex.10.20130335
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Messina A, 2008, INT J SOLIDS STRUCT, V45, P4068, DOI 10.1016/j.ijsolstr.2008.02.015
   Mookiah MRK, 2012, KNOWL-BASED SYST, V33, P73, DOI 10.1016/j.knosys.2012.02.010
   Nanthagopal AP, 2013, J VISUAL-JAPAN, V16, P19, DOI 10.1007/s12650-012-0153-y
   Padma A, 2014, ARAB J SCI ENG, V39, P767, DOI 10.1007/s13369-013-0649-3
   Panchal MB, 2013, ADV VIB ENG, V12, P311
   Ramasamy R, 2011, COMM COM INF SC, V198, P387
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Simon D, 2011, EVOL COMPUT, V19, P167, DOI 10.1162/EVCO_a_00018
   Wu YL, 2014, MULTIMED TOOLS APPL, V70, P2037, DOI 10.1007/s11042-012-1220-z
   Xu S, 2014, MULTIMED TOOLS APPL, V71, P699, DOI 10.1007/s11042-013-1526-5
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/130134
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2015, IEEJ T ELECTR ELECTR, V10, P116, DOI 10.1002/tee.22059
   Zhang YD, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/546814
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 35
TC 147
Z9 150
U1 3
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15601
EP 15617
DI 10.1007/s11042-015-2649-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700030
DA 2024-07-18
ER

PT J
AU Bhardwaj, S
   Atrey, PK
   Saini, MK
   El Saddik, A
AF Bhardwaj, Shally
   Atrey, Pradeep K.
   Saini, Mukesh K.
   El Saddik, Abdulmotaleb
TI Personality assessment using multiple online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online social networks; Personality; Facebook; LinkedIn
ID 5-FACTOR MODEL; SUSCEPTIBILITY; NEUROTICISM; MOTIVATION; INTERNET;
   ANXIETY; ABILITY; TRAITS; WORDS
AB Personality plays an important role in various aspects of our daily life. It is being used in many application scenarios such as i) personalized marketing and advertisement of commercial products, ii) designing personalized ambient environments, iii) personalized avatars in virtual world, and iv) by psychologists to treat various mental and personality disorders. Traditional methods of personality assessment require a long questionnaire to be completed, which is time consuming. On the other hand, several works have been published that seek to acquire various personality traits by analyzing Internet usage statistics. Researchers have used Facebook, Twitter, YouTube, and various other websites to collect usage statistics. However, we are still far from a successful outcome. This paper uses a range of divergent features of Facebook and LinkedIn social networks, both separately and collectively, in order to achieve better results. In this work, the big five personality trait model is used to analyze the five traits: openness to experience, conscientiousness, extroversion, agreeableness, and neuroticism. The experimental results show that the accuracy of personality detection improves with the use of complementary features of multiple social networks (Facebook and LinkedIn, in our case) for openness, conscientiousness, agreeableness, and neuroticism. However, for extroversion we found that the use of only LinkedIn features provides better results than the use of only Facebook features or both Facebook and LinkedIn features.
C1 [Bhardwaj, Shally; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Atrey, Pradeep K.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.
   [Saini, Mukesh K.] NYU, Div Engn, Abu Dhabi, U Arab Emirates.
C3 University of Ottawa; State University of New York (SUNY) System; State
   University of New York (SUNY) Albany
RP Atrey, PK (corresponding author), SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.
EM sbhardwaj072@gmail.com; patrey@albany.edu; mks4@nyu.edu;
   elsaddik@uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
CR Amichai-Hamburger Y, 2002, COMPUT HUM BEHAV, V18, P1, DOI 10.1016/S0747-5632(01)00034-6
   Amichai-Hamburger Y, 2000, COMPUT HUM BEHAV, V16, P441, DOI DOI 10.1016/S0747-5632(00)00017-0
   Amichai-Hamburger Y, 2005, PERSONALITY INTERNET, P27
   Amichai-Hamburger Y, 2008, COMPUT HUM BEHAV, V24, P1907, DOI 10.1016/j.chb.2008.02.005
   Amichai-Hamburger Y, 2010, COMPUT HUM BEHAV, V26, P1289, DOI 10.1016/j.chb.2010.03.018
   [Anonymous], 2012, ARXIV12044809
   Association for Psychological Science, 2012, SCIENCEDAILY    0521
   Bachrach Y, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P24
   Back MD, 2010, PSYCHOL SCI, V21, P372, DOI 10.1177/0956797609360756
   Bhardwaj S, 2013, P 2 IEEE ICME INT WO, P180
   Birknerov Z., 2013, J FINANCE EC, V1, P17
   BLOCK J, 1995, PSYCHOL BULL, V117, P187, DOI 10.1037/0033-2909.117.2.187
   Blumer T, 2012, CYBERPSYCHOL J PSYCH, V6
   Brody N., 1998, PERSONALITY PSYCHOL, V3
   Busato VV, 2000, PERS INDIV DIFFER, V29, P1057, DOI 10.1016/S0191-8869(99)00253-6
   Capara GV, 1999, POLITICAL PSYCHOL, V20, P175
   Chamorro-Premuzic T., 2007, PERS INDIV DIFFER
   Cherry K, TRAIT THEORY PERSONA
   Correa T, 2010, COMPUT HUM BEHAV, V26, P247, DOI 10.1016/j.chb.2009.09.003
   Costa P. T., 1992, PSYCHOL ASSESSMENT, V4, P5, DOI DOI 10.1037/1040-3590.4.1.5
   COSTA PT, 1988, J PERS SOC PSYCHOL, V54, P853, DOI 10.1037/0022-3514.54.5.853
   FOWLES DC, 1987, J RES PERS, V21, P417, DOI 10.1016/0092-6566(87)90030-4
   Global Faces and Networked Places, WHAT DO PERS TRAITS
   Global Faces and Networked Places, 2009, NIELS REP SOC NETW N
   Golbeck J., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P149, DOI 10.1109/PASSAT/SocialCom.2011.33
   Golbeck J, 2011, P 2011 ANN C HUM FAC, P253
   Guadagno RE, 2008, COMPUT HUM BEHAV, V24, P1993, DOI 10.1016/j.chb.2007.09.001
   Hardie E., 2007, Australian Journal of Emerging Technologies and Society, V5, P34
   Haugtvedt C.P., 1988, Advances in consumer research, V15, P209
   Hirsh JB, 2012, PSYCHOL SCI, V23, P578, DOI 10.1177/0956797611436349
   Hirsh JB, 2010, PERS SOC PSYCHOL B, V36, P655, DOI 10.1177/0146167210366854
   Holzwarth M, 2006, J MARKETING, V70, P19, DOI 10.1509/jmkg.70.4.19
   Iacobelli F, 2011, LECT NOTES COMPUT SC, V6975, P568, DOI 10.1007/978-3-642-24571-8_71
   Judge TA, 2000, J APPL PSYCHOL, V85, P751, DOI 10.1037/0021-9010.85.5.751
   LARSEN RJ, 1991, J PERS SOC PSYCHOL, V61, P132, DOI 10.1037/0022-3514.61.1.132
   LARSEN RJ, 1989, PERS INDIV DIFFER, V10, P1221, DOI 10.1016/0191-8869(89)90233-X
   Li L, 2006, ACTA PSYCHOL SINICA, V3
   Mehroof M, 2010, CYBERPSYCH BEH SOC N, V13, P313, DOI 10.1089/cyber.2009.0229
   Milutinovi V, 2012, P 35 INT CONV, P1017
   Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041
   Quercia D., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P180, DOI 10.1109/PASSAT/SocialCom.2011.26
   Roberts BW, 2007, PERSPECT PSYCHOL SCI, V2, P313, DOI 10.1111/j.1745-6916.2007.00047.x
   Ross C, 2009, COMPUT HUM BEHAV, V25, P578, DOI 10.1016/j.chb.2008.12.024
   Suh KS, 2011, MIS QUART, V35, P711
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Tuten TL, 2001, SOC BEHAV PERSONAL, V29, P391, DOI 10.2224/sbp.2001.29.4.391
   Verschuren A, 2012, THESIS
   Wald R, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P109, DOI 10.1109/IRI.2012.6302998
   Yarkoni T, 2010, J RES PERS, V44, P363, DOI 10.1016/j.jrp.2010.04.001
NR 49
TC 7
Z9 9
U1 1
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13237
EP 13269
DI 10.1007/s11042-015-2793-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cheng, KW
   Chen, YT
   Fang, WH
AF Cheng, Kai-Wen
   Chen, Yie-Tarng
   Fang, Wen-Hsien
TI An efficient subsequence search for video anomaly detection and
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Anomaly detection; Localization; Subsequence
ID EVENT; HISTOGRAMS; MODEL
AB This paper presents a novel framework for anomaly event detection and localization in crowded scenes. For anomaly detection, one-class support vector machine with Bayesian derivation is applied to detect unusual events. We also propose a novel event representation, called subsequence, which refers to a time series of spatial windows in proximity. Unlike recent works encoded an event with a 3D bounding box which may contain irrelevant information, e.g. background, a subsequence can concisely capture the unstructured property of an event. To efficiently locate anomalous subsequences in a video space, we propose the maximum subsequence search. The proposed search algorithm integrates local anomaly scores into a global consistent detection so that the start and end of an abnormal event can be determined under false and missing detections. Experimental results on two public datasets show that our method is robust to the illumination change and achieve at least 80% localization rate which approximately doubles the accuracy of recent works. This study concludes that anomaly localization is crucial in finding abnormal events.
C1 [Cheng, Kai-Wen; Chen, Yie-Tarng; Fang, Wen-Hsien] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Cheng, KW (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM d10102101@mail.ntust.edu.tw; ytchen@mail.ntust.edu.tw;
   whf@mail.ntust.edu.tw
RI Chen, Yietarng/W-7806-2019
FU National Science Council of R.O.C. [101-2221-E-011-163]
FX This research was supported by National Science Council of R.O.C. under
   contract 101-2221-E-011-163.
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2007, CVPR SHORT COURSE
   [Anonymous], INT C COMP VIS
   Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Benezeth Y, 2011, PATTERN RECOGN LETT, V32, P423, DOI 10.1016/j.patrec.2010.10.008
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Boiman O, 2005, IEEE I CONF COMP VIS, P462
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Chen YT, 2010, J CHIN INST ENG, V33, P681, DOI 10.1080/02533839.2010.9671657
   Cheng Kai-Wen., 2013, P 4 ACM IEEE INT WOR, P49
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Du Tran, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3321, DOI 10.1109/CVPR.2011.5995416
   Duque D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P362, DOI 10.1109/CIDM.2007.368897
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hu DH, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1715
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kettnaker V.M., 2003, PROC COMPUTER VISION, P34
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Kwon J, 2012, PROC CVPR IEEE, P1266, DOI 10.1109/CVPR.2012.6247810
   Lampert C. H., 2008, C COMPUT VIS PATTERN, P1
   Lee CK, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P407
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nater F, 2010, PROC CVPR IEEE, P2014, DOI 10.1109/CVPR.2010.5539877
   Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594
   Roshtkhari MJ, 2013, IMAGE VISION COMPUT, V31, P864, DOI 10.1016/j.imavis.2013.08.005
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Voulodimos AS, 2014, MULTIMED TOOLS APPL, V69, P293, DOI 10.1007/s11042-012-0993-4
   Wang T, 2013, IEEE INT W PERFORM, P45, DOI 10.1109/PETS.2013.6523794
   Wiliem Arnold, 2008, 2008 Digital Image Computing: Techniques and Applications, P398, DOI 10.1109/DICTA.2008.45
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Yin J, 2008, IEEE T KNOWL DATA EN, V20, P1082, DOI 10.1109/TKDE.2007.1042
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 47
TC 15
Z9 17
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 15101
EP 15122
DI 10.1007/s11042-015-2453-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500062
DA 2024-07-18
ER

PT J
AU Chou, JK
   Yang, CK
   Chang, HC
AF Chou, Jia-Kai
   Yang, Chuan-Kai
   Chang, Hsing-Ching
TI Encryption domain content-based image retrieval and convolution through
   a block-based transformation algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image transformation/encryption; Ecryption domain content-based image
   retrieval/convolution
ID FEATURES
AB In this paper, we propose a block-based transformation algorithm to achieve the purpose of image content protection. More importantly, under the proposed image content protection framework, image retrieval and image convolution can also be performed directly on the content-protected images. As a consequence, not only secure image storage and communication are accomplished, but also the computation efforts can be fully distributed, thus making it a perfect match for nowadays popular cloud computing technology. Security analyses are conducted to prove that the proposed image encryption scheme offers certain degree of security in both statistical and computational aspects. Although a higher data confidentiality may be reached by adopting traditional cryptographic encryption algorithms, we believe it could be accepted by ordinary users with general image storage needs, since extra functionalities, i.e. content-based image retrieval and image convolution, are provided. Experimental results also demonstrate the decent performance of the proposed encryption domain image retrieval and convolution with acceptable storage overhead.
C1 [Chou, Jia-Kai] Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
   [Yang, Chuan-Kai] Natl Taiwan Univ Sci & Technol, Informat Management Dept, Taipei, Taiwan.
   [Chang, Hsing-Ching] Chungyu Inst Technol, Keelung, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Chou, JK (corresponding author), Natl Taiwan Univ Sci & Technol, Taipei, Taiwan.
EM D9809101@mail.ntust.edu.tw; ckyang@cs.ntust.edu.tw;
   D9309104@mail.ntust.edu.tw
FU Ministry of Science and Technology, Taiwan [NSC 101-2221-E-011-150-MY3]
FX The authors thank the anonymous reviewers' spending valuable time
   reviewing and giving out useful comments. We also would like to thank
   Nick Leaf for proof-reading the paper and providing suggestions on how
   to address the reviewers' comments. This work was supported in part by
   the Ministry of Science and Technology, Taiwan under the grant NSC
   101-2221-E-011-150-MY3.
CR [Anonymous], IEEE SIGNAL PROCESS
   Bianchi T, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/716357
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Cancellaro M, 2008, PROC SPIE, V6819, DOI 10.1117/12.766650
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   Demaine ED, 2007, GRAPH COMBINATOR, V23, P195, DOI 10.1007/s00373-007-0713-4
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Ferguson N., 2010, Cryptography Engineering: Design Principles and Practical Applications
   Fisher RonaldR., 1938, Statistical tables for biological, agricultural aad medical research
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Gautam Aditee, 2011, INT J ADV ENG SCI TE, V8, p90 
   Gentry C, 2010, COMMUN ACM, V53, P97, DOI 10.1145/1666420.1666444
   Hsu CY, 2011, PROC SPIE, V7880, DOI 10.1117/12.873325
   Jeong S, 2004, COMPUT VIS IMAGE UND, V94, P44, DOI 10.1016/j.cviu.2003.10.015
   Jolfaei Alireza, 2010, Journal of Theoretical and Applied Information Technology, V19, P117
   Kelsey J, 2000, LECT NOTES COMPUT SC, V1758, P13
   Lathey A, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2656205
   Lathey A, 2013, IEEE INT C SEMANT CO, P310, DOI 10.1109/ICSC.2013.60
   Lauter K, 2011, PROCEEDINGS OF THE 3RD ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'11), P113
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu W, 2009, SPIE IS T MEDIA FORE, V7254
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Maniccam SS, 2001, PATTERN RECOGN, V34, P1229, DOI 10.1016/S0031-3203(00)00062-5
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Park M, 2002, FIFTH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, PROCEEDINGS, P178, DOI 10.1109/IAI.2002.999914
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Rakesh S., 2012, IJCIS, V2, P49
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHARMA N, 2011, SIGNAL IMAGE PROCESS, V2, P94, DOI DOI 10.5121/SIPIJ.2011.2108
   Shih J., 2002, P IEE VIS IM SIGN PR, P88
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Upmanyu M, ICCV, P1639
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WANG LT, 1988, IEEE T COMPUT, V37, P1302, DOI 10.1109/12.5994
   Yao A. C., 1982, 23rd Annual Symposium on Foundations of Computer Science, P160, DOI 10.1109/SFCS.1982.38
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Younes MAB, 2008, INT J COMPUT SCI NET, V8, P191
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zhang XP, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P446, DOI 10.1109/ChinaSIP.2014.6889282
   Zhi-Chun Huang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P719, DOI 10.1109/ICMLC.2010.5580566
NR 43
TC 7
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13805
EP 13832
DI 10.1007/s11042-015-2917-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800043
DA 2024-07-18
ER

PT J
AU Lin, F
   Xiahou, JB
   Xu, ZX
AF Lin, Fan
   Xiahou, Jianbing
   Xu, Zhuxiang
TI TCM clinic records data mining approaches based on weighted-LDA and
   multi-relationship LDA model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic model; Latent Dirichlet Allocation(LDA); Multi-relationship; Data
   mining; Author-Topic model; TF-IDF; Traditional Chinese Medicine(TCM)
AB As an important part of traditional medicine, TCM (Traditional Chinese Medicine) has unique and distinct clinical effects in the aspect of disease diagnosis and treatment. Thousands of years of TCM treatment has accumulated abundant clinical data and medical literatures, including valued TCM theories and clinical practice rules. Researchers have conducted various methods such as clustering analysis, association rules and regression analysis to study TCM theory. However, none of them could reflect well the semantic complexity of TCM and systemic characteristics of TCM treatment. This paper conducted a research on the inherent rules of TCM clinic records with a topic model. On the basis of LDA model, weighted mechanism was adopted for each feature word to improve the distinguishing ability and interpretability between the topics. Meanwhile, the modeled topic is taken as the feature for the classification of SVM (Support Vector Machine) to improve the classification accuracy. The topic number of LDA topic model is confirmed by the KL distance and similarity between the topics. After analyzing the relationship between topic model and TCM differentiation and treatment, MULTI-RELATIONSHIP Topics LDA MODEL was proposed on the basis of LDA model and Author-topic model to automatically extract the topic structures between the four parties and explore the relationship of the multiple parties with clinical significance. In the meantime, relevancy between the parties and the feature word weighted mechanism are used to improve the MULTI-RELATIONSHIP Topics LDA MODEL and the classification accuracy of the topics. The experiments showed that analysis of clinical data with topic model can extract TCM treatment rules and provide a novel theoretical method for TCM clinical research.
C1 [Lin, Fan; Xiahou, Jianbing; Xu, Zhuxiang] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
C3 Xiamen University
RP Lin, F (corresponding author), Xiamen Univ, Software Sch, Xiamen, Peoples R China.
EM iamafan@xmu.edu.cn; jbxiahou@xmu.edu.cn
RI Lin, Fan/D-9900-2016
FU National Natural Science Foundation of China [61402386, 61305061,
   61402389]
FX The Project was supported by the National Natural Science Foundation of
   China (No. 61402386, No. 61305061 and Grant No. 61402389). And we wish
   to thank the anonymous reviewers who helped to improve the quality of
   the paper.
CR [Anonymous], CHIN J BASIC MED TRA
   [Anonymous], 2008, Proceedings of ACL-08: HLT
   [Anonymous], 2002, CHIN ARCH TRADIT CHI
   Bhattacharya I, 2006, LATENT DIRICHLET MOD
   Blei D.M., 2006, INT C MACHINE LEARNI, DOI [DOI 10.1145/1143844.1143859, 10.1145/1143844.1143859]
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DavidM., 2008, Supervised topic models
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2004, HIERARCHICAL TOPIC M, V16
   Blei DM, 2006, CORRELATED TOPIC MOD, V18
   Boyd-Graber J., 2009, Syntactic Topic Models
   Boyd-Graber J., 2007, Proc. of EMNLP-CoNLL, P1024
   DeerWester S., 1990, J AM SOC INFORM SCI
   Doyle G., 2009, P 26 ANN INT C MACHI, P281
   Gerrish S, 2010, P ICMI HAIF ISR
   Griffiths TL, 2004, INTEGRATING TOPICS S, V17
   Gruber A, 2007, P ART INT STAT AISTA
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hu J, 2004, MOD TRADIT CHIN MED, V6, P14
   Jiang D., 2015, TELECOMMUN SYST, P1
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Li Wei, 2006, P 23 INT C MACH LEAR, DOI [10.1145/1143844.1143917, DOI 10.1145/1143844.1143917]
   Li Wen-Bo, 2008, Chinese Journal of Computers, V31, P620
   LI ZG, 2008, ACTA CHIN MED PHARM, V36, P29
   Lin T, 2006, CHIN J BASIC MED TRA, V11, P710
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lv ZH, 2015, 2015 3RD IEEE VR INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P9, DOI 10.1109/VAAT.2015.7155403
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   McCallum A., 2004, UMCS2004096, DOI 10.1.1.84.5833
   Mei Q., 2007, WWW, DOI DOI 10.1145/1242572.1242596
   Mimno D. M., 2007, ICML, V227, P633
   Nallapati R., 2008, LINK PLSA LDA NEW UN
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Sheng G, 2015, COMM COM INF SC, V557, P280, DOI 10.1007/978-3-662-48683-2_25
   Song Y, 2007, ACM-IEEE J CONF DIG, P342, DOI 10.1145/1255175.1255243
   Steyvers M., 2004, P 10 ACM SIGKDD INT
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Wang JJY, 2015, ENG APPL ARTIF INTEL, V37, P1, DOI 10.1016/j.engappai.2014.08.009
   Wang K, 2015, IEEE INT C CL COMP, P236, DOI 10.1109/CLUSTER.2015.42
   WANG X, 2005, UMCS2005071
   Wang Xuerui., P 12 ACM SIGKDD INT, P424
   Wang ZB, 2015, ULTRASON SONOCHEM, V27, P649, DOI 10.1016/j.ultsonch.2015.05.023
   Wei O., 2015 IEEE INT C SYST
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang J., 2016, MULTIMEDIA TOOLS APP
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   [姚美村 Yao Meicun], 2002, [北京中医药大学学报, Journal of Beijing University of Traditional Chinese Medicine], V25, P20
   Zhang C, 2008, STUDY STRATEGY CLASS
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
   Zhang X, 2011, STUDY TOPIC MODEL IT
NR 53
TC 20
Z9 21
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14203
EP 14232
DI 10.1007/s11042-016-3363-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500013
DA 2024-07-18
ER

PT J
AU Luo, XY
   Song, XF
   Li, XL
   Zhang, WM
   Lu, JC
   Yang, CF
   Liu, FL
AF Luo, Xiangyang
   Song, Xiaofeng
   Li, Xiaolong
   Zhang, Weiming
   Lu, Jicang
   Yang, Chunfang
   Liu, Fenlin
TI Steganalysis of HUGO steganography based on parameter recognition of
   syndrome-trellis-codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive steganography; Highly Undetectable steGO steganography;
   Steganalysis; Message extraction; Syndrome-Trellis codes (STCs); Blind
   parameters recognition
AB Highly Undetectable steGO (HUGO steganography) is a well-known image steganography method proposed in recent years. The security of HUGO steganography is analyzed in this paper, and a corresponding steganalysis method is proposed based on the blind coding parameters recognition. Firstly, the principle of covert communication based on HUGO steganography and the characteristics of the Syndrome-Trellis codes (STCs) used in HUGO are analyzed; and then the potential security risk of HUGO is pointed out; Secondly, based on the idea of the blind parameters recognition for channel coding, the submatrix parameter of STCs is recognized correctly, and thus the message embedded by HUGO can be extracted correctly by decode algorithm of STCs. A series of experimental results show that the proposed steganalysis method can not only detect the stego- images reliably, but also extract the embedded message correctly; these validated the existence of security flaw of HUGO steganography.
C1 [Luo, Xiangyang; Song, Xiaofeng; Lu, Jicang; Yang, Chunfang; Liu, Fenlin] State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.
   [Luo, Xiangyang; Song, Xiaofeng; Lu, Jicang; Liu, Fenlin] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
   [Li, Xiaolong] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Zhang, Weiming] Univ Sci & Technol China, Sch Informat Sci & Technol, Anhua 230026, Anhui, Peoples R China.
   [Yang, Chunfang] Sci & Technol Informat Assurance Lab, Beijing 100072, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Peking University; Chinese Academy of Sciences; University
   of Science & Technology of China, CAS
RP Luo, XY (corresponding author), State Key Lab Math Engn & Adv Comp, Zhengzhou 450001, Peoples R China.; Luo, XY (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Peoples R China.
EM xiangyangluo@126.com; xiaofengsong@sina.com; lixiaolong@pku.edu.cn;
   zhangwm@ustc.edu.cn; lujicang@sina.com; chunfangyang@126.com;
   liufenlin@vip.sina.com
RI Li, xiaolong/GRS-9148-2022; li, xiao/GSN-6181-2022
FU National Natural Science Foundation of China [61379151, 61272489,
   61302159, 61401512, 61373020]; Excellent Youth Foundation of Henan
   Province of China [144100510001]; Foundation of Science and Technology
   on Information Assurance Laboratory [KJ-14-108]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61379151, 61272489, 61302159, 61401512 and 61373020), the
   Excellent Youth Foundation of Henan Province of China (No.
   144100510001), and the Foundation of Science and Technology on
   Information Assurance Laboratory (No. KJ-14-108).
CR [Anonymous], 2008, NIST SPECIAL PUBLICA
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8
   Fridrich J., 2013, TRONIC IMAGING MEDIA, V8665, P1
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gul Gokhan, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P71, DOI 10.1007/978-3-642-24178-9_6
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Holub V, 2012, P 4 IEEE INT WORKSH, P69
   Holub V., 2013, P SOC PHOTO-OPT INS, V8665, P1
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Kodovsky J, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P69
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Li FY, 2014, ANN TELECOMMUN, V69, P431, DOI 10.1007/s12243-013-0415-2
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   Luo XY, 2011, IEEE J SEL AREA COMM, V29, P1404, DOI 10.1109/JSAC.2011.110807
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N, 2011, P 10 C USENIX SEC S, P323
   Shi Y Q, 2011, P 14 INT WORKSH INF, P63
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   WESTFELD A., 2001, P 4 INT WORKSH INF H, V2137, P289, DOI DOI 10.1007/3-540-45496-9_21
NR 25
TC 60
Z9 61
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13557
EP 13583
DI 10.1007/s11042-015-2759-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800031
DA 2024-07-18
ER

PT J
AU Ma, ZG
   Liu, WY
AF Ma, Zhigang
   Liu, Wenyi
TI Outlier correction method of telemetry data based on wavelet
   transformation and Wright criterion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Outlier correction; Wavelet transformation; 3 sigma criterion;
   Prediction; Telemetry data
ID TURNING-POINT DETECTION
AB An outlier revision method is proposed based on Wright criterion, quadratic difference prediction and wavelet transformation. Making use of wavelet transformation, the original telemetry data is decomposed into multi-level detail and approximation components. In detail component of every level, outliers are distinguished by Wright criterion, and which are corrected by quadratic difference prediction method. After wavelet reconstruction, the revised data will be obtained. This method not only can revise the outliers effectively, but also can reserve the key information in original data. Finally, this method has been proved efficacious and feasible for revising the outliers of telemetry data.
C1 [Ma, Zhigang; Liu, Wenyi] North Univ China, Key Lab Instrumentat Sci & Dynam Measurement, Sci & Technol Elect Test & Measurement Lab, Minist Educ, Taiyuan 030051, Peoples R China.
   [Ma, Zhigang] Shanxi Agr Univ, Coll Informat Sci & Engn, Taigu 030801, Peoples R China.
C3 North University of China; Shanxi Agricultural University
RP Liu, WY (corresponding author), North Univ China, Key Lab Instrumentat Sci & Dynam Measurement, Sci & Technol Elect Test & Measurement Lab, Minist Educ, Taiyuan 030051, Peoples R China.
EM liuwenyi@nuc.edu.cn
FU National Natural Science Foundation (NNSF) of People's Republic of China
   [5127549]
FX This work is supported by the National Natural Science Foundation (NNSF)
   of People's Republic of China (Grant No. 5127549).
CR An WJ, 2015, P I MECH ENG C-J MEC, V229, P580, DOI 10.1177/0954406214537475
   De Paola A, 2015, IEEE T CYBERNETICS, V45, P888, DOI 10.1109/TCYB.2014.2338611
   [高宁 Gao Ning], 2003, [中国惯性技术学报, Journal of Chinese inertial technology eng], V11, P25
   Grané A, 2010, COMPUT STAT DATA AN, V54, P2580, DOI 10.1016/j.csda.2009.12.010
   Gu YY, 2012, TACTICAL MISSILE TEC, V25, P60
   Hashemipour HR, 1998, AUTOMATIC CONTROL IE, V33, P88
   [贺明科 He Mingke], 2002, [宇航学报, Journal of Chinese Society of Astronautics], V23, P34
   Hu Sh. L., 1999, J ASTRONAUT SCI, V20, P68
   [胡绍林 Hu Shaohin], 2003, [中国空间科学技术, Chinese Space Science and Technology], V23, P66
   Li AL, 2011, J SPACECR TT C TECHN, V30, P89
   Li YS, 2014, COMPUTATION STAT, V29, P1481, DOI 10.1007/s00180-014-0502-5
   Li YS, 2013, ECON MODEL, V30, P317, DOI 10.1016/j.econmod.2012.08.028
   Li ZX, 2008, AERO WEAPONRY, P45
   Liu J, 2013, KNOWL-BASED SYST, V51, P60, DOI 10.1016/j.knosys.2013.07.005
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373
   Rao KD, 2004, IEEE T AERO ELEC SYS, V40, P2, DOI 10.1109/TAES.2004.1292138
   Rizzo P, 2007, J SOUND VIB, V307, P52, DOI 10.1016/j.jsv.2007.06.058
   Shen MX, 2015, INFORM SCIENCES, V294, P242, DOI 10.1016/j.ins.2014.09.037
   Wang ZM, 1997, MATH PRACTICE THEORY, V27, P266
   Xu YH, 2014, COMPUT STAT DATA AN, V75, P66, DOI 10.1016/j.csda.2014.01.003
   Zhou Ning, 2008, Journal of Test and Measurement Technology, V22, P313
   Zhu Zhuan-Min, 2004, Systems Engineering and Electronics, V26, P147
NR 23
TC 5
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14477
EP 14489
DI 10.1007/s11042-015-3241-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500027
DA 2024-07-18
ER

PT J
AU Malik, H
   Subbalakshmi, KP
   Chandramouli, R
AF Malik, Hafiz
   Subbalakshmi, K. P.
   Chandramouli, R.
TI Joint-channel modeling to attack QIM steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Quantization index modulation; Maximum
   likelihood estimation; Generalized likelihood ratio test (GLRT);
   Joint-channel modeling
ID QUANTIZATION INDEX MODULATION; IMAGE STEGANOGRAPHY; STEGANALYSIS;
   FRAMEWORK; WATERMARKING
AB This paper presents a statistical steganalysis framework to attack quantization index modulation (QIM) based steganography. The quantization process is generally modeled as an additive noise channel. The proposed method exploits the fact that plainquantization (quantization without message embedding) decreases local-randomness (or increases local-correlation) in the resulting quantized image. Moreover, QIM-stego image exhibits relatively higher level of local-randomness than the corresponding quantized-cover, though both are obtained using same set of parameters. The local-randomness (or interblock correlation) of the test-image is used to capture traces left behind by quantization. A parametric model is developed to characterize channel-dependent local-randomness. Maximum likelihood estimation (MLE) framework is used to estimate parameters of the distribution of local-randomness mask. Distributions of parameters, estimated from the quantized-cover and the QIM-stego images, are used to characterize quantization with and without message embedding. To investigate variations in the estimated parameters as a function of frequency, inter-(variations within each channel(or subband)) and intra-channel (across all channels), joint-channel modeling and single-channel modeling, respectively, is considered. For each approach, a set of parametric detectors based on generalized likelihood ratio test (GLRT) is used to distinguish between the cover-and the stego-images. To improve detection accuracy, decisions from both detectors are fused to generate the final stego-detection decision. Effectiveness of the proposed framework is evaluated using a dataset consisting of over 35000 test-images obtained from 880 uncompressed natural images. Experimental results show that the proposed scheme can successfully detect QIMstego images with very low false rates. In addition, performance comparison with existing state-of-the-art also shows that the proposed method performs significantly superior than the selected methods.
C1 [Malik, Hafiz] Univ Michigan, Elect & Comp Engn Dept, Dearborn, MI 48128 USA.
   [Subbalakshmi, K. P.; Chandramouli, R.] Stevens Inst Technol, Elect & Comp Engn Dept, Hoboken, NJ 07030 USA.
C3 University of Michigan System; University of Michigan; Stevens Institute
   of Technology
RP Malik, H (corresponding author), Univ Michigan, Elect & Comp Engn Dept, Dearborn, MI 48128 USA.
EM hafiz@umich.edu; ksubbala@stevens.edu; mouli@stevens.edu
RI Malik, Hafiz/AAE-6141-2020; Subbalakshmi, Koduvayur/JYO-3634-2024
OI Subbalakshmi, Koduvayur/0000-0002-1670-9378; Malik,
   Hafiz/0000-0001-6006-3888; Chandramouli, Rajarathnam/0000-0001-7889-740X
CR [Anonymous], ENVIRON-BEHAV PROC J
   [Anonymous], PATTREN CLASSIFICATI
   [Anonymous], P SPIE
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], SPIE ELECT IMAGING S
   [Anonymous], SPIE ELECT IMAGING S
   [Anonymous], ACM WORKSH MULT SEC
   [Anonymous], STEGANALYSIS QIM STE
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], SPIE ELECT IMAGING S
   [Anonymous], INT CONF ACOUST SPEE
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Celik MU, 2004, PROC SPIE, V5306, P467, DOI 10.1117/12.531359
   Chandramouli R, 2004, I C CONT AUTOMAT ROB, P964
   Chandramouli R, 2003, MULTIMEDIA SYST, V9, P303, DOI 10.1007/s00530-003-0101-8
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   COSTA MHM, 1983, IEEE T INFORM THEORY, V29, P439, DOI 10.1109/TIT.1983.1056659
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Eggers J., 2002, Informed Watermarking
   Fillatre L, 2012, IEEE T SIGNAL PROCES, V60, P556, DOI 10.1109/TSP.2011.2174231
   Fridrich J, 2005, PROC SPIE, V5681, P595, DOI 10.1117/12.584426
   Fridrich J, 2003, PROC SPIE, V5020, P191, DOI 10.1117/12.479739
   Fridrich J., 2002, Information Hiding. 5th International Workshop, IH 2002. Revised Papers (Lecture Notes in Computer Science Vol.2578), P310
   Fridrich J., 2013, TRONIC IMAGING MEDIA, V8665, P1
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu DD, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P310, DOI 10.1109/MMSP.2006.285320
   Guillon P, 2002, P SOC PHOTO-OPT INS, V4675, P38, DOI 10.1117/12.465294
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Huang CH, 2008, IEEE T MULTIMEDIA, V10, P557, DOI 10.1109/TMM.2008.921733
   Kelley C.T., 2003, Solving nonlinear equations with Newton's method, DOI DOI 10.1137/1.9780898718898
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Lee K, 2004, LECT NOTES COMPUT SC, V2939, P316
   Li SB, 2012, J ZHEJIANG U-SCI C, V13, P624, DOI 10.1631/jzus.C1100374
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Liu QZ, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899420
   Lubenko I, 2012, SPIE ELECT IMAGING M, V8303, P1
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Malik H, 2012, IEEE T INF FOREN SEC, V7, P418, DOI 10.1109/TIFS.2011.2169058
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Poor H. Vincent, 1994, An introduction to signal detection and estimation
   Qinxia Wu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P929, DOI 10.1109/IIH-MSP.2009.316
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Sullivan K, 2004, IEEE IMAGE PROC, P1165
   Sullivan K, 2003, IEEE IMAGE PROC, P497
   Trivedi S, 2005, IEEE T SIGNAL PROCES, V53, P746, DOI 10.1109/TSP.2004.839925
   Vasic B, 2013, IEEE T MULTIMEDIA, V15, P1532, DOI 10.1109/TMM.2013.2265673
   Widrow B, 1996, IEEE T INSTRUM MEAS, V45, P353, DOI 10.1109/19.492748
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xuan GR, 2005, LECT NOTES COMPUT SC, V3727, P262
   Yu XY, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P45, DOI 10.1109/MINES.2009.272
NR 58
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13585
EP 13611
DI 10.1007/s11042-015-3006-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800032
DA 2024-07-18
ER

PT J
AU Muthuramalingam, S
   Karthikeyan, N
   Geetha, S
   Sindhu, SSS
AF Muthuramalingam, S.
   Karthikeyan, N.
   Geetha, S.
   Sindhu, Siva S. Sivatha
TI Stego anomaly detection in images exploiting the curvelet higher order
   statistics using evolutionary support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image steganalysis; Curvelet transformation; Evolutionary SVM
   model; Higher order statistics
ID DIGITAL IMAGES; STEGANALYSIS; WATERMARKING
AB Steganalysis is an important extension to existing security infrastructure, and is gaining more research focus of forensic investigators and information security researchers. This paper reports the design principles and evaluation results of a new experimental blind image steganalysing system. This work approaches the steganalysis task as a pattern classification problem. The detection accuracy of the steganalyser depends on the selection of low-dimensional informative features. We investigate this problem as a three step process and propose a novel steganalyser with the following implications: a) Selection of the Curvelet sub-band image representation that offers better discrimination ability for detecting stego anomalies in images, than other conventional wavelet transforms. b) Exploiting the empirical moments of the transformation as effective steganalytic features c) Realizing the system using an efficient classifier, evolutionary-Support Vector Machine (SVM) model that provides promising classification rate. An extensive empirical evaluation on a database containing 5600 clean and stego images shows that the proposed scheme is a state-of-the-art steganalyser that outperforms other previous steganalytic methods.
C1 [Muthuramalingam, S.] Thiagarajar Coll Engn, Dept Informat Technol, Madurai, Tamil Nadu, India.
   [Karthikeyan, N.] Syed Ammal Engn Coll, Dept Comp Sci & Engn, Ramanathapuram, Tamil Nadu, India.
   [Geetha, S.] VIT Univ, Sch Comp Sci & Engn, Chennai Campus, Madras, Tamil Nadu, India.
   [Sindhu, Siva S. Sivatha] Shan Syst LLC, Jersey City, NJ USA.
C3 Thiagarajar College of Engineering; Syed Ammal Engineering College;
   Vellore Institute of Technology (VIT); VIT Chennai
RP Geetha, S (corresponding author), VIT Univ, Sch Comp Sci & Engn, Chennai Campus, Madras, Tamil Nadu, India.
EM smrit@tce.edu; nkarthikkeyan@gmail.com; geethabaalan@gmail.com;
   sivathasindhu@gmail.com
RI Nagarajan, Karthikeyan/ABI-6163-2020; , Dr.S.Geetha/ABI-7036-2020;
   Nagarajan, Karthikeyan/H-3894-2019; Kamaraj, N./AAS-2531-2020; Sankayya,
   Muthuramalingam/L-1177-2019
OI Nagarajan, Karthikeyan/0000-0002-6199-5131; Kamaraj,
   N./0000-0002-0424-5529; Sankayya, Muthuramalingam/0000-0002-3122-1004;
   S, Geetha/0000-0002-6850-9423
FU All India Council for Technical Education Research Promotion
   [20/AICTE/RIFD/RPS(POLICY-II)65/2012-13]
FX This paper is based upon work supported by the All India Council for
   Technical Education Research Promotion Scheme under Grant No.
   20/AICTE/RIFD/RPS(POLICY-II)65/2012-13.
CR [Anonymous], JSTEG SHELL 2 0
   [Anonymous], J EURASIP APPL SIGNA
   [Anonymous], THESIS
   [Anonymous], 9 INT WORKSH INF HID
   [Anonymous], P ACIS INT C SOFTW E
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], THESIS
   [Anonymous], LECT COMPUTER SCI
   [Anonymous], P IEEE INT C WAV AN
   [Anonymous], P WORLD C INT CONTR
   [Anonymous], PICTUREMARC EMB WAT
   [Anonymous], P ACM INT C INF SEC
   [Anonymous], ENH PART SWARM ALG I
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 6 IEEE IND C COMP VI
   [Anonymous], P IEEE T INF FORENSI
   [Anonymous], S TOOLS VERSION 4 0
   [Anonymous], 1999, P IEEE INT C IM PROC
   [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], 2000, Digital Watermarking
   Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Baker J.E., P INT C GEN ALG THEI, P101
   Bánoci V, 2014, RADIOENGINEERING, V23, P1213
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Candes E.J., 1999, CURVE SURFACE FITTIN
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Cho SG, 2013, J VIS COMMUN IMAGE R, V24, P846, DOI 10.1016/j.jvcir.2013.05.007
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Farid H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P905
   Fridrich J, 2003, PROC SPIE, V5020, P143, DOI 10.1117/12.473142
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Holotyak T, 2005, LECT NOTES COMPUT SC, V3677, P273
   Huang JW, 1998, ELECTRON LETT, V34, P748, DOI 10.1049/el:19980545
   Kim YS, 1999, ELECTRON LETT, V35, P466, DOI 10.1049/el:19990327
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Li FY, 2013, IEEE SIGNAL PROC LET, V20, P233, DOI 10.1109/LSP.2013.2240385
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Lie WN, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P228, DOI 10.1109/ISCAS.2000.857069
   Liu SH, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P509
   Manikopoulos C, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P355
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Ogihara T., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P675, DOI 10.1109/ICPR.1996.546908
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pérez-González F, 2003, IEEE T SIGNAL PROCES, V51, P960, DOI 10.1109/TSP.2003.809368
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Ru XM, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P3937
   Sajedi H, 2010, J SIGNAL PROCESS SYS, V61, P367, DOI 10.1007/s11265-010-0460-2
   Savoldi A, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P93
   Shi YQ, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P768, DOI 10.1109/ITCC.2005.138
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
NR 58
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13627
EP 13661
DI 10.1007/s11042-015-2984-8
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800034
DA 2024-07-18
ER

PT J
AU Nah, J
   Kim, J
AF Nah, Jihah
   Kim, Jongweon
TI Collusion attack-resistant watermarking scheme using correlation peak
   position modulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correlation peak position modulation; Image watermarking; Spread
   spectrum; Collusion attack
AB In this paper, we propose a new digital watermarking algorithm that hides specific information related to content-users. The proposed algorithm uses a correlation peak position modulation (CPPM) to ensure robustness and sufficient capacity, and this is modulated by user information. For a JPEG compression operation with a quality factor of 35, the other methods show a bit error rate of 2.45 % when two messages are embedded, but using CPPM this is reduced to 0 %, even with four messages. In case of a collusion attack, CPPM can detect up to 12 attackers, compared with a maximum of five attackers with position-based watermarking. Our experiments demonstrate that the proposed algorithm is a competitive method for image watermarking.
C1 [Nah, Jihah; Kim, Jongweon] Sangmyung Univ, Digital Copyright Protect Res Inst, Seoul 110743, South Korea.
   [Kim, Jongweon] Sangmyung Univ, Dept Intellectual Property, Seoul 110743, South Korea.
C3 Sangmyung University; Sangmyung University
RP Kim, J (corresponding author), Sangmyung Univ, Digital Copyright Protect Res Inst, Seoul 110743, South Korea.
EM jihah.nah@gmail.com; jwkim@smu.ac.kr
RI Kim, Jongweon/AAO-2221-2020
OI Kim, Jongweon/0000-0002-8916-6431
FU Ministry of Culture, Sports and Tourism (MCST); Korea Copyright
   Commission
FX This research project was supported by the Ministry of Culture, Sports
   and Tourism (MCST) and Korea Copyright Commission in 2011.
CR Aikebaier A, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-6
   BORGES PV, 2004, IEEE P 17 BRAZ S COM
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Gonzalez J. L., 2012, J CONVERGENCE, V2, P79
   Grobois R., 2001, P IEEE WORKSH MULT S, P3
   Kim J, 2010, SIGNAL PROCESS-IMAGE, V25, P559, DOI 10.1016/j.image.2010.07.004
   Lee Y, 2011, COMM COM INF SC, V263, P139
   Li D, 2012, APPL MATH INFORM SCI, V6, p513S
   Luo HL, 2011, HUM-CENT COMPUT INFO, V1, DOI 10.1186/2192-1962-1-5
   Maity S. P., 2006, P 12 NAT C COMM NCC, P114
   Maity SP, 2011, INFORM SCIENCES, V181, P450, DOI 10.1016/j.ins.2010.09.029
   MAITY SP, 2005, P NAT C COMM JAN, P569
   Nah J, 2012, LECT NOTES ELEC ENG, V203, P159
   Nah J, 2011, J KOREA CONTENTS ASS
   Nah J, 2013, APPL MATH INFORM SCI, V7, P2391, DOI 10.12785/amis/070632
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Wei Q, 2012, J CONVERGENCE, V2, P11
NR 17
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14917
EP 14926
DI 10.1007/s11042-014-2233-6
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500053
DA 2024-07-18
ER

PT J
AU Zhu, GY
   Huang, CC
   Hu, B
   Li, GY
AF Zhu, Guiyan
   Huang, Chuanchao
   Hu, Bin
   Li, Guangyu
TI Autonomy in individual behavior under multimedia information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive resilience; Individual choice behavior; Behavioral tendencies;
   Catastrophe theory
ID COGNITIVE FUNCTION; DECISION-MAKING; STRESS; PERSONALITY; RESILIENCE
AB The myriad changes that have accompanied modernization - the "big data" era, rapid technological advancement, societal transformations on both large and small scales - pose severe challenges to individual, autonomous decision-making behavior, which is vital to the formation of a network public opinion environment. According to the Yerkes-Dodson law between cognition and pressure and prospect theory, we built a model to investigate the impact of cognitive resilience on the individual, autonomous behavior choices. We utilized the model to investigate changes in individual choice behavior from the perspective of catastrophe theory, and propose several network control strategies accordingly. Results indicated that individuals who demonstrate high levels of sensitivity to information and knowledge show relatively strong cognitive resilience. We also found that the catastrophe model explains the mechanism of change in individual choice behavior better than traditional models. Finally, we found that under the same situational factors, individuals with strong cognitive resilience maintain a high level of autonomy in when posed with challenges related to social cognition, and that controlling the level of social cognition in networks is an efficient way to manage individual behavior on the whole.
C1 [Zhu, Guiyan; Huang, Chuanchao; Hu, Bin; Li, Guangyu] Huazhong Univ Sci & Technol, Sch Management, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Hu, B (corresponding author), Huazhong Univ Sci & Technol, Sch Management, Wuhan 430074, Peoples R China.
EM 2365305723@qq.com; bin_hu@hust.edu.cn
FU Chinese National Natural Sciences Foundation [71531009, 71271093,
   71401090]
FX This work was supported by the Chinese National Natural Sciences
   Foundation (Grant Nos. 71531009, 71271093 and 71401090).
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   [Anonymous], RECENT RES DEV PSYCH
   Cen H, 2006, LECT NOTES COMPUT SC, V4053, P164
   DICKMAN SJ, 1990, J PERS SOC PSYCHOL, V58, P95, DOI 10.1037/0022-3514.58.1.95
   FLAY BR, 1978, BEHAV SCI, V23, P335, DOI 10.1002/bs.3830230404
   Henry D, 2012, RELIAB ENG SYST SAFE, V99, P114, DOI 10.1016/j.ress.2011.09.002
   Holaday M, 1997, J COUNS DEV, V75, P346, DOI 10.1002/j.1556-6676.1997.tb02350.x
   Kumpfer K. L., 2002, RESILIENCE DEV LONGI, P179, DOI [DOI 10.1007/0-306-47167-1_9, DOI 10.1007/0-306-47167-19]
   Lieberman HR, 2002, PSYCHOPHARMACOLOGY, V164, P250, DOI 10.1007/s00213-002-1217-9
   Liu SD, 2006, INTER-ASIA CULT STUD, V7, P144, DOI 10.1080/14649370500463802
   Masten A.S., 1990, Development Psychopathology, V2, P425, DOI [10.1017/S0954579400005812, DOI 10.1017/S0954579400005812]
   MCEWEN BS, 1995, CURR OPIN NEUROBIOL, V5, P205, DOI 10.1016/0959-4388(95)80028-X
   Mendl M, 1999, APPL ANIM BEHAV SCI, V65, P221, DOI 10.1016/S0168-1591(99)00088-X
   Paulus MP, 2012, TRENDS COGN SCI, V16, P476, DOI 10.1016/j.tics.2012.07.009
   Richardson G.E., 1990, Health Education, V21, P33, DOI DOI 10.1080/00970050.1990.10614589
   Roberts BW, 2007, PERSPECT PSYCHOL SCI, V2, P313, DOI 10.1111/j.1745-6916.2007.00047.x
   Starcke K, 2012, NEUROSCI BIOBEHAV R, V36, P1228, DOI 10.1016/j.neubiorev.2012.02.003
   TAYLOR SE, 1983, AM PSYCHOL, V38, P1161, DOI 10.1037/0003-066X.38.11.1161
   Thom R, 1975, STRUCTURAL STABILITY, P23
   TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574
   Wang MH, 2012, COMPUT MATH ORGAN TH, V18, P463, DOI 10.1007/s10588-012-9107-0
   Wemer E.E., 2001, JOURNEYS CHILDHOOD M
   Yang J, 2015, MULTIMED TOOLS APPL, P1, DOI DOI 10.3109/19401736.2015.1018206
   Zhao X, 2015, INT J MODEL SIMUL SC, V6, DOI 10.1142/S1793962315500361
NR 24
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14433
EP 14449
DI 10.1007/s11042-016-3570-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500025
DA 2024-07-18
ER

PT J
AU Ji, XY
   Wang, QF
   Chen, BW
   Rho, S
   Kuo, CCJ
   Dai, QH
AF Ji, Xiangyang
   Wang, Qifei
   Chen, Bo-Wei
   Rho, Seungmin
   Kuo, C. C. Jay
   Dai, Qionghai
TI Online distribution and interaction of video data in social multimedia
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High dimensional; Video streaming; Social media network; Interaction
ID MULTIVIEW VIDEO
AB As the emerging multimedia on the latest social multimedia network, high dimensional video (HDV) data distribution is one of the most challenging problems in social multimedia applications. In the paper, we provide a state-of-the-art analysis on the streaming and interactive technologies for the two most popular representations of HDV, video plus depth map and multi-view video since both of them can enable the view-point interaction and behavior analysis in social media applications. Additionally, view-point switching techniques in HDV streaming with emphasis on interactive functionality are discussed, including SP-frame, Wyner-ziv frame and view switchable stream generation. Moreover, the overall performance of key tools focusing on HDV streaming is evaluated and potential improvements are discussed.
C1 [Ji, Xiangyang] Tsinghua Univ, Room 711A,Main Bldg, Beijing 100084, Peoples R China.
   [Wang, Qifei] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   [Chen, Bo-Wei] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
   [Kuo, C. C. Jay] Univ Southern Calif, Media Commun Lab, Los Angeles, CA USA.
   [Kuo, C. C. Jay] Univ Southern Calif, Elect Engn Comp Sci & Math, Los Angeles, CA USA.
   [Dai, Qionghai] Tsinghua Univ, Dept Automat, Room 410,Cent Main Bldg, Beijing, Peoples R China.
C3 Tsinghua University; University of California System; University of
   California Berkeley; Princeton University; Sungkyul University;
   University of Southern California; University of Southern California;
   Tsinghua University
RP Ji, XY (corresponding author), Tsinghua Univ, Room 711A,Main Bldg, Beijing 100084, Peoples R China.
EM xyji@tsinghua.edu.cn; qifei.wang@gmail.com; dennisbwc@gmail.com;
   smrho@sungkyul.ac.kr; chenbw2004@hotmail.com
RI Rho, Seungmin/HTP-6683-2023; Chen, Bowei/AAB-7002-2021; Kuo, C.-C.
   Jay/A-7110-2011
OI Chen, Bowei/0000-0002-4045-3253; Kuo, C.-C. Jay/0000-0001-9474-5035
FU National Science Foundation for Distinguished Young Scholars of China
   [61325003]
FX The project was supported by the National Science Foundation for
   Distinguished Young Scholars of China (Grant No. 61325003).
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Akar GB, 2007, IEEE T CIRC SYST VID, V17, P1622, DOI 10.1109/TCSVT.2007.905365
   [Anonymous], 2008, Image-Based Rendering
   Bjontegaard G., 2008, VCEGAI11
   CHEN YB, 2009, EURASIP, V2009, P1, DOI DOI 10.1155/2009/786015
   Cheung G, 2011, IEEE T IMAGE PROCESS, V20, P744, DOI 10.1109/TIP.2010.2070074
   Cheung N, 2007, P PICT COD S PCS 07
   Guo X, 2005, IEEE INT SYMP CIRC S, P3471
   Guo X, 2006, P VIS COMM IM PROC V, P298
   Gürler CG, 2013, IEEE COMMUN MAG, V51, P108, DOI 10.1109/MCOM.2013.6515054
   Hewage CTER, 2013, IEEE COMMUN MAG, V51, P101, DOI 10.1109/MCOM.2013.6515053
   Kurutepe E, 2007, IEEE T CIRC SYST VID, V17, P1558, DOI 10.1109/TCSVT.2007.903664
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Merkle P, 2007, IEEE T CIRCUITS SYST, V17, P1641
   Shimizu S, 2007, IEEE T CIRC SYST VID, V17, P1485, DOI 10.1109/TCSVT.2007.903773
   Wang QF, 2012, IEEE T CIRC SYST VID, V22, P875, DOI 10.1109/TCSVT.2011.2181229
NR 17
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12941
EP 12954
DI 10.1007/s11042-014-2335-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700037
DA 2024-07-18
ER

PT J
AU Wang, CY
   Wang, L
   Xue, PX
AF Wang Changyuan
   Wang Li
   Xue Pengxiang
TI The line of sight to estimate method based on stereo vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Estimate the line of sight; Stereo vision; System calibration; Eye
   placement
ID GAZE TRACKING; LIGHT-SOURCES; EYE; CAMERA; 3D
AB In order to get high-performance gaze direction, this paper proposes a three-dimensional view estimation method based on double cameras and double light source, to overcome the natural head movement under relatively large, estimated accuracy of sight. This paper presents a completely rely on spatial geometry calculations to achieve the user's line of sight placement calculation method. First calibrate the camera, and then use of calibrated cameras to the three-dimensional position of display screen and a light source for calibration; Due to the corneal curvature center and the pupil center on the same optical axis, so to determine the spatial orientation of the optical axis through the center of curvature of the cornea is calculated and imaginary pupil center; Second to determine the optical axis, the article does not directly estimation deviation angle of optical axis and optical axis Kappa, but by calibrate rotation matrix of a 3 * 3 M indirectly obtained the relationship between the optical axis and visual axis, to determine the visual axis direction; Finally through calculation to get the intersection of the visual axis and screen, That fixation point.
C1 [Wang Changyuan; Wang Li; Xue Pengxiang] Xian Technol Univ, Comp Sci & Engn, Xian, Peoples R China.
C3 Xi'an Technological University
RP Wang, L (corresponding author), Xian Technol Univ, Comp Sci & Engn, Xian, Peoples R China.
EM wangli4545@qq.com
CR Aytekin M, 2014, J NEUROSCI
   Beymer D., 2003, P IEEE COMP SOC C CO, V2
   Caligari M, 2013, AMYOTROPH LATERAL SC, V14
   Carlos H, 2005, J COMPUTER VISION IM, V98, P4
   Duchowski A., 2003, Eye Tracking Methodology: Theory and Practice
   Ebisawa Y, 2013, IEEE T BIO-MED ENG, V60, P2952, DOI 10.1109/TBME.2013.2266478
   Gielen CCAM, 2009, CORTEX, V45, P340, DOI 10.1016/j.cortex.2008.02.009
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Guitton D, 1998, EYE HEAD COORDINATIO, P196
   Kenneth HolmqvistMarcus Nystrom., 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   Komogortsev O, 2014, APPL EXPERT SYST MED
   Liu RF, 2009, IEEE WRK SIG PRO SYS, P1, DOI 10.1109/SIPS.2009.5336281
   Lu F, 2014, IMAGE VISION COMPUT, V32, P169, DOI 10.1016/j.imavis.2014.01.005
   Mautz R, 2015, ANN MS COMPUT SCI IN, V9, P7
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Morimoto CH, 2002, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2002.1047459
   Popelka S, 2013, CARTOGR J, V50, P240, DOI 10.1179/1743277413Y.0000000058
   Robert J, 1991, ACM T INF SYST, V9
   Saito Y, 2009, SENSOR ACTUAT A-PHYS, V150, P175, DOI 10.1016/j.sna.2008.12.019
   Shih S, 2004, IEEE T SYST MAN CYBE
   Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128
   Ye Z, 2012, P 2012 ACM C UB COMP
   Zhang G, 2014, BIOM REC 9 CHIN C CC
   Zhu ZW, 2004, MACH VISION APPL, V15, P139, DOI 10.1007/s00138-004-0139-4
NR 25
TC 3
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12123
EP 12136
DI 10.1007/s11042-016-3283-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200030
DA 2024-07-18
ER

PT J
AU Wang, T
   Zhang, S
   Dong, JY
   Liu, LA
   Yu, H
AF Wang, Ting
   Zhang, Shu
   Dong, Junyu
   Liu, Li'an
   Yu, Hui
TI Automatic evaluation of the degree of facial nerve paralysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial nerve paralysis; Facial asymmetry quantification; Facial
   movement; Facial grading system
ID QUANTITATIVE-ANALYSIS; MOTION; MOVEMENT
AB Facial paralysis affects both mental and physical health of patients. Evaluation of facial paralysis in clinical practice is normally based on the static facial asymmetry at the maximal movement state and the dynamic change of facial muscle movement. However, most existing research only considers one of these two aspects when evaluating the degree of facial paralysis. This will result in an incomplete utilization of the diagnosis information leading to a low evaluation accuracy, or even misjudgment. In this paper, a novel method is presented for evaluating the degree of facial paralysis considering both static facial asymmetry and dynamic transformation factors. A quantitative approach of static facial asymmetry based on local mirror asymmetry is proposed. The method compares the differences of the corresponding local regions between both sides of the face. This makes it effective analyzing the left and right side asymmetry for abnormal faces. A quantitative evaluation of static facial asymmetry is achieved through three steps: localization of local facial regions, extraction of asymmetry features and quantification of bilateral facial asymmetry. Once the static facial asymmetry is quantified, its dynamic counterparts can be calculated using the speed of changings in different regions caused by facial muscle movement. Then we combine the static and dynamic quantification results to evaluate the degree of facial nerve paralysis. The efficiency and effectiveness of the proposed method have been tested using our facial paralysis database with 62 patients. The experiments show that our method produced encouraging performance compared with ground truth.
C1 [Wang, Ting; Zhang, Shu] Ocean Univ China, Comp Applicat Technol, Qingdao, Peoples R China.
   [Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Wang, Ting; Zhang, Shu] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
   [Yu, Hui] Univ Portsmouth, Portsmouth, Hants, England.
   [Liu, Li'an] Qingdao Hiser Med Ctr, Qingdao, Peoples R China.
C3 Ocean University of China; Ocean University of China; University of
   Portsmouth; University of Portsmouth
RP Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM qdwangting@ouc.edu.cn; dongjunyu@ouc.edu.cn; qdliulian@126.com;
   hui.yu@port.ac.uk
RI Yu, Hui/G-1115-2018; Zhang, Shu/ABC-4379-2020
OI Yu, Hui/0000-0002-7655-9228; Zhang, Shu/0000-0002-5873-634X; Dong,
   Junyu/0000-0001-7012-2087
FU National Natural Science Foundation of China [61271405]; Ph.D. Program
   Foundation of Ministry of Education of China [20120132110018]; China
   Postdoctoral Science Foundation [2014 M551962]; Fundamental Research
   Funds for the Central Universities [201413020]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61271405), Ph.D. Program Foundation of Ministry of Education
   of China (20120132110018), China Postdoctoral Science Foundation (No.
   2014 M551962) and Fundamental Research Funds for the Central
   Universities (No. 201413020).
CR Anguraj K., 2012, Eur. J. Sci. Res, V77, P543
   Anguraj K, 2012, INT J COMPUT APPL, V54, P1
   [Anonymous], J IMAGE VIDEO PROCES
   BajajLuthra A, 1997, PLAST RECONSTR SURG, V99, P1894, DOI 10.1097/00006534-199706000-00014
   BURRES SA, 1986, ANN OTO RHINOL LARYN, V95, P238, DOI 10.1177/000348948609500306
   BURRES SA, 1985, LARYNGOSCOPE, V95, P708
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Delannoy Jane Reilly, 2010, IET Irish Signals and Systems Conference (ISSC 2010), P228, DOI 10.1049/cp.2010.0517
   Dong J., 2008, J INFORM COMPUTATION, V5, P639
   Dong JY, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION WORKSHOP: IITA 2008 WORKSHOPS, PROCEEDINGS, P483, DOI 10.1109/IITA.Workshops.2008.93
   Dulguerov P, 1999, AM J OTOL, V20, P672
   Gebhard A, 2000, PRINCIPLES 3D IMAGE, P1
   Gunaratne P, 2003, LECT NOTES COMPUT SC, V2879, P1
   He S, 2009, IEEE T BIO-MED ENG, V56, P1864, DOI 10.1109/TBME.2009.2017508
   Hontanilla B, 2008, J PLAST RECONSTR AES, V61, P18, DOI 10.1016/j.bjps.2007.03.037
   HOUSE JW, 1985, OTOLARYNG HEAD NECK, V93, P146, DOI 10.1177/019459988509300202
   Isono M, 1996, OTOLARYNG HEAD NECK, V114, P27, DOI 10.1016/S0194-5998(96)70279-6
   Isono M, 1994, Nihon Jibiinkoka Gakkai Kaiho, V97, P393
   JOHNSON PC, 1994, ANN PLAS SURG, V32, P171, DOI 10.1097/00000637-199402000-00013
   Johnson PJ, 1997, PLAST RECONSTR SURG, V100, P1710, DOI 10.1097/00006534-199712000-00010
   Liu LA, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P514, DOI 10.1109/WKDD.2010.145
   McGrenary S, 2005, COMP MED SY, P587, DOI 10.1109/CBMS.2005.78
   Meier-Gallati V, 1998, OTOLARYNG HEAD NECK, V118, P545, DOI 10.1016/S0194-5998(98)70216-5
   MURTY GE, 1994, OTOLARYNG HEAD NECK, V110, P156, DOI 10.1177/019459989411000203
   NEELY JG, 1992, AM J OTOL, V13, P97
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PECKITT NS, 1992, J ORAL MAXIL SURG, V50, P338, DOI 10.1016/0278-2391(92)90392-D
   Rogers CR, 2007, ANN PLAS SURG, V58, P39, DOI 10.1097/01.sap.0000250761.26824.4f
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Wachtman GS, 2001, PLAST RECONSTR SURG, V107, P1124, DOI 10.1097/00006534-200104150-00005
   Wang S, 2004, MED BIOL ENG COMPUT, V42, P598, DOI 10.1007/BF02347540
   Wang T, 2014, PERCEPTION, V43, P19
   Wang T, 2014, BIO-MED MATER ENG, V24, P2751, DOI 10.3233/BME-141093
NR 33
TC 37
Z9 38
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11893
EP 11908
DI 10.1007/s11042-015-2696-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Yang, DW
   Qi, R
   Gong, ZG
AF Zhang, Yujie
   Yang, Diwei
   Qi, Rui
   Gong, Zhiguo
TI Blind image separation based on reorganization of block DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse component analysis; Blind image separation; Blocked discrete
   cosine transform; Reorganization
ID SPARSE COMPONENT ANALYSIS; ALGORITHM; REPRESENTATION
AB Blind image separation consists in processing a set of observed mixed images to separate them into a set of original components. Most of the current blind separation methods assume that the sources are as statistically independent or sparsity as possible given the observations. However, these hypotheses do not hold in real world situation. Considering that the images do not satisfy the independent and sparsity conditions, so the mixed images cannot be separated with independent component analysis and sparse component analysis directly. In this paper, a method based on reorganization of blocked discrete cosine transform (RBDCT) is first proposed to separate the mixed images. Firstly, we get the sparse blocks through RBDCT, and then select the sparsest block adaptively by linear strength in which the mixing matrix can be estimated by clustering methods. In addition, a theoretical result about the linearity of the RBDCT is proved. The effectiveness of the proposed approach is demonstrated by several numerical experiments and compared the results with other classical blind image methods.
C1 [Zhang, Yujie; Yang, Diwei] China Univ Geosci, Sch Math & Phys, Wuhan, Peoples R China.
   [Zhang, Yujie] Univ Windsor, Sch Comp Sci, Windsor, ON, Canada.
   [Qi, Rui] Naval Univ Engn, Sch Sci, Wuhan, Peoples R China.
   [Gong, Zhiguo] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 China University of Geosciences; University of Windsor; Wuhan Naval
   University of Engineering; University of Macau
RP Zhang, YJ (corresponding author), China Univ Geosci, Sch Math & Phys, Wuhan, Peoples R China.; Zhang, YJ (corresponding author), Univ Windsor, Sch Comp Sci, Windsor, ON, Canada.
EM jiansuoba@qq.com
RI zhang, yujie/JAA-9367-2023
FU Natural Science Foundation of China [61203287]; Natural Science
   Foundation of Hubei Province [2014CFB414]; Special Fund for Basic
   Scientific Research of Central Colleges, China University of Geosciences
   Wuhan [CUGL130247]; Youth Foundation of Naval University of Engineering
   [HGDQNJJ13005]
FX This work was supported by Natural Science Foundation of China (Grant
   No. 61203287), Natural Science Foundation of Hubei Province (No.
   2014CFB414), the Special Fund for Basic Scientific Research of Central
   Colleges, China University of Geosciences Wuhan (Grant No. CUGL130247)
   and the Youth Foundation of Naval University of Engineering (Grant No.
   HGDQNJJ13005).
CR Albera L, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P737, DOI 10.1016/B978-0-12-374726-6.00023-0
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Caiafa CF, 2009, NEURAL COMPUT, V21, P3487, DOI 10.1162/neco.2009.08-08-846
   Cichocki A., ICALAB TOOLBOXES
   Costagli M, 2007, DIGIT SIGNAL PROCESS, V17, P935, DOI 10.1016/j.dsp.2007.04.003
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776
   Georgiev P, 2005, IEEE T NEURAL NETWOR, V16, P992, DOI 10.1109/TNN.2005.849840
   Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827
   Hamed M, 2015, MULTIMED TOOLS APPL, V74, P5825
   Hao JC, 2010, NEURAL COMPUT, V22, P1646, DOI 10.1162/neco.2010.11-08-906
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jin XL, 2015, MULTIMED TOOLS APPL, V74, P2743, DOI 10.1007/s11042-015-2458-z
   Karray E, 2010, ADV SAT MULTMED SYS, P381, DOI 10.1109/ASMS-SPSC.2010.5586889
   Karri S, 2015, MULTIMED TOOLS APPL, V74, P9207, DOI 10.1007/s11042-014-2077-0
   Kim S, 2009, IEEE T SIGNAL PROCES, V57, P2604, DOI 10.1109/TSP.2009.2017570
   [李荣华 Li Rong-hua], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P319
   Li XL, 2010, IEEE T SIGNAL PROCES, V58, P5151, DOI 10.1109/TSP.2010.2055859
   Luo XF, 2011, IEEE T AUTOM SCI ENG, V8, P482, DOI 10.1109/TASE.2010.2094608
   Modaghegh H, 2015, MULTIMED TOOLS APPL, V74, P5825, DOI 10.1007/s11042-014-1890-9
   Özgen MT, 2009, DIGIT SIGNAL PROCESS, V19, P360, DOI 10.1016/j.dsp.2007.12.003
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Reju VG, 2009, SIGNAL PROCESS, V89, P1762, DOI 10.1016/j.sigpro.2009.03.017
   Tonazzini A, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-58
   Vía J, 2011, IEEE T SIGNAL PROCES, V59, P1586, DOI 10.1109/TSP.2010.2101065
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie SL, 2012, IEEE T NEUR NET LEAR, V23, P306, DOI 10.1109/TNNLS.2011.2177475
   Xiong ZX, 1996, IEEE SIGNAL PROC LET, V3, P289, DOI 10.1109/97.542157
   Xu Z, 2016, IEEE T CLOUD COMPUT, DOI [10.1109/TCC.2016.2517638, DOI 10.1109/TCC.2016.2517638]
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Yang ZY, 2013, IEEE T NEUR NET LEAR, V24, P47, DOI 10.1109/TNNLS.2012.2224124
   Yang ZY, 2012, IEEE T NEUR NET LEAR, V23, P1601, DOI 10.1109/TNNLS.2012.2208476
   Yu XC, 2013, SIGNAL PROCESS, V93, P288, DOI 10.1016/j.sigpro.2012.08.010
   Zarzoso V, 2010, IEEE T NEURAL NETWOR, V21, P248, DOI 10.1109/TNN.2009.2035920
   Zeng YN, 2014, ICIC EXPRESS LETT, V8, P1975
   Zhang YJ, 2012, J INF COMPUT SCI, V9, P2451
   Zhao DB, 2002, IEEE T CIRC SYST VID, V12, P819, DOI 10.1109/TCSVT.2002.803218
   Zibulevsky M, 2010, IEEE SIGNAL PROC MAG, V27, P76, DOI 10.1109/MSP.2010.936023
   何昭水, 2006, [中国科学. E辑, 技术科学, Science in China. E], V36, P864
NR 39
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12101
EP 12121
DI 10.1007/s11042-016-3397-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200029
DA 2024-07-18
ER

PT J
AU Choe, GM
   Yuan, C
   Wang, TJ
   Feng, Q
   Hyon, G
   Choe, C
   Ri, J
   Ji, G
AF Choe, Gwangmin
   Yuan, Caihong
   Wang, Tianjiang
   Feng, Qi
   Hyon, Gyongil
   Choe, Chunhwa
   Ri, Jonghwan
   Ji, Gumhyok
TI Combined salience based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrians; Disjoint camera views; Person re-identification; Mean
   salience; Global bi-directional matching
AB Human eye perceives an object as the entity with global information and local information. Human salience is distinctive local information in matching pedestrians across disjoint camera views, and matching on overall foreground guarantees reliable and robust identification. In this paper, we propose a strategy for the matching of mean salience to identify pedestrians. Also, we consider that person re-identification based on the local single directional matching suffers from the variations of pose, illumination and overlapping, and propose a global bi-directional matching to solve the challenging problems of person re-identification. Furthermore, our matching of mean salience is tightly combined with the global bi-directional matching. Patch matching is utilized to handle the misalignment problem in pedestrian images. We test our feature and matching approaches in person re-identification scenario. Experimental results demonstrate that the mean salience and the global bi-directional matching have promising discriminative capability in comparison with other ones.
C1 [Choe, Gwangmin; Yuan, Caihong; Wang, Tianjiang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Hyon, Gyongil; Choe, Chunhwa; Ri, Jonghwan; Ji, Gumhyok] Kim Il Sung Univ, Sch Comp Sci & Technol, Pyongyang, North Korea.
   [Yuan, Caihong] Henan Univ, Sch Comp & Informat Engn, Kaifeng, Henan, Peoples R China.
C3 Huazhong University of Science & Technology; Henan University
RP Choe, GM; Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
EM cca2005@foxmail.com; twang@hust.edu.cn
FU Technology Breakthroughs in Wuhan City [2014010202010110]
FX This research is founded by the grant of The Technology Breakthroughs in
   Wuhan City No. 2014010202010110.
CR [Anonymous], 2012, AS C COMP VIS ACCV
   [Anonymous], 2007, ICCV
   [Anonymous], 2011, CVPR
   [Anonymous], 2010, BMVC
   [Anonymous], 2013, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2008, ECCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2012, CVPR
   [Anonymous], 2007, IEEE INT WORKSH PERF
   [Anonymous], 2010, CVPR
   [Anonymous], 2009, MACHINE LEARNING
   [Anonymous], 2013, CVPR
   [Anonymous], 2011, BMVC
   [Anonymous], ACM SIGIR
   [Anonymous], 2005, ICML
   [Anonymous], ACCV
   Barnes Connelly., 2010, ECCV
   Barnes Connelly., 2009, Patchmatch: A randomized correspondence algorithm for structural image editing
   Carterette B, 2006, ACM SIGIR
   Goferman S, 2012, PAMI
   Liu C., 2012, ECCV
   Lu Y, 2013, ICCV
   Ma Bingpeng., 2012, BiCov: A novel image representation for person re-identification and face verification
   Ma K., 2012, CVPR
   McFee B., 2010, METRIC LEARNING RANK
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Zheng W.-S., 2013, PAMI
NR 28
TC 1
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11447
EP 11468
DI 10.1007/s11042-015-2862-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900029
DA 2024-07-18
ER

PT J
AU Shrivastava, N
   Tyagi, V
AF Shrivastava, Nishant
   Tyagi, Vipin
TI Noise-invariant structure pattern for image texture classification and
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture Classification; Local Binary Pattern (LBP); Rotation Invariance;
   Noise Invariant Structure Pattern
AB A local region in an image can be defined using centre pixel and its differences with neighboring pixels. In order to characterize different texture structure in a discriminating manner, this paper proposes twoframeworks of Noise Invariant Structure Pattern (NISP) which utilizes both the centre pixel and local and global information of an image. To replace the centre pixel, a threshold computed from adding centre pixel and intensity averages is used in the LBP code computation. For adding the magnitude information, binary patterns generated by taking thresholds involving centre pixel and local and global average contrast are adopted. Also for adding the information of individual neighborhood of a given pixel, the binary patterns generated from global thresholding of local averages are used. Based on the use of local and global information, this paper suggests two noise invariant models that are CNLP and CNGP (i.e. Completed Noise-invariant Local-structure Pattern and Global-structure Pattern). The proposed NISPs are also insensitive to noise as the centre pixel is not directly used as threshold. The proposed texture descriptors are tested on some of the representative texture databases like Outex, Curet, UIUC, Brodatz and XU - HR. The experimental results have shown that the proposed schemes can achieve higher classification and retrieval rates while being more robust to noise.
C1 [Shrivastava, Nishant; Tyagi, Vipin] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Raghogarh 473226, Guna, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Raghogarh 473226, Guna, India.
EM dr.vipin.tyagi@gmail.com
RI Shrivastava, Nishant/A-2784-2019; Tyagi, Vipin/I-2451-2013
OI Shrivastava, Nishant/0000-0001-9626-2301; Tyagi,
   Vipin/0000-0003-4994-3686
CR [Anonymous], 2007, Computer Vision
   Chang FC, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P210
   Chen J.L., 1992, IC 92 1992 INT C AC, V1-5, pC69
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   EICHMANN G, 1988, COMPUT VISION GRAPH, V41, P267, DOI 10.1016/0734-189X(88)90102-8
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Khellah F, 2011, IEEE T IMAGE PROCESS, V19, P12
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu X-F, 2014, J INF HIDING MULTIME, V5, P431
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Porter R, 1997, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.1997.595462
   Shrivastava N, 2016, MULTIMED TOOLS APPL, V75, P6569, DOI 10.1007/s11042-015-2589-2
   Shrivastava N, 2014, VISUAL COMPUT, V30, P1223, DOI 10.1007/s00371-013-0887-0
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2003, PROC CVPR IEEE, P691
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xu Y., 2005, P INT C COMP VIS PAT, P1932
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Zhang D.L., 2014, J INF HIDING MULTIME, V5, P72
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
NR 27
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10887
EP 10906
DI 10.1007/s11042-015-2811-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900004
DA 2024-07-18
ER

PT J
AU Chiang, KH
   Fan, CY
   Liu, HH
   Chen, GD
AF Chiang, Kuang-Hung
   Fan, Cheng-Yu
   Liu, Hsiao-Hung
   Chen, Gwo-Dong
TI Effects of a computer-assisted argument map learning strategy on
   sixth-grade students' argumentative essay reading comprehension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Argument mapping; Graphic organization; Reading comprehension;
   Argumentative essay
ID EXPOSITORY TEXT; KNOWLEDGE; MODEL; TOOL
AB Numerous studies have proved that graphic strategies, such as graphic organization and concept mapping, can facilitate improving reading comprehension. However, the question as to what graphic strategies can improve argumentative essay reading comprehension ability is not yet resolved. To determine whether graphic strategies can improve students' reading comprehension ability, we designed a computer-aided argumentative essay reading system that can construct graphic strategies. In the designed system, three approaches, namely a traditional teaching approach without graphic strategies, concept mapping, and argument mapping, are created for determining the effects of graphic strategies on students' argumentative essay reading comprehension ability. In addition, the proposed argument mapping system provides a function for helping students identify three key argumentative essay elements, namely claims, reasons, and evidence, to enable them to construct an argument map with no burden. The designed system can help students learn how to read argumentative essays easily, improving their reading comprehension ability. The experimental results from 373 sixth graders showed that the argument mapping method enhanced students' argumentative essay reading comprehension ability compared with traditional and concept mapping approaches. Statistical results revealed that between-group differences were statistically significant (p value between the experimental and Control Group 1 was 0.001 and that between the experimental and Control Group 2 was 0.013).
C1 [Chiang, Kuang-Hung; Fan, Cheng-Yu; Chen, Gwo-Dong] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 320, Taiwan.
   [Liu, Hsiao-Hung] Bihua Elementary Sch, New Taipei 160, Taiwan.
C3 National Central University
RP Chen, GD (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 320, Taiwan.
EM chen@csie.ncu.edu.tw
OI Fan, Cheng-Yu/0000-0002-7813-5859
FU Ministry of Science and Technology of Taiwan [MOST103-2511-S-008-002]
FX This project was supported by the Ministry of Science and Technology of
   Taiwan under contract numbers MOST103-2511-S-008-002.
CR Aidman E., 1998, International Journal of Instructional Media, V25, P277
   Akhondi M, 2011, READ TEACH, V64, P368, DOI 10.1598/RT.64.5.9
   Almasi J.F., 2012, Teaching strategic processes in reading, V2nd
   [Anonymous], 2013, 12 YEARS A SLAVE
   [Anonymous], 1999, NARRATIVE COMPREHENS
   Blunt JR, 2014, J EDUC PSYCHOL, V106, P849, DOI 10.1037/a0035934
   Braund M, 2013, INT J EDUC DEV, V33, P175, DOI 10.1016/j.ijedudev.2012.03.007
   Britt MA, 2003, J MEM LANG, V48, P794, DOI 10.1016/S0749-596X(03)00002-0
   Butchart S, 2009, AUSTRALAS J ED TECHN, V25
   Buzan T., 2000, THE CONCEPT MAP BOOK
   Chambliss MJ, 2002, DISCOURSE PROCESS, V34, P91, DOI 10.1207/S15326950DP3401_4
   CHAMBLISS MJ, 1995, READ RES QUART, V30, P778, DOI 10.2307/748198
   Davies M, 2011, HIGH EDUC, V62, P279, DOI 10.1007/s10734-010-9387-6
   DeLauder H, 2012, SOC INF TECHN TEACH, V2012
   Dwyer CR, 2010, THINK SKILLS CREAT, V5, P16, DOI 10.1016/j.tsc.2009.05.001
   Dyer PA, 1985, DISS ABSTR INT, V46, P26
   Felton MK, 2004, J ADOLESC ADULT LIT, V47, P672
   Gifford M, 2014, THESIS
   Griffin C.C., 1991, J READING WRITING LE, V7, P355, DOI DOI 10.1080/0748763910070407
   Grogan MS, 2014, READING ARGUMENTATIO
   GURIROZENBLIT S, 1989, READ RES QUART, V24, P236, DOI 10.2307/747866
   Hogan M., 2014, KNOWLEDGE CARTOGRAPH, P401, DOI [10.1007/978-1-4471-6470-8_18, DOI 10.1007/978-1-4471-6470-8_18]
   Hsu CK, 2013, COMPUT EDUC, V63, P327, DOI 10.1016/j.compedu.2012.12.004
   Hwang GJ, 2014, COMPUT EDUC, V71, P77, DOI 10.1016/j.compedu.2013.09.013
   Kalhor M, 2012, LIFE SCI J, V9, P725
   Karpicke JD, 2011, SCIENCE, V331, P772, DOI 10.1126/science.1199327
   Khajavi Y, 2012, INFLUENCING EFL LEAR
   Kiili C, 2013, J COMPUT ASSIST LEAR, V29, P248, DOI 10.1111/j.1365-2729.2012.00492.x
   KINTSCH W, 1978, PSYCHOL REV, V85, P363, DOI 10.1037/0033-295X.85.5.363
   Kunsch DW, 2014, J EDUC BUS, V89, P403, DOI 10.1080/08832323.2014.925416
   Larson M., 2004, Reading Psychology, V25, P205, DOI [10.1080/02702710490489908, DOI 10.1080/02702710490489908]
   Li LY, 2015, J COMPUT EDUC, V2, P211, DOI 10.1007/s40692-015-0032-3
   Lin SS, 2010, INT J SCI MATH EDUC, V8, P993, DOI 10.1007/s10763-010-9215-6
   Liu CC, 2011, COMPUT EDUC, V56, P873, DOI 10.1016/j.compedu.2010.10.029
   Liu PL, 2010, COMPUT EDUC, V54, P436, DOI 10.1016/j.compedu.2009.08.027
   Lorch RF, 1996, J EDUC PSYCHOL, V88, P38, DOI 10.1037/0022-0663.88.1.38
   Mayer RE, 1996, EDUC PSYCHOL REV, V8, P357, DOI 10.1007/BF01463939
   Merkley DM, 2000, READ TEACH, V54, P350
   Munneke L., 2003, International Journal of Educational Research, V39, P113, DOI DOI 10.1016/S0883-0355(03)00076-4
   Newell GE, 2011, READ RES QUART, V46, P273, DOI 10.1598/RRQ.46.3.4
   Nussbaum EM, 2007, J EXP EDUC, V76, P59, DOI 10.3200/JEXE.76.1.59-92
   Okada A, 2008, INT J RES METHOD EDU, V31, P291, DOI 10.1080/17437270802417184
   Okada Alexandra., 2014, KNOWLEDGE CARTOGRAPH
   Redford JS, 2012, LEARN INSTR, V22, P262, DOI 10.1016/j.learninstruc.2011.10.007
   Reed C, 2007, KNOWL ENG REV, V22, P87, DOI 10.1017/S0269888907001051
   Ruddell R.B., 1989, READ RES INSTRUCT, V29, P12
   Shum SB, 2003, COMP SUPP COMP W SER, P3
   Soleimani H., 2012, ENGLISH LANGUAGE TEA, V5, P78, DOI DOI 10.5539/ELT.V5N9P78
   Toulmin S.E., 2003, The use of argument, V2nd, DOI DOI 10.1017/CBO9780511840005
   van Amelsvoort M, 2008, COMPUT HUM BEHAV, V24, P1293, DOI 10.1016/j.chb.2007.05.004
   van Drie J, 2005, COMPUT HUM BEHAV, V21, P575, DOI 10.1016/j.chb.2004.10.024
   Van Gelder T., 2002, The American Philosophical Association Newsletter on Philosophy and Computers, V85, P85
   van Gelder T., 2007, LAW PROBAB RISK, V6, P23, DOI DOI 10.1093/LPR/MGM032
   Zumbach J, 2009, COMPUT HUM BEHAV, V25, P811, DOI 10.1016/j.chb.2008.07.005
NR 54
TC 11
Z9 12
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9973
EP 9990
DI 10.1007/s11042-015-2904-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500025
DA 2024-07-18
ER

PT J
AU Attar, A
   Shahbahrami, A
   Rad, RM
AF Attar, Abdolrahman
   Shahbahrami, Asadollah
   Rad, Reza Moradi
TI Image quality assessment using edge based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Edge based features; Full reference
ID STRUCTURAL SIMILARITY; STATISTICS
AB There are many applications for Image Quality Assessment (IQA) in digital image processing. Many techniques have been proposed to measure the quality of an image such as Peak Signal to Noise Ratio (PSNR), Structural Similarity (SSIM), and Mean Structural Similarity Index Measurement (MSSIM). In this paper, a new technique, namely, Edge Based Image Quality Assessments (EBIQA) is proposed. The proposed technique is based on different edge features which are extracted from original (distortion free) and distorted images. The new approach was implemented and tested using different images which have been taken from A57 and WIQ image databases. The experimental results show that the functionality of the EBIQA technique is better than the state of art IQA techniques. The proposed technique is consistent with the mean opinion score which makes it suitable for automatic image quality assessment.
C1 [Attar, Abdolrahman] Lincoln Univ, Sch Comp Sci, Computat Intelligence Lab, Lincoln LN6 7TS, England.
   [Shahbahrami, Asadollah] Univ Guilan, Dept Comp Engn, Fac Engn, POB 3756-41635, Rasht, Iran.
   [Rad, Reza Moradi] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur 50603, Malaysia.
C3 University of Lincoln; University of Guilan; Universiti Malaya
RP Shahbahrami, A (corresponding author), Univ Guilan, Dept Comp Engn, Fac Engn, POB 3756-41635, Rasht, Iran.
EM rattar@lincoln.ac.uk; shahbahrami@guilan.ac.ir; rezace@siswa.um.edu.my
RI Shahbahrami, Asadollah/ABD-2432-2020
OI Shahbahrami, Asadollah/0000-0002-5195-1688
CR [Anonymous], P INT C IM SIGN PROC
   [Anonymous], 2010, Wireless Imaging Quality Database
   [Anonymous], FIN REP VID QUAL EXP
   Attar A, 2011, 7 IR MACH VIS IM PRO
   Blasch E., 2008, 11 INT C DIG OBJ ID, P1, DOI DOI 10.1109/ICIF.2008.4632263
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chandler DM, 2006, PROC SPIE, V6057, DOI 10.1117/12.655442
   Furht B, 2003, HDB VIDEO DATABASES, P1041
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   Ivkovic G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P713
   Kim DO, 2010, IEEE T CONSUM ELECTR, V56, P2756, DOI 10.1109/TCE.2010.5681166
   Kim DO, 2010, IEEE T CONSUM ELECTR, V56, P930, DOI 10.1109/TCE.2010.5506022
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Li X, 2002, IEEE IMAGE PROC, P449
   Li-xiong Liu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P311, DOI 10.1109/FSKD.2009.610
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Marr D., 1982, Visual perception
   Navas K, 2008, IEEE INT C COMP VIS, P1
   Park HJ, 2011, IEEE T CONSUM ELECTR, V57, P1176, DOI 10.1109/TCE.2011.6018872
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14
   Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang ZY, 2015, MULTIMED TOOLS APPL, V74, P10277, DOI 10.1007/s11042-014-2166-0
   Wu JJ, 2014, IEEE SIGNAL PROC LET, V21, P437, DOI 10.1109/LSP.2014.2304714
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yaohua Yi, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P253, DOI 10.1109/CSSE.2008.529
   Zamani Ahmad Nazri, 2008, 2008 Second Asia International Conference on Modeling & Simulation, P505, DOI 10.1109/AMS.2008.168
   Zhai GT, 2005, IEEE WRK SIG PRO SYS, P331
   Zhang J, 2010, IEEE T CONSUM ELECTR, V56, P743, DOI 10.1109/TCE.2010.5505996
   Zhang L, 2014, IEEE MULTIMEDIA, V21, P67, DOI 10.1109/MMUL.2014.50
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhang M, 2015, IEEE SIGNAL PROC LET, V22, P207, DOI 10.1109/LSP.2014.2326399
NR 43
TC 17
Z9 17
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 7407
EP 7422
DI 10.1007/s11042-015-2663-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400033
DA 2024-07-18
ER

PT J
AU Cohen, F
   Zhang, ZC
   Liu, ZX
AF Cohen, Fernand
   Zhang, Zhongchuan
   Liu, Zexi
TI Mending broken vessels a fusion between color markings and anchor points
   on surface breaks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D weighted moments; Absolute invariant; Intrinsic geometric features;
   3D reconstruction; Ceramic fragments; Convex hull
ID RECONSTRUCTION; IMAGES; TOOL
AB This paper presents a method to assist in the tedious process of reconstructing ceramic vessels from excavated fragments. The method exploits vessel surface marking information coupled with a series of generic models constructed by the archaeologists to produce a virtual reconstruction of what the original vessel may have looked like. Generic models are generated based on the experts' historical knowledge of the period, provenance of the artifact, and site location. The generic models need not to be identical to the original vessel, but must be within a geometric transformation of it in most parts. By aligning the fragments against the generic models, the ceramic vessels are virtually reconstructed. The alignment is based on a novel set of weighted discrete moments computed from convex hulls of the markings on the surface of the fragments and the generic vessels. When the fragments have no markings on them, they are virtually mended to abutting fragments using intrinsic differential anchor points computed on the surface breaks and aligned using a set of absolute invariants. For axially symmetric objects, a global constraint induced by the surface of revolution is added to guarantee global mending consistency.
C1 [Cohen, Fernand; Zhang, Zhongchuan; Liu, Zexi] Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Zhang, ZC (corresponding author), Drexel Univ, Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM fscohen@coe.drexel.edu; zz57@drexel.edu; zl54@drexel.edu
FU National Science Foundation IIS division [0803670]; Direct For Computer
   & Info Scie & Enginr; Div Of Information & Intelligent Systems [0803670]
   Funding Source: National Science Foundation
FX This work is supported by the National Science Foundation IIS division
   under grant number 0803670. We would also like to acknowledge the
   efforts in scanning which was conducted by Drexel University STAR
   Scholar Program undergraduate students Girish Balakrishnan, David Myers
   and Mark Petrovitch, under the direction of Dr. Glen Muschio and by
   Drexel University Electrical and Computer Engineering Department
   graduate student Ezgi Taslidere. We would like also to acknowledge the
   expertise provided our archaeologist collaborator Dr. Patrice Jeppson in
   providing the generic models.
CR Amigoni F, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P581
   [Anonymous], 2003, IEEE CVPR WORKSH, DOI DOI 10.1109/CVPRW.2003.10008
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Bratko I., 1990, PROLOG PROGRAMMING A, V2
   Brown BJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360683
   Brown BJ, 2007, ACM SIGGRAPH SAN DIE
   Bujakiewicz A, 2006, P ISPRS COMM 5 S IM
   Cohen F, 2013, INT C IM AN PROC WOR
   Cohen F, 2010, CVPR SAN FRANC CA US
   FABER TL, 1988, IEEE T PATTERN ANAL, V10, P626, DOI 10.1109/34.6771
   Huang QX, 2006, ACM T GRAPHIC, V25, P569, DOI 10.1145/1141911.1141925
   Igwe P.C., 2006, IEEE Proceedings on Geometric Modeling and Imaging, P9, DOI [10.1109/GMAI.2006.1, DOI 10.1109/GMAI.2006.1]
   K?hnel W., 2006, DIFFERENTIAL GEOMETR
   Kampel M, 2006, LECT NOTES COMPUT SC, V4270, P387
   Karasik A, 2008, J ARCHAEOL SCI, V35, P1148, DOI 10.1016/j.jas.2007.08.008
   Kleber Florian, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1061, DOI 10.1109/ICDAR.2009.154
   Knopf GK, 2002, J ELECTRON IMAGING, V11, P187, DOI 10.1117/1.1453411
   Koutsoudis A, 2009, J CULT HERIT, V10, P281, DOI 10.1016/j.culher.2008.07.012
   Kozinska D, 1997, GRAPH MODEL IM PROC, V59, P373, DOI 10.1006/gmip.1997.0447
   Liu Z, 2013, INT C COMP VIS THEOR
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Lu Y., 2007, Proc. 9th Conf. Australian Pattern Recognition Society Digital Image Computing Techniques and Applications, P23
   MARA H, 2007, P 2 ISPRS INT WORKSH
   Olsen S., 2004, SIGCHI WORKSH AMB IN
   Oxholm G, 2011, P IEEE WORKSH APPL C, P174
   Papaioannou G, 2003, IMAGE VISION COMPUT, V21, P401, DOI 10.1016/S0262-8856(03)00008-8
   Rodriguez W, 2004, ROBOT AUTON SYST, V49, P165, DOI 10.1016/j.robot.2004.09.004
   Sagiroglu MS, 2006, INT C PATT REC HONG
   Sagiroglu MS, 2005, S VIRT REAL ARCH CUL
   Saharan R., 2011, International Journal of computer applications, V19, P41
   Son Kilho, 2013, IEEE C COMP VIS PATT
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Thomas TP, 2011, COMPUT METHOD BIOMEC, V14, P263, DOI 10.1080/10255841003762042
   Trummer M, 2009, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2009.5459321
   Tsamoura E, 2010, IEEE T IMAGE PROCESS, V19, P680, DOI 10.1109/TIP.2009.2035840
   Üçoluk G, 1999, COMPUT GRAPH-UK, V23, P573, DOI 10.1016/S0097-8493(99)00075-8
   Umbach D, 2003, IEEE T INSTRUM MEAS, V52, P1881, DOI 10.1109/TIM.2003.820472
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Van Gool L, 2006, MACH VISION APPL, V17, P347, DOI 10.1007/s00138-006-0042-2
   Willis A., 2003, IEEE WORKSH APPL COM
   Winkelbach S, 2008, INT J COMPUT VISION, V78, P1, DOI 10.1007/s11263-007-0121-5
   Yang Z, 1999, IEEE T PATTERN ANAL, V21
   Yang Z., 1999, IEEE Transactions on Image Processing, V8
   Zhu LJ, 2008, IEEE T PATTERN ANAL, V30, P1, DOI 10.1109/TPAMI.2007.1163
NR 44
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3709
EP 3732
DI 10.1007/s11042-014-2190-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200008
DA 2024-07-18
ER

PT J
AU Jaime, J
   Barbancho, I
   Urdiales, C
   Tardón, LJ
   Barbancho, AM
AF Jaime, Jose
   Barbancho, Isabel
   Urdiales, Cristina
   Tardon, Lorenzo J.
   Barbancho, Ana M.
TI A new multiformat rhythm game for music tutoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Guitar game; OMR; Rhythmic pattern
ID AUTOMATIC TRANSCRIPTION; CHORDS; MELODY; MODEL
AB In this paper, a new rhythm based game for tutored music learning is presented. The main differences with similar existing systems are: i) songs can be automatically extracted from any music file or printed score; ii) it works with multiple interfaces, ranging from any MIDI controller to most popular game controllers; iii) note sequences are obtained from the melody itself rather than from time features alone. The whole system has been successfully tested for different songs using different combinations of music instances and game controllers.
C1 [Jaime, Jose; Barbancho, Isabel; Urdiales, Cristina; Tardon, Lorenzo J.; Barbancho, Ana M.] Univ Malaga, ETSI Telecomunicac, Andalucia Tech, Campus Teatinos S-N, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Barbancho, AM (corresponding author), Univ Malaga, ETSI Telecomunicac, Andalucia Tech, Campus Teatinos S-N, E-29071 Malaga, Spain.
EM jariza@uma.es; ibp@ic.uma.es; acurdiales@uma.es; lorenzo@ic.uma.es;
   abp@ic.uma.es
RI Urdiales, Cristina/H-4664-2019; Tardon, Lorenzo J./M-4492-2014;
   Barbancho, Isabel/L-7244-2014
OI Urdiales, Cristina/0000-0002-9251-6447; Tardon, Lorenzo
   J./0000-0002-5441-225X; Barbancho, Isabel/0000-0001-7002-9106
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TIN2013-47276-C6-2-R, TEC2011-29106]; Junta de Andalucia [P11-TIC-7154,
   TIC-7839]
FX This work has been funded by the Ministerio de Economia y Competitividad
   of the Spanish Government under Project No. TIN2013-47276-C6-2-R and
   Project No. TEC2011-29106, by the Junta de Andalucia under Project No.
   P11-TIC-7154 and Project No. TIC-7839. The authors are grateful to the
   person in charge of the Archivo de la Catedral de Malaga, who allowed
   the utilization of the data sets used in this work. Universidad de
   Malaga. Campus de Excelencia Internacional Andalucia Tech.
CR [Anonymous], 1990, COGNITIVE FDN MUSICA
   Barbancho AM, 2012, IEEE T AUDIO SPEECH, V20, P915, DOI 10.1109/TASL.2011.2174227
   Barbancho AM, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/179367
   Barbancho AM, 2009, IEEE INT CON MULTI, P1186, DOI 10.1109/ICME.2009.5202712
   Barbancho I, 2013, SOUND PERCEPTION PER, P367
   Cataltepe Z, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36409
   Dixon S, 2001, J NEW MUSIC RES, V30, P39, DOI 10.1076/jnmr.30.1.39.7119
   Dixon S, 2006, P INT C DIG AUD EFF
   Droettboom M., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P378
   Kostka S, 2008, TOTAL HARMONY
   Molina E, 2015, IEEE T AUDIO SPEECH, V99, P325
   Pampalk E., 2006, COMPUTATIONAL MODELS
   Pinto JC, 2000, LECT NOTES COMPUT SC, V1923, P24
   Roig C, 2014, KNOWL-BASED SYST, V71, P419, DOI 10.1016/j.knosys.2014.08.018
   Rosa-Pujazon A, 2013, SMAC 2013 STOCKH MUS, P284
   Rosa-Pujazon A, 2015, INT J CREAT INTERFAC, P1
   Ryynänen MP, 2008, COMPUT MUSIC J, V32, P72, DOI 10.1162/comj.2008.32.3.72
   Schulze W, 2011, IEEE MULTIMEDIA, V18, P78, DOI 10.1109/MMUL.2010.44
   Shan MK, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P97, DOI 10.1109/ICME.2002.1035727
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Tardón LJ, 2014, KNOWL-BASED SYST, V67, P169, DOI 10.1016/j.knosys.2014.05.015
   Tardón LJ, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/843401
   Uhle C, 2003, P DIG AUD EFF WORKSH
   Yeh TC, 2014, 15 INT SOC MUS INF R
NR 24
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4349
EP 4362
DI 10.1007/s11042-015-2478-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700009
DA 2024-07-18
ER

PT J
AU Yang, HC
   Bai, X
   Liu, YZ
   Wang, YY
   Bai, L
   Zhou, J
   Tang, WZ
AF Yang, Haichuan
   Bai, Xiao
   Liu, Yanzhen
   Wang, Yanyang
   Bai, Lu
   Zhou, Jun
   Tang, Wenzhong
TI Maximum margin hashing with supervised information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Hashing; Supervised learning
ID QUANTIZATION; REPRESENTATION; SHAPE
AB Binary code is a kind of special representation of data. With the binary format, hashing framework can be built and a large amount of data can be indexed to achieve fast research and retrieval. Many supervised hashing approaches learn hash functions from data with supervised information to retrieve semantically similar samples. This kind of supervised information can be generated from external data other than pixels. Conventional supervised hashing methods assume a fixed relationship between the Hamming distance and the similar (dissimilar) labels. This assumption leads to too rigid requirement in learning and makes the similar and dissimilar pairs not distinguishable. In this paper, we adopt a large margin principle and define a Hamming margin to formulate such relationship. At the same time, inspired by support vector machine which achieves strong generalization capability by maximizing the margin of its decision surface, we propose a binary hash function in the same manner. A loss function is constructed corresponding to these two kinds of margins and is minimized by a block coordinate descent method. The experiments show that our method can achieve better performance than the state-of-the-art hashing methods.
C1 [Yang, Haichuan; Bai, Xiao; Liu, Yanzhen; Tang, Wenzhong] Beihang Univ, Sch Comp Sci & Engn, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
   [Wang, Yanyang] Beihang Univ, Sch Aeronaut Sci & Engn, 37 Xueyuan Rd, Beijing, Peoples R China.
   [Bai, Lu] Cent Univ Finance & Econ, Sch Informat, Beijing 100081, Peoples R China.
   [Zhou, Jun] Griffith Univ, Sch Informat & Commun Technol, Nathan, Qld 4111, Australia.
C3 Beihang University; Beihang University; Central University of Finance &
   Economics; Griffith University
RP Bai, X (corresponding author), Beihang Univ, Sch Comp Sci & Engn, 37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM baixiao@buaa.edu.cn; wangyanyang@buaa.edu.cn
RI li, yao/IYJ-1364-2023; Zhou, Jun/W-2233-2019
OI Zhou, Jun/0000-0001-5822-8233
FU NSFC [61370123, 61503422]; Australian Research Council [522 DE120102948]
FX This work was supported by NSFC projects (No. 61370123 and 61503422),
   and the Australian Research Councils DECRA Projects funding scheme
   (project ID 522 DE120102948).
CR [Anonymous], 2014, PR MACH LEARN RES
   [Anonymous], 2008, Proceedings of the 21st International Conference on Neural Information Processing Systems
   [Anonymous], 2012, NIPS
   [Anonymous], 2009, NIPS
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P5033, DOI 10.1109/TIP.2014.2352458
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Charikar M., 2002, P THIRY 4 ANN ACM S, P380
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang YG, 2013, IEEE T MULTIMEDIA, V15, P442, DOI 10.1109/TMM.2012.2231061
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Leng C, 2015, PROC CVPR IEEE, P2503, DOI 10.1109/CVPR.2015.7298865
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2014, PATTERN RECOGN, V47, P748, DOI 10.1016/j.patcog.2013.08.022
   Liu XF, 2015, ADV METEOROL, V2015, DOI 10.1155/2015/950262
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mu YD, 2010, PROC CVPR IEEE, P3344, DOI 10.1109/CVPR.2010.5540024
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Olsson Carl, 2007, Computer Vision and Pattern Recognition, P1
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang Jun., 2010, ICML, P1127
   Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yan L, 2015, WORLD WIDE WEB, P1
   Yan LY, 2015, INT J COMPUT INT SYS, V8, P725, DOI 10.1080/18756891.2015.1046332
   Yang H, 2013, P INT C IM PROC
   Yang HC, 2014, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2014.251
   Yang YL, 2014, PROCEEDINGS OF THE ASME 4TH INTERNATIONAL CONFERENCE ON MICRO/NANOSCALE HEAT AND MASS TRANSFER - 2013
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang HG, 2013, IEEE T IMAGE PROCESS, V22, P4984, DOI 10.1109/TIP.2013.2281406
NR 45
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3955
EP 3971
DI 10.1007/s11042-015-3159-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200019
DA 2024-07-18
ER

PT J
AU Yang, PF
   Wang, Q
   Zhang, JY
AF Yang, Pengfei
   Wang, Quan
   Zhang, Jiyang
TI Parallel design and implementation of Error Diffusion Algorithm and IP
   core for FPGA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel; Error diffusion; FPGA; IP core
AB This paper offers an improved error diffusion algorithm for its real-time implementation in FPGA by creating Error-Error Diffusion Value Lookup Tables to spare multiplications, adopting four pipelines instead of traditional sequential process, and performing color error diffusion in four parallel channels among other techniques whereby it takes only one clock circle on average to get the halftone result of a pixel. In accordance with the Avalon bus specification, the improved algorithm is packaged into an IP core which is later adopted to construct a practical halftoning hardware system using the SOPC technique. Tests of the system in the "USB Direct Printing System" of the research office show that the IP core is efficient to meet the requirements of the printing domain.
C1 [Yang, Pengfei; Wang, Quan; Zhang, Jiyang] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
C3 Xidian University
RP Yang, PF (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM pfyang@stu.xidian.edu.cn; qwang@xidian.edu.cn; zjy8813@21cn.com
CR [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], ELECT IMAGING INT SO
   [Anonymous], INFORM COMMUNICATION
   [Anonymous], P 2005 ACM S DOC ENG
   [Anonymous], SPIE OPTO INT SOC OP
   [Anonymous], ELECT TECHNOL
   [Anonymous], NIOS 2 HARDW DEV TUT
   [Anonymous], COMPUT ENG DESIGN
   [Anonymous], AV INT SPEC
   [Anonymous], EFFICIENT HALFTONING
   [Anonymous], J TIANJIN POLYTECHNI
   [Anonymous], IS T SPIE ELECT IMAG
   Huang K, 2011, DESIGN AUTOMATION TE, P1
   Kim CG, 2014, MULTIMED TOOLS APPL, V68, P237, DOI 10.1007/s11042-011-0906-y
   Liu LY, 2013, J ZHEJIANG U-SCI C, V14, P918, DOI 10.1631/jzus.C1300142
   Siddiqui H, 2010, IEEE T IMAGE PROCESS, V19, P746, DOI 10.1109/TIP.2009.2035238
   Venugopal R. K., 2011, Proceedings 2011 IEEE 9th Symposium on Application Specific Processors (SASP 2011), P66, DOI 10.1109/SASP.2011.5941080
   Wu HS, 2013, MULTIMED TOOLS APPL, V67, P529, DOI 10.1007/s11042-012-1048-6
NR 18
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4723
EP 4733
DI 10.1007/s11042-015-2499-3
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700026
DA 2024-07-18
ER

PT J
AU Zhao, YN
   Zhao, X
   Luo, RT
   Liu, YC
AF Zhao, Yanna
   Zhao, Xu
   Luo, Ruotian
   Liu, Yuncai
TI Person Re-identification by encoding free energy feature maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Appearance modeling; Gaussian mixture model;
   Free energy score space
AB Recognizing objects from disjoint camera views, known as person re-identification, is an important and challenging problem in the field of computer vision. Recent progress in person re-identification is due to new visual features and models that deal with cross-view differences. Existing appearance models focus on visual features in the normal sense, e.g., color histogram, Scale-invariant Feature Transform (SIFT) and Histogram of Oriented Gradients (HOG). In this paper, we propose a new appearance based method using the generative information of local image features and their encoding. In this paradigm, local image features which capture the color and structural cues of the human images are first extracted. A Gaussian Mixture Model (GMM) is then learned to approximate the generation process of these features. It provides a relatively comprehensive statistical representation. Finally, discriminative feature maps are obtained by calculating Free Energy Score Space (FESS) for GMM. The obtained feature maps are concatenated and encoded into a fixed-length feature vector for person re-identification. Our approach demonstrates promising performance on challenging datasets. It is also very practical: it has low computational cost both at training and testing. A GMM trained on images with different imaging conditions can be applied to other images without any significant loss in performance.
C1 [Zhao, Yanna] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Zhao, Yanna; Zhao, Xu; Luo, Ruotian; Liu, Yuncai] Shanghai Jiao Tong Univ, Sch Automat, Shanghai 200030, Peoples R China.
C3 Shandong University; Shanghai Jiao Tong University
RP Zhao, YN; Zhao, X (corresponding author), Shanghai Jiao Tong Univ, Sch Automat, Shanghai 200030, Peoples R China.
EM yannazhao@outlook.com; zhaoxu@sjtu.edu.cn; skylikelrt@sjtu.edu.cn;
   whomliu@sjtu.edu.cn
RI Luo, Ruotian/AAD-4909-2019
FU NSFC [61375019, 61273285];  [2011CB302203]
FX This research has been partially supported by the funding from China
   2011CB302203, NSFC 61375019 and NSFC 61273285.
CR [Anonymous], P ACM INT C MULT
   [Anonymous], P INT C IM PROC ICIP
   [Anonymous], 2009, BMVC
   [Anonymous], P IEEE WORKSH APPL C
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], P BR MACH VIS C BMVC
   [Anonymous], 2010, Asian Conference on Computer Vision
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Ess A, 2007, PROC IEEE INT C COMP, P1
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Holub AD, 2008, INT J COMPUT VISION, V77, P239, DOI 10.1007/s11263-007-0084-6
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Perina A, 2012, IEEE T PATTERN ANAL, V34, P1249, DOI 10.1109/TPAMI.2011.241
   Perronnin F., 2007, P IEEE CVPR, P1
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wu Y, 2012, LECT NOTES COMPUT SC, V7574, P497, DOI 10.1007/978-3-642-33712-3_36
   Xiong Li, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P49, DOI 10.1007/978-3-642-40994-3_4
   Xiong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2713, DOI 10.1109/CVPR.2011.5995584
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 37
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4795
EP 4813
DI 10.1007/s11042-015-2503-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700030
DA 2024-07-18
ER

PT J
AU Wang, S
   Yan, XH
   Sang, JZ
   Niu, XM
AF Wang, Shen
   Yan, Xuehu
   Sang, Jianzhi
   Niu, Xiamu
TI Meaningful visual secret sharing based on error diffusion and random
   grids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Meaningful visual secret sharing; Error
   diffusion; Random grids
ID IMAGE ENCRYPTION; CRYPTOGRAPHY
AB Random grid (RG) is an efficient method of eliminating the drawback of pixel expansion problem in visual secret sharing (VSS). Error diffusion (ED) technique is a brilliant method that improves the diffusion performance in an image by reducing the pattern noise and removing boundary and 'blackhole' effects. In this paper, a novel meaningful RG-ED-based VSS, which encodes the (k, n) threshold into meaningful shadow images, is proposed at the price of not-clear recovered images. In addition, the novel scheme realizes the (k, n) threshold, avoids the design of complex codebook and averts the pixel expansion problem. Furthermore, the proposed RG-ED-based VSS inherits conventional benefits of VSS without the need of cryptographic efforts to decode the secret. Compared with other schemes reported in the literature, the present scheme has the benefits mentioned above, at the price of possible degrading of recovered images' quality.
C1 [Wang, Shen; Yan, Xuehu; Sang, Jianzhi; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150006, Peoples R China.
EM Shen.Wang@hit.edu.cn
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61301099, 61100187,
   11201100]
FX This work is supported by the National Natural Science Foundation of
   China (61301099, 61100187, 11201100)
CR [Anonymous], AUTOMATICA
   [Anonymous], 2012, J VIS COMMUN IMAGE R
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Chao KY, 2009, INT J PATTERN RECOGN, V23, P263, DOI 10.1142/S0218001409007090
   Chen T., 2008, P 18 INF SEC C HUAL
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, FUND INFORM, V96, P61, DOI 10.3233/FI-2009-167
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Dong L, 2012, SCI CHINA INFORM SCI, V55, P1151, DOI 10.1007/s11432-011-4302-z
   FLOYD RW, 1976, P SID, V17, P75
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kang I, 2011, IEEE T IMAGE PROCESS, V20, P132, DOI 10.1109/TIP.2010.2056376
   Lau D. L., 2011, MODERN DIGITAL HALFT
   Myodo E, 2006, IEEE IMAGE PROC, P97, DOI 10.1109/ICIP.2006.312371
   Myodo E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2114
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tsai DS, 2008, IMAGING SCI J, V56, P49, DOI 10.1179/174313107X214330
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Wu Xiao-tian, 2011, Journal of Computer Applications, V31, P74, DOI 10.3724/SP.J.1087.2011.00074
   Yan X., 2013, Journal of Information Hiding Multimedia and Signal Process (JIHMSP), V4, P118
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Yi Feng, 2008, Journal of Tsinghua University (Science and Technology), V48, P121
   Yip SK, 2005, I S INTELL SIG PROC, P125
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 33
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3353
EP 3373
DI 10.1007/s11042-014-2438-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600020
DA 2024-07-18
ER

PT J
AU Zhu, WZ
   Huang, WM
   Lin, ZP
   Yang, YZ
   Huang, S
   Zhou, JY
AF Zhu, Wanzheng
   Huang, Weimin
   Lin, Zhiping
   Yang, Yongzhong
   Huang, Su
   Zhou, Jiayin
TI Data and feature mixed ensemble based extreme learning machine for
   medical object detection and segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extreme learning machine (ELM); Ensemble learning; Overfitting;
   Classifier; Medical object detection and segmentation; Iterative
   learning
ID LIVER-TUMOR DETECTION; IMBALANCE; MODEL
AB Extreme learning machine (ELM) is a single-hidden layer feed-forward neural network with an efficient learning algorithm. Conventionally an ELM is trained using all the data based on the least square solution, and thus it may suffer from overfitting. In this paper, we present a new method of data and feature mixed ensemble based extreme learning machine (DFEN-ELM). DFEN-ELM combines data ensemble and feature subspace ensemble to tackle the overfitting problem and it takes advantage of the fast speed of ELM when building ensembles of classifiers. Both one-class and two-class ensemble based ELM have been studied. Experiments were conducted on computed tomography (CT) data for liver tumor detection and segmentation as well as magnetic resonance imaging (MRI) data for rodent brain segmentation. To improve the ensembles with new training data, sequential kernel learning is adopted further in the experiments on CT data for speedy retraining and iteratively enhancing the image segmentation performance. Experiment results on different testing cases and various testing datasets demonstrate that DFEN-ELM is a robust and efficient algorithm for medical object detection and segmentation.
C1 [Zhu, Wanzheng] Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Lin, Zhiping; Yang, Yongzhong] Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Huang, Weimin; Zhou, Jiayin] Inst Infocomm Res, 1 Fusionopolis Way,21-01, Connexis 138632, Singapore.
   [Huang, Su] Inst Infocomm Res, Agcy Sci Technol & Res A STAR, 1 Fusionopolis Way,21-01, Connexis 138632, Singapore.
C3 Nanyang Technological University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R);
   Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Huang, WM (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way,21-01, Connexis 138632, Singapore.
EM zhuw0006@e.ntu.edu.sg; wmhuang@i2r.a-star.edu.sg; ezplin@ntu.edu.sg;
   yyang8@e.ntu.edu.sg; huangs@i2r.a-star.edu.sg; jzhou@i2r.a-star.edu.sg
RI Lin, Zhiping/AAF-2719-2020
OI Lin, Zhiping/0000-0002-1587-1226
FU Nanyang Technological University under the Undergraduate Research
   Experience on CAmpus (URECA) programme; Agency for Science, Technology
   and Research (A*STAR) Joint Council Office under DP Grant [1334 k00084]
FX We wish to acknowledge the funding support for this project from Nanyang
   Technological University under the Undergraduate Research Experience on
   CAmpus (URECA) programme and the funding support by Agency for Science,
   Technology and Research (A*STAR) Joint Council Office under DP Grant
   1334 k00084.
CR Cao JW, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/103054
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Cao JW, 2014, P 9 IEEE C IND EL AP, P9
   Chi YL, 2013, INT J COMPUT ASS RAD, V8, P511, DOI 10.1007/s11548-013-0832-8
   Chou N, 2011, IEEE T IMAGE PROCESS, V20, P2554, DOI 10.1109/TIP.2011.2126587
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Häme Y, 2012, MED IMAGE ANAL, V16, P140, DOI 10.1016/j.media.2011.06.006
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang WM, 2014, IEEE ENG MED BIO, P4675, DOI 10.1109/EMBC.2014.6944667
   Huang WM, 2013, IEEE ENG MED BIO, P3662, DOI 10.1109/EMBC.2013.6610337
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013
   Li BN, 2012, EXPERT SYST APPL, V39, P9661, DOI 10.1016/j.eswa.2012.02.095
   Li JH, 2011, I S BIOMED IMAGING, P1741, DOI 10.1109/ISBI.2011.5872742
   Lin SJ, 2013, KNOWL-BASED SYST, V39, P214, DOI 10.1016/j.knosys.2012.11.003
   Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356
   Minhas R, 2010, NEUROCOMPUTING, V73, P1906, DOI 10.1016/j.neucom.2010.01.020
   Mirza B, 2015, NEUROCOMPUTING, V149, P316, DOI 10.1016/j.neucom.2014.03.075
   Oguz I, 2011, SPIE MED IMAGING
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rakha MA, 2004, APPL MATH COMPUT, V158, P185, DOI 10.1016/j.amc.2003.09.004
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Wang XY, 2014, NEUROCOMPUTING, V145, P90, DOI 10.1016/j.neucom.2014.05.068
   Xiong Wei, 2008, INT C MED IM COMP CO, V41, P43, DOI DOI 10.54294/RFKJIX
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
   Zong WW, 2011, NEUROCOMPUTING, V74, P2541, DOI 10.1016/j.neucom.2010.12.041
NR 32
TC 19
Z9 20
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2815
EP 2837
DI 10.1007/s11042-015-2582-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000026
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Shen, XJ
   Chen, HP
AF Zhu, Ye
   Shen, Xuanjing
   Chen, Haipeng
TI Copy-move forgery detection based on scaled ORB
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image blind identification; Copy-move forgery; Scale space; ORB feature;
   RANSAC
ID EFFICIENT
AB To solve the problem of the false matching and low robustness in detecting copy-move forgeries, a new method was proposed in this study. It involves the following steps: first, establish a Gaussian scale space; second, extract the orientated FAST key points and the ORB features in each scale space; thirdly, revert the coordinates of the orientated FAST key points to the original image and match the ORB features between every two different key points using the hamming distance; finally, remove the false matched key points using the RANSAC algorithm and then detect the resulting copy-move regions. The experimental results indicate that the new algorithm is effective for geometric transformation, such as scaling and rotation, and exhibits high robustness even when an image is distorted by Gaussian blur, Gaussian white noise and JPEG recompression; the new algorithm even has great detection on the type of hiding object forgery.
C1 [Zhu, Ye; Shen, Xuanjing; Chen, Haipeng] Jilin Univ, Coll Comp Sci & Technol, 2699 Str Qianjing, Changchun 130012, Peoples R China.
C3 Jilin University
RP Chen, HP (corresponding author), Jilin Univ, Coll Comp Sci & Technol, 2699 Str Qianjing, Changchun 130012, Peoples R China.
EM chenhp@jlu.edu.cn
FU National Natural Science Foundation for young [61305046]
FX The research is partly supported by National Natural Science Foundation
   for young (No. 61305046).
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J, 2003, P DIG FOR RES WORK
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Heng Yao, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P591, DOI 10.1109/MINES.2011.104
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Jie Hu, 2011, 2011 Second International Conference on Networking and Distributed Computing, P23, DOI 10.1109/ICNDC.2011.12
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo W, 2007, ICPR, V4, P746, DOI [10.1109/ICPR.2006.1003, DOI 10.1109/ICPR.2006.1003]
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   POPESCU A. C., 2004, THESIS DARTMOUTH COL
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Wen SF, 2009, MODELLING SIMULATION, P1, DOI 10.1109/cisp.2009.5301325
   Xiaofeng Wang, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P304, DOI 10.1109/MINES.2011.98
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
NR 25
TC 62
Z9 67
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3221
EP 3233
DI 10.1007/s11042-014-2431-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600014
DA 2024-07-18
ER

PT J
AU Bonnet, P
   Joly, A
   Goëau, H
   Champ, J
   Vignau, C
   Molino, JF
   Barthélémy, D
   Boujemaa, N
AF Bonnet, Pierre
   Joly, Alexis
   Goeau, Herve
   Champ, Julien
   Vignau, Christel
   Molino, Jean-Francois
   Barthelemy, Daniel
   Boujemaa, Nozha
TI Plant identification: man vs. machine LifeCLEF 2014 plant identification
   challenge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual plant identification; Human evaluation; Digital data; Image
   analysis
ID RECOGNITION
AB This paper reports a large-scale experiment aimed at evaluating how state-of-art computer vision systems perform in identifying plants compared to human expertise. A subset of the evaluation dataset used within LifeCLEF 2014 plant identification challenge was therefore shared with volunteers of diverse expertise, ranging from the leading experts of the targeted flora to inexperienced test subjects. In total, 16 human runs were collected and evaluated comparatively to the 27 machine-based runs of LifeCLEF challenge. One of the main outcomes of the experiment is that machines are still far from outperforming the best expert botanists at the image-based plant identification competition. On the other side, the best machine runs are competing with experienced botanists and clearly outperform beginners and inexperienced test subjects. This shows that the performances of automated plant identification systems are very promising and may open the door to a new generation of ecological surveillance systems.
C1 [Bonnet, Pierre] CIRAD, UMR AMAP, Montpellier, France.
   [Joly, Alexis; Champ, Julien] LIRMM, Montpellier, France.
   [Joly, Alexis; Goeau, Herve] Inria ZENITH Team, Montpellier, France.
   [Champ, Julien] INRA UMR AGAP, Montpellier, France.
   [Vignau, Christel] Tela Bot, Montpellier, France.
   [Molino, Jean-Francois] IRD, Montpellier, France.
   [Barthelemy, Daniel] CIRAD, BIOS Direct, F-34398 Montpellier, France.
   [Barthelemy, Daniel] INRA, UMR AMAP, F-34398 Montpellier, France.
   [Boujemaa, Nozha] INRIA, Direct Saclay Ctr, Paris, France.
C3 CIRAD; Centre National de la Recherche Scientifique (CNRS); Institut de
   Recherche pour le Developpement (IRD); Universite de Montpellier; Centre
   National de la Recherche Scientifique (CNRS); Universite Paul-Valery;
   Universite Perpignan Via Domitia; Universite de Montpellier; INRAE;
   Institut de Recherche pour le Developpement (IRD); CIRAD; CIRAD; Centre
   National de la Recherche Scientifique (CNRS); Institut de Recherche pour
   le Developpement (IRD); Universite de Montpellier; INRAE; Inria
RP Goëau, H (corresponding author), Inria ZENITH Team, Montpellier, France.
EM pierre.bonnet@cirad.fr; alexis.joly@inria.fr; herve.goeau@inria.fr;
   julien.champ@lirmm.fr; christel@tela-botanica.org;
   jean-francois.molino@ird.fr; daniel.barthelemy@cirad.fr;
   nozha.boujemaa@inria.fr
RI Bonnet, Pierre/AAG-6819-2020; joly, alexis/AAV-3101-2021; Molino,
   Jean-François/C-5011-2009; Champ, Julien/AAG-1092-2020
OI Bonnet, Pierre/0000-0002-2828-4389; joly, alexis/0000-0002-2161-9940;
   Molino, Jean-François/0000-0001-8853-7133; Champ,
   Julien/0000-0002-2042-0411; barthelemy, Daniel/0000-0003-3187-2517;
   Goeau, Herve/0000-0003-3296-3795
FU Agropolis foundation
FX Part of this work was funded by the Agropolis foundation through the
   project Pl@ntNet (http://www.plantnet-project.org/).
CR Angelova A., 2012, DEV DEPLOYMENT LARGE
   [Anonymous], 2008, IND C COMP VIS GRAPH
   [Anonymous], CLEF 2014 C
   [Anonymous], 2012, EUR C COMP VIS
   [Anonymous], 2012, P 2 ACM INT C MULT R
   Backes AR, 2009, INT J PATTERN RECOGN, V23, P1145, DOI 10.1142/S0218001409007508
   Cai J, 2007, 3 INT C INT SENS ISS
   Cerutti Guillaume, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P202
   Cerutti G, 2011, INT S VIS COMP
   Chen Q, 2014, CLEF 2014 C
   Dimitrovski I, 2014, CLEF 2014 C
   Fakhfakh S, 2014, CLEF 2014 C
   Farnsworth EJ, 2013, BIOSCIENCE, V63, P891, DOI 10.1525/bio.2013.63.11.8
   Gaston KJ, 2004, PHILOS T R SOC B, V359, P655, DOI 10.1098/rstb.2003.1442
   Goeau H, 2013, P 21 ACM INT C MULT
   Goeau H., 2011, ACM C MULT
   Goeau H., 2012, CLEF WORKING NOTES
   Goeau H., 2011, CLEF WORKING NOTES
   Goeau H, 2014, CLEF WORKING NOTES
   Goeau H, 2014, P INT C MULT RETR, P2014
   Goeau H, 2014, CLEF 2014 C
   Hsu TH, 2011, MULTIMED TOOLS APPL, V53, P53, DOI 10.1007/s11042-010-0490-6
   Issolah M, 2014, CLEF 2014 C
   Joly A, 2013, ECOLOGICAL INFORM
   Joly A, 2013, INT WORKSH MULT AN E, P2013
   Joly A, 2014, P CLEF
   Karamti H, 2014, CLEF 2014 C
   Kebapci H, 2010, COMPUTER J
   Paczolay D, 2014, CLEF 2014 C
   Spampinato, 2012, MAED 12 P 1 ACM INT
   Szucs G, 2014, CLEF 2014 C
   Trifa VM, 2008, J ACOUST SOC AM, V123, P2424, DOI 10.1121/1.2839017
   Voorhees E.M., 1999, Proceedings of TREC
   Yanikoglu B, 2014, CLEF 2014 C
NR 34
TC 19
Z9 22
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1647
EP 1665
DI 10.1007/s11042-015-2607-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600017
DA 2024-07-18
ER

PT J
AU Lee, JS
   Wei, KJ
   Chen, SJ
   Wang, YH
AF Lee, Jung-San
   Wei, Kuo-Jui
   Chen, Shin-Jen
   Wang, Yi-Hua
TI Tele-micropayment scam prevention based on visual secret sharing
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tele-micropayment; SMS Spam Blocker; One time password; Visual secret
   sharing
ID ENCRYPTION
AB Telecommunication micropayment (Tele-micropayment) is an alternative of shelling out from traditional electronic commerce with high flexibility. It has been applied to the applications of online software, music, e-book, and game credit, in which the consumers are only charged with petty expense. The verification procedure of this payment relies on OTP(one time password) via SMS(short message service). Obtaining the OTP from smart phone and importing the content into the website is easy for a consumer to complete the transaction. Nevertheless, the SMS Spam Blocker has brought a fatal damage to Tele-micropayment, which could be spread by malicious smart phone Apps(Applications). With the intercepted SMS, an attacker can further learn the content to launch a micropayment scam. As the amount of micropayment is petty, it is hard to be aware of this behavior after the victim receives the bill. In this proposal, we aim to design a brand-new OTP by introducing visual secret sharing technique. According to the experiments, even the attacker can intercept the SMS to get OTP, he cannot learn the content via OCR(Optical character recognition) software. This has proved that our design can greatly help to stop this micropayment scam.
C1 [Lee, Jung-San; Wei, Kuo-Jui; Chen, Shin-Jen; Wang, Yi-Hua] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
EM leejs@fcu.edu.tw
CR Chang C, 2009, P 3 INT C UB INF MAN, P309
   Chang CC, 2009, COMPUTERS ELECT ENG, V35, P1
   Chen CT, 2004, 2004 IEEE INTERNATIONAL CONFERNECE ON E-TECHNOLOGY, E-COMMERE AND E-SERVICE, PROCEEDINGS, P267
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Eldefrawy Mohamed Hamdy, 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P327, DOI 10.1109/ITNG.2011.64
   Gargenta Marko., 2011, Learning android
   Hsieh WB, 2011, INT WIREL COMMUN, P201, DOI 10.1109/IWCMC.2011.5982418
   Indu S, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P140, DOI 10.1109/ICICES.2013.6508205
   Joy Jo-Yi Chang, 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P458, DOI 10.1109/ISCIT.2010.5664885
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee JS, 2013, ELECTRON COMMER R A, V12, P1, DOI 10.1016/j.elerap.2012.09.005
   Lee JS, 2012, ELECTRON COMMER R A, V11, P388, DOI 10.1016/j.elerap.2012.04.001
   Lee JS, 2010, WIRELESS PERS COMMUN, V53, P569, DOI 10.1007/s11277-009-9703-6
   Lee Jungnam, 2012, Comp Funct Genomics, V2012, P807270, DOI 10.1155/2012/807270
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Roy S., 2014, Electrical, Electronics and Computer Science, V2, P1, DOI [DOI 10.1186/S40712-014-0010-Y, DOI 10.1109/SCEECS.2014.6804449, 10.1109/SCEECS.2014.6804449]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Yen SM, 2014, INFORM SCIENCES, V259, P160, DOI 10.1016/j.ins.2013.07.031
NR 20
TC 1
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2233
EP 2248
DI 10.1007/s11042-014-2403-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000023
DA 2024-07-18
ER

PT J
AU Lin, TL
   Thakur, US
   Chou, CC
   Chen, SL
AF Lin, Ting-Lan
   Thakur, Uday Singh
   Chou, Chi-Chan
   Chen, Shih-Lun
TI Hole filling using multiple frames and iterative texture synthesis with
   illumination compensation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Freeview generation; Depth-image-based rendering (DIBR); Depth boundary
   rectification; Inpainting algorithm; Depth discontinuity; Illumination
   compensation
ID DEPTH
AB In this paper, we propose a novel freeview generation system. We first discuss the problem of misalignment of the edges between color frame and depth frame, and propose an optimization method to solve it. Then an original frame is separated into two parts, depending on the sizes of the resulting dis-occluded areas in the virtual view. Illumination changes between current frame and the information from previous frames are modeled and compensated. In the virtual view, the missing pixels are recovered by the proposed inpainting method. Using depth information, we compute the priority of the recovering order among the missing pixels. The recovering process accounts for pixel consistency, and the process iterates between virtual color frame and depth frame. Experimental results show that, compared with a state-of-the-art work, the proposed method has better subjective and objective performances; the PSNR gain can be up to 2.9575 dB.
C1 [Lin, Ting-Lan; Chou, Chi-Chan; Chen, Shih-Lun] Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
   [Thakur, Uday Singh] Rhein Westfal TH Aachen, Inst Nachrichtentech, Aachen, Germany.
C3 Chung Yuan Christian University; RWTH Aachen University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
EM tinglan@cycu.edu.tw; Thakur@ient.rwth-aachen.de; g10276011@cycu.edu.tw;
   chrischen@cycu.edu.tw
RI Chen, Shih-Lun/AFF-8659-2022
FU National Science Council, Taiwan [NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018, NSC-102-2221-E-033-063]; Ministry of Science and
   Technology, Taiwan [MOST 103-2221-E-033-020, MOST-103-2221-E-033-070,
   MOST-103-2622-E-033-001-CC2]; College of Electrical Engineering and
   Computer Science in Chung Yuan Christian University, Taiwan
   [CYCU-EECS-10301]
FX This research is supported by the National Science Council, Taiwan,
   under Grants NSC 101-2221-E-033-036, NSC 102-2221-E-033-018,
   NSC-102-2221-E-033-063, by the Ministry of Science and Technology,
   Taiwan under Grant MOST 103-2221-E-033-020, MOST-103-2221-E-033-070,
   MOST-103-2622-E-033-001-CC2, and by the College of Electrical
   Engineering and Computer Science in Chung Yuan Christian University,
   Taiwan under Grant CYCU-EECS-10301.
CR Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hervieu A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4101, DOI 10.1109/ICPR.2010.997
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Schmeing M, 2010, 2010 3DTV C TRUE VIS, P1, DOI DOI 10.1109/3DTV.2010.5506596
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723
   Tian D, 2009, PROC SPIE, V7443, DOI 10.1117/12.829372
   Wang L. F., 2008, WATER SAV IRRIG, V2008, P1, DOI DOI 10.1038/NATURE07065
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 13
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1899
EP 1921
DI 10.1007/s11042-014-2379-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000008
DA 2024-07-18
ER

PT J
AU Afshari, S
   Movahhedinia, N
AF Afshari, Saeid
   Movahhedinia, Naser
TI QoE assessment of interactive applications in computer networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive applications; Quality of experience; User
   satisfaction/dissatisfaction measurement; Non-intrusive measurement
ID QUALITY; EXPERIENCE; MOBILE; SERVICES; REGION; MODELS; VIDEO
AB Measuring end user Quality of Experience (QoE) is currently performed by subjective or objective standard methods each with its own deficiencies. The subjective quality assessment is laboratory based, costly and offline; while, the objective estimation of user satisfaction is obtained through a static manner, not directly related to end user contentment. The attempt is made here to measure user QoE based on an online, user-aware and non-intrusive method. This is investigated by identifying the measurable objective indicators of user satisfaction/dissatisfaction and assigning them to the subjective nature of QoE concept. Proposing an architectural model, the extent of modalities for implicit sensing of the user QoE is explored with respect to the real-time measurement of her/his experiences. The vocal and interactional signs of VoIP service users on their smartphone devices are applied to estimate their satisfaction/dissatisfaction levels as a case study. The obtained results are compared to the users' self-report in order to evaluate the accuracy of this proposed method.
C1 [Afshari, Saeid; Movahhedinia, Naser] Univ Isfahan, Dept Comp Engn, Fac Engn, Esfahan, Iran.
C3 University of Isfahan
RP Afshari, S (corresponding author), Univ Isfahan, Dept Comp Engn, Fac Engn, Esfahan, Iran.
EM afshari@eng.ui.ac.ir
CR Afshari S, 2014, WIRELESS PERS COMMUN, P1
   [Anonymous], 2012, 4 ACM WORKSH MOB VID
   [Anonymous], 2013, FACIAL EXPRESSION AN
   Bhattacharya A, 2012, HUM-CENT COMPUT INFO, V2, DOI 10.1186/2192-1962-2-7
   Bhaykar M., 2013, Natl Conf Commun (NCC), P1, DOI [10.1109/NCC.2013.6487998, DOI 10.1109/NCC.2013.6487998]
   Brooks P, 2010, IEEE NETWORK, V24, P8, DOI 10.1109/MNET.2010.5430138
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen KT, 2010, IEEE NETWORK, V24, P28, DOI 10.1109/MNET.2010.5430141
   Chen KT, 2009, IEEE INFOCOM SER, P702, DOI 10.1109/INFCOM.2009.5061978
   Choudhury T, 2008, IEEE PERVAS COMPUT, V7, P32, DOI 10.1109/MPRV.2008.39
   Ciubotaru B, 2009, IEEE T BROADCAST, V55, P202, DOI 10.1109/TBC.2009.2020448
   Dai Q, 2011, LECT NOTES COMPUT SC, V6955, P146
   De Moor K, 2010, MOBILE NETW APPL, V15, P378, DOI 10.1007/s11036-010-0223-0
   De Pessemier T, 2013, IEEE T BROADCAST, V59, P47, DOI 10.1109/TBC.2012.2220231
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Geerts David, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P158, DOI 10.1109/QOMEX.2010.5516292
   Ghinea G, 2004, MULTIMED TOOLS APPL, V22, P187, DOI 10.1023/B:MTAP.0000011934.59111.b5
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Gulliver SR, 2007, IEEE T BROADCAST, V53, P449, DOI 10.1109/TBC.2007.896955
   Gustarini M, 2013, P 2013 ACM C PERV UB, P1447, DOI DOI 10.1145/2494091.2496041
   Hasani H. R., 2011, 2011 Proceedings of IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI 2011), P513, DOI 10.1109/CINTI.2011.6108560
   Hektner J. M., 2007, EXPERIENCE SAMPLING
   Jumisko-Pyykk S., 2008, Proc 1st Int Conf Designing Interact User Experiences TVand video, V2008, P183, DOI DOI 10.1145/1453805.1453841
   Kane J, 2013, INT CONF ACOUST SPEE, P7982, DOI 10.1109/ICASSP.2013.6639219
   Ketyko I., 2010, IEEE INT S BROADB MU, P1
   Knapp RB, 2011, COGN TECHNOL, P133, DOI 10.1007/978-3-642-15184-2_9
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Matulin M, 2013, PROMET-ZAGREB, V25, P255, DOI 10.7307/ptt.v25i3.1195
   McNamara N, 2011, INT J HUM-COMPUT ST, V69, P375, DOI 10.1016/j.ijhcs.2011.01.005
   Menkovski V, 2010, INT J MOB COMPUT MUL, V2, P1, DOI 10.4018/jmcmc.2010100101
   Mitra K, 2011, LECT NOTES COMPUT SC, V6869, P135, DOI 10.1007/978-3-642-22875-9_12
   Möller S, 2009, INT WORK QUAL MULTIM, P7, DOI 10.1109/QOMEX.2009.5246986
   Muntean GM, 2008, IEEE T BROADCAST, V54, P296, DOI 10.1109/TBC.2008.919012
   Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1
   Ping HY, 2013, INT J COMPUT TECHNOL, V11, P2189, DOI DOI 10.24297/ijct.v11i1.1190
   Raake Alexander., 2007, Speech Quality of VoIP: Assessment and Prediction
   Reiter U., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P513, DOI 10.1109/ISCE.2011.5973883
   Schattschneider R., 2011, P 2011 IEEE INT C CO, P1, DOI [DOI 10.1109/ICC.2011.5963220, 10.1109/icc.2011.5963220]
   Schatz Raimund, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P219, DOI 10.1007/978-3-642-36784-7_10
   Serif T, 2008, COMPUT HUM BEHAV, V24, P1385, DOI 10.1016/j.chb.2007.07.012
   Serif T, 2004, P ACM S APPL COMP, P1580
   Shahin IMA, 2013, INT C COMM SIGN PROC, P1
   Skorin-Kapov Lea, 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P662
   Song W., 2012, Mobile Multimedia: User and Technology Perspectives, P3
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Stankiewicz R, 2011, COMPUT NETW, V55, P1459, DOI 10.1016/j.comnet.2011.02.004
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Wu CC, 2013, IEEE T MULTIMEDIA, V15, P1121, DOI 10.1109/TMM.2013.2241043
   Wu W, 2009, P 17 ACM INT C MULT
   Xu CQ, 2013, IEEE T VEH TECHNOL, V62, P2273, DOI 10.1109/TVT.2012.2228682
   Zhang JJ, 2011, IEEE COMMUN MAG, V49, P185, DOI 10.1109/MCOM.2011.5936172
NR 54
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 903
EP 918
DI 10.1007/s11042-014-2331-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700010
DA 2024-07-18
ER

PT J
AU Babu, RV
   Tom, M
   Wadekar, P
AF Babu, R. Venkatesh
   Tom, Manu
   Wadekar, Paras
TI A survey on compressed domain video analysis techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video object segmentation; Human action recognition; Indexing;
   Retrieval; Face detection; Video classification; Object tracking; Object
   localization; Moving object detection; H.264/AVC; HEVC; MPEG; Compressed
   domain; Quantization parameter; Motion vectors; Transform coefficients;
   Video analysis
ID MOVING OBJECT SEGMENTATION; SPATIOTEMPORAL SEGMENTATION; MOTION;
   RETRIEVAL; RECOGNITION; CLASSIFICATION; EFFICIENCY; TRACKING; SPEED
AB Image and video analysis requires rich features that can characterize various aspects of visual information. These rich features are typically extracted from the pixel values of the images and videos, which require huge amount of computation and seldom useful for real-time analysis. On the contrary, the compressed domain analysis offers relevant information pertaining to the visual content in the form of transform coefficients, motion vectors, quantization steps, coded block patterns with minimal computational burden. The quantum of work done in compressed domain is relatively much less compared to pixel domain. This paper aims to survey various video analysis efforts published during the last decade across the spectrum of video compression standards. In this survey, we have included only the analysis part, excluding the processing aspect of compressed domain. This analysis spans through various computer vision applications such as moving object segmentation, human action recognition, indexing, retrieval, face detection, video classification and object tracking in compressed videos.
C1 [Babu, R. Venkatesh; Tom, Manu; Wadekar, Paras] Indian Inst Sci, SERC, Video Analyt Lab, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, SERC, Video Analyt Lab, Bangalore 560012, Karnataka, India.
EM venky@serc.iisc.ernet.in
RI Radhakrishnan, Venkatesh Babu/D-5313-2009; Tom, Manu/AAJ-3815-2020; Tom,
   Manu/ABV-9231-2022
OI Tom, Manu/0000-0002-0352-7153; Tom, Manu/0000-0002-0352-7153;
   Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
FU CARS project from Centre for Artificial Intelligence and Robotics,
   Defence Research and Development Organization (DRDO), Govt. of India
   [CARS-25]
FX This work was supported by CARS (CARS-25) project from Centre for
   Artificial Intelligence and Robotics, Defence Research and Development
   Organization (DRDO), Govt. of India. The authors wish to express
   grateful thanks to the referees for their useful comments and
   suggestions to improve the presentation of this paper.
CR Achanta R., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P61, DOI 10.1109/ICME.2002.1035400
   Ali S, 2007, PROC CVPR IEEE, P65
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2013, COMPUTER VISION PATT
   [Anonymous], 1993, JTC1111722 ISOIEC
   [Anonymous], 1994, JTC1138182 ISOIEC
   [Anonymous], 1999, JTC1144962 ISOIEC
   [Anonymous], P IEEE INT C EL COMP
   Babu RV, 2007, MULTIMED TOOLS APPL, V32, P93, DOI 10.1007/s11042-006-0048-9
   Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   Babu RV, 2002, PATTERN RECOGN LETT, V23, P1203, DOI 10.1016/S0167-8655(02)00067-3
   Benzougar A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P402, DOI 10.1109/ICIP.2001.958136
   Bhaskaran V., 1995, IMAGE VIDEO COMPRESS
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Biswas S, 2013, INT CONF ACOUST SPEE, P2040, DOI 10.1109/ICASSP.2013.6638012
   Bjontegaard G, 2002, C028 ISOIEC JOINT VI
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen W, 2011, IEEE VISUAL COMMUNIC, P1, DOI [10.1109/VCIP.2011.6115985, DOI 10.1109/VCIP.2011.6115985]
   Chen YM, 2011, IEEE T MULTIMED, V13, P421
   Chua TS, 2002, VISUAL COMPUT, V18, P121, DOI 10.1007/s003710100137
   De Bruyne S, 2009, IEEE INT CON MULTI, P330, DOI 10.1109/ICME.2009.5202501
   Dong L., 2006, IEEE INT C AC SPEECH, pII, DOI DOI 10.1109/ICASSP.2006.1660430
   Dong L, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P753, DOI 10.1109/ICME.2006.262408
   Eng HL, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1531, DOI 10.1109/ICME.2000.871059
   Favalli L, 2000, IEEE T CIRC SYST VID, V10, P427, DOI 10.1109/76.836288
   Fei W, 2010, IET IMAGE PROCESS, V4, P11, DOI 10.1049/iet-ipr.2009.0038
   Goya Y., 2006, Intelligent Transportation Systems Conference, P864
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   Hong WD, 2007, FUTURE GENER COMP SY, V1, P385
   How-Lung Eng, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P284, DOI 10.1109/ICIP.1999.817118
   Ibrahim M, 2007, IEEE INT WORKSH MOT, P17
   Jamrozik ML, 2002, IEEE IMAGE PROC, P113
   Kapotas S. K., 2010, 2010 IEEE INT C IMAG, P325
   Kas C, 2008, P 3 PAC RIM S ADV IM, P318
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lie Wen-Nang., 2001, IEEE International Conference on Multimedia and Expo (ICME), P965
   Liu Z, 2007, J VIS COMMUN IMAGE R, V18, P275, DOI 10.1016/j.jvcir.2007.02.002
   Mak CM, 2009, IET IMAGE PROCESS, V3, P272, DOI 10.1049/iet-ipr.2008.0093
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Mehmood K, 2009, SIGNAL PROCESS-IMAGE, V24, P814, DOI 10.1016/j.image.2009.06.006
   Mehrabi M, 2012, MULTIMED TOOLS APPL, V60, P443, DOI 10.1007/s11042-010-0597-9
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   MEZARIS V, 2004, WORKSH IM AN MULT IN
   Mezaris V, 2003, IEEE T CIRC SYST VID, V14, P606
   Mitsumoto S., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P422
   Niu CF, 2010, LECT NOTES COMPUT SC, V5995, P645
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ozer B, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P61, DOI 10.1109/HUMO.2000.897372
   Ozer IB, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P133, DOI 10.1109/MOTION.2002.1182225
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P428, DOI 10.1016/j.jvcir.2009.05.001
   Porikli F, 2004, P SOC PHOTO-OPT INS, V5297, P195, DOI 10.1117/12.527188
   Porikli F, 2010, IEEE T CIRC SYST VID, V20, P2, DOI 10.1109/TCSVT.2009.2020253
   Rangarajan B., 2014, IEEE 9 INT C INT SEN, P1, DOI DOI 10.1109/ISSNIP.2014.6827622
   Rijkse K, 1996, IEEE COMMUN MAG, V34, P42, DOI 10.1109/35.556485
   Rodriguez-Benitez L, 2009, IMAGE VISION COMPUT, V27, P648, DOI 10.1016/j.imavis.2008.07.002
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sharma A, 2014, INT CONF COMP COMMUN
   Shi YQ, 2008, IMAGE PROCESS SER, P3
   Solana-Cipres C, 2009, INT J APPROX REASON, V51, P99, DOI 10.1016/j.ijar.2009.09.002
   Soomro K, 2012, ARXIVABS12120402
   Sukmarg O., 2000, 2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119), P364, DOI 10.1109/TENCON.2000.892290
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szczerba K, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P478, DOI 10.1109/AVSS.2009.78
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Wang T, 2012, J PROBAB STAT, V2012, DOI 10.1155/2012/524724
   Thilak Vimal, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P281
   Tom M, 2013, NAT CONF COMPUT VIS
   Tom M, 2015, MULTIMED TOOLS APPL, V74, P9323, DOI 10.1007/s11042-014-2083-2
   Vacavant A, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P51
   VERSTOCKT S, 2009, IEEE INT C ADV VID S, P370
   Wang FP, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P258, DOI 10.1109/AVSS.2012.46
   Wang HL, 1997, IEEE T CIRC SYST VID, V7, P615, DOI 10.1109/76.611173
   Wang J, 2009, INT J IMAGE GRAPH, V9, P609, DOI 10.1142/S0219467809003617
   Wang Pei, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P716, DOI 10.1109/ICSPS.2010.5555657
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Wang WQ, 2008, IEEE T CIRC SYST VID, V18, P670, DOI 10.1109/TCSVT.2008.918800
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang JW, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P252, DOI 10.1109/AVSS.2012.68
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeo CH, 2008, IEEE T CIRC SYST VID, V18, P1006, DOI 10.1109/TCSVT.2008.927112
   Yoneyama A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P934, DOI 10.1109/ICIP.1999.823035
   You W, 2012, ARXIVABS12024743
   You W, 2007, LECT NOTES COMPUT SC, V4577, P483
   Yu DL, 2003, THESIS NATL U SINGAP
   Yu XD, 2003, IEEE INT C IM PROC, V3, DOI [10.1109/ICIP.2003.1247399, DOI 10.1109/ICIP.2003.1247399]
   Yu XD, 2007, MULTIMED TOOLS APPL, V34, P85, DOI 10.1007/s11042-006-0073-8
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
   Zeng W, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P524
   Zhou QY, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P592, DOI 10.1109/ICIG.2007.20
NR 95
TC 45
Z9 49
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1043
EP 1078
DI 10.1007/s11042-014-2345-z
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700017
DA 2024-07-18
ER

PT J
AU Lee, GC
   Yeh, FH
   Hsiao, YH
AF Lee, Greg C.
   Yeh, Fu-Hao
   Hsiao, Yi-Han
TI Kinect-based Taiwanese sign-language recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign-language recognition; Gesture recognition; Kinect
AB Gesture-recognition is an important component for many intelligent human-computer interaction applications. For example, a realtime sign-language recognition system would detect and interpret hand gestures. Many vision-based sign-language recognition methods have been proposed over the years with mix results of usability. Some system are limited to recognize only a few gestures, while others require the use of 3D camera to provides depth information to improve recognition accuracy. In this paper, a Kinect-based Taiwanese sign-language recognition system is proposed. Three main features are extracted from the signing gestures, namely hand positions, hand signing direction, and hand shapes. The hand positions are readily available through the input sensor. The signing direction is determined using HMM on trajectory of the hand movement, and a SVM is trained and used to recognize the hand shapes. Experimental results show that the proposed system achieved an 85.14 % recognition rate.
C1 [Lee, Greg C.; Hsiao, Yi-Han] Natl Taiwan Normal Univ, Dept Comp Sci & Informat Engn, Taipei 116, Taiwan.
   [Yeh, Fu-Hao] Fooyin Univ, Program Informat Technol, Kaohsiung, Taiwan.
C3 National Taiwan Normal University; Fooyin University
RP Yeh, FH (corresponding author), Fooyin Univ, Program Informat Technol, 151 Chinhsueh Rd, Kaohsiung, Taiwan.
EM leeg@csie.ntnu.edu.tw; yehvolvo@gmail.com; soratoka@gmail.com
FU Ministry of Science and Technology of Taiwan, R.O.C.
   [100-2511-S-003-020-MY2, 101-2511-S-003-057-MY3]
FX This research was partially supported by the Ministry of Science and
   Technology of Taiwan, R.O.C., under grant numbers 100-2511-S-003-020-MY2
   and 101-2511-S-003-057-MY3.
CR Agarwal Anant, 2013, 2013 Sixth International Conference on Contemporary Computing (IC3), P181, DOI 10.1109/IC3.2013.6612186
   [Anonymous], 2007, PROC INTERSPEECH 200
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Bongkyu Lee, 1995, Neural, Parallel & Scientific Computations, V3, P417
   Brashear H., 2006, Proceedings of the 8th international ACM SIGACCESS conference on Computers and Accessibility, Assets '06, P79
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dimitrios K, 2005, P IEEE INT C IM PROC, V3, P1220
   Doulamis ND, 2005, IEEE WRK SIG PRO SYS, P319, DOI 10.1109/SIPS.2005.1579886
   Feng Ziyong., 2012, P 4 INT C INTERNET M, P70, DOI DOI 10.1145/2382336.2382356
   Garibotto G, 2013, LECT NOTES COMPUT SC, V8157, P721, DOI 10.1007/978-3-642-41184-7_73
   Kadous M W., 1996, P WORKSHOP INTEGRATI, P165
   Kalin S, 2013, P WORKSH MULT CORP A
   Kelly D., 2009, Proceedings of the 2009 International Conference on Multimodal Interfaces, P351, DOI DOI 10.1145/1647314.1647387
   Lang S, 2012, LECT NOTES ARTIF INT, V7267, P394, DOI 10.1007/978-3-642-29347-4_46
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Ma ZG, 2013, PROC CVPR IEEE, P2627, DOI 10.1109/CVPR.2013.339
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Segen J, 1999, P IEEE INT C COMP VI, P1479
   Siddiky Feroz Ahmed, 2007, 2007 10th International Conference on Computer and Information Technology (ICCIT 2007), P1, DOI 10.1109/ICCITECHN.2007.4579424
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Tran SD, 2008, LECT NOTES COMPUT SC, V5303, P610, DOI 10.1007/978-3-540-88688-4_45
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
   Zafrulla Z., 2011, Proceedings of the 13th international conference on multimodal interfaces, New York, NY, USA, P279, DOI DOI 10.1145/2070481.2070532
   Zieren J., 2004, PROC IFACIFIPIFORSIE, P27
NR 30
TC 33
Z9 34
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 261
EP 279
DI 10.1007/s11042-014-2290-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500014
DA 2024-07-18
ER

PT J
AU Ling, Q
   Xu, LX
   Yan, JF
   Zhang, YC
   Li, F
AF Ling, Qiang
   Xu, Lixiang
   Yan, Jinfeng
   Zhang, Yicheng
   Li, Feng
TI A feedback-based adaptive data migration method for hybrid storage VOD
   caching systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SSD; Caching; Data migration; Feedback
AB Nowadays Video-On-Demand (VOD) caching systems are often equipped with hybrid storage devices, which have been designed to combine the high read speed of Solid State Disks (SSDs) and the large capacity of Hard Disk Drives (HDDs). However, the number of erase cycles of SSDs is limited. So it is important to control the write load of SSDs in real applications. This paper proposes a Feedback-based Adaptive Data Migration (FADM) method, which can utilize the real-time feedback of the write load of SSDs to adjust the rule of moving data between HDDs and SSDs. More specifically, a video in HDDs is allowed to be moved into SSDs when its popularity is higher than that of the least popular video in SSDs by a threshold. This threshold is adaptively adjusted according to the feedback of the write load of SSDs. With FADM, the desired lifetime of SSDs can be well guaranteed even under various user behaviors while good read performance can be maintained. Simulations are done to demonstrate the effectiveness of FADM.
C1 [Ling, Qiang; Xu, Lixiang; Yan, Jinfeng; Zhang, Yicheng; Li, Feng] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ling, Q (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
EM qling@ustc.edu.cn
RI Zhang, yicheng/HNC-5513-2023; Zhang, Yicheng/E-2098-2016; LI,
   feng/HIR-1703-2022
OI Zhang, Yicheng/0000-0001-5979-793X; 
FU National Natural Science Foundation of China [61273112]; Fundamental
   Research Funds for the Central Universities; 973 Program [2013CB733100]
FX This work was partially supported by the National Natural Science
   Foundation of China (No. 61273112), the Fundamental Research Funds for
   the Central Universities and the 973 Program (No. 2013CB733100).
CR Abhari A, 2010, MULTIMED TOOLS APPL, V46, P91, DOI 10.1007/s11042-009-0309-5
   [Anonymous], NETWORKING STORAGE S
   [Anonymous], P 1990 ACM SIGMETRIC
   [Anonymous], 1998, AP684 INT CORP
   [Anonymous], LFU K EFFECTIVE BUFF
   [Anonymous], LRU BASED ALGORITHMS
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Chen F., 2011, Proc. of ACM Int. Conf. on Supercomputing, P22
   Chen T, 2007, EUR J OPER RES, V181, P828, DOI 10.1016/j.ejor.2006.05.034
   Cheong SK, 2011, COMM COM INF SC, V184, P508
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Dorf R.C., 2008, Modern Control Systems, V11th
   Kang J., 2006, Proceedings of the International Conference on Embedded Software (EMSOFT), P161
   Kim J, 2002, IEEE T CONSUM ELECTR, V48, P366
   Kim YJ, 2007, IEEE T CONSUM ELECTR, V53, P1469, DOI 10.1109/TCE.2007.4429239
   Koltsidas I, 2008, PROC VLDB ENDOW, V1, P514, DOI 10.14778/1453856.1453913
   Lin Lin, 2011, Proceedings of the 2011 IEEE 19th International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS 2011), P318, DOI 10.1109/MASCOTS.2011.41
   Narayanan D, 2009, EUROSYS'09: PROCEEDINGS OF THE FOURTH EUROSYS CONFERENCE, P145
   Reisslein M, 2002, INFORM SCIENCES, V140, P3, DOI 10.1016/S0020-0255(01)00179-7
   Ruixuan Li, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P450, DOI 10.1109/ICPP.2012.17
   Soundararajan Gokul., 2010, Proceedings of the 8th USENIX conference on File and storage technologies, FAST'10, P8
   Un-Keun Yoon, 2010, 2010 IEEE/ACIS 9th International Conference on Computer and Information Science (ICIS 2010), P280, DOI 10.1109/ICIS.2010.19
   Un-Keun Yoon, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P189, DOI 10.1109/CSE.2009.215
   Wolf JL, 1997, MULTIMEDIA SYST, V5, P358, DOI 10.1007/s005300050067
   Wu KL, 2004, IEEE T MULTIMEDIA, V6, P770, DOI 10.1109/TMM.2004.834870
   Wu XJ, 2009, PROCEEDINGS OF THE ASME FLUIDS ENGINEERING DIVISION SUMMER CONFERENCE -2008, VOL 1, PT A AND B, P583
   Xiaojian Wu, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P583, DOI 10.1109/ICCNC.2012.6167490
   Xiaojian Wu, 2010, Proceedings 18th IEEE/ACM International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS 2010), P14, DOI 10.1109/MASCOTS.2010.11
   Yu J, 2006, MULTIMEDIA SYST, V12, P135, DOI 10.1007/s00530-006-0045-x
NR 29
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 165
EP 180
DI 10.1007/s11042-014-2281-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500009
DA 2024-07-18
ER

PT J
AU Rani, A
   Raman, B
AF Rani, Asha
   Raman, Balasubramanian
TI An image copyright protection scheme by encrypting secret data with the
   host image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Discrete cosine transform; Singular-value
   decomposition; Zero-watermarking; Certified authority
AB In this paper, a zero-watermarking based copyright protection scheme is proposed. The secret watermark image is not embedded in the host image rather it is encrypted with the host image. The proposed scheme is making use of discrete cosine transform and singular value decomposition to extract robust features of the host image. Further the selected robust features are used to encrypt the secret image. The secret image is encrypted with the host image by generating two shares namely master share and ownership share. The master share is generated by differential classification of features extracted. The ownership share is generated with the help of master share and the secret image. The two shares separately don't give any clue of the secret image but when stacked together the encrypted secret image is revealed. Experimental study is conducted to evaluate the robustness of the algorithm against various signal processing and geometrical attacks.
C1 [Rani, Asha] IIT Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
   [Raman, Balasubramanian] IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Rani, A (corresponding author), IIT Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM asha0chaudhary@gmail.com; balarfma@iitr.ac.in
FU Council of Scientific and Industrial Research (CSIR), New Delhi
   [CSR-557-MTD]
FX This research work is supported by Council of Scientific and Industrial
   Research (CSIR), New Delhi under the grant number CSR-557-MTD.
CR Agarwal H, 2014, MULTIMEDIA TOOLS APP
   Bhatnagar G, 2011, MULTIMEDIA TOOLS APP
   Cao HQ, 2006, PROC SPIE, V6247, DOI 10.1117/12.663927
   Chang CC, 2002, PATTERN RECOGN LETT, V23, P931, DOI 10.1016/S0167-8655(02)00023-5
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Fu Z, 2013, MULTIMEDIA TOOLS APP
   Gao G, 2012, MULTIMEDIA TOOLS APP
   Guitart O, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2400067
   Hsu C, 2005, OPT ENG, V44
   huynh-Thu Q., 2008, ELECT LETT, V44
   Hwang R.-J, 2000, TAMKANG J SCI ENG, V3, P97
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Matsumoto M., 1998, SPECIAL ISSUE UNIFOR, V8, P3, DOI DOI 10.1145/272991.272995
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Su Q, 2013, MULTIMEDIA TOOLS APP
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang FH, 2007, INF SCI, V177
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Wang MS, 2006, OPT ENG, V46
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Yaxun Zhou, 2011, 2011 International Conference on Multimedia Technology, P2873
   Yu L, 2005, IMAGE VISION COMPUT, V23
NR 29
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1027
EP 1042
DI 10.1007/s11042-014-2344-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700016
DA 2024-07-18
ER

PT J
AU Cao, YP
   O'Halloran, K
AF Cao, Yanpeng
   O'Halloran, Kay
TI Learning human photo shooting patterns from large-scale community photo
   collections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User patterns and trends analysis; Geo-social multimedia data mining;
   Large-scale image processing; Monocular 3D depth perception
ID EXTRACTION
AB Social photo sharing platforms on the Internet (e.g. Flickr) host billions of publicly accessible photos captured by millions of individual users from all over the world. These user-contributed and geo-tagged photo collections provide insights into human sociocultural life and provide important clues for understanding people's engagement and reaction to places and events around the world today. In this paper, we analyze over 2 million geo-tagged images uploaded by 12,000 individual Flickr users to investigate the photograph shooting patterns of different user groups; that is, tourist and local, Asian and European, and male and female users. Specifically, we make use of visual features extracted on single monocular images and their spatial configurations to infer 3D depth information of the photographs to establish the preferred shooting scale (close-up or far-distant) of the user groups. The results reveal which objects and scenes interest different groups of people and how these preferences change over space and time. As such, the research offers a new approach to the human sciences which study the individual, groups and society.
C1 [Cao, Yanpeng] ASTAR, Visual Comp Dept, Inst Infocomm Res I2R, Singapore, Singapore.
   [O'Halloran, Kay] Curtin Univ, Sch Educ, Perth, WA 6845, Australia.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Curtin University
RP Cao, YP (corresponding author), ASTAR, Visual Comp Dept, Inst Infocomm Res I2R, Singapore, Singapore.
EM caoyp@i2r.a-star.edu.sg; kay.ohalloran@curtin.edu.au
RI O'Halloran, Kay/AAT-8830-2020
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P 18 INT C WORLD WID
   [Anonymous], 2007, MIR
   [Anonymous], SCI REPORTS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2003, Text, DOI [10.1515/text.2003.014, DOI 10.1515/TEXT.2003.014]
   [Anonymous], SEQUENTIAL MINIMAL O
   Arase Y., 2010, Proceedings of the international conference on Multimedia, MM '10, (New York, NY, USA), P133
   Barinova O, 2008, LECT NOTES COMPUT SC, V5303, P100, DOI 10.1007/978-3-540-88688-4_8
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Cao YP, 2012, COMPUT VIS IMAGE UND, V116, P86, DOI 10.1016/j.cviu.2011.09.002
   Conte R, 2012, EUR PHYS J-SPEC TOP, V214, P325, DOI 10.1140/epjst/e2012-01697-8
   Delage E, 2007, SPRINGER TRAC ADV RO, V28, P305
   Fan ZG, 2004, LECT NOTES COMPUT SC, V3316, P1026
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Garcia MA, 2004, IEEE INT CONF ROBOT, P847, DOI 10.1109/ROBOT.2004.1307255
   Griffin G., Caltech-256 object category dataset
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kosecká J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Leung D, 2010, PROC CVPR IEEE, P2955, DOI 10.1109/CVPR.2010.5540040
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Negoescu RA, 2010, IEEE T MULTIMEDIA, V12, P399, DOI 10.1109/TMM.2010.2050649
   Nister David, 2006, CVPR
   Pan YP, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P21, DOI 10.1109/ICVRV.2013.12
   Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Simon I, 2007, IEEE I CONF COMP VIS, P274
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Ulges A, 2011, IEEE T MULTIMEDIA, V13, P330, DOI 10.1109/TMM.2010.2101051
   Yanpeng C., 2009, IEEE Workshop on Applications of Computer Vision (WACV), P1
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
NR 45
TC 10
Z9 10
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11499
EP 11516
DI 10.1007/s11042-014-2247-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600024
DA 2024-07-18
ER

PT J
AU Cheng, B
   Hu, XX
   Zhang, SC
   Chen, JL
AF Cheng Bo
   Hu Xiaoxiao
   Zhang Shicheng
   Chen Junliang
TI Concurrent home multimedia conferencing platform using a service
   component architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concurrent; Ubiquitous; Home multimedia conferencing; Platform; Service
   component architecture
ID IPTV; QUALITY
AB Recent advances in audio/video processing, communication protocols, and Internet technologies have allowed for high-quality multimedia conferencing services at relatively low cost in the digital home. This paper presents a high concurrent and ubiquitous home multimedia conferencing platform using a service component architecture. For the proposed architecture, we focus on the design of a home multimedia conferencing platform framework, as well as home conferencing components, session management for media signaling, load balancing, and concurrent control for conferencing process management. We also present an efficient network address translation and a firewall traversal schema. High concurrency of the proposed architecture is achieved by coordinated distributed home conferencing services and concurrent control for conferencing process management. The performance of the proposed home multimedia conferencing platform has been evaluated, and the results show that the proposed architecture greatly improves the concurrency.
C1 [Cheng Bo; Hu Xiaoxiao; Zhang Shicheng; Chen Junliang] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100088, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Cheng, B (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100088, Peoples R China.
EM chengbo@bupt.edu.cn
FU National Grand Fundamental Research 973 Program of China [2011CB302506,
   2012CB315802]; National Key Technology Research and Development Program
   of China [2012BAH94F02]; National High-tech R&D Program of China (863
   Program) [2013AA102301]; National Natural Science Foundation of China
   [61132001]; Program for New Century Excellent Talents in University
   [NCET-11-0592]; New Generation Broad band Wireless Network
   [2014ZX03006003]
FX This research is supported by the National Grand Fundamental Research
   973 Program of China under Grant No. 2011CB302506, 2012CB315802;
   National Key Technology Research and Development Program of China (Grant
   No. 2012BAH94F02); National High-tech R&D Program of China (863 Program)
   under Grant No. 2013AA102301; National Natural Science Foundation of
   China under Grant No. 61132001); Program for New Century Excellent
   Talents in University (Grant No. NCET-11-0592); Project of New
   Generation Broad band Wireless Network under Grant No. 2014ZX03006003;
CR Almeroth KC, 2000, IEEE NETWORK, V14, P10, DOI 10.1109/65.819167
   Alves A., 2007, Web Services Business Process Execution Language Version 2.0
   Amirante A, 2011, IEEE COMMUN MAG, V49, P36, DOI 10.1109/MCOM.2011.5978413
   [Anonymous], PACK BAS MULT COMM S
   Barnes M., 2008, 5239 RFC IETF
   Chilamkurti N, 2013, MULTIMED TOOLS APPL, V65, P201, DOI 10.1007/s11042-011-0779-0
   Cho YH, 2007, CONSUM COMM NETWORK, P347, DOI 10.1109/CCNC.2007.75
   Develder C, 2012, TELECOMMUN SYST, V49, P129, DOI 10.1007/s11235-010-9358-3
   Dooms S, 2014, MULTIMED TOOLS APPL, V72, P281, DOI 10.1007/s11042-012-1347-y
   Femminella M, 2011, IEEE COMMUN LETT, V15, P1405, DOI 10.1109/LCOMM.2011.093011.110851
   Guo TT, 2011, IEEE T MULTIMEDIA, V13, P1116, DOI 10.1109/TMM.2011.2150208
   Jansen J, 2011, IEEE T MULTIMEDIA, V13, P869, DOI 10.1109/TMM.2011.2159369
   Kamel I, 2010, MULTIMED TOOLS APPL, V47, P87, DOI 10.1007/s11042-009-0408-3
   Kim J-T, 2008, IEEE T CONSUM ELECTR, V54, P864
   Kudumakis P, 2011, IEEE SIGNAL PROC MAG, V28, P159, DOI 10.1109/MSP.2011.942296
   Lee BD, 2011, IEEE T CONSUM ELECTR, V57, P1120, DOI 10.1109/TCE.2011.6018864
   Lee H, 2010, IEEE T CONSUM ELECTR, V56, P1473, DOI 10.1109/TCE.2010.5606285
   Matsufuru N, 1999, IEEE INFOCOM SER, P389, DOI 10.1109/INFCOM.1999.749306
   Mellia M, 2010, EUR T TELECOMMUN, V21, P324, DOI 10.1002/ett.1401
   Meng SC, 2013, IEEE T SERV COMPUT, V6, P358, DOI 10.1109/TSC.2012.4
   Park S, 2009, IEEE T CONSUM ELECTR, V55, P126, DOI 10.1109/TCE.2009.4814424
   Park WK, 2006, IEEE T CONSUM ELECTR, V52, P110, DOI 10.1109/TCE.2006.1605034
   Rosenberg J., 2008, 5389 IETF RFC
   Rosenberg J, 2012, 3261 RFC
   Rosenberg J., 2010, 5766 IETF RFC
   Rosenberg J, 2003, FRAMEWORK C IN PRESS
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Tien Anh Le, 2012, 2012 IEEE Wireless Communications and Networking Conference (WCNC), P2185, DOI 10.1109/WCNC.2012.6214155
   Trestian R, 2013, IEEE T BROADCAST, V59, P340, DOI 10.1109/TBC.2013.2244790
   Welsh M., 2001, Operating Systems Review, V35, P230, DOI 10.1145/502059.502057
   Wu WJ, 2006, INT J COMMUN SYST, V19, P445, DOI 10.1002/dac.803
NR 31
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10847
EP 10872
DI 10.1007/s11042-014-2210-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700032
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Yin, JS
   Yuadi, I
AF Tsai, Min-Jen
   Yin, Jin-Sheng
   Yuadi, Imam
TI Tree group based Wavelet Watermarking using Energy Modulation and
   Consistency Check (WW-EMCC) for digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Wavelet tree quantization; Wavelet Transform
ID MODIFIED ROBUST SCHEME; QUANTIZATION; PROTECTION; WTGM
AB Wavelet tree based watermarking algorithms are generally using the energy difference among grouped wavelet coefficients for invisible watermark embedding and extraction. According to cryptanalysis of wavelet tree quantization (WTQ) scheme, the robustness of watermarking is weak if the wavelet tree group coefficients are only unilaterally modulated. Therefore, bilaterally modulated techniques like modified wavelet tree quantization (MWTQ) and wavelet tree group modulation (WTGM) improve the security since the attackers can not decipher how tree coefficients are modulated. However, MWTQ needs the wavelet tree group information as the extra information which results the method is not purely blind for watermark extraction. For that matter, a novel wavelet tree group based watermarking using energy modulation and consistency check (WW-EMCC) is proposed in this study which not only resists the cryptanalysis attacks but also provides the dual function of choices for blind (WW-EMCCB) and non-blind (WW-EMCCN) watermark embedding. The essence of WW-EMCC design is to embed the watermark in the tree group coefficients as well as the relationship between the tree groups. Such approach extends the bilateral modulation into higher dimension of modulation and increase the robustness of security. In addition, WW-EMCC can even be modified as a captioning watermarking with lossless image quality which integrates watermarking and cryptography for copyright protection. This study has performed intensive comparison for the proposed scheme with WTQ, MWTQ and WTGM under various geometric and nongeometric attacks. The experimental results demonstrate that the proposed technique yields better performance with higher degree of robustness.
C1 [Tsai, Min-Jen; Yin, Jin-Sheng; Yuadi, Imam] Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
RI Yuadi/V-3570-2018
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Al-Otum HM, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2372467
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chan CS, 2012, J INF HIDING MULTIME, V3, P340
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ., 2007, DIGITAL WATERMARKING
   Das TK, 2006, MULTIMEDIA SYST, V12, P151, DOI 10.1007/s00530-006-0046-9
   Das TK, 2005, IEEE T SIGNAL PROCES, V53, P768, DOI 10.1109/TSP.2004.839930
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Huang HC, 2010, SIMUL MODEL PRACT TH, V18, P436, DOI 10.1016/j.simpat.2009.09.004
   KUNDUR D, 1998, P IEEE ICASSP, V5, P2869
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Podilchuk CI, 1998, IEEE J SEL AREA COMM, V16, P525, DOI 10.1109/49.668975
   Ritchey PhilipC., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P212
   SEDGEWICK R, 2001, ALGORITHMS C 1
   Tsai MJ, 2008, IEICE T FUND ELECTR, VE91A, P1961, DOI 10.1093/ietfec/e91-a.8.1961
   Tsai MJ, 2007, INT CONF ACOUST SPEE, P173
   Tsai MJ, 2008, IEICE A
   Voloshynovskiy Sviatoslav., 1999, Third International Workshop on Information Hiding, P211
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
NR 28
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11139
EP 11161
DI 10.1007/s11042-014-2222-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600009
DA 2024-07-18
ER

PT J
AU Wu, JH
   Zhu, JQ
   Liu, QG
   Zhang, Y
AF Wu, Jianhua
   Zhu, Jinqiang
   Liu, Qiegen
   Zhang, Ye
TI Human mouth-state recognition based on learned discriminative dictionary
   and sparse representation combined with homotopy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mouth-state recognition; Label consistent K-SVD; Discriminative
   dictionary; Homotopy; Sparse representation
ID K-SVD
AB In order to detect the number of audio sources and improve the speech recognition capability of an intelligent robot auditory system, recognizing human mouth-states, open or closed, is studied in this paper. A discriminative dictionary and sparse representation combined with homotopy based human mouth-state recognition algorithm is proposed. In the algorithm, a label consistent K-SVD (LC-KSVD) algorithm is used to learn a discriminative single over-complete dictionary and an optimal linear classifier simultaneously. Meanwhile, homotopy algorithm is used at the sparse decomposition stage. Experiments are carried out with the database established with the ROI images localized and extracted from the face images downloaded from Google online. Compared with several state-of-the-art methods, the proposed method obtains higher classification rates (CRs), costs less time for recognizing a test sample and has good noise immunity performance. Particularly, superior performance is attained when the training samples are extremely limited, even one sample per class.
C1 [Wu, Jianhua; Zhu, Jinqiang; Liu, Qiegen; Zhang, Ye] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
C3 Nanchang University
RP Zhang, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
EM zhangye@ncu.edu.cn
RI Wu, Jianhua/AFL-8480-2022; Li, Yuanyuan/J-3539-2014; zhou,
   chuyue/JOJ-9001-2023
OI Wu, Jianhua/0000-0002-4505-0568; Li, Yuanyuan/0000-0001-6151-9306; 
FU National Natural Science Foundation of China [61162014, 61210306074];
   Natural Science Foundation of Jiangxi Province [20122BAB201029]; Science
   & Technology Project of Jiangxi Provincial Department of Education
   [GJJ13008]; Science and Technology Program of Jiangxi Provincial
   Department of Education [GJJ14135, GJJ14583]; Graduate Student
   Innovation Special Funds of Jiangxi Province [YC2012-S016]
FX Our work was supported by the National Natural Science Foundation of
   China (61162014, 61210306074), the Natural Science Foundation of Jiangxi
   Province (20122BAB201029), the Science & Technology Project of Jiangxi
   Provincial Department of Education (GJJ13008), the Science and
   Technology Program of Jiangxi Provincial Department of Education
   (GJJ14135, GJJ14583) and the Graduate Student Innovation Special Funds
   of Jiangxi Province (YC2012-S016).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2009, PEARSON ED INDIA
   [Anonymous], 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2008.4587408
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Karahanoglu NB, 2012, DIGIT SIGNAL PROCESS, V22, P555, DOI 10.1016/j.dsp.2012.03.003
   Kong S, 2012, LECT NOTES COMPUT SC, V7572, P186, DOI 10.1007/978-3-642-33718-5_14
   Liu QJ, 2012, SIGNAL PROCESS, V92, P1916, DOI 10.1016/j.sigpro.2011.11.007
   Missaoui I., 2012, JDCTA INT J DIGITAL, V6, P532
   Moussallam M, 2012, SIGNAL PROCESS, V92, P2532, DOI 10.1016/j.sigpro.2012.03.019
   Qin Q, 2012, MEASUREMENT, V45, P897, DOI 10.1016/j.measurement.2012.02.005
   Rivet B, 2007, SPEECH COMMUN, V49, P667, DOI 10.1016/j.specom.2007.04.008
   Stiefelhagen R, 1997, EUR 97, P2007
   Wang CT, 2011, ISBE 2011: 2011 INTERNATIONAL CONFERENCE ON BIOMEDICINE AND ENGINEERING, VOL 2, P1, DOI 10.1109/APBITM.2011.5996279
   Wang SW, 2007, I C WIREL COMM NETW, P763, DOI 10.1109/SITIS.2007.37
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Ye Zhang, 2013, International Journal of Digital Content Technology and its Applications, V7, P599, DOI 10.4156/jdcta.vol7.issue4.72
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 22
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10697
EP 10711
DI 10.1007/s11042-014-2199-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700025
DA 2024-07-18
ER

PT J
AU Lu, P
   Sheng, B
   Luo, SM
   Jia, X
   Wu, W
AF Lu, Ping
   Sheng, Bin
   Luo, Shengmei
   Jia, Xia
   Wu, Wen
TI Image-based non-photorealistic rendering for realtime virtual sculpting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual sculpting; Non-photorealistic rendering; Image abstraction;
   Haptic feedback
AB This paper discusses a real-time virtual sculpting system in a non-photorealistic manner. Up till now, a majority of researchers pursuing virtual sculpting have highlighted the physical fidelity of simulation, with approaches for realizing photorealism being principal specialized contributions. We aim at capitalizing on the strengths of non-photorealistic rendering with respect to aesthetics, expression and computing expense. By means of touch-enabled manipulation, the haptic interaction is conducted to form the deformable surfaces, and the edge extraction is employed to stress boundaries. Afterwards, we utilize anisotropic diffusion to lessen unimportant details as well as a fresh inverse Gaussian bilateral filter for spot removal. Processed in a spatiotemporal style, the non-photorealistic rendering works to maintain coherence in time. Moreover, the parallel realization of the system put forward on graphics hardware (GPU) guarantees real-time behavior.
C1 [Lu, Ping] Southeast Univ, Sch Informat Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Lu, Ping; Luo, Shengmei; Jia, Xia] ZTE Corp, Shenzhen, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Sheng, Bin] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China.
   [Wu, Wen] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Southeast University - China; ZTE; Shanghai Jiao Tong University;
   Chinese Academy of Sciences; Institute of Software, CAS; University of
   Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
FU National Natural Science Foundation of China [61202154, 61133009];
   National Basic Research Project of China [2011CB302203]; Shanghai
   Pujiang Program [13PJ1404500]; National Laboratory of Pattern
   Recognition (Chinese Academy of Sciences); State Key Laboratory of
   CAD&CG, Zhejiang University [A1401]
FX Thanks to our colleagues for participating program testing and helpful
   discussion. The authors would like to thank all reviewers for their
   helpful suggestions and constructive comments. The work is supported by
   the National Natural Science Foundation of China (No.
   61202154,61133009), and the National Basic Research Project of China
   (No. 2011CB302203), in part by Shanghai Pujiang Program under Grant
   13PJ1404500, in part by the Open Project Program of the National
   Laboratory of Pattern Recognition (Chinese Academy of Sciences), and in
   part by the Open Project Program of the State Key Laboratory of CAD&CG,
   Zhejiang University, under Grant A1401.
CR Agusanto K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208, DOI 10.1109/ISMAR.2003.1240704
   [Anonymous], 1987, Intelligence: the eye, the brain, and the computer
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   Chen Hui., 2002, VRST 02, P81
   Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1109/SARNOF.2007.4567317, 10.1145/1276377.1276506, 10.1145/1239451.1239554]
   Collomosse JP, 2005, IEEE T VIS COMPUT GR, V11, P540, DOI 10.1109/TVCG.2005.85
   Dachille F, 2001, COMPUT AIDED DESIGN, V33, P403, DOI 10.1016/S0010-4485(00)00131-7
   Dachille F, 1999, S INT 3 D GRAPH P 19
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Edwards J. C., 1996, Proceedings of the Japan-USA Symposium on Flexible Automation - 1996, P221
   Fischer J, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P186
   Fischer J, 2005, P IEEE VIRT REAL ANN, P195
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Haeberli P., 1990, P SIGGRAPH, P207
   Haller M, 2005, ACM SIGGRAPH 2005 PO, P34
   Hallil A, 2004, MED PHYS, V31, P1912, DOI 10.1118/1.1636163
   Higashi M., 2002, Transactions of the ASME. Journal of Computing and Information Science in Engineering, V2, P265, DOI 10.1115/1.1559581
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kozamernik F, 2005, SMPTE MOTION IMAG J, V114, P152, DOI 10.5594/J11535
   Mark W. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P447, DOI 10.1145/237170.237284
   McMenemy Karen., 2007, HITCHHIKERS GUIDE VI
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Pham TQ, 2005, SEPARABLE BILATERAL
   Ruspini D. C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P345, DOI 10.1145/258734.258878
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   VERLET L, 1968, PHYS REV, V165, P201, DOI 10.1103/PhysRev.165.201
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Zhao HL, 2008, VISUAL COMPUT, V24, P727, DOI 10.1007/s00371-008-0254-8
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 33
TC 12
Z9 13
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9697
EP 9714
DI 10.1007/s11042-014-2146-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200029
DA 2024-07-18
ER

PT J
AU Hu, W
   Cheng, T
AF Hu, Wen
   Cheng, Tao
TI Simulative research on the function of internet of things basing on the
   changing of topological structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network resource; Topological structure; Network performance
AB As for the next generation of Internet, the Internet of things impacts people's lives profoundly, its application will be more broadly. There are many kinds of things network terminal, network topological structure is complex, the reset of network resource will drive the topological structure, changes, which have an important impact on network performance. By using the Simulative method, we study the relationship between the changes of topological structure and network performance before the network resource reset, which can improve the project of resource replacement, furthermore, improve the network performance.
C1 [Hu, Wen; Cheng, Tao] Harbin Univ Commerce, Sch Comp & Informat Engn, Harbin, Peoples R China.
C3 Harbin University of Commerce
RP Hu, W (corresponding author), Harbin Univ Commerce, Sch Comp & Informat Engn, Harbin, Peoples R China.
EM huwen1957@126.com
RI Hu, Wen/B-5784-2011
FU Heilongjiang Nature Science Fund [F201034]
FX Supported by Heilongjiang Nature Science Fund(F201034).
CR [Anonymous], INT J PUBLIC HLTH
   [Anonymous], INT J MULTIMEDIA UBI
   Chen K., 2009, INT J ADV SCI TECHNO, V4, P9
   Gao HD, 2012, INT J SECUR APPL, V6, P91
   Islam Md.S., 2011, International Journal of Advanced Science and Technology (IJAST), V36, P1
   Jun L, 2002, COMPUTER APPL RES, P54
   Leiming X., 2008, NS NETWORK SIMULATIO
   Salami O, 2010, INT J SECUR APPL, V4, P17
   Sharma K., 2010, International Journal of Advanced Science and Technology (IJAST), V17, P31
   Song L, 2012, COMPUTER SAFETY, P59
   Wei D, 2009, COMP ENG APPL
   Xu H, 2012, INT J FUTUR GENER CO, V5, P73
   Ye J, 2008, COMP APPL, P64
   Yuhua Y, 2011, COMP ENG
NR 14
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8445
EP 8454
DI 10.1007/s11042-013-1615-5
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600012
DA 2024-07-18
ER

PT J
AU Wu, HZ
   Wang, HX
   Zhao, H
   Yu, XY
AF Wu, Hanzhou
   Wang, Hongxia
   Zhao, Hong
   Yu, Xiuying
TI Multi-layer assignment steganography using graph-theoretic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Graph; Depth-first search; Multi-layer; Palette image
AB This paper proposes a novel multibit assignment steganographic scheme for palette images, in which some colors in the palette are exploited to represent several secret bits. For the proposed scheme, each palette color is treated as a graph vertex, and an edge among any two vertices indicates an adjacent relationship between them. A graph traversal technique named depth-first search is used to accomplish the multibit assignment for the vertices that correspond to the palette colors. The major idea of the proposed data-embedding is to modify colors of image pixels according to the assigned bits and secret message. Image pixels are classified as embeddable pixels and non-embeddable pixels before data-embedding. During the data-embedding, for each embeddable pixel, if the original color of the pixel matches the secret data, the pixel is then kept unchanged; otherwise, a suitable adjacent color of the original color will be used to replace the original color so that the new color matches the secret data. Experimental results show that the secret data can be embedded and extracted successfully without introducing visual artifacts, and the proposed scheme can always achieve a high capacity or maintain good image quality, comparing with the related works.
C1 [Wu, Hanzhou; Wang, Hongxia; Yu, Xiuying] Southwest Jiaotong Univ, Chengdu, Peoples R China.
   [Zhao, Hong] South Univ Sci & Technol China, Shenzhen, Peoples R China.
C3 Southwest Jiaotong University; Southern University of Science &
   Technology
RP Wang, HX (corresponding author), Southwest Jiaotong Univ, Chengdu, Peoples R China.
EM wuhanzhou_2007@126.com; hxwang@home.swjtu.edu.cn; zh1985444@gmail.com;
   xyyu@home.swjtu.edu.cn
RI Wu, Hanzhou/AAL-3361-2021; Wang, Hongxia/AAE-2135-2022
OI Wu, Hanzhou/0000-0002-1599-7232; 
FU National Natural Science Foundation of China (NSFC) [61170226,
   61373180]; Fundamental Research Funds for the Central Universities
   [SWJTU12ZT02]; Young Innovative Research Team of Sichuan Province
   [2011JTD0007]; Chengdu Science and Technology program [12DXYB214JH-002]
FX It was supported by the National Natural Science Foundation of China
   (NSFC) under the grant Nos. 61170226, 61373180, the Fundamental Research
   Funds for the Central Universities under the grant No. SWJTU12ZT02, the
   Young Innovative Research Team of Sichuan Province under the grant No.
   2011JTD0007, and Chengdu Science and Technology program under the grant
   No. 12DXYB214JH-002. The authors also gratefully acknowledge the worthy
   comments and suggestions of the reviewers.
CR Agaian SS, 2005, ARCHIVING 2005, FINAL PROGRAM AND PROCEEDINGS, P159
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], GIFSHUFFLE
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cogranne R, 2013, IEEE T INF FOREN SEC, V8, P464, DOI 10.1109/TIFS.2013.2238232
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Fridrich J, 2000, LECT NOTES COMPUT SC, V1768, P47
   Fridrich J, 2013, IEEE T INF FOREN SEC, V8, P361, DOI 10.1109/TIFS.2012.2235832
   Fridrich Jessica, 2010, Steganography in digital media: Principles, algorithms and applications
   Hetzl S, 2005, LECT NOTES COMPUT SC, V3677, P119
   Hetzl S., 2003, STEGHIDE
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Knuth D. E., 1997, ART COMPUTER PROGRAM, V2
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lifang Y, 2010, EURASIP J ADV SIG PR, V2010, P32
   Lin ZH, 2010, IETE TECH REV, V27, P318, DOI 10.4103/0256-4602.64605
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Machado R, 1996, EZSTEGO
   Niimi M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P917
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Tzeng CH, 2004, IEEE T COMMUN, V52, P791, DOI 10.1109/TCOMM.2004.826379
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang X, 2006, IEEE COMMUN LETT, V13, P285
   Zhang XP, 2008, IEEE SIGNAL PROC LET, V15, P553, DOI 10.1109/LSP.2008.2001117
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 31
TC 16
Z9 17
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8171
EP 8196
DI 10.1007/s11042-014-2050-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200034
DA 2024-07-18
ER

PT J
AU Lee, HJ
   Lee, W
   Kim, S
   Noh, M
   Kim, JG
   Kim, H
AF Lee, Hyun Jong
   Lee, Wonhyuk
   Kim, Seunghae
   Noh, Minki
   Kim, Jeom Goo
   Kim, Hyuncheol
TI A revised cache allocation algorithm for VoD multicast service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Streaming algorithm; IPTV VoD
AB The Internet is replacing the traditional telephone network as the ubiquitous network infrastructure. Internet customers are increasing at an exponential rate and will continue to increase in the near future. Among the various Internet services, IPTV VoD (Video on Demand) service is expected to be one of the most popular services. In general, for deploying streamed video service, it is likely to use proxy by locating it nearby end-users. The use of proxy in on-demand media streaming service can help reduce the server streaming load and reduce the startup delay of media playback due to swift retrieval of beginning portion of media. We had proposed a cache allocation scheme for server-proxy media streaming environment by utilizing the advantage of threshold-based multicast mechanism. However it suffer from a little radical change of threshold value. In this paper, enhanced multicast-based server-proxy on-demand media streaming algorithm to IPTV VoD services is presented from the storage, caching size and bandwidth requirement viewpoints.
C1 [Lee, Hyun Jong] Kakao Cooperat, Seoul, South Korea.
   [Lee, Wonhyuk; Kim, Seunghae; Noh, Minki] Korea Inst Sci Technol Informat, Daejon, South Korea.
   [Kim, Jeom Goo; Kim, Hyuncheol] Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
C3 Kakao; Korea Institute of Science & Technology Information (KISTI);
   Namseoul University
RP Kim, H (corresponding author), Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.
EM reneponette@gmail.com; livezone@kisti.re.kr; shkim@kisti.re.kr;
   mknoh@kisti.re.kr; jgoo@nsu.ac.kr; hckim@nsu.ac.kr
RI Kim, Seunghae/AAE-9934-2020
OI Kim, Seunghae/0000-0002-8403-7577
FU Namseoul university
FX This work was supported by Namseoul university. We would also like to
   thank the reviewers for their valuable comments, questions, and
   suggestions.
CR Brunkhorst Ingo, 2008, 2008 IEEE International Conference on Web Services (ICWS), P262, DOI 10.1109/ICWS.2008.37
   Cho C., 2009, IEEE INT S MODELING, P1
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Guangqian Kong, 2012, 2012 3rd International Conference on System Science, Engineering Design and Manufacturing Informatization (ICSEM 2012), P230, DOI 10.1109/ICSSEM.2012.6340851
   Lobzhanidze A, 2013, IEEE INT CON MULTI
   Park JG, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2014), P439, DOI 10.1109/ICOIN.2014.6799720
   Song E, 2007, 2007 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS, P523
   Sujatha DN, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P157, DOI 10.1109/IADCC.2010.5423020
   Yoon C, 2014, INT CONF ADV COMMUN, P73, DOI 10.1109/ICACT.2014.6778924
NR 9
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6557
EP 6572
DI 10.1007/s11042-014-2243-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700031
DA 2024-07-18
ER

PT J
AU Jang, YJ
   Kwak, J
AF Jang, Yu-Jong
   Kwak, Jin
TI Digital forensics investigation methodology applicable for social
   network services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Network Service; Digital forensic; Data analysis; Mobile device
AB Social network services (SNSs) contain various information such as conversations between users, user location information, personal network, and user psychology. This information can be useful for incident investigation. However, in SNSs, unlike computing services that offer services by saving data on a device, a device that uses a SNS with real-time synchronization generally only saves information that is not effective evidence, such as SNS usage log records. However, if digital evidence can be collected through an appropriate digital forensic process, various information such as a social network user's friend list, conversations, and personal relationships can be collected as digital evidence. Therefore, this paper suggests a digital forensic process for digital devices using SNSs. To analyze digital evidence about SNSs, this proposed method is composed of effective processes, classifying digital devices, collecting digital evidence, and analysis.
C1 [Jang, Yu-Jong] Soonchunhyang Univ, ISAA Lab Dept Informat Secur Engn, Asan, South Korea.
   [Kwak, Jin] Soonchunhyang Univ, Dept Informat Secur Engn, Asan, South Korea.
C3 Soonchunhyang University; Soonchunhyang University
RP Jang, YJ (corresponding author), Soonchunhyang Univ, ISAA Lab Dept Informat Secur Engn, Asan, South Korea.
EM uyjjang@gmail.com; jkwak@sch.ac.kr
OI Kwak, Jin/0000-0001-6931-2705
FU MSIP (Ministry of Science, ICT & Future Planning); Korea in the ICT;
   Soonchunhyang University Research Fund
FX This research was funded by the MSIP (Ministry of Science, ICT & Future
   Planning), Korea in the ICT R & D Program 2014.; This work was supported
   by the Soonchunhyang University Research Fund.
CR [Anonymous], J CONVERGENCE
   Choi J, 2013, SEOULNEWSPAPER
   Chorianopoulos K, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-10
   Dubey T, 2013, J INF PROCESS SYST, V9, P477, DOI 10.3745/JIPS.2013.9.3.477
   Gallego D, 2012, J CONVERG, V3, P31
   Jang Y, 2013, J KOREA NAVIG I, V17, P325
   Kim I, 2013, ETNEWS
   Lee S-H, 2011, J INF PROCESS SYST, V9, P287
   Lee SH, 2006, J KOREA I INF SECUR, V11, P87
   이지희, 2012, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V22, P1363
   Lim S, 2011, MBC NEWS, V2011
   Pyshkin E, 2010, J CONVERG, V1, P1
   Shtykh RY, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-2
   Teraoka T, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-1
   Zou MS, 2011, J INF PROCESS SYST, V7, P173, DOI 10.3745/JIPS.2011.7.1.173
NR 15
TC 14
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5029
EP 5040
DI 10.1007/s11042-014-2061-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900003
DA 2024-07-18
ER

PT J
AU Liu, YF
   Zhang, YF
   Zhang, CM
AF Liu, Yifang
   Zhang, Yunfeng
   Zhang, Caiming
TI A fast algorithm for YCbCr to perception color model conversion based on
   fixed-point DSP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time video system; Color space conversion; Perception color model;
   Video quality assessment
ID SEGMENTATION; SPACE; INTENSITY; IMAGES; VIDEO
AB Real-time video processing heavily relies on the color space conversion. Due to the real-time requirement, the traditional conversion methods often suffer from the moderate conversion speed, inaccuracy and low video quality. In order to meet the efficiency requirement of color space conversion in real-time video systems, we present a fast algorithm for color space YCbCr to perception color model conversion, which is based on the simplified shift and look-up table (SSLUT). The approach can be divided into two steps. At first, the simplified fixed-point shift method is used to convert YCbCr to RGB. Then look-up table assists with the YCbCr to perception color model conversion, such as HSV, HSI and HSL. To validate the proposed fast algorithm, the conversion speed and accuracy are compared with the traditional methods based on Code Composer Studio (CCS) test platform. Moreover, we make the video quality evaluation by using the peak signal-to-ratio (PSNR) and the structural similarity (SSIM). Experimental results illustrate the real-time, robustness and accuracy of the fast algorithm.
C1 [Liu, Yifang; Zhang, Yunfeng; Zhang, Caiming] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Liu, Yifang; Zhang, Yunfeng; Zhang, Caiming] Digital Media Technol, Shandong Prov Key Lab, Jinan 250014, Peoples R China.
C3 Shandong University of Finance & Economics
RP Zhang, YF (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
EM yfzhang@sdufe.edu.cn
RI Zhang, Caiming/AHD-6558-2022
OI Zhang, Caiming/0000-0002-6365-6221
FU National Natural Science Foundation of China (NSFC) [61073080,
   61020106001, 61202364, 61202150]; Natural Science Foundation of Shandong
   Province [ZR2010FQ025]
FX The work was supported by the National Natural Science Foundation of
   China (NSFC) (No. 61073080, 61020106001, 61202364, 61202150), Natural
   Science Foundation of Shandong Province (ZR2010FQ025).
CR [Anonymous], 2005, P MULT INF RETR WORK
   [Anonymous], 1978, ACM SIGGRAPH COMPUT, DOI [10.1145/800248.807361, DOI 10.1145/965139.807361]
   Bensaali F, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P265
   Briggs D, 2012, DIMENSIONS COLOUR
   Ford A., 1998, COLOUR SPACE CONVERS
   Han JZ, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P48, DOI 10.1109/ICOSP.2000.894441
   Inacio C, 1996, IEEE SPECTRUM, V33, P72, DOI 10.1109/6.535397
   Lee DJ, 2000, PROC SPIE, V4197, P358, DOI 10.1117/12.403782
   Li JF, 2002, P 1 INT C MACH LEARN, V3, P1493
   Liévin M, 2004, IEEE T IMAGE PROCESS, V13, P63, DOI 10.1109/TIP.2003.818013
   Liu Yi-fang, 2012, Application Research of Computers, V29, P741, DOI 10.3969/j.issn.1001-3695.2012.02.091
   Rasras R.J., 2007, COMPUT SCI INF SYST, V4, P43, DOI [10.2298/CSIS0701043R, DOI 10.2298/CSIS0701043R]
   Semary N, 2013, INT ARAB J INF TECHN, V10, P546
   Stokman H, 2007, IEEE T PATTERN ANAL, V29, P371, DOI 10.1109/TPAMI.2007.58
   Sural S., 2002, P IEEE INT C IM PROC, DOI DOI 10.1109/ICIP.2002.1040019
   Tiwari N, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P167, DOI 10.1109/IADCC.2010.5423018
   Wang SJ, 2009, J SYST SOFTWARE, V82, P656, DOI 10.1016/j.jss.2008.09.025
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Webb JLH, 2001, IEEE T CIRC SYST VID, V11, P981, DOI 10.1109/76.937449
   WEEKS AR, 1995, P SOC PHOTO-OPT INS, V2424, P291, DOI 10.1117/12.205231
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yang J, 2010, PATTERN RECOGN, V43, P1454, DOI 10.1016/j.patcog.2009.11.014
   Yang Y, 2007, IEEE T CONSUM ELECTR, V53, P1490, DOI 10.1109/TCE.2007.4429242
   Zhang C, 2000, INT C PATT RECOG, P613, DOI 10.1109/ICPR.2000.903620
   Zheng LY, 2009, COMPUT ELECTRON AGR, V65, P93, DOI 10.1016/j.compag.2008.08.002
NR 27
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 6041
EP 6067
DI 10.1007/s11042-014-1906-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100033
DA 2024-07-18
ER

PT J
AU Sharif, M
   Hussain, A
   Jaffar, MA
   Choi, TS
AF Sharif, Muhammad
   Hussain, Ayyaz
   Jaffar, Muhammad Arfan
   Choi, Tae-Sun
TI Fuzzy similarity based non local means filter for Rician noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image restoration; Magnetic resonance imaging; Image denoising;
   Rician noise; Fuzzy logic
ID MR-IMAGES
AB Rician noise contaminated Magnetic Resonance (MR) Images can effect the accuracy of quantitative analysis. For accurate analysis of MR data, noise smoothing is considered as an important pre-processing step. In this article, a novel Fuzzy Similarity based Non-Local Means (FSNLM) filter has been proposed for the removal of Rician noise from MR images. Proposed technique consists of three major modules: Pre-processing, Fuzzy similarity and Fuzzy restoration. In pre-processing module, some important statistical parameters are identified. These parameters are then used by the fuzzy similarity mechanism to find non-local homogeneous neighboring pixels. Selected homogeneous pixels play an important role during fuzzy logic based restoration process for the estimation of noise-free pixels. The proposed scheme FSNLM has been tested on simulated and real data sets, and compared with state-of-the-art filters based on well known global and local quantitative measures such as root-mean-squared-error (RMSE), peak-signal-to-noise-ratio (PSNR), structural-similarity-index-measure (SSIM), and figure-of-merit (FOM). Experimental results show that the proposed noise filtering technique is more effective than the existing methods, both at low and high densities of Rician noise.
C1 [Sharif, Muhammad; Jaffar, Muhammad Arfan] Natl Univ Comp & Emerging Sci FAST NU, Dept Comp Sci, Islamabad, Pakistan.
   [Hussain, Ayyaz; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Dept Mechatron, Signal & Image Proc Lab, Gwangju, South Korea.
   [Hussain, Ayyaz] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Jaffar, Muhammad Arfan] Al Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Gwangju Institute of Science & Technology (GIST); International Islamic
   University, Pakistan; Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Hussain, A (corresponding author), Gwangju Inst Sci & Technol, Dept Mechatron, Signal & Image Proc Lab, Gwangju, South Korea.
EM m.sharif@nu.edu.pk; ayyazhussain@gist.ac.kr;
   arfan.jaffar@ccis.imamu.edu.sa; tschoi@gist.ac.kr
RI Jaffar, Arfan/GQB-2768-2022
OI Choi, Tae-Sun/0000-0001-7496-2438
FU Mid-career Researcher Program through NRF - MEST [2012-0005542]; Higher
   Education Commission (HEC) of Pakistan
FX This work (2012-0005542) was supported by Mid-career Researcher Program
   through NRF grant funded by the MEST. Authors would also like to thank
   the Higher Education Commission (HEC) of Pakistan, for financial
   support.
CR [Anonymous], 1990, Two-Dimensional Signal and Image Processing
   [Anonymous], DIGITAL IMAGE PROCES
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Binaee K, 2011, MACH VIS IM PROC MVI, P1
   Bloch I, 2011, INFORM SCIENCES, V181, P2002, DOI 10.1016/j.ins.2010.03.019
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Deng ZF, 2007, IEEE SIGNAL PROC LET, V14, P31, DOI 10.1109/LSP.2006.881524
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Hamid MS, 2003, IEEE T CIRC SYST VID, V13, P406, DOI 10.1109/TCSVT.2003.811608
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   Hussain A, 2010, KNOWL INF SYST, V24, P77, DOI 10.1007/s10115-009-0236-9
   Krissian K, 2009, IEEE T IMAGE PROCESS, V18, P2265, DOI 10.1109/TIP.2009.2025553
   Liang SF, 2008, IEEE T FUZZY SYST, V16, P863, DOI 10.1109/TFUZZ.2008.917297
   Liu H, 2010, MAGN RESON IMAGING, V28, P1485, DOI 10.1016/j.mri.2010.06.023
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Matlab, 2009, VERS 7 9 0 R2009B
   Muresan DD, 2003, IEEE IMAGE PROC, P101
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Rice SO, 1944, BELL SYST TECH J, V23, P282, DOI 10.1002/j.1538-7305.1944.tb00874.x
   Samsonov AA, 2004, MAGN RESON MED, V52, P798, DOI 10.1002/mrm.20207
   Sharif M, 2010, LECT NOTES COMPUT SC, V6377, P525, DOI 10.1007/978-3-642-16167-4_67
   Sijbers J, 2004, MAGNET RESON MED, V51, P586, DOI 10.1002/mrm.10728
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WU J, 2012, SIVIP, V8, P349
   Yaroslavsky L, 2001, P SOC PHOTO-OPT INS, V4304, P155, DOI 10.1117/12.424970
NR 27
TC 18
Z9 19
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5533
EP 5556
DI 10.1007/s11042-014-1867-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100008
DA 2024-07-18
ER

PT J
AU Chambers, J
   Yan, W
   Garhwal, A
   Kankanhalli, M
AF Chambers, J.
   Yan, W.
   Garhwal, A.
   Kankanhalli, M.
TI Currency security and forensics: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Currency forensics; Currency security; Banknote recognition; Substrate
   analysis; Ink analysis; Counterfeit currency
ID FORGERY DETECTION; CLASSIFICATION; QUALITY; IDENTIFICATION;
   SPECTROSCOPY; SEPARATION; BLACK
AB By its definition, the word 'currency' refers to an agreed medium for exchange, a nation's currency is the formal medium enforced by the elected governing entity. Throughout history, issuers have faced one common threat: counterfeiting. Despite technological advancements, overcoming counterfeit production remains a distant future. Scientific determination of authenticity requires a deep understanding of the raw materials and manufacturing processes involved. This survey serves as a synthesis of the current literature to understand the technology and the mechanics involved in currency manufacture and security, whilst identifying gaps in the current literature. Ultimately, a robust currency is desired.
C1 [Chambers, J.; Yan, W.; Garhwal, A.; Kankanhalli, M.] AUT Univ, Auckland, New Zealand.
C3 Auckland University of Technology
RP Yan, W (corresponding author), AUT Univ, Auckland, New Zealand.
EM dcsyanwq@gmail.com
RI Kankanhalli, Mohan/Q-9284-2019; Garhwal, Abhimanyu Singh/AAE-5933-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015; Garhwal, Abhimanyu
   Singh/0000-0002-9810-6705
CR Adams G, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P263
   Ahmed DH, 2011, INT J HEAT FLUID FL, V32, P298, DOI 10.1016/j.ijheatfluidflow.2010.06.011
   Arabo A, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P818, DOI 10.1109/ICCCE.2008.4580719
   Baiqing Sun, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P90, DOI 10.1109/CSSE.2008.881
   Beekhof FP., 2008, P 1 INT ICST C FOR A, P1, DOI [10.4108/e-forensics.2008.2647, DOI 10.4108/E-FORENSICS.2008.2647]
   Bender K W., 2006, Moneymakers: The Secret World of Banknote Printing
   Berthier S, 2007, APPL PHYS A-MATER, V86, P123, DOI 10.1007/s00339-006-3723-9
   Bruna A, 2013, SENSORS-BASEL, V13, P2515, DOI 10.3390/s130202515
   Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   Burger A., 2009, DEV WORKSH MEM NAZ C
   Camenisch J, 2007, P IEEE S SECUR PRIV, P101, DOI 10.1109/SP.2007.15
   Cao Bu-Qing, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P246, DOI 10.1109/ICCMS.2010.270
   Chae SH, 2009, COMM COM INF SC, V56, P477, DOI 10.1007/978-3-642-10844-0_55
   Chia TH, 2009, OPT EXPRESS, V17, P22054, DOI 10.1364/OE.17.022054
   Chiang PJ, 2009, IEEE SIGNAL PROC MAG, V26, P72, DOI 10.1109/MSP.2008.931082
   Chin Chen Chang, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P860, DOI 10.1109/SITIS.2007.146
   Clarkson W, 2009, P IEEE S SECUR PRIV, P301, DOI 10.1109/SP.2009.7
   Daraee F., 2010, 6 IR MACH VIS IM PRO, V2010, P1
   Das VV, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P119, DOI 10.1109/FITME.2009.35
   Dasari H, 2007, PROC INT CONF DOC, P486
   Dass R., 2011, 2011 7th International Conference on Next Generation Web Services Practices, P99, DOI 10.1109/NWeSP.2011.6088160
   Dayakshini, 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P299, DOI 10.1109/RAICS.2011.6069322
   Debnath KK, 2009, 12 INT C COMP INF TE, P367
   Debnath KK, 2010, 12 INT C COMP INF TE, V5, P367
   Gai S, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P106, DOI 10.1109/ICICISYS.2009.5357719
   Gaubatz MD, 2009, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2009.5386463
   Gaubatz MD, 2009, IEEE IMAGE PROC, P1489, DOI 10.1109/ICIP.2009.5414608
   Geusebroek Jan-Mark, 2011, Proceedings of the 2011 International Conference on Pattern Analysis and Intelligent Robotics (ICPAIR 2011), P41, DOI 10.1109/ICPAIR.2011.5976909
   Glock S, 2009, LECT NOTES COMPUT SC, V5748, P422, DOI 10.1007/978-3-642-03798-6_43
   Gou HL, 2011, COMM COM INF SC, V202, P243
   Grijalva F., 2010, 2010 IEEE ANDESCON, P1
   Guedes A, 2013, SPECTROSC LETT, V46, P569, DOI 10.1080/00387010.2013.769007
   Guo JZ, 2008, I W ADV ISS E COMMER, P267, DOI [10.1109/CEC/EEE.2008.12, 10.1109/CECandEEE.2008.91]
   Halder Biswajit, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3212, DOI 10.1109/ICPR.2010.785
   Hasanuzzaman Faiz M, 2011, WOCC, V2011, P1
   Hasanuzzaman FM, 2012, IEEE T SYST MAN CY C, P1
   Hassanpour H, 2009, EXPERT SYST APPL, V36, P10105, DOI 10.1016/j.eswa.2009.01.057
   He KX, 2008, INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL 1, PROCEEDINGS, P159, DOI 10.1109/ICICTA.2008.35
   Heudt L, 2012, FORENSIC SCI INT, V219, P64, DOI 10.1016/j.forsciint.2011.12.001
   Hrishikesh Chabukswar, 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P222, DOI 10.1109/ICETET.2009.183
   Huang S, 2007, IEEE T INF FOREN SEC, V2, P164, DOI 10.1109/TIFS.2007.897255
   Huber-Mörk R, 2007, LECT NOTES COMPUT SC, V4673, P514
   Ishigaki T, 2008, INT CONF ACOUST SPEE, P1873, DOI 10.1109/ICASSP.2008.4517999
   Jahangir N, 2007, PROCEEDINGS OF 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT 2007), P379
   Jin Y, 2008, IEEE SIGNAL PROC LET, V15, P425, DOI 10.1109/LSP.2008.921470
   Junfang Guo, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P359, DOI 10.1109/ICNIDC.2010.5657978
   Kee E, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P3, DOI 10.1145/1411328.1411332
   Kersten J., 2010, ART MAKING MONEY STO
   Kim HY, 2007, SIBGRAPI, P105, DOI 10.1109/SIBGRAPI.2007.31
   Kim T, 2009, APMC: 2009 ASIA PACIFIC MICROWAVE CONFERENCE, VOLS 1-5, P1056, DOI 10.1109/APMC.2009.5384368
   Kulcar R, 2010, DYES PIGMENTS, V86, P271, DOI 10.1016/j.dyepig.2010.01.014
   Kumar D., 2010, Principles and practice of clinical cardiovascular genetics, P1, DOI [10.1109/NCC.2010.5430160, DOI 10.1109/NCC.2010.5430160]
   Kumpulainen P, 2011, NEURAL COMPUT APPL, V20, P803, DOI 10.1007/s00521-010-0497-y
   Kumpulainen P, 2009, COMM COM INF SC, V43, P178
   Lee KH, 2010, I C CONT AUTOMAT ROB, P1175, DOI 10.1109/ICARCV.2010.5707429
   Li Jing, 2010, 2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering (CMCE 2010), P286, DOI 10.1109/CMCE.2010.5610492
   Li WH, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P6262, DOI 10.1109/WCICA.2010.5554382
   Ling Y, 2007, IN C IND ENG ENG MAN, P1898, DOI 10.1109/IEEM.2007.4419522
   Liu L., 2010, IEEE Xplore, DOI [DOI 10.1109/ICMSS.2010.5576813, 10.1109/ICMSS.2010.5576813]
   Mirembe Drake Patrick, 2008, 2008 Third International Conference on Broadband Communications, Information Technology & Biomedical Applications, P389, DOI 10.1109/BROADCOM.2008.37
   Morshidi MA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P1335, DOI 10.1109/ICCCE.2008.4580822
   Nah J, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P595, DOI 10.1109/ISM.2009.82
   Neumann C, 2011, J CHROMATOGR A, V1218, P2793, DOI 10.1016/j.chroma.2010.12.070
   Nieves Javier, 2010, 2010 21st International Conference on Database and Expert Systems Applications, P247, DOI 10.1109/DEXA.2010.86
   Nishimura Kazuo, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P5347
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Omatu S, 2009, 2009 THIRD INTERNATIONAL CONFERENCE ON ADVANCED ENGINEERING COMPUTING AND APPLICATIONS IN SCIENCES (ADVCOMP 2009), P35, DOI 10.1109/ADVCOMP.2009.37
   Peng H, 2009, INTERNATIONAL CONFERENCE ON FUTURE NETWORKS, PROCEEDINGS, P220, DOI 10.1109/ICFN.2009.20
   Penrose J, 2011, POLIT GEOGR, V30, P429, DOI 10.1016/j.polgeo.2011.09.007
   Pollard SB, 2010, WORKSH INF FOR SEC W
   Pramoun T, 2009, 9 INT S COMM INF TEC, P247
   Preradovic S, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P206, DOI 10.1109/ICASID.2009.5276935
   Roy A, 2010, P 7 IND C COMP VIS G, P383
   Rusanov V, 2009, DYES PIGMENTS, V81, P254, DOI 10.1016/j.dyepig.2008.07.020
   Russ JohnC., 2007, IMAGE PROCESSING HDB, Vfifth
   Ryu SJ, 2008, LECT NOTES COMPUT SC, V5353, P486
   Sajal Raihan Ferdous, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P533, DOI 10.1109/ICCITECHN.2008.4803060
   Schulze C, 2008, LECT NOTES COMPUT SC, V5158, P35
   Shankar NG, 2009, MEASUREMENT, V42, P645, DOI 10.1016/j.measurement.2008.10.012
   Simske S, 2009, NIP 25: DIGITAL FABRICATION 2009, TECHNICAL PROGRAM AND PROCEEDINGS, P158
   Simske SJ, 2007, NIP 23: 23RD INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, TECHNICAL PROGRAM AND PROCEEDINGS/DIGITAL FABRICATION 2007, P543
   Simske SJ, 2008, J IMAGING SCI TECHN, V52, DOI 10.2352/J.ImagingSci.Technol.(2008)52:5(050201)
   Singh B, 2011, INT J COMPUT APPL, V16, P34, DOI DOI 10.5120/1999-2695
   Solymar Z., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P841, DOI 10.1109/ECCTD.2011.6043828
   Sumin Qian, 2011, 2011 17th International Conference on Automation and Computing, P230
   Sun BQ, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL II, PROCEEDINGS, P95, DOI 10.1109/IITA.2008.157
   Tarnoff B, 2011, MONEYMAKERES WICKED
   Tobbin P., 2011, 2011 Tenth International Conference on Mobile Business, ICMB, P185, DOI 10.1109/ICMB.2011.19
   Trémeau A, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.(2009)53:1(010201)
   van Benthem J, 2010, PROOFS CATEGORIES CO, P1
   van Beusekom J, 2011, PROC INT CONF DOC, P289, DOI 10.1109/ICDAR.2011.66
   Verikas A, 2011, EXPERT SYST APPL, V38, P13441, DOI 10.1016/j.eswa.2011.04.035
   Vila A, 2007, ANAL CHIM ACTA, V591, P97, DOI 10.1016/j.aca.2007.03.060
   Wang D-X, 2010, INT C ED INF TECHN I, V3
   Wang LL, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P536, DOI 10.1109/IAS.2009.23
   Wenfa Qi, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P881, DOI 10.1109/IIH-MSP.2009.58
   Wu QH, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL IV, P3, DOI 10.1109/GCIS.2009.225
   Wu YB, 2009, IEEE IMAGE PROC, P2909, DOI 10.1109/ICIP.2009.5413420
   Xie JB, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1268, DOI 10.1109/ROBIO.2009.5420820
   Yang CN, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, PROCEEDINGS, P439, DOI 10.1109/ISPA.2009.77
   Yeh CY, 2011, APPL SOFT COMPUT, V11, P1439, DOI 10.1016/j.asoc.2010.04.015
   Yoshida K, 2007, PROCEEDINGS OF 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT 2007), P402
   Zhang JL, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P585, DOI 10.1109/CIS.Workshops.2007.44
   Zhao LL, 2008, OPTOELECTRON LETT, V4, P371, DOI 10.1007/s11801-008-8039-x
   Zhongnian Li, 2009, Proceedings of the 2009 9th International Conference on Electronic Measurement & Instruments (ICEMI 2009), P1, DOI 10.1109/ICEMI.2009.5274513
   Zhou Hong, 2009, 2009 WRI World Congress on Computer Science and Information Engineering (CSIE 2009), P126, DOI 10.1109/CSIE.2009.194
   Zhou Wan-chun, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V7147, DOI 10.1117/12.813210
   Zhu Y., 2009, 2009 International Conference on Computational Science and Engineering (CSE), P326, DOI 10.1109/CSE.2009.364
   Ziljak V, 2009, INFRARED PHYS TECHN, V52, P62, DOI 10.1016/j.infrared.2009.01.001
NR 109
TC 32
Z9 33
U1 0
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4013
EP 4043
DI 10.1007/s11042-013-1809-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hsieh, SL
   Chen, CC
   Chen, CR
AF Hsieh, Shang-Lin
   Chen, Chun-Che
   Chen, Chuan-Ren
TI A novel approach to detecting duplicate images using multiple hash
   tables
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Duplicate image detection; Image copy detection; Image hashing; Multiple
   hash tables
ID COPY DETECTION; SCHEME
AB This paper presents a new duplicate image detection scheme that adopts multiple hash tables in a novel way for quick image matching and, consequently, fast duplicate detection. The proposed scheme contains two phases: the feature generation phase and the duplication inspection phase. The former phase extracts the features of images that need protection and transforms them into key-value pairs, which are stored in the slots of multiple hash tables. When a possibly duplicated image needs to be examined, the latter phase hashes the features of the suspect image into the corresponding slots of the multiple hash tables and determines if the suspect image is a duplicate one. The execution time of the scheme is relatively short thanks to the unique design of the multiple hash tables. The experimental results show that the proposed scheme obtained satisfactory results both on the recall and precision rates, hence demonstrating it can effectively identify duplicate images including digitally modified copies.
C1 [Hsieh, Shang-Lin; Chen, Chun-Che; Chen, Chuan-Ren] Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.
   [Chen, Chun-Che] Taipei Coll Maritime Technol, Taipei, Taiwan.
C3 Tatung University
RP Hsieh, SL (corresponding author), Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.
EM slhsieh@ttu.edu.tw; f1079@mail.tcmt.edu.tw; indigozizz@gmail.com
FU Tatung University, Taipei, Taiwan [B100-I07-036]
FX Financial support of this study by Tatung University, Taipei, Taiwan,
   under grant B100-I07-036 is gratefully acknowledged.
CR [Anonymous], 2010, J COMPUT INFORM SYST
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BERRANI S.-A., 2003, Proceedings of the 1st ACM international workshop on Multimedia databases, P70, DOI DOI 10.1145/951676.951690
   Ghosh P, 2007, ADV INTELLIGENT INFO, P149
   Hsieh SL, 2011, MULTIMED TOOLS APPL, V52, P597, DOI 10.1007/s11042-010-0520-4
   Hsu CY, 2009, IEEE IMAGE PROC, P1281, DOI 10.1109/ICIP.2009.5413600
   Kekre HB, 2010, J SCI ENGG TECH MGT, V2
   Khan N. Y., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P501, DOI 10.1109/DICTA.2011.90
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Ling HF, 2011, MULTIMED TOOLS APPL, V52, P551, DOI 10.1007/s11042-009-0439-9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Nikolaidis N, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P3, DOI 10.1109/ICAPR.2009.83
   Peker Kadir A., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P217, DOI 10.1109/CBMI.2011.5972548
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Voyatzis G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P237, DOI 10.1109/ICIP.1996.560753
   Wan YH, 2008, CONF CYBERN INTELL S, P738, DOI 10.1109/ICCIS.2008.4670942
   Wang Shuo-zhong, 2007, Journal of Shanghai University, V11, P323, DOI 10.1007/s11741-007-0401-2
   Wu MN, 2005, LECT NOTES ARTIF INT, V3801, P464
   Yao Jinliang, 2011, 2011 International Conference of Soft Computing and Pattern Recognition, P258, DOI 10.1109/SoCPaR.2011.6089117
   Zhan RX, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P119, DOI 10.1109/ISDA.2008.66
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
NR 25
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4947
EP 4964
DI 10.1007/s11042-014-1857-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400024
DA 2024-07-18
ER

PT J
AU Leszczuk, M
   Dudek, L
   Witkowski, M
AF Leszczuk, Mikolaj
   Dudek, Lukasz
   Witkowski, Marcin
TI Classification of video sequences into chosen generalized use classes of
   target size and lighting level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subjective evaluation techniques; Objective evaluation techniques;
   Quality of experience; Implementation
AB The VQiPS (Video Quality in Public Safety) Working Group, supported by the U.S. Department of Homeland Security, has been developing a user guide for public safety video applications. According to VQiPS, five parameters have particular importance influencing the ability to achieve a recognition task. They are: usage time-frame, discrimination level, target size, lighting level, and level of motion. These parameters form what are referred to as Generalized Use Classes (GUCs). The aim of our research was to develop algorithms that would automatically assist classification of input sequences into one of the GUCs. Target size and lighting level parameters were approached. The experiment described reveals the experts' ambiguity and hesitation during the manual target size determination process. However, the automatic methods developed for target size classification make it possible to determine GUC parameters with 70 % compliance to the end-users' opinion. Lighting levels of the entire sequence can be classified with an efficiency reaching 93 %. To make the algorithms available for use, a test application has been developed. It is able to process video files and display classification results, the user interface being very simple and requiring only minimal user interaction.
C1 [Leszczuk, Mikolaj; Dudek, Lukasz; Witkowski, Marcin] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Dudek, L (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM leszczuk@agh.edu.pl; vq@kt.agh.edu.pl
RI Witkowski, Marcin/S-3331-2017; Leszczuk, Mikołaj I/C-4857-2011
OI Witkowski, Marcin/0000-0003-2921-6502; Leszczuk, Mikołaj
   I/0000-0001-9123-1039
FU European Community [218086]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2013) under
   grant agreement No. 218086.
CR Dalka P, 2011, COMM COM INF SC, V149, P37
   Duplaga M, 2008, OPTO-ELECTRON REV, V16, P428, DOI 10.2478/s11772-008-0041-0
   International Telecommunication Union, 2008, ITU T P 912 SUBJ VID
   International Telecommunication Union, 1999, ITU T P 910 SUBJ VID
   Janowski L, 2012, 4 INT WORKSH QUAL MU, P182, DOI [10.1109/QoMEX.2012.6263863, DOI 10.1109/QOMEX.2012.6263863]
   Janowski L, 2014, MULTIMED TOOLS APPL, V68, P23, DOI 10.1007/s11042-012-1199-5
   Leszczuk M, 2011, 2011 IEEE INT S BROA, P1, DOI [10.1109/BMSB.2011.5954938, DOI 10.1109/BMSB.2011.5954938]
   Leszczuk M, 2011, COMM COM INF SC, V149, P10
   Szwoch G., 2008, 2008 SIGN PROC ALG A, P15
   Szwoch G, 2008, PROCEEDINGS OF THE 2008 1ST INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, P337
   The MathWorks Inc., 2013, MATL DOC
   VQiPS, 2011, VID QUAL TESTS OBJ R
   Witkowski M, 2012, IEEE INT SYM BROADB, DOI 10.1109/BMSB.2012.6264239
NR 13
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4381
EP 4395
DI 10.1007/s11042-013-1546-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600012
PM 26321872
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Peng, JL
   Li, Q
   El-Latif, AAA
   Niu, XM
AF Peng, Jialiang
   Li, Qiong
   El-Latif, Ahmed A. Abd
   Niu, Xiamu
TI Linear discriminant multi-set canonical correlations analysis (LDMCCA):
   an efficient approach for feature fusion of finger biometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal biometrics; Finger; Feature fusion; Canonical correlation
   analysis
ID FEATURE-LEVEL FUSION; KNUCKLE-PRINT; VEIN; IDENTIFICATION; GEOMETRY
AB Feature fusion-based multimodal biometrics has become an increasing interest to many researchers in recent years, particularly for finger biometrics. There are, however, many challenges in fusing multiple feature sets, as the case with Canonical Correlation Analysis (CCA) and Multi-set Canonical Correlation Analysis (MCCA). How to extend them to fuse multiple feature sets is a significant problem in general. In this paper, we propose a novel multimodal finger biometric method, which provides feature fusion approach called linear discriminant multi-set canonical correlation analysis (LDMCCA). It combines finger vein, fingerprint, finger shape and finger knuckle print features of a single human finger. Compared with CCA and MCCA, LDMCCA contains the class information of the training samples and represents the fused features more efficiently and discriminatively in few dimensions. The experimental results on a merged multimodal finger biometric database show that LDMCCA is beneficial to fuse multiple features as well as achieves lower error rates than the existing approaches.
C1 [Peng, Jialiang; Li, Qiong; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Peng, Jialiang] Heilongjiang Univ, Informat & Network Adm Ctr, Harbin 150080, Peoples R China.
   [El-Latif, Ahmed A. Abd] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Heilongjiang University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Li, Q (corresponding author), Harbin Inst Technol, Sci Zone, Room 1523,Bldg 2A,2 Yikuang St, Harbin 150080, Peoples R China.
EM qiong.li@hit.edu.cn
RI Abd El-Latif, Ahmed A. A./GRO-1613-2022
OI Abd El-Latif, Ahmed A. A./0000-0002-5068-2033
FU Fundamental Research Funds for the Central Universities [HIT. NSRIF.
   2013061]; Ministry of Scientific Research (Egypt-Tunisia Cooperation
   Program)
FX This work is supported by The Fundamental Research Funds for the Central
   Universities (Grant Number: HIT. NSRIF. 2013061) and Ministry of
   Scientific Research (Egypt-Tunisia Cooperation Program).
CR [Anonymous], 2008, P 2008 INT C CONTENT, DOI DOI 10.1145/1386352.1386373
   [Anonymous], 5 INT C DIG IM PROC
   [Anonymous], 56 SESS INT STAT SOC
   [Anonymous], 2006, Handbook of Multibiometrics
   [Anonymous], 2009, Encyclopedia of Biometrics
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   He MX, 2010, PATTERN RECOGN, V43, P1789, DOI 10.1016/j.patcog.2009.11.018
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   Kang B, 2011, OPT ENG, V50
   Kang BJ, 2010, IET COMPUT VIS, V4, P209, DOI 10.1049/iet-cvi.2009.0081
   KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Lee HC, 2009, P INT C UBIQ INFORM, P307
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Peng JL, 2013, IEICE T INF SYST, VE96D, P1886, DOI 10.1587/transinf.E96.D.1886
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719
   Sun N, 2010, NEURAL COMPUT APPL, V19, P377, DOI 10.1007/s00521-009-0291-x
   Sun QS, 2005, LECT NOTES COMPUT SC, V3686, P268
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Wang N, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.2.023013
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P623, DOI 10.1016/j.patrec.2011.11.002
   Yu P, 2010, ADV COMP THEOR ENG I, V5, pV5
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zhang L, 2012, PATTERN RECOGN, V45, P2522, DOI 10.1016/j.patcog.2012.01.017
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
   Zhu LQ, 2010, PATTERN RECOGN LETT, V31, P1641, DOI 10.1016/j.patrec.2010.05.010
NR 34
TC 32
Z9 39
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4469
EP 4486
DI 10.1007/s11042-013-1817-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400001
DA 2024-07-18
ER

PT J
AU Kim, M
   Lee, DW
   Kim, K
   Kim, JH
AF Kim, Minkyung
   Lee, Dong-Wook
   Kim, Kangseok
   Kim, Jai-Hoon
TI Hierarchical structured data logging system for effective lifelog
   management in ubiquitous environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lifelog; Lifelog management system; Activity recognition; Hierarchical
   structured data logging; Mobile device; Ubiquitous computing
ID SENSECAM
AB The researches for collecting personal daily behaviors and providing lifelog services with them have been recently increasing. Recent advances in mobile devices and sensor technologies have motivated to collect a huge amount of personal lifelog data in real time. With the rapid growth of the need for the research, there is a coming need for the effective lifelog management system which collects time-series big lifelog data sent from sensing devices and extracts major activities through processing them. For the effective lifelog management, the lifelog data can be processed in separated computing resources depending on the size and level of data. In this paper, we propose hierarchical structured data logging to support lifelog based personal services and to reduce the processing complexity and storage cost. First, we present the architecture of personal lifelog management system. With the system we present hierarchical lifelog data logging to optimally utilize computing and storage resources. Then we describe cost analysis and performance comparison for demonstrating the efficacy of our proposed system. Finally, as an initial step for experiments in our research, we describe experimental results of recognizing physical activities and extracting lifelog data which indicate major activities from them.
C1 [Kim, Minkyung] Ajou Univ, Grad Sch, Dept Comp Engn, Suwon 441749, South Korea.
   [Lee, Dong-Wook] Ajou Univ, Ubiquitous Convergence Res Inst, Suwon 441749, South Korea.
   [Kim, Kangseok] Ajou Univ, Grad Sch, Dept Knowledge Informat Engn, Suwon 441749, South Korea.
   [Kim, Jai-Hoon] Ajou Univ, Dept Informat & Comp Engn, Suwon 441749, South Korea.
C3 Ajou University; Ajou University; Ajou University; Ajou University
RP Kim, JH (corresponding author), Ajou Univ, Dept Informat & Comp Engn, Suwon 441749, South Korea.
EM dendlonglove@ajou.ac.kr; dwlee@ajou.ac.kr; kangskim@ajou.ac.kr;
   jaikim@ajou.ac.kr
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [NRF-2012R1A1A2A10041537]
FX This research is supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science and Technology (NRF-2012R1A1A2A10041537).
CR [Anonymous], P FTRA INT C ADV IT
   [Anonymous], P CEWIT INT C
   [Anonymous], 2003, P 26 ANN INT ACM SIG
   [Anonymous], 2010, P 1 AUGMENTED HUMAN
   [Anonymous], P 6 INT C INF INT WE
   [Anonymous], J CONVERG
   [Anonymous], INT J MULTIMED UBIQU
   [Anonymous], MSRTR2004102
   Blum M, 2006, IEEE MULTIMEDIA, V13, P40, DOI 10.1109/MMUL.2006.87
   Byrne D, 2010, MULTIMED TOOLS APPL, V49, P119, DOI 10.1007/s11042-009-0403-8
   Dickie C., 2004, P THE 1 ACM WORKSHOP, P105
   Doherty AR, 2011, COMPUT HUM BEHAV, V27, P1948, DOI 10.1016/j.chb.2011.05.002
   Doherty AR, 2010, SENSORS-BASEL, V10, P1423, DOI [10.3390/100301423, 10.3390/s100301423]
   Gemmell J, 2006, COMMUN ACM, V49, P88, DOI 10.1145/1107458.1107460
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Hodges S, 2011, MEMORY, V19, P685, DOI 10.1080/09658211.2011.605591
   Kim B, 2012, J INF PROCESS SYST, V8, P555, DOI 10.3745/JIPS.2012.8.4.555
   Latif Khalid., 2006, P INT C COMPUTING IN
   Lee H, 2008, MULTIMEDIA SYST, V14, P341, DOI 10.1007/s00530-008-0129-x
   Teraoka T, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/2192-1962-2-1
   Whittaker S, 2008, PERS UBIQUIT COMPUT, V12, P197, DOI 10.1007/s00779-007-0146-3
NR 21
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3561
EP 3577
DI 10.1007/s11042-013-1671-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000021
DA 2024-07-18
ER

PT J
AU Choi, YH
   Park, MW
   Eom, JH
   Chung, TM
AF Choi, Young-Hyun
   Park, Min-Woo
   Eom, Jung-Ho
   Chung, Tai-Myoung
TI Dynamic binary analyzer for scanning vulnerabilities with taint analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary analysis; Taint analysis; Dynamic analysis; Vulnerability
AB In this paper, we introduce an overview of a dynamic binary analyzer for scanning vulnerabilities by performing taint analysis. People have been using the traditional security programs of pattern matching technique such as anti-virus and anti-spyware to protect their computer from malicious code. These security programs, however, cannot completely scan malicious behaviors attacking through the unknown vulnerability and are hard to protect from the attacks using self-modifying code which changes its own codes during runtime. To prevent these security risks, we develop the dynamic binary analyzer that can find these unknown vulnerabilities and self-modifying code. We adopt taint analysis to find vulnerabilities that transpire during runtime. Also using taint analysis let us check what effects have been occurred to programs by the input data and how they do spread widely to across the resources in an operating system. Adopting the dynamic analysis that drives and analyzes the system only in virtual machine circumstance through the emulator can make us detect the falsification of program code in program operational process. So we describe the framework of our analyzer and then explain the execution process and output of each process by using three test case demonstrations. Furthermore, we introduce several test cases of the security vulnerability for the demonstration and explain the results of proposed analyzer on test cases. The dynamic binary analyzer for scanning vulnerabilities with taint analysis (1) can find out existed security vulnerabilities in binary file, (2) can monitor all the actions of the binary file that affects operating system and (3) can be an expandable tool through the additional security element and policy.
C1 [Choi, Young-Hyun; Park, Min-Woo] Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon, Gyeonggi Do, South Korea.
   [Eom, Jung-Ho] Daejeon Univ, Mil Studies, Taejon, South Korea.
   [Chung, Tai-Myoung] Sungkyunkwan Univ, Dept Software, Suwon, Gyeonggi Do, South Korea.
C3 Sungkyunkwan University (SKKU); Daejeon University; Sungkyunkwan
   University (SKKU)
RP Chung, TM (corresponding author), Sungkyunkwan Univ, Dept Software, 300 Cheoncheon Dong, Suwon, Gyeonggi Do, South Korea.
EM yhchoi@imtl.skku.ac.kr; mwpark@imtl.skku.ac.kr; eomhun@gmail.com;
   tmchung@ece.skku.ac.kr
FU Priority Research Centers Program through the National Research
   Foundation of Korea (NRF) - Ministry of Education, Science and
   Technology [2012-0005861]
FX This work was supported by Priority Research Centers Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science and Technology (2012-0005861).
CR Bellard F., 2007, Qemu open source processor emulator
   Brumley David, 2011, Computer Aided Verification. Proceedings 23rd International Conference, CAV 2011, P463, DOI 10.1007/978-3-642-22110-1_37
   Caballero J, 2010, CRASH ANAL BITBLAZE
   Choi Y-H, 2013, P ICISA 2013 PATT, P374
   Chow J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P321
   Claburn T, 2009, INFORM WEEK GOVT
   Clause J., 2007, P 2007 INT S SOFTW T
   Elinor M, 2009, CNET NEWS
   Heo GI, 2015, MULTIMED TOOLS APPL, V74, P8831, DOI 10.1007/s11042-013-1627-1
   Jang YT, 2015, MULTIMED TOOLS APPL, V74, P159, DOI 10.1007/s11042-013-1430-z
   Kang Min Gyung, 2011, NDSS
   Martyn W, 2009, COMPUTERWORLD
   Mayer CB, 2004, MULTIMED TOOLS APPL, V24, P233, DOI 10.1023/B:MTAP.0000039389.56384.be
   Min J-W, 2013, P ICCSA2013, P195
   Newsome J., 2004, TECHNICAL REPORT
   Rahbar A, 2006, STACK OVERFLOW WINDO
   Scholten M., 2007, TAINT ANAL PRACTICE, P1
   Schwartz EJ, 2010, P IEEE S SECUR PRIV, P317, DOI 10.1109/SP.2010.26
   Song D, 2008, LECT NOTES COMPUT SC, V5352, P1, DOI 10.1007/978-3-540-89862-7_1
   SUDWORTH J, 2009, BBC NEWS
   Urueña M, 2014, MULTIMED TOOLS APPL, V68, P159, DOI 10.1007/s11042-012-1155-4
   Wu HT, 2013, MULTIMED TOOLS APPL, V66, P215, DOI 10.1007/s11042-011-0792-3
   Yin H., 2007, Panorama: Capturing system-wide information flow for malware detection and analysis
NR 23
TC 9
Z9 14
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2301
EP 2320
DI 10.1007/s11042-014-1922-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200008
DA 2024-07-18
ER

PT J
AU Jung, H
   Yoo, H
   Lee, Y
   Chung, KY
AF Jung, Hoill
   Yoo, Hyun
   Lee, Youngho
   Chung, Kyung-Yong
TI Interactive pain nursing intervention system for smart health service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive health; Collaborative filtering; Nursing support; Medical
   data mining; Pain; Intervention
ID MODEL
AB In modern society, the amount of information has significantly increased due to the development of BT-IT convergence technology. This leads to developing information obtaining and searching technologies from much data. Although system integration for medicare has been largely established to accumulate large amounts of information, there is a lack of provision and support of information for nursing activities, using such an established database. In particular, the judgment for pain intervention depends on the experience of individual nurses, leading to usually making subjective decisions. Thus, there is some danger in applying unwanted anesthesia and drug abuse. In this paper, we proposed the interactive pain nursing intervention system for smart health service. The proposed method uses collaborative filtering that extracts some pain strengths, which represent a high relative level, based on similar pain strengths. Pain strength estimation method using collaborative filtering calculates patient similarities through Pearson correlation coefficients in which a neighbor selection method is used based on the pain strength. In general, medical data in patients shows various distributions due to its own characteristics, as sample data demonstrates. Therefore, this is determined as an applicable theory to the sparsity problem. In addition, it is compensated using a default voting method. The medical data evaluated by applying standard data and its accuracy in pain prediction is verified. The test of the proposed method yielded excellent extraction results; it is possible to provide the fundamental data and guideline to nurses for recognizing the pain of patients based on the results of this study. This represents increased patient welfare for smart health services.
C1 [Jung, Hoill] Sangji Univ, Sch Comp Informat Engn, Intelligent Syst Lab, Wonju 220702, Gangwon Do, South Korea.
   [Yoo, Hyun] Sangji Univ, Comp Syst Team, Wonju 220702, Gangwon Do, South Korea.
   [Lee, Youngho] Gachon Univ, Dept Comp Sci, Songnam, Gyeonggi Do, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
C3 Sangji University; Sangji University; Gachon University; Sangji
   University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, 83 Usan Dong, Wonju 220702, Gangwon Do, South Korea.
EM hijung1982@gmail.com; rhpa@sangji.ac.kr; lyh@gachon.ac.kr;
   dragonhci@hanmail.net
RI Chung, Kyungyong/JAC-2276-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2013R1A1A2059964]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2059964)
CR Baek SJ, 2013, WIRELESS PERS COMMUN, V73, P309, DOI 10.1007/s11277-013-1239-0
   Boutaba R, 2014, CLUSTER COMPUT, V17, P723, DOI 10.1007/s10586-014-0349-0
   Brekken Shirley A, 2008, Nurs Adm Q, V32, P288, DOI 10.1097/01.NAQ.0000336725.03065.44
   Chung KY, 2014, PERS UBIQUIT COMPUT, V18, P1291, DOI 10.1007/s00779-013-0743-2
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P843, DOI 10.1007/s11042-013-1355-6
   Chung KY, 2013, WIRELESS PERS COMMUN, V73, P243, DOI 10.1007/s11277-013-1234-5
   Fumikazu T, 1994, J KOREAN PAIN SOC, V7, P1
   Goh I., 2011, J ARCHIT I KOREA, V31
   Ha OK, 2014, PERS UBIQUIT COMPUT, V18, P553, DOI 10.1007/s00779-013-0675-x
   Han JS, 2015, MULTIMED TOOLS APPL, V74, P9087, DOI 10.1007/s11042-013-1664-9
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Jung EY, 2013, WIRELESS PERS COMMUN, V73, P207, DOI 10.1007/s11277-013-1231-8
   Jung EY, 2011, J NURS ED TODAY, V32, P458
   Jung H, 2015, MULTIMED TOOLS APPL, V74, P8979, DOI 10.1007/s11042-013-1730-3
   Jung KY, 2004, IEICE T INF SYST, VE87-D, P154
   정호일, 2013, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V13, P1, DOI 10.5392/JKCA.2013.13.04.001
   류현, 2011, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V11, P1
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   Kang SK, 2013, WIRELESS PERS COMMUN, V73, P341, DOI 10.1007/s11277-013-1242-5
   Kim GH, 2015, MULTIMED TOOLS APPL, V74, P8745, DOI 10.1007/s11042-013-1536-3
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Kim JY, 2014, MULTIMED TOOLS APPL, V68, P465, DOI 10.1007/s11042-013-1357-4
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Kim K, 2015, PEER PEER NETW APPL, V8, P610, DOI 10.1007/s12083-014-0257-3
   Kim O. N., 2009, U HLTH COMING US, P23
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Kim SH, 2014, MULTIMED TOOLS APPL, V68, P455, DOI 10.1007/s11042-013-1356-5
   Ko JW, 2015, MULTIMED TOOLS APPL, V74, P8907, DOI 10.1007/s11042-013-1581-y
   Lin WY, 2002, DATA MIN KNOWL DISC, V6, P83, DOI 10.1023/A:1013284820704
   Melzack R, 2005, ANESTHESIOLOGY, V103, P199, DOI 10.1097/00000542-200507000-00028
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Park I.S., 2010, J KOREAN CLIN NURS R, V16, P128
   정귀임, 2004, [Journal of Korean Clinical Nursing Research, 임상간호연구], V10, P111
   Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159
   Song MH, 2015, MULTIMED TOOLS APPL, V74, P8861, DOI 10.1007/s11042-013-1665-8
   Wang J, 2006, LECT NOTES COMPUT SC, V3936, P37
   Yoo H, 2011, PAIN NURSING INTERVE
   Yoo H., 2011, LNEE, V120, P435
NR 39
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2449
EP 2466
DI 10.1007/s11042-014-1923-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200017
DA 2024-07-18
ER

PT J
AU Wang, JH
   Chang, HC
AF Wang, Jenq-Haur
   Chang, Hung-Chi
TI CoBITs: a distributed indexing approach to collaborative content-based
   multimedia retrieval across digital archives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed archiving; Distributed crawler; Collaborative repository;
   Peer-to-peer computing; Content-based retrieval
ID PERFORMANCE
AB There's more and more precious content digitized in digital archives especially for cultural heritage. It could cost much effort in digitization and archiving. To meet the requirements in a digital archiving system, several issues must be addressed. First, it usually requires resources such as computation and storage for each individual digital archive to maintain its own service. Second, the archived content would be more useful if they can be easily utilized in providing services such as searching across multiple archives. Current approaches usually adopt metadata harvesting that would build a centralized index from separate digital libraries. They usually suffer from the problem of metadata inconsistency. In this paper, we propose a distributed indexing approach to collaborative content-based multimedia retrieval across digital archives. To reduce the loads in each archive, we dynamically distribute the tasks of crawling, indexing, and query processing depending on the response time. Distributed crawler-based approach can simplify the design of indexing and query processing steps by maintaining the data to be indexed local to the machine for crawling. It can facilitate efficient archiving and indexing by automatically following the link structure of contents published on the Web. Also, it enables simpler implementation and easier support for cross-archive applications such as search and copy detection. Experimental results show the potential of the proposed approach in load balancing with appropriate task distribution.
C1 [Wang, Jenq-Haur] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Chang, Hung-Chi] Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
C3 National Taipei University of Technology; Academia Sinica - Taiwan
RP Wang, JH (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
EM jhwang@csie.ntut.edu.tw; cchess0201@hotmail.com
RI Wang, Jenq-Haur/HJJ-1020-2023
OI Wang, Jenq-Haur/0000-0002-6076-7380
FU National Science Council, Taiwan [NSC101-2219-E-027-005]
FX We would like to thank the support from National Science Council, Taiwan
   under the grant number NSC101-2219-E-027-005.
CR [Anonymous], 2002, Advances in Information Retrieval. The Information Retrieval Series, DOI DOI 10.1007/0-306-47019-55
   Banbridge D, 2004, P 8 EUR C RES ADV TE, P1
   Bender M., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P67, DOI 10.1145/1076034.1076049
   Boldi P, 2004, SOFTWARE PRACT EXPER, V34, P711, DOI 10.1002/spe.587
   Buchanan G, 2005, ACM-IEEE J CONF DIG, P23, DOI 10.1145/1065385.1065392
   Cho Junghoo., 2002, WWW 02, P124, DOI [DOI 10.1145/511446.511464, 10.1145/511446.511464]
   Efron M, 2011, P AM SOC INFO SCI TE, V48, P1, DOI [10.1002/meet.2011.14504801048, DOI 10.1002/MEET.2011.14504801048]
   Heydon A., 1999, World Wide Web, V2, P219, DOI 10.1023/A:1019213109274
   Lagoze Carl., OPEN ARCH INITIATIVE
   Liu XM, 2003, ACM-IEEE J CONF DIG, P191
   Lu J, 2005, LECT NOTES COMPUT SC, V3408, P52
   Lu Jie., 2003, CIKM 03, P199
   Maniatis P, 2005, ACM T COMPUT SYST, V23, P2, DOI 10.1145/1047915.1047917
   Payette S., 1998, Research and Advanced Technology for Digital Libraries. Second European Conference, ECDL'98. Proceedings, P41
   Seára EFR, 2012, INT J DIGIT LIBRARIE, V12, P13, DOI 10.1007/s00799-012-0080-5
   Shkapenyuk V, 2002, PROC INT CONF DATA, P357, DOI 10.1109/ICDE.2002.994750
   Simeoni F, 2008, J AM SOC INF SCI TEC, V59, P12, DOI 10.1002/asi.20694
   Singh A., 2003, SIGIR WORKSHOP DISTR, P126
   Smith M., 2003, D LIB MAG, V9
   Staples T, 2003, D LIB MAG, V9
   Stribling J, 2005, LECT NOTES COMPUT SC, V3640, P69, DOI 10.1007/11558989_7
   Suel Torsten., 2003, WEBDB, P67
   Teregowda Pradeep, 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P115, DOI 10.1109/CLOUD.2010.49
   Trnkoczy J, 2008, FUTURE GENER COMP SY, V24, P824, DOI 10.1016/j.future.2008.04.007
   Trnkoczy J, 2006, LIBR COLLECT ACQUIS, V30, P139, DOI 10.1016/j.lcats.2006.12.004
   Vignatti T, 2009, IEEE INT CONF PEER, P194, DOI 10.1109/P2P.2009.5284519
   Wang J, 2008, PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE OF MODELLING AND SIMULATION, VOL IV, P332
   Wittek P., 2011, Proceedings of the 2011 IEEE 3rd International Conference on Cloud Computing Technology and Science (CloudCom 2011), P606, DOI 10.1109/CloudCom.2011.93
NR 28
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2639
EP 2658
DI 10.1007/s11042-013-1461-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300005
DA 2024-07-18
ER

PT J
AU Hsieh, CC
   Karkoub, M
   Lai, WR
   Lin, PH
AF Hsieh, Chen-Chiung
   Karkoub, Mansour
   Lai, Wei-Ru
   Lin, Po-Hong
TI Visual people counting using gender features and LRU updating scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Digital signage; Gender classification; People counting
ID CLASSIFICATION; SURVEILLANCE; TRACKING; MOTION
AB The general public spends a significant amount of time in front of digital signage seeking information from many venues such as exhibition halls and shopping centers. This is why advertisement purchasers believe that the number of passing viewers provides crucial information for their marketing strategies. In this paper, a real-time person counting/memorizing system is designed capable of distinguishing the gender of potential customers. An adaptive boosting (Adaboost) machine learning algorithm is used to detect human faces and utilize specific filtering criteria to eliminate useless data. For each detected person, face and torso information are recorded in a database for identification. The least recently used identification record will be deleted if the database is full. Gender classification is performed by support vector machine using hair ratios extracted from gender characterizing regions. Based on a variety of experiments, the accuracy of the proposed algorithm is higher than 90 % for person-counting and higher than 94 % for gender classification. Moreover, the execution speed on personal computers may reach 15-20 fps.
C1 [Hsieh, Chen-Chiung; Lin, Po-Hong] Tatung Univ, Dept Comp Sci & Engn, Taipei 104, Taiwan.
   [Karkoub, Mansour] Texas A&M Univ Qatar, Dept Mech Engn, Doha, Qatar.
   [Lai, Wei-Ru] Yuan Ze Univ, Dept Commun Engn, Chungli 320, Taiwan.
C3 Tatung University; Qatar Foundation (QF); Texas A&M University Qatar;
   Yuan Ze University
RP Hsieh, CC (corresponding author), Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Jhongshan N Rd, Taipei 104, Taiwan.
EM cchsieh@ttu.edu.tw
OI Hsieh, Chen-Chiung/0000-0002-7716-7306
FU National Science Foundation of the Republic of China [NSC
   97-2622-E-036-003-CC3]
FX This work was supported in part by the National Science Foundation of
   the Republic of China under grant NSC 97-2622-E-036-003-CC3.
CR Ahn JH, 2009, PATTERN ANAL APPL, V12, P167, DOI 10.1007/s10044-008-0112-3
   [Anonymous], P 10 IASTED INT C CO
   [Anonymous], P INT C COMP VIS WOR
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], PATTERN CLASSIFICATI
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 2003, PROC GRAPHICON
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Chen DY, 2008, TRIIS08009 AC SIN
   Collins R., 2000, CMURITR0012
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Khan S. A., 2011, 2011 Proceedings of the IEEE 14th International Multitopic Conference (INMIC 2011), P25, DOI 10.1109/INMIC.2011.6151483
   Kim HC, 2006, PATTERN RECOGN LETT, V27, P618, DOI 10.1016/j.patrec.2005.09.027
   Lian XC, 2009, LECT NOTES COMPUT SC, V5507, P647, DOI 10.1007/978-3-642-03040-6_79
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651
   Rodriguez M., 2011, P INT C COMP VIS
   Sivic J, 2005, P ACM INT C IM VID R
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Steinwart I, 2002, J COMPLEXITY, V18, P768, DOI 10.1006/jcom.2002.0642
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang RYR, 2005, PATTERN ANAL APPL, V7, P343, DOI 10.1007/s10044-004-0231-4
   Wong YS, 2012, LECT NOTES COMPUT SC, V7332, P228, DOI 10.1007/978-3-642-31020-1_27
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xia B, 2008, IEEE IJCNN, P3388, DOI 10.1109/IJCNN.2008.4634279
NR 31
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1741
EP 1759
DI 10.1007/s11042-013-1715-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500002
DA 2024-07-18
ER

PT J
AU Ul Qayyum, Z
AF Ul Qayyum, Zia
TI Image retrieval through qualitative representations over semantic
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Semantic features; Qualitative representations;
   Qualitative similarity
ID CLASSIFICATION
AB This paper proposes a qualitative knowledge-driven semantic modelling approach for image understanding and retrieval. The similarity measure is calculated for each query by exploiting the notion of conceptual neighbourhood-a measure of closeness between qualitative relations. The relative similarity of two images is proportional to the qualitative similarity measure value. The approach is motivated by the need to bridge the semantic gap between a human user and that of CBIR systems and enable semantic querying in such systems. Local semantic concepts, such as sky, grass, of an image are used to obtain a semantic image description. Four kinds of qualitative spatial representations have been applied to these semantic concepts. This allows for representation and reasoning of an image's content structures at a more abstract level than pixels or other low level features and provides a higher level, semantic basis for image understanding. We investigate whether such a representation of an image's visual content also provides an effective and natural way to provide content-oriented querying. We also investigate whether querying based on multiple representations is effective, and report on three voting schemes used to retrieve images in this way. The test data set having hand-assigned class labels has been used to have a metric evaluation of the retrieval accuracy. The results compare favourably with a non-qualitative representation based on the same semantic features which simply compares the percentage of each feature in pairs of images.
C1 Natl Univ Comp & Emerging Sci, Dept Comp Sci, Faisalabad, Pakistan.
RP Ul Qayyum, Z (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Chiniot Faisalabad Campus, Faisalabad, Pakistan.
EM ziaqayyum@gmail.com
FU National University of Sciences & Technology, Rawalpindi-Pakistan
FX We thank Julia Vogel for providing the labelled data set and helpful
   discussions and acknowledge financial support provided by National
   University of Sciences & Technology, Rawalpindi-Pakistan, to Zia Ul
   Qayyum during period of this research.
CR Aghrabi Z, 2003, NII J
   Allen J.F., 1983, COMMUNICATIONS ACM, V26
   Bradshaw B, 2000, SEMANTIC BASED IMAGE
   Bruns T., 1996, proceedings of the the Seven International Symposium on Spatial Data Handling (SDH'96), P173
   Ciocca G, 2011, INFORM SCIENCES, V181, P4943, DOI 10.1016/j.ins.2011.06.025
   Cohn A G, 2006, RES DEV INTELLIGENT, VXXIII
   Cohn AG, 2001, FUND INFORM, V46, P1
   Deb S, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P59
   Depalov Dejan, 2006, P SPIE, V6057
   Enser P, 2003, SPRINGER LECT NOTES, V27-28, P279
   FREKSA C, 1992, ARTIF INTELL, V54, P199, DOI 10.1016/0004-3702(92)90090-K
   Howe NR, 2003, LECT NOTES COMPUT SC, V2728, P61
   HYVONEN E, 2002, P XML FINL 2002 C HE, P15
   Iqbal Q., 2002, C CONTROL AUTOMATION, P205
   Li B., 2006, SPAT COGN COMPUT, V6, P31, DOI [10.1207/s15427633scc0601_2, DOI 10.1207/S15427633SCC0601_2]
   Madugunki M., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P372, DOI 10.1109/ICECTECH.2011.5941923
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Mörchen F, 2005, STUD CLASS DATA ANAL, P272, DOI 10.1007/3-540-28084-7_30
   Picard R, 1995, ACM J MULTISYST
   Qayyum ZU, 2007, P 18 BRIT MACH VIS C, P1
   Randell D. A., 1992, Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference (KR '92), P165
   Rasiwasia N, 2006, LECT NOTES COMPUT SC, V4071, P51
   Sebe N, 2003, LECT NOTES COMPUT SC, V2728, P1
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Singha Manimala, 2012, SIGNAL IMAGE PROCESS, V3
   Singhai N., 2010, International Journal of Computer Applications IJCA, V4, P22, DOI DOI 10.5120/802-1139
   Sun JY, 2002, P 1 INT C MACH LEARN
   TOWN CP, 2000, 200014 AT T LAB CAMB
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   WANG W, 2002, P 15 INT C VIS INT V
   Wu Siqing, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P3095, DOI 10.1109/CECNET.2011.5768297
NR 32
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1935
EP 1959
DI 10.1007/s11042-013-1731-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ben Ahmed, O
   Benois-Pineau, J
   Allard, M
   Ben Amar, C
   Catheline, G
AF Ben Ahmed, Olfa
   Benois-Pineau, Jenny
   Allard, Michele
   Ben Amar, Chokri
   Catheline, Gwenaeelle
CA Alzheimers Dis Neuroimaging
TI Classification of Alzheimer's disease subjects from MRI using
   hippocampal visual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based visual indexing; Visual features; Circular Harmonic
   Functions descriptors; SVM; Bag-of-Visual-Words; Late fusion;
   Hippocampus; CSF
ID MILD COGNITIVE IMPAIRMENT; IMAGE RETRIEVAL; SEGMENTATION; SCALE;
   MORPHOMETRY; ATROPHY
AB Indexing and classification tools for Content Based Visual Information Retrieval (CBVIR) have been penetrating the universe of medical image analysis. They have been recently investigated for Alzheimer's disease (AD) diagnosis. This is a normal "knowledge diffusion" process, when methodologies developed for multimedia mining penetrate a new application area. The latter brings its own specificities requiring an adjustment of methodologies on the basis of domain knowledge. In this paper, we develop an automatic classification framework for AD recognition in structural Magnetic Resonance Images (MRI). The main contribution of this work consists in considering visual features from the most involved region in AD (hippocampal area) and in using a late fusion to increase precision results. Our approach has been first evaluated on the baseline MR images of 218 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database and then tested on a 3T weighted contrast MRI obtained from a subsample of a large French epidemiological study: "Bordeaux dataset". The experimental results show that our classification of patients with AD versus NC (Normal Control) subjects achieves the accuracies of 87 % and 85 % for ADNI subset and "Bordeaux dataset" respectively. For the most challenging group of subjects with the Mild Cognitive Impairment (MCI), we reach accuracies of 78.22 % and 72.23 % for MCI versus NC and MCI versus AD respectively on ADNI. The late fusion scheme improves classification results by 9 % in average for these three categories. Results demonstrate very promising classification performance and simplicity compared to the state-of-the-art volumetric AD diagnosis methods.
C1 [Ben Ahmed, Olfa; Benois-Pineau, Jenny; Allard, Michele; Catheline, Gwenaeelle] Univ Bordeaux, LaBRI, Lab Bordelais Rech Informat, Bordeaux, France.
   [Allard, Michele; Catheline, Gwenaeelle] Univ Bordeaux, Aquitaine Inst Cognit & Integrat Neurosci, Bordeaux, France.
   [Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, Sfax, Tunisia.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); Universite de Bordeaux; Universite de Sfax; Ecole Nationale
   dIngenieurs de Sfax (ENIS)
RP Ben Ahmed, O (corresponding author), Univ Bordeaux, LaBRI, Lab Bordelais Rech Informat, Bordeaux, France.
EM olfa.ben-ahmed@labri.fr; jenny.benois@labri.fr;
   michelle.allard@chu-bordeaux.fr; chokri.benamar@ieee.org;
   gwenaelle.catheline@chu-bordeaux.fr
RI catheline, gwenaelle/C-8532-2018; Benois-Pineau, Jenny/ABG-6325-2020;
   Chokri, BEN AMAR/K-5237-2012
OI Benois-Pineau, Jenny/0000-0003-0659-8894; 
FU Franco-Tunisian program; LaBRI, University of Bordeaux 1; university of
   Bordeaux 2; Alzheimer's Disease Neuroimaging Initiative (ADNI) (National
   Institutes of Health) [U01 AG024904]; DOD ADNI (Department of Defense)
   [W81XWH-12-2-0012]; National Institute on Aging; National Institute of
   Biomedical Imaging and Bioengineering; Canadian Institutes of Health
   Research
FX This research is supported by the Franco-Tunisian program, the LaBRI,
   University of Bordeaux 1 and university of Bordeaux 2. Data collection
   and sharing for this project was funded by the Alzheimer's Disease
   Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01
   AG024904) and DOD ADNI (Department of Defense award number
   W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging,
   the National Institute of Biomedical Imaging and Bioengineering, and
   through generous contributions from the following: Alzheimer's
   Association; Alzheimer's Drug Discovery Foundation; BioClinica, Inc.;
   Biogen Idec Inc.; Bristol-Myers Squibb Company; Eisai Inc.; Elan
   Pharmaceuticals, Inc.; Eli Lilly and Company; F. Hoffmann-La Roche Ltd
   and its affiliated company Genentech, Inc.; GE Healthcare; Innogenetics,
   N.V.; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research &
   Development, LLC.; Johnson & Johnson Pharmaceutical Research &
   Development LLC.; Medpace, Inc.; Merck & Co., Inc.; Meso Scale
   Diagnostics, LLC.; NeuroRx Research; Novartis Pharmaceuticals
   Corporation; Pfizer Inc.; Piramal Imaging; Servier; Synarc Inc.; and
   Takeda Pharmaceutical Company. The Canadian Institutes of Health
   Research is providing funds to support ADNI clinical sites in Canada.
   Private sector contributions are facilitated by the Foundation for the
   National Institutes of Health (www.fnih.org). The grantee organization
   is the Northern California Institute for Research and Education, and the
   study is coordinated by the Alzheimer's Disease Cooperative Study at the
   University of California, San Diego. ADNI data are disseminated by the
   Laboratory for Neuro Imaging at the University of Southern California.
CR Agarwal M, 2010, LECT NOTES COMPUT SC, V5853, P49, DOI 10.1007/978-3-642-11769-5_5
   Akgul CeyhunBurak., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, p34:1, DOI DOI 10.1145/1646396.1646438
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Ayache S, 2007, LECT NOTES COMPUT SC, V4425, P494
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Ben Ahmed O, 2013, INT WORK CONTENT MUL, P79, DOI 10.1109/CBMI.2013.6576557
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Catheline G, 2010, NEUROBIOL AGING, V31, P1582, DOI 10.1016/j.neurobiolaging.2008.08.012
   Chupin M, 2009, NEUROIMAGE, V46, P749, DOI 10.1016/j.neuroimage.2009.02.013
   Chupin M, 2009, HIPPOCAMPUS, V19, P579, DOI 10.1002/hipo.20626
   Colliot O, 2008, RADIOLOGY, V248, P194, DOI 10.1148/radiol.2481070876
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013
   Daliri MR, 2012, J MED SYST, V36, P995, DOI 10.1007/s10916-011-9738-6
   Gerardin E, 2009, NEUROIMAGE, V47, P1476, DOI 10.1016/j.neuroimage.2009.05.036
   Gutman B, 2009, HIPPOCAMPUS, V19, P572, DOI 10.1002/hipo.20627
   Klöppel S, 2008, BRAIN, V131, P681, DOI 10.1093/brain/awm319
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Liu YW, 2011, NEUROBIOL AGING, V32, P1198, DOI 10.1016/j.neurobiolaging.2009.07.008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mangin JF, 2003, LECT NOTES COMPUT SC, V2732, P160
   Mizotin M, 2012, IEEE IMAGE PROC, P1241, DOI 10.1109/ICIP.2012.6467091
   Müller H, 2011, BIOL MED PHYS BIOMED, P471, DOI 10.1007/978-3-642-15816-2_19
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Platt JC, 2000, ADV NEUR IN, P61
   Ridha BH, 2007, ARCH NEUROL-CHICAGO, V64, P849, DOI 10.1001/archneur.64.6.849
   Rueda Andrea, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P559, DOI 10.1007/978-3-642-33275-3_69
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shaw LM, 2009, ANN NEUROL, V65, P403, DOI 10.1002/ana.21610
   Shen KK, 2012, NEUROIMAGE, V59, P2155, DOI 10.1016/j.neuroimage.2011.10.014
   Sorgi L., 2006, BMVC, P539, DOI [10.5244/C.20.56, DOI 10.5244/C.20.56]
   Sorokin DV, 2011, LECT NOTES COMPUT SC, V6753, P284, DOI 10.1007/978-3-642-21593-3_29
   Toews M, 2010, NEUROIMAGE, V49, P2318, DOI 10.1016/j.neuroimage.2009.10.032
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Unay D, 2010, IEEE T INF TECHNOL B, V14, P897, DOI 10.1109/TITB.2009.2038152
   Villain N, 2008, J NEUROSCI, V28, P6174, DOI 10.1523/JNEUROSCI.1392-08.2008
   Wolz R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025446
   Yang XF, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047406
NR 40
TC 74
Z9 77
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1249
EP 1266
DI 10.1007/s11042-014-2123-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300006
DA 2024-07-18
ER

PT J
AU Shen, SY
   Huang, LH
   Tian, QL
AF Shen, Shuyuan
   Huang, Lihong
   Tian, Qinglong
TI A novel data hiding for color images based on pixel value difference and
   modulus function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Data hiding; LSB; Modulus function; PVD
ID SCHEME
AB This paper proposes a novel data hiding method using pixel-value difference and modulus function for color image with the large embedding capacity(hiding 810757 bits in a 512x512 host image at least) and a high-visual-quality of the cover image. The proposed method has fully taken into account the correlation of the R, G and B plane of a color image. The amount of information embedded the R plane and the B plane determined by the difference of the corresponding pixel value between the G plane and the median of G pixel value in each pixel block. Furthermore, two sophisticated pixel value adjustment processes are provided to maintain the division consistency and to solve underflow and overflow problems. The most importance is that the secret data are completely extracted through the mathematical theoretical proof.
C1 [Shen, Shuyuan; Huang, Lihong] Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
   [Shen, Shuyuan] S China Normal Univ, Sch Software, Guangzhou 510631, Guangdong, Peoples R China.
   [Huang, Lihong] Hunan Womens Univ, Inst Appl Math & Intelligent Informat Proc, Changsha 410004, Hunan, Peoples R China.
   [Tian, Qinglong] Hunan Univ, Coll Elect & Informat Technol, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University; South China Normal University; Hunan University
RP Shen, SY (corresponding author), Hunan Univ, Coll Math & Econometr, Changsha 410082, Hunan, Peoples R China.
EM ssyuan02@126.com; lhhuang@hnu.edu.cn
RI Huang, Li/IUQ-0909-2023
FU Natural Science Foundation of P.R. China [11371127, 11101164]; Natural
   Science Foundation of Guangdong [S2011040003243]
FX This work was supported by the Natural Science Foundation of P.R. China
   (11371127, 11101164) and Natural Science Foundation of
   Guangdong(S2011040003243)
CR [Anonymous], INT J INFORM SCI TEC
   Celik MU, 2002, IEEE INT C IM PROC, V2, P1646
   Chae JJ, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P460, DOI 10.1109/ICIP.1998.723528
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGNIT LET
   Chang CC, 2009, SOFT COMPUT, V13, P321, DOI 10.1007/s00500-008-0332-x
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang K.-C., 2007, Systems, Man and Cybernetics, P1165
   Fridrich J, 2001, P 4 INF HID WORKSH P, V2137, P27
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Jiun-Jian Liaw, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P650, DOI 10.1109/ICGEC.2010.166
   Jung KH, 2008, ICHIT 2008: INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, PROCEEDINGS, P355, DOI 10.1109/ICHIT.2008.279
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Li SL, 2006, IS16004 ICICIC
   Lin MH, 2002, INT J PATTERN RECOGN, V16, P697, DOI 10.1142/S0218001402001903
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu T, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1568, DOI 10.1109/ICOSP.2002.1180096
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Ni RR, 2002, 2002 IEEE REGION 10 CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND POWER ENGINEERING, VOLS I-III, PROCEEDINGS, P598, DOI 10.1109/TENCON.2002.1181346
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang RZ, 2006, IEE ELECT LETT, V36, P2069
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xuan GR, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P211
   Yalman Y., 2010, Proceedings 2010 IEEE 13th International Conference on Computational Science and Engineering (CSE 2010), P346, DOI 10.1109/CSE.2010.52
   Yang C.H., 2006, P INT COMP S TAIP TA, P831
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 36
TC 27
Z9 28
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 707
EP 728
DI 10.1007/s11042-014-2016-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400003
DA 2024-07-18
ER

PT J
AU Xu, RY
   Guan, YP
   Huang, YZ
AF Xu, Ruiyue
   Guan, Yepeng
   Huang, Yizhen
TI Multiple human detection and tracking based on head detection for
   real-time video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human detection and tracking; Real-time; Associative mechanism
ID PARTICLE FILTER
AB Multiple human detection and tracking is a very important and active research topic in computer vision. At present, the recognition performance is not satisfactory, which is mainly due to the fact that the full-body of human cannot be captured efficiently by cameras. In this paper, an improved method is developed to detect and track multiple heads by considering them as rigid body parts. The appearance model of human heads is updated according to fusion of color histogram and oriented gradients. An associative mechanism of detection and tracking has been developed to recover transient missed detections and suppress transient false detections. The object identity can be kept invariant during tracking even if unavoidable occlusion occurs. Besides, the proposed method is fast to detect and track multiple human in a dynamic scene without any hypothesis for the scenario contents in advance. Comparisons with state-of-the-arts have indicated the superiority and good performance of the proposed method.
C1 [Xu, Ruiyue; Guan, Yepeng; Huang, Yizhen] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Guan, Yepeng] Minist Educ, Key Lab Adv Displays & Syst Applicat, Shanghai, Peoples R China.
C3 Shanghai University
RP Guan, YP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM ypguan@shu.edu.cn
FU Natural Science Foundation of China [11176016, 60872117]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20123108110014]
FX This work is supported in part by the Natural Science Foundation of
   China (Grant No. 11176016, 60872117), and Specialized Research Fund for
   the Doctoral Program of Higher Education (Grant No. 20123108110014).
CR Ali I, 2012, IMAGE VISION COMPUT, V30, P966, DOI 10.1016/j.imavis.2012.08.013
   [Anonymous], 200137540 CAVIAR IST
   [Anonymous], UT-Interaction Dataset, ICPR contest on Semantic Description of Human Activities (SDHA)
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Berclaz J., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, V1, P744, DOI DOI 10.1109/CVPR.2006.258
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Czyz J, 2007, IMAGE VISION COMPUT, V25, P1271, DOI 10.1016/j.imavis.2006.07.027
   Di Xie, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P2832, DOI 10.1109/FSKD.2012.6234136
   Doucet A, 2002, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOL I, P474, DOI 10.1109/ICIF.2002.1021192
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Tao Yang, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P1910
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CH, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (6TH), VOL II, P198, DOI 10.1109/MEDIACOM.2010.72
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252
   Yizhen Huang, 2006, Proceedings of the 2006 IEEE Signal Processing Society Workshop, P465
   Yuk JSC, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P384
   Zhao M, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P4875, DOI 10.1109/WCICA.2012.6359401
NR 20
TC 29
Z9 33
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 729
EP 742
DI 10.1007/s11042-014-2177-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400004
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhou, WD
   Li, FZ
AF Zhang, Li
   Zhou, Wei-Da
   Li, Fan-Zhang
TI Kernel sparse representation-based classifier ensemble for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation-based classifier; Kernel method; Ensemble learning
AB Kernel sparse representation-based classifier (KSRC) has been proposed, which has good representation and classification performance on face image data. The performance of KSRC on face image data is partly dependent on the random projection matrix when using the random projection method and the kernel Gram matrix. This paper develops the kernel sparse representation-based classifier ensemble (KSRCE), which does not require to consider the effect of random projection and kernel Gram matrix on KSRC. Actually, the random projection matrix and the kernel Gram matrix could be used for designing the diversity schemes for KSRCE. In the combination stage, we can combine the labels or the reconstruction errors of a test sample. Experimental results on three face data sets show that KSRCE is very promising.
C1 [Zhang, Li; Li, Fan-Zhang] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China.
   [Zhou, Wei-Da] AI Speech Ltd, Suzhou 215123, Peoples R China.
C3 Soochow University - China
RP Zhang, L (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Jiangsu, Peoples R China.
EM lizhang.ml@gmail.com
RI Lei, Ming/JAD-1050-2023; wei, li/ISB-3361-2023; Li, Fan/GRX-7461-2022
FU National Natural Science Foundation of China [60970067, 61033013];
   Natural Science Foundation of Jiangsu Province of China [BK2011284,
   BK201222725]; Natural Science Pre-research Project of Soochow University
   [SDY2011B09]; Qing Lan Project
FX Supported in part by the National Natural Science Foundation of China
   under Grant Nos. 60970067 and 61033013, by the Natural Science
   Foundation of Jiangsu Province of China under Grant Nos. BK2011284,
   BK201222725, by the Natural Science Pre-research Project of Soochow
   University under Grant No. SDY2011B09 and by the Qing Lan Project.
CR Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Candes E., 2005, l1-magic: Recovery of sparse signals via convex programming
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Duda R., 1973, Pattern Classification and Scene Analysis
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li SZ, 1998, PROC CVPR IEEE, P839, DOI 10.1109/CVPR.1998.698702
   Makhorin A., 2004, INTRO GLPK
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Roli F., 2004, LECT NOTES COMPUTER, V3077
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang A. Y., 2007, Tech. Rep. UCB/EECS-2007-99
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang L, 2011, PATTERN RECOGN, V44, P97, DOI 10.1016/j.patcog.2010.07.021
   Zhang L, 2005, INT J COMPUT INTELL, V5, P283, DOI 10.1142/S1469026805001489
NR 23
TC 25
Z9 27
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 123
EP 137
DI 10.1007/s11042-013-1457-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300008
DA 2024-07-18
ER

PT J
AU Ventura, C
   Vilaplana, V
   Giró-i-Nieto, X
   Marqués, F
AF Ventura, Carles
   Vilaplana, Veronica
   Giro-i-Nieto, Xavier
   Marques, Ferran
TI Improving retrieval accuracy of Hierarchical Cellular Trees for generic
   metric spaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia retrieval; Content-based image retrieval; Indexing
   techniques; Metric access methods; Hierarchical cellular tree
ID EARTH-MOVERS-DISTANCE; SEARCH
AB Metric Access Methods (MAMs) are indexing techniques which allow working in generic metric spaces. Therefore, MAMs are specially useful for Content-Based Image Retrieval systems based on features which use non Lp norms as similarity measures. MAMs naturally allow the design of image browsers due to their inherent hierarchical structure. The Hierarchical Cellular Tree (HCT), a MAM-based indexing technique, provides the starting point of our work. In this paper, we describe some limitations detected in the original formulation of the HCT and propose some modifications to both the index building and the search algorithm. First, the covering radius, which is defined as the distance from the representative to the furthest element in a node, may not cover all the elements belonging to the node's subtree. Therefore, we propose to redefine the covering radius as the distance from the representative to the furthest element in the node's subtree. This new definition is essential to guarantee a correct construction of the HCT. Second, the proposed Progressive Query retrieval scheme can be redesigned to perform the nearest neighbor operation in a more efficient way. We propose a new retrieval scheme which takes advantage of the benefits of the search algorithm used in the index building. Furthermore, while the evaluation of the HCT in the original work was only subjective, we propose an objective evaluation based on two aspects which are crucial in any approximate search algorithm: the retrieval time and the retrieval accuracy. Finally, we illustrate the usefulness of the proposal by presenting some actual applications.
C1 [Ventura, Carles; Vilaplana, Veronica; Giro-i-Nieto, Xavier; Marques, Ferran] Tech Univ Catalonia UPC, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Ventura, C (corresponding author), Tech Univ Catalonia UPC, Barcelona, Spain.
EM carles.ventura@upc.edu
RI Giró-i-Nieto, Xavier/M-5834-2013; Vilaplana, Veronica/O-1726-2014;
   Vilaplana, Veronica/HRC-0739-2023
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332; Vilaplana,
   Veronica/0000-0001-6924-9961; Vilaplana, Veronica/0000-0001-6924-9961
FU Catalan Broadcasting Corporation through the Spanish project
   [CENIT-2009-1026 BuscaMedia]; Spanish Government [TEC2010-18094
   MuViPro]; FPU Research Fellowship Program of the Spanish Ministry of
   Education
FX This work was partially founded by the Catalan Broadcasting Corporation
   through the Spanish project CENIT-2009-1026 BuscaMedia, by TEC2010-18094
   MuViPro project of the Spanish Government, and by FPU-2010 Research
   Fellowship Program of the Spanish Ministry of Education.
CR Ahmad I, 2011, MULTIMED TOOLS APPL, V55, P423, DOI 10.1007/s11042-010-0556-5
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 1970, RANK CORRELATION MET
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Bayer R., 1972, Acta Informatica, V1, P173, DOI 10.1007/BF00288683
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Chierichetti Flavio, 2007, P 26 ACM SIGMOD SIGA, P103
   Ciaccia P., 1997, SEBD, V97, P67
   Ding XR, 2013, APPL MECH MATER, V321-324, P1129, DOI 10.4028/www.scientific.net/AMM.321-324.1129
   Fagin R, 2003, SIAM PROC S, P28
   Geraci F, 2007, THESIS U STUDIO SIEN
   Giro X, 2010, ACM INT C IM VID RET, P358, DOI DOI 10.1145/1816041.1816093
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Ji-Chen Yang, 2011, IET International Communication Conference on Wireless Mobile and Computing (CCWMC 2011), P274, DOI 10.1049/cp.2011.0890
   Kiranyaz S, 2005, IEE P-VIS IMAGE SIGN, V152, P356, DOI 10.1049/ip-vis:20045061
   Kiranyaz S, 2007, IEEE T MULTIMEDIA, V9, P102, DOI 10.1109/TMM.2006.886362
   Kiranyaz S, 2011, COMPUT BIOL MED, V41, P463, DOI 10.1016/j.compbiomed.2011.04.008
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Novak David., 2010, Proceedings of the Third International Conference on SImilarity Search and APplications, SISAP'10, P59
   Patella M, 2009, J DISCRET ALGORITHMS, V7, P36, DOI 10.1016/j.jda.2008.09.014
   Pele O, 2008, LECT NOTES COMPUT SC, V5304, P495, DOI 10.1007/978-3-540-88690-7_37
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Singitham Pavan Kumar C, 2004, Proceedings of the 30tfc International Conference on Very Large Data Bases (VLDB), V30, P624
   Ventura C, 2012, LECT NOTES COMPUT SC, V7131, P652
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
NR 29
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1983
EP 2008
DI 10.1007/s11042-013-1686-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200040
DA 2024-07-18
ER

PT J
AU de Andrade, LA
   Zingarelli, MRU
   Silva, RR
   Goularte, R
AF de Andrade, Leonardo A.
   Zingarelli, Matheus R. U.
   Silva, Rodolfo R.
   Goularte, Rudinei
TI A new approach to spatial compression of stereoscopic videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia coding; Digital video; Anaglyphic stereoscopic video; Spatial
   video compression
ID LCD MONITORS
AB This paper presents a new spatial compression method specifically designed for stereo videos. Different form current compressors, which simply apply known 2D compression techniques, the method proposed here was developed taking into account specificities of the components of the spatial compression process which may impact the correct depth visualization, named Chrominance Subsampling, Discrete WaveletTransform (DWT) and Quantization. Each component was evaluated analyzing where datalosses occur and proposing ways to provide a good balance between compression ratio and image quality, minimizing losses in depth perception. The evaluations were made using standard objective (PSNR) and subjective (DSCQS) metrics, applied to an anaglyphic stereoscopic video base. The results showedour method is competitive regarding compression rate and providessuperior image quality.
C1 [de Andrade, Leonardo A.] Univ Fed Sao Carlos, Dept Artes & Comunicacao, Sao Paulo, Brazil.
   [Zingarelli, Matheus R. U.; Silva, Rodolfo R.; Goularte, Rudinei] Univ Sao Paulo, Inst Ciencias Matemat & Comp, Sao Paulo, Brazil.
C3 Universidade Federal de Sao Carlos; Universidade de Sao Paulo
RP de Andrade, LA (corresponding author), Univ Fed Sao Carlos, Dept Artes & Comunicacao, Rod Washington Luiz,Km 235, Sao Paulo, Brazil.
EM landrade@ufscar.br; zinga@icmc.usp.br; rodo@grad.icmc.usp.br;
   rudinei@icmc.usp.br
RI Andrade, Leonardo A/D-4580-2013; Goularte, Rudinei/E-2441-2011
OI Andrade, Leonardo/0000-0002-9989-3771; Goularte,
   Rudinei/0000-0003-1531-1576
FU FAPESP; CNPq
FX The authors would like to thank FAPESP and CNPq Brazilian agencies for
   their financial support on this project.
CR Acharya T., 2004, JPEG2000 Standard for Image Compression: Concepts, Algorithms and VLSI Architectures
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   Dubois E, 2001, INT CONF ACOUST SPEE, P1661, DOI 10.1109/ICASSP.2001.941256
   Ebrahimi F, 2004, P SPIE
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hartman NW, 2005, Ninth International Conference on Information Visualisation, Proceedings, P992, DOI 10.1109/IV.2005.120
   ITU-R, 2002, 50011 ITUR
   ITU-T, 2008, 247 ITUT
   Kerr DA, 2009, REDING DIGITAL PHOTO
   Konrad J, 2007, IEEE SIGNAL PROC MAG, V24, P97, DOI 10.1109/MSP.2007.905706
   Mandal MK, 2003, MULTIMEDIA SIGNALS
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Matsuura F, 2008, J VISUAL-JAPAN, V11, P79, DOI 10.1007/BF03181917
   Mendiburu Bernard., 2009, 3D Movie Making: Stereoscopic Digital Cinema From Scrip to Screen
   Nayan MY, 2002, PROCEEDINGS OF THE
   Peinsipp-Byma E, 2009, P SPIE, V7237
   Smolic A, 2009, PROCEEDINGS OF THE 2
   StereoGraphics Corporation, 1997, STER DEV HDB
   Su Y, 2006, COMMON TEST CONDITIO
   Thanapirom S, 2005, OPT ENG, V44, DOI 10.1117/1.1951768
   Tian D, 2007, STUDY MVC CODING TOO
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wandell B. A, 1995, Foundations of vision
   Wiegand T, 2003, 1449610 ISOIEC AVC
   Winkler S., 2001, P INT S WIRELESS PER, P547
   Woods AJ, 2004, P SPEI T EL IMA, V5291
   Woods AJ, 2010, P SPIE STEREOSCOPIC, V7253, p0Q1
   Woods AJ, 2006, PROC INT MEET INF DI, P98
   Woods AJ, 2007, J SOC INF DISPLAY, V15, P889, DOI 10.1889/1.2812989
   Yun-Jeong, 1996, IEEE T CONSUMER ELEC, V42
NR 30
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1673
EP 1697
DI 10.1007/s11042-012-1300-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000032
DA 2024-07-18
ER

PT J
AU Xiang, LY
   Sun, XM
   Luo, G
   Xia, B
AF Xiang, Lingyun
   Sun, Xingming
   Luo, Gang
   Xia, Bin
TI Linguistic steganalysis using the features derived from synonym
   frequency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Steganography; Linguistic steganalysis; Support vector
   machine (SVM); Synonym substitution (SS)
AB A linguistic steganalysis method is proposed to detect synonym substitution-based steganography, which embeds secret message into a text by substituting words with their synonyms. First, attribute pair of a synonym is introduced to represent its position in an ordered synonym set sorting in descending frequency order and the number of its synonyms. As a result of synonym substitutions, the number of high frequency attribute pairs may be reduced while the number of low frequency attribute pairs would be increased. By theoretically analyzing the changes of the statistical characteristics of attribute pairs caused by SS steganography, a feature vector based on the difference of the relative frequencies of different attribute pairs is utilized to detect the secret message. Finally, the impact on the extracted feature vector caused by synonym coding strategies is analyzed. Experimental results demonstrate that the proposed linguistic steganalysis method can achieve better detection performance than previous methods.
C1 [Xiang, Lingyun] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410004, Hunan, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Luo, Gang; Xia, Bin] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Nanjing University of
   Information Science & Technology; Hunan University
RP Sun, XM (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
EM suhong210@yahoo.com.cn; sunnudt@163.com; luog@yahoo.cn; xnby@foxmail.com
RI Sun, Xingming/AAD-1866-2019; Li, Lei/JPE-6543-2023
FU National Natural Science Foundation of China [60973128, 61073191,
   61070196, 61070195, 61103215, 61173141, 61173142, 61232016]; National
   Basic Research Program 973 of China [2010CB334706, 2011CB311808]; PAPD
   fund;  [2011GK2009];  [GYHY201206033];  [201301030];  [0S2013GR0445]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos. 60973128, 61073191, 61070196, 61070195, 61103215,
   61173141, 61173142, and 61232016), National Basic Research Program 973
   of China (Nos. 2010CB334706, and 2011CB311808), 2011GK2009,
   GYHY201206033, 201301030, 0S2013GR0445 and PAPD fund.
CR [Anonymous], 2001, Word Frequencies in Written and Spoken English
   Atallah M. J., 2001, Information Hiding, P185
   Bolshakov IA, 2004, LECT NOTES COMPUT SC, V3200, P180
   Chang C., 2010, LIBSVM: A library for support vector machines 2010
   Chapman MT, 1997, LECT NOTES COMPUTER, V1334, P333
   Chen ZL, 2008, LECT NOTES COMPUT SC, V5284, P224
   Chiang YL, 2004, LECT NOTES COMPUT SC, V2939, P129
   Leech G, 2010, WORD FREQUENCIES WRI
   Liu YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2094
   [罗纲 Luo Gang], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P1696
   Meral HM, 2009, COMPUT SPEECH LANG, V23, P107, DOI 10.1016/j.csl.2008.04.001
   Muhammad HZ, 2009, 2009 CONFERENCE ON INNOVATIVE TECHNOLOGIES IN INTELLIGENT SYSTEMS AND INDUSTRIAL APPLICATIONS, P423, DOI 10.1109/CITISIA.2009.5224169
   Shirali-Shahreza MH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1524, DOI 10.1109/IIH-MSP.2008.6
   Taskiran CM, 2006, P SPIE SECURITY STEG, V6072, P97
   Topkara U., 2006, P 8 WORKSHOP MULTIME, P164, DOI DOI 10.1145/1161366.1161397
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Winstein K, 2010, TYRANNOSAURUS LEX
   Winstein K, 2010, LEXICAL STEGANOGRAPH
   Yang JL, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P481
   Yuling Liu, 2008, Information Technology Journal, V7, P654, DOI 10.3923/itj.2008.654.660
   Zhenshan Yu, 2008, 2008 Second International Conference on Future Generation Communication and Networking (FGCN), P134, DOI 10.1109/FGCN.2008.39
NR 21
TC 53
Z9 57
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1893
EP 1911
DI 10.1007/s11042-012-1313-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000041
DA 2024-07-18
ER

PT J
AU Chu, HC
   Yang, SW
   Hsu, CH
   Park, JH
AF Chu, Hai-Cheng
   Yang, Szu-Wei
   Hsu, Ching-Hsien
   Park, Jong Hyuk
TI Digital evidence discovery of networked multimedia smart devices based
   on social networking activities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Mobile social network; Location-based social
   networking; Networked smart devices; Volatile memory acquisition
ID INFORMATION; PRIVACY
AB Unquestionably, networked multimedia smart devices are commonly adopted in contemporary ubiquitous wireless computing era with unprecedented evolving pace in terms of mobility, portability, and pervasiveness. Regrettably, those technology-oriented gadgets are phenomenally exploited by cyber criminals or get involved in computer-related incidents unknowingly. Substantively, the detection, prevention, and the related digital forensics of the above scenarios are becoming tremendously urgent both in public and private sectors. Therefore, in this research, we investigate the scenario when state-of-the-art wireless communication technologies are integrated with the networked smart devices where digital evidences may exist and they could be disclosed when appropriate standard operating procedures are suitably applied. Accordingly, in this paper, a PDA with the built-in GPS navigation functionality via the ubiquitous Wi-Fi connection to a popular social networking platform (facebook) is cross examined concerning the related digital evidence collecting and discovering in terms of revealing previous facebook user accounts on the mobile device without shutting off the power. The research provides a generic framework for the digital forensics specialists to contemplate when the networked smart devices are involved in the related criminal investigation cases especially when omnipresent social networking platforms are becoming the new avenue for the escalating, stringent, and heinous cybercrimes.
C1 [Chu, Hai-Cheng] Natl Taichung Univ Educ, Dept Int Business, Taichung 40306, Taiwan.
   [Yang, Szu-Wei] Natl Taichung Univ Educ, Dept Educ, Taichung 40306, Taiwan.
   [Hsu, Ching-Hsien] Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul 139743, South Korea.
C3 National Taichung University of Education; National Taichung University
   of Education; Chung Hua University; Seoul National University of Science
   & Technology
RP Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, 172 Gongneung Dong 2, Seoul 139743, South Korea.
EM hcchu@mail.ntcu.edu.tw; swyang@mail.ntcu.edu.tw; chh@chu.edu.tw;
   parkjonghyuk1@hotmail.com
RI Hsu, Ching-Hsien/AAE-6917-2020
FU NSC (National Science Council) of Taiwan [NSC 101-2221-E-142-009]; Basic
   Science Research Program through the National Research Foundation of
   Korea(NRF) - Ministry of Education, Science and Technology
   [2012-0008296]
FX The author would like to acknowledge the funding support of NSC
   (National Science Council) of Taiwan concerning the grant of Project NSC
   101-2221-E-142-009. This research was partially supported by Basic
   Science Research Program through the National Research Foundation of
   Korea(NRF) funded by the Ministry of Education, Science and Technology
   (2012-0008296).
CR Acquisti A, 2006, LECT NOTES COMPUT SC, V4258, P36
   ANDREW MW, 2007, P 2 INT WORKSH SYST
   [Anonymous], 2009, P 27 INT C HUM FACT
   [Anonymous], P 26 ANN SIGCHI C HU
   [Anonymous], 2007, AMCIS 2007 P
   Asher C, 2009, IFIP ADV INF COMM TE, V309, P139, DOI 10.1007/978-3-642-05437-2_13
   Brown R, 2005, LECT NOTES ARTIF INT, V3683, P395
   Chen HC, 2004, COMPUTER, V37, P50, DOI 10.1109/MC.2004.1297301
   Chuan D, 2011, J CONVERG, V2, P53
   Counts S, 2008, P 41 HAW INT C SYST, P1
   Dominguez-Sal David, 2010, International Journal of Information Technology, Communications and Convergence, V1, P41, DOI 10.1504/IJITCC.2010.035226
   Dong FY, 2009, PROCEEDINGS OF 2009 2ND IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY, P740, DOI 10.1109/ICBNMT.2009.5347780
   El-Khatib K, 2004, WIREL COMMUN MOB COM, V4, P595, DOI 10.1002/wcm.231
   Ellison NB, 2007, J COMPUT-MEDIAT COMM, V12, P1143, DOI 10.1111/j.1083-6101.2007.00367.x
   Iqbal M., 2008, Int. J. Commun. Law Policy, V3, P178
   Joore P, 2008, SOC SCI INFORM, V47, P253, DOI 10.1177/0539018408092573
   Keenan TP, 2008, FUTURE OF IDENTITY IN THE INFORMATION SOCIETY, P37
   Kryvinska Natalia, 2010, International Journal of Information Technology, Communications and Convergence, V1, P77, DOI 10.1504/IJITCC.2010.035228
   Lee S, 2005, INT WORK SYS APPR D, P236, DOI 10.1109/SADFE.2005.9
   Li N, 2009, ICCSSE 2009: PROCEEDINGS OF 2009 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE & EDUCATION, P1029, DOI 10.1109/ICCSE.2009.5228475
   Nance K., 2009, P HAW INT C SYST SCI, P1
   Schapsis Claudio., 2010, LOCATION BASED SOCIA
   Simon M, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P283, DOI 10.1109/ARES.2010.73
   Skeels MM, 2009, P ACM 2009 INT C SUP
   Sohn H, 2009, LECT NOTES COMPUT SC, V5450, P388, DOI 10.1007/978-3-642-04438-0_33
   Strawn C., 2009, SMALL SCALE DIGITAL, P1
   Walters A., 2007, VOLATOOLS INTEGRATIN
   Wang JL, 2009, P IEEE S TECHN SOC P
   Xiong L., 2011, J CONVERGENCE, V2, P31
NR 29
TC 4
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 219
EP 234
DI 10.1007/s11042-012-1349-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700012
DA 2024-07-18
ER

PT J
AU Wang, PC
   Kong, DH
   Zhang, Y
   Yin, BC
AF Wang, Pengcheng
   Kong, Dehui
   Zhang, Yong
   Yin, Baocai
TI Adaptive particle shape setting and normal calculation methods in fluid
   rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fluid rendering; Splatting; Particle shape; Normal calculation
ID FLOW
AB In this paper, we present an adaptive particle shape setting method in Lagrangian-approach based screen space splatting algorithm in real-time fluid rendering. The particle radius will be adjusted according to its Weber number and local density in the rendering process so that a large radius of peaceful fluid particle can help to eliminate a bumpy surface artifact, and a small radius can prevent the obviously spherical shape of particles in splash. The shape of fluid particle will be controlled adaptively on the basis of Weber number too, so that fast moving particles could have an ellipsoidal appearance which describes the splash particle shape in turbulent flow persuasively. We also propose an adaptive normal calculation method to avoid the numerical calculation errors in the normal computation process. The sampling interval will be set in accordance with the viewing distance from camera to the fluid so that fuzzy edges or double image effect in a fixed sampling interval normal computation process could be prevented. Both of the two approaches introduced in this paper take only small amount of computing time and will have little impact on the time consuming property of a real-time fluid rendering application.
C1 [Wang, Pengcheng; Kong, Dehui; Zhang, Yong; Yin, Baocai] Beijing Univ Technol, Multimedia & Intelligent Software Technol Beijing, Coll Comp Sci, Beijing, Peoples R China.
C3 Beijing University of Technology
RP Wang, PC (corresponding author), Beijing Univ Technol, Multimedia & Intelligent Software Technol Beijing, Coll Comp Sci, Beijing, Peoples R China.
EM wangpengcheng369@gmail.com; kdh@bjut.edu.cn; zhangyong2010@bjut.edu.cn;
   ybc@bjut.edu.cn
RI Zhang, Yongzhe/AAF-5787-2021; Zhang, Yong/AAW-8880-2021
OI Zhang, Yong/0000-0001-6650-6790
FU NSFC [60825203, U0935004, 61170104]; Beijing Municipal Natural Science
   Foundation [4112008]
FX This research is supported by NSFC (No. 60825203, U0935004, 61170104)
   and Beijing Municipal Natural Science Foundation (4112008).
CR [Anonymous], THESIS U BRIT COLUMB
   [Anonymous], 2008, Fluid Simulation for Computer Graphics
   Bagar F, 2010, COMPUT GRAPH FORUM, V29, P1383, DOI 10.1111/j.1467-8659.2010.01734.x
   Cords H, 2008, P ACM SIGGR EUR S CO
   Cristini V, 2003, J RHEOL, V47, P1283, DOI 10.1122/1.1603240
   Desbrun M, 1996, EUR WORKSH COMP AN S, P61
   Elia B, 2010, ACS APPL MATER INTER, V2, P2140
   Mihalef V, 2009, COMPUT GRAPH FORUM, V28, P229, DOI 10.1111/j.1467-8659.2009.01362.x
   Müller M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P9
   Muller M., 2003, SCA, P154
   ROSADO G, 2007, GPU GEMS, V3, P575
   Van der Laan W.J., 2009, P 2009 S INT 3D GRAP, P91, DOI [DOI 10.1145/1507149.1507164, 10.1145/1507149.1507164]
   Weast R.C., 1990, CRC Handbook of Chemistry and Physics
   Xu T-C, 2011, P 10 INT C VIRT REAL, P307
   Zhang Yanci., 2008, Proceedings of the Fifth Euro- graphics / IEEE VGTC Conference on Point-Based Graphics, SPBG'08, P137
NR 15
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 517
EP 532
DI 10.1007/s11042-013-1525-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400009
DA 2024-07-18
ER

PT J
AU Fan, WT
   Bouguila, N
AF Fan, Wentao
   Bouguila, Nizar
TI Variational learning for Dirichlet process mixtures of Dirichlet
   distributions and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dirichlet process; Nonparametric Bayesian; Dirichlet mixtures; Infinite
   mixtures; Variational learning; Human action video; Image spam
ID SAMPLING METHODS; MODEL
AB In this paper, we propose a Bayesian nonparametric approach for modeling and selection based on a mixture of Dirichlet processes with Dirichlet distributions, which can also be seen as an infinite Dirichlet mixture model. The proposed model uses a stick-breaking representation and is learned by a variational inference method. Due to the nature of Bayesian nonparametric approach, the problems of overfitting and underfitting are prevented. Moreover, the obstacle of estimating the correct number of clusters is sidestepped by assuming an infinite number of clusters. Compared to other approximation techniques, such as Markov chain Monte Carlo (MCMC), which require high computational cost and whose convergence is difficult to diagnose, the whole inference process in the proposed variational learning framework is analytically tractable with closed-form solutions. Additionally, the proposed infinite Dirichlet mixture model with variational learning requires only a modest amount of computational power which makes it suitable to large applications. The effectiveness of our model is experimentally investigated through both synthetic data sets and challenging real-life multimedia applications namely image spam filtering and human action videos categorization.
C1 [Fan, Wentao] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, CIISE, Montreal, PQ, Canada.
EM wenta_fa@encs.concordia.ca; nizar.bouguila@concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020; Fan,
   Wentao/AAO-9378-2020; Fan, Wentao/JUU-7543-2023
OI Fan, Wentao/0000-0001-6694-7289; Fan, Wentao/0000-0001-6694-7289
CR [Anonymous], J AM STAT ASS
   [Anonymous], P C EM ANT CEAS
   [Anonymous], P 27 INT C HUM FACT
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 1999, P ADV NEUR INF PROC
   [Anonymous], 1983, RECNT ADV STAT
   [Anonymous], 2003, INT C INT C MACH LEA, DOI DOI 10.1016/0026-2714(92)90278-S
   ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871
   Biggio B, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P105, DOI 10.1109/ICIAP.2007.4362765
   Biggio B, 2011, PATTERN RECOGN LETT, V32, P1436, DOI 10.1016/j.patrec.2011.03.022
   BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372
   Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664
   Bouguila N, 2006, IEEE T KNOWL DATA EN, V18, P993, DOI 10.1109/TKDE.2006.133
   Bouguila N, 2008, MACHINE LEARN SIGN P, P297, DOI 10.1109/MLSP.2008.4685496
   Boyd S., 2004, CONVEX OPTIMIZATION
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Fumera G, 2006, J MACH LEARN RES, V7, P2699
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   KORWAR RM, 1973, ANN PROBAB, V1, P705, DOI 10.1214/aop/1176996898
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma ZY, 2011, IEEE T PATTERN ANAL, V33, P2160, DOI 10.1109/TPAMI.2011.63
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Mehta B., 2008, 17 INT C WORLD WID W, P497, DOI DOI 10.1145/1367497.1367565
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653
   Parisi G., 1988, STAT FIELD THEORY, DOI DOI 10.1063/1.2811677
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Robert Christian P., 1999, Monte Carlo Statistical Methods, V2
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SETHURAMAN J, 1994, STAT SINICA, V4, P639
   Woolrich MW, 2006, IEEE T MED IMAGING, V25, P1380, DOI 10.1109/TMI.2006.880682
   Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 40
TC 16
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1685
EP 1702
DI 10.1007/s11042-012-1191-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500015
DA 2024-07-18
ER

PT J
AU Liu, JL
   Zuo, BQ
   Zeng, XY
AF Liu, Jianli
   Zuo, Baoqi
   Zeng, Xianyi
TI The visual quality recognition of nonwovens using a novel wavelet based
   contourlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contourlet transform; Support vector machine; Energy based signatures;
   Visual quality recognition; Nonwovens
AB In this paper, a novel wavelet based contourlet transform for texture extraction is presented. The visual quality recognition of nonwovens based on image processing approach can be considered as a special case of the application of computer vision and pattern recognition on industrial inspection. For concreteness, the method proposed in this paper can be divided into two stages, i.e., the feature extraction is solved by wavelet based contourlet transform, which is followed by the grade recognition with support vector machine (SVM). For the texture analysis, we propose a novel wavelet based contourlet transform, which can be considered as a simplified but more sufficient for texture analysis for nonwoven image compared with version of the one introduced by Eslami in theory view. In experiment, nonwoven images of five different visual quality grades are decomposed using wavelet based contourlet transform with 'PKVA' filter as the default filter of Laplacian Pyramid (LP) and Directional Filter Bank (DFB) at 3 levels firstly. Then, two energy-based features, norm-1 L (1) and norm-2 L (2), are calculated from the wavelet coefficients at the first level and contourlet coefficients of each high frequency subband. Finally, the SVM is designed to be a classifier to be trained and tested with the samples selected from the feature set. Experimental results indicate that when the nonwoven images are decomposed at 3 levels and 16 L (2)s are extracted, with 500 samples to train the SVM, the average recognition accuracy of test set is 99.2 %, which is superior to the comparative method using wavelet texture analysis.
C1 [Liu, Jianli] Jiangnan Univ, Coll Text & Clothing, Wuxi 214122, Peoples R China.
   [Liu, Jianli] Donghua Univ, Engn Res Ctr Tech Text, Minist Educ, Shanghai 201620, Peoples R China.
   [Zuo, Baoqi] Soochow Univ, Coll Text & Clothing Engn, Suzhou 215123, Peoples R China.
   [Zuo, Baoqi] Soochow Univ, Natl Engn Lab Modern Silk, Suzhou 215123, Peoples R China.
   [Zeng, Xianyi] Univ Lille Nord France, F-59000 Lille, France.
   [Zeng, Xianyi] GEMTEX, ENSAIT, F-59056 Roubaix, France.
C3 Jiangnan University; Donghua University; Soochow University - China;
   Soochow University - China; Universite de Lille; Universite de Lille;
   Ecole Nationale Superieure des Arts et Industries Textiles (ENSAIT)
RP Liu, JL (corresponding author), Jiangnan Univ, Coll Text & Clothing, Wuxi 214122, Peoples R China.
EM jian-li.liu@hotmail.com
OI Zeng, Xianyi/0000-0002-3236-6766
FU Fundamental Research Funds for the Central Universities [JUSRP11103];
   Foundation of Engineering Research Center of Technical Textiles,
   Ministry of Education [2011k-03]; China Postdoctoral Science Foundation
   [20110490098]
FX The authors would like to tank the anonymous reviewers and the handling
   associate editor for their insightful comments and also thank Dr. Wenbin
   Wang for his work on the comparitive experiments. This work was
   supported by "the Fundamental Research Funds for the Central
   Universities" [grant number JUSRP11103], "the Foundation of Engineering
   Research Center of Technical Textiles, Ministry of Education" [grant
   number 2011k-03] and "China Postdoctoral Science Foundation" [grant
   number 20110490098].
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cherkassky A, 2010, TEXT RES J, V80, P226, DOI 10.1177/0040517509105072
   Courtney A., 2008, Physics in Canada, V64, P7
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Eslami R, 2004, IEEE IMAGE PROC, P3189
   Jäkel F, 2007, J MATH PSYCHOL, V51, P343, DOI 10.1016/j.jmp.2007.06.002
   Kaganami H.G., 2011, J INFORM HIDING MULT, V2, P33
   Liu JL, 2010, EXPERT SYST APPL, V37, P2241, DOI 10.1016/j.eswa.2009.07.049
   Ma YD, 2010, IMAGE VISION COMPUT, V28, P1524, DOI 10.1016/j.imavis.2010.03.006
   Militky J, 1999, INT J CLOTH SCI TECH, V11, P141
   Militky J., 2007, J INFORM COMPUTING S, V2, P85
   Payvandy P, 2010, J TEXT I, V101, P46, DOI 10.1080/00405000802224551
   Po DDY, 2006, IEEE T IMAGE PROCESS, V15, P1610, DOI 10.1109/TIP.2006.873450
   Pronobis A, 2010, IMAGE VISION COMPUT, V28, P1080, DOI 10.1016/j.imavis.2010.01.015
   Qian HM, 2010, PATTERN RECOGN LETT, V31, P100, DOI 10.1016/j.patrec.2009.09.019
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
NR 16
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1667
EP 1684
DI 10.1007/s11042-012-1189-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500014
DA 2024-07-18
ER

PT J
AU Mattos, CI
   Ribeiro, EP
   Fernandez, EMG
   Pedroso, CM
AF Mattos, Carlos Ignacio
   Ribeiro, Eduardo Parente
   Garcia Fernandez, Evelio Martin
   Pedroso, Carlos Marcelo
TI An unified VoIP model for workload generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic models; Voice over IP; Workload generation
AB This paper presents a new model for VoIP workload generation. The novelty of our proposal consists in modeling the sessions by characterizing both the user behavior (session level) and the packet generation for an active call (intra-session level) with easily measured parameters and low computational complexity. This approach also facilitates systematic study of changes in user behavior and voice codec. The session level was modeled by analysis of call-holding time and time interval between successive calls. The model for call-holding time, characterizing the individual user behavior, uses the Pareto type 2 probability distribution. The time interval between calls is obtained from aggregate traffic and can be modeled by exponential probability distribution. Aggregate traffic is obtained by superposition of simultaneous sessions. The data used to characterize the session level were collected at the backbone of two Brazilian telecommunication carriers. The model for intra-session level comprises the characterization of the packet size and the packet inter-arrival time. The intra-session model was based on data generated in a laboratory environment, in order to properly characterize the codec influence on packet generation and to avoid the effects of delay, jitter and loss commonly present in an operational network. Models for constant bit rate and variable bit rate codecs were considered. A simulator was implemented and the results indicate that our model properly mimics the characteristics observed in real traffic and can be used for VoIP modeling and workload generation. Additionally, an application to automate the performance analysis was developed.
C1 [Mattos, Carlos Ignacio; Ribeiro, Eduardo Parente; Garcia Fernandez, Evelio Martin; Pedroso, Carlos Marcelo] Univ Fed Parana, Dept Elect Engn, BR-80060000 Curitiba, Parana, Brazil.
C3 Universidade Federal do Parana
RP Pedroso, CM (corresponding author), Univ Fed Parana, Dept Elect Engn, BR-80060000 Curitiba, Parana, Brazil.
EM pedroso@eletrica.ufpr.br
RI Ribeiro, Eduardo Parente/AAF-6011-2021; Fernandez, Evelio/AAO-4660-2020;
   Pedroso, Carlos Marcelo/AAE-3142-2019
OI Ribeiro, Eduardo Parente/0000-0002-8276-528X; Fernandez,
   Evelio/0000-0003-1707-8595; Pedroso, Carlos Marcelo/0000-0002-3747-7238
CR *12 ISG, 2009, 12 ISG
   *16TH ITC, 1999, 16 INT TEL C ITC, P827
   *3GPP, 1999, 3GPP REC TR26 075 PE
   Abry P, 2010, TELECOMMUN SYST, V43, P147, DOI 10.1007/s11235-009-9205-6
   [Anonymous], 2003, Itu-t recommendation g. 107: The e-model, a computational model for use in transmission planning
   [Anonymous], 2004, Loss Models: From Data to Decisions
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   Banks J., 2010, Discrete-event System Simulation
   Barford P., 1998, Performance Evaluation Review, V26, P151, DOI 10.1145/277858.277897
   *BAS, 1996, BAVARIAN ARCH SPEECH
   Beran J., 1994, STAT LONG MEMORY PRO
   Box G.E., 1970, J AM STAT ASSOC, V65, P1509
   Box GE, 1994, TIME SERIES ANAL FOR
   CASILARI E, 2002, P COMM SYST NETW DIG
   CHANDY KM, 1981, COMMUN ACM, V24, P198, DOI 10.1145/358598.358613
   Chen WE, 2007, IEEE NETWORK, V21, P22, DOI 10.1109/MNET.2007.4395107
   Crovella ME, 1997, IEEE ACM T NETWORK, V5, P835, DOI 10.1109/90.650143
   DEMATTOS CI, 2010, INT TEL S
   FLOOD J, 1997, TELECOMMUNICATIONS N
   HEFFES H, 1986, IEEE J SEL AREA COMM, V4, P856, DOI 10.1109/JSAC.1986.1146393
   Huang TY, 2010, IEEE NETWORK, V24, P42, DOI 10.1109/MNET.2010.5430143
   *ITU T, 1988, REC G 711 PULS COD M
   *ITU T, 1996, REC G 729 COD SPEECH
   *ITU T, 2000, Q 1901 BEAR IND CALL
   JAIN R, 1986, IEEE J SEL AREA COMM, V4, P986, DOI 10.1109/JSAC.1986.1146410
   JIANG W, 2000, P 9 IEEE INT C COMP
   LELAND WE, 1994, IEEE ACM T NETWORK, V2, P1, DOI 10.1109/90.282603
   Lindblom J, 2005, IEEE T SPEECH AUDI P, V13, P787, DOI 10.1109/TSA.2005.851913
   MENASCE D.A., 1998, CAPACITY PLANNING WE
   Menth M, 2009, IEEE ACM T NETWORK, V17, P1042, DOI 10.1109/TNET.2008.2006222
   Orebaugh Angela, 2006, Wireshark & Ethereal Network Protocol Analyzer Toolkit
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Rosenberg Jonathan, 2002, document RFC 3261, DOI [10.174 87/RFC3261, DOI 10.17487/RFC3261]
   SCHULZRINNE H, 1998, RTP TRANSPORT PROTOC
   VITEZ M, 2011, PICOPHONE
NR 35
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2309
EP 2329
DI 10.1007/s11042-012-1243-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500042
DA 2024-07-18
ER

PT J
AU Wu, B
   Zhang, N
   Ma, SW
   Zhao, DB
   Gao, W
AF Wu, Bo
   Zhang, Nan
   Ma, Siwei
   Zhao, Debin
   Gao, Wen
TI Optimal entropy-constrained non-uniform scalar quantizer design for low
   bit-rate pixel domain DVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DVC; Non-uniform scalar quantizer; Optimal quantizer
ID INFORMATION
AB In this paper, an optimal entropy-constrained non-uniform scalar quantizer is proposed for the pixel domain DVC. The uniform quantizer is efficient for the hybrid video coding since the residual signals conforming to a single-variance Laplacian distribution. However, the uniform quantizer is not optimal for pixel domain distributed video coding (DVC). This is because the uniform quantizer is not adaptive to the joint distribution of the source and the SI, especially for low level quantization. The signal distribution of pixel domain DVC conforms to the mixture model with multi-variance. The optimal non-uniform quantizer is designed according to the joint distribution, the error between the source and the SI can be decreased. As a result, the bit rate can be saved and the video quality won't sacrifice too much. Accordingly, a better R-D trade-off can be achieved. First, the quantization level is fixed and the optimal RD trade-off is achieved by using a Lagrangian function J(Q). The rate and distortion components is designed based on P(Y|Q). The conditional probability density function of SI Y depend on quantization partitions Q, P(Y|Q), is approximated by a Guassian mixture model at encocder. Since the SI can not be accessed at encoder, an estimation of P(Y|Q) based on the distribution of the source is proposed. Next, J(Q) is optimized by an iterative Lloyd-Max algorithm with a novel quantization partition updating algorithm. To guarantee the convergence of J(Q), the monotonicity of the interval in which the endpoints of the quantizer lie must be satisfied. Then, a quantizer partition updating algorithm which considers the extreme points of the histogram of the source is proposed. Consequently, the entropy-constrained optimal non-uniform quantization partitions are derived and a better RD trade-off is achieved by applying them. Experiment results show that the proposed scheme can improve the performance by 0.5 dB averagely compared to the uniform scalar quantization.
C1 [Wu, Bo; Zhang, Nan] Capital Med Univ, Sch Biomed Engn, Beijing, Peoples R China.
   [Ma, Siwei] Peking Univ, Sch Elect Engn & Comp Sci, Inst Digital Media, Beijing 100871, Peoples R China.
   [Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
   [Zhao, Debin] Harbin Inst Technol, Harbin 150006, Peoples R China.
C3 Capital Medical University; Peking University; Peking University; Harbin
   Institute of Technology
RP Zhang, N (corresponding author), Capital Med Univ, Sch Biomed Engn, 10 Xitoutiao, Beijing, Peoples R China.
EM zhangnan@ccmu.edu.cn; swma@pku.edu.cn; dbzhao@jdl.ac.cn; wgao@pku.edu.cn
RI Zhang, Nan/GXH-0361-2022; Zhao, Debin/JEP-0204-2023
FU National Natural Science Foundation of China [61103064]; Science and
   Technology Program of Beijing Municipal Commission of Education
   [KM201010005011]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61103064) and the Science and Technology Program of Beijing
   Municipal Commission of Education (No. KM201010005011).
CR Aaron A, 2004, P VIS COMM IM PROC V
   AARON A, 2003, P IEEE INT C IM PROC
   Artigas X., 2007, 26 PICTURE CODING SY
   Becker-Lakus A., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P382, DOI 10.1109/PCS.2010.5702514
   BERGER T, 1972, IEEE T INFORM THEORY, V18, P759, DOI 10.1109/TIT.1972.1054906
   Berrou C, 1996, IEEE T COMMUN, V44, P1261, DOI 10.1109/26.539767
   Brites C, 2006, P PICT COD S PCS BEI
   Bruce R, 1964, THESIS MIT
   Fang S, 2007, 8 ACIS INT C SOFTW E, V1, P848
   Huang B, 2007, PROC 6 INT C INF COM, P1
   Kraskov A, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066138
   Kwon S., 2012, CIRED 2012 WORKSHOP, P1
   Lahsini C, 2011, DAT COMPR C DCC 2011, P382
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548
   Muresan D, 2008, IEEE T INFORM THEORY, V54, P344, DOI 10.1109/TIT.2007.911170
   Ou T- S, 2011, IEEE T CIRCUITS SYST
   Rebollo-Monedero D, 2003, IEEE DATA COMPR CONF, P13
   Roca A, 2008, PROC SPIE, V6822, DOI 10.1117/12.768970
   SHEININ V, 2006, INT CONF ACOUST SPEE, P217
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Swaroop K. V. Suchethan, 2010, 2010 42nd Southeastern Symposium on System Theory (SSST 2010), P371, DOI 10.1109/SSST.2010.5442807
   Tu ZY, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P224, DOI 10.1109/CISS.2006.286467
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weerakkody WARJ, 2009, ELECTRON LETT, V45, P261, DOI 10.1049/el:20091992
   Wu B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P165, DOI 10.1109/ICME.2006.262595
   WU XL, 1991, J ALGORITHM, V12, P663, DOI 10.1016/0196-6774(91)90039-2
   WU XL, 1993, IEEE T INFORM THEORY, V39, P1049, DOI 10.1109/18.256513
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhang YS, 2011, IEEE T CIRC SYST VID, V21, P1100, DOI 10.1109/TCSVT.2011.2133830
NR 30
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1799
EP 1824
DI 10.1007/s11042-012-1210-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500020
DA 2024-07-18
ER

PT J
AU Ionescu, BE
   Seyerlehner, K
   Mironica, I
   Vertan, C
   Lambert, P
AF Ionescu, Bogdan Emanuel
   Seyerlehner, Klaus
   Mironica, Ionut
   Vertan, Constantin
   Lambert, Patrick
TI An audio-visual approach to web video categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio block-based descriptors; Color perception; Action assessment;
   Video relevance feedback; Video genre classification
ID RELEVANCE FEEDBACK; GENRE CLASSIFICATION; IMAGE RETRIEVAL; FEATURES
AB In this paper, we discuss and audio-visual approach to automatic web video categorization. To this end, we propose content descriptors which exploit audio, temporal, and color content. The power of our descriptors was validated both in the context of a classification system and as part of an information retrieval approach. For this purpose, we used a real-world scenario, comprising 26 video categories from the blip.tv media platform (up to 421 h of video footage). Additionally, to bridge the descriptor semantic gap, we propose a new relevance feedback technique which is based on hierarchical clustering. Experiments demonstrated that with this technique retrieval performance can be increased significantly and becomes comparable to that of high level semantic textual descriptors.
C1 [Ionescu, Bogdan Emanuel; Mironica, Ionut; Vertan, Constantin] Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
   [Ionescu, Bogdan Emanuel; Lambert, Patrick] Univ Savoie, Polytech Annecy Chambery, LISTIC, F-74944 Savoie, France.
   [Seyerlehner, Klaus] Johannes Kepler Univ Linz, DCP, A-4040 Linz, Austria.
C3 National University of Science & Technology POLITEHNICA Bucharest;
   Universite Savoie Mont Blanc; Johannes Kepler University Linz
RP Ionescu, BE (corresponding author), Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
EM bionescu@alpha.imag.pub.ro; klaus.seyerlehner@jku.at;
   imironica@alpha.imag.pub.ro; constantin.vertan@upb.ro;
   patrick.lambert@univ-savoie.fr
RI Vertan, Constantin/F-4459-2015; Ionescu, Bogdan/IWU-7778-2023
FU Romanian Sectoral Operational Programme Human Resources Development
   [POSDRU/89/1.5/S/62557, POSDRU/89/1.5/S/64109]; Austrian Science Fund
   (FWF) [L511-N15]
FX This work was supported by the Romanian Sectoral Operational Programme
   Human Resources Development 2007-2013 through the Financial Agreement
   POSDRU/89/1.5/S/62557 and POSDRU/89/1.5/S/64109, and by the Austrian
   Science Fund (FWF): L511-N15. We also acknowledge the 2011 Genre Tagging
   Task of the MediaEval Multimedia Benchmark [16] for providing the test
   data set.
CR [Anonymous], 2009, CoRR
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Cigarran J., 2011, P MEDIAEVAL 2011 WOR
   Fan JP, 2004, ACM-IEEE J CONF DIG, P192, DOI 10.1145/996350.996395
   Fernando W. A. C., 1999, IEEE INT C IM PROC K, P299
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Gibert X, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P345
   Hong GY, 2005, KYBERNETES, V34, P784, DOI 10.1108/03684920510595490
   Huang SH, 2006, MULTIMEDIA SYST, V12, P14, DOI 10.1007/s00530-006-0028-y
   Ibrahim ZA, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/537372
   Ionescu B., 2012, 18 INT C MULTIMEDIA
   Ionescu B, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/849625
   Ivanovici M, 2011, IEEE T IMAGE PROCESS, V20, P227, DOI 10.1109/TIP.2010.2059032
   Kelm P, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P25, DOI 10.1109/WIAMIS.2009.5031423
   Krzanowski W.J., 1993, Principles of multivarite analysis, a user's perspective
   Larson M., 2011, P MEDIAEVAL 2011 WOR
   Larson M., 2011, P MEDIAEVAL 2011 WOR, V807
   Lee MH, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P157
   Liang S, 2008, PATTERN RECOGN LETT, V29, P1733, DOI 10.1016/j.patrec.2008.05.004
   Liu Z, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P27, DOI 10.1109/MMSP.1998.738908
   MacArthur SD, 2002, COMPUT VIS IMAGE UND, V88, P55, DOI 10.1006/cviu.2002.0977
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Montagnuolo M, 2009, MULTIMED TOOLS APPL, V41, P125, DOI 10.1007/s11042-008-0222-3
   Nguyen N.V., 2009, INT C MACH LEARN PAT
   Perea-Ortega J. M., 2011, P MEDIAEVAL 2011 WOR
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   Rasheed Z, 2002, INT C PATT RECOG, P1086, DOI 10.1109/ICPR.2002.1048494
   Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230
   Rouvier M., 2011, P MEDIAEVAL 2011 WOR
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Schmiedeke S., 2011, P MEDIAEVAL 2011 WOR
   Semela T., 2011, P MEDIAEVAL 2011 WOR
   Seyerlehner K., 2010, 6 ANN MUS INF RETR E
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek CGM, 2005, ACM INT C MULT NEW Y
   Srinivasan U, 2005, MULTIMED TOOLS APPL, V27, P105, DOI 10.1007/s11042-005-2716-6
   Su CW, 2005, IEEE T MULTIMEDIA, V7, P1106, DOI 10.1109/TMM.2005.858394
   Tiwari R, 2011, P MEDIAEVAL 2011 WOR
   Truong BT, 2000, INT C PATT RECOG, P230, DOI 10.1109/ICPR.2000.902901
   Wang HL, 2003, J VIS COMMUN IMAGE R, V14, P150, DOI 10.1016/S1047-3203(03)00019-1
   Wang ZS, 2010, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2010.5540125
   Wei G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1345, DOI 10.1109/ICME.2000.871015
   Wu YM, 2004, MULTIMEDIA SYST, V10, P41, DOI 10.1007/s00530-004-0136-5
   Xu LQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P485
   Yuan X, 2006, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2006.313037
NR 46
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1007
EP 1032
DI 10.1007/s11042-012-1097-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900019
DA 2024-07-18
ER

PT J
AU López, MB
   Hannuksela, J
   Silvén, O
   Vehviläinen, M
AF Lopez, Miguel Bordallo
   Hannuksela, Jari
   Silven, Olli
   Vehvilainen, Markku
TI Interactive multi-frame reconstruction for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-frame reconstruction; Mobile device; Mobile interactivity
ID VISION
AB The small size of handheld devices, their video capabilities and multiple cameras are under-exploited assets. Properly combined, the features can be used for creating novel applications that are ideal for pocket-sized devices, but may not be useful in laptop computers, such as interactively capturing and analyzing images on the fly. In this paper we consider building mosaic images of printed documents and natural scenes from low resolution video frames. High interactivity is provided by giving a real-time feedback on the video quality, while simultaneously guiding the user's actions. In our contribution, we analyze and compare means to reach interactivity and performance with sensor signal processing and GPU assistance. The viability of the concept is demonstrated on a mobile phone. The achieved usability benefits suggest that combining interactive imaging and energy efficient high performance computing could enable new mobile applications and user interactions.
C1 [Lopez, Miguel Bordallo; Hannuksela, Jari; Silven, Olli] Univ Oulu, Ctr Machine Vis Res, FIN-90570 Oulu, Finland.
   [Vehvilainen, Markku] Nokia Res Ctr, Tampere, Finland.
C3 University of Oulu; Nokia Corporation; Nokia Finland; Siemens AG; Nokia
   Siemens Networks
RP López, MB (corresponding author), Univ Oulu, Ctr Machine Vis Res, FIN-90570 Oulu, Finland.
EM miguelbl@ee.oulu.fi
RI López, Miguel Bordallo/G-1685-2013
OI López, Miguel Bordallo/0000-0002-5707-9085; Silven,
   Olli/0000-0002-2661-804X; Hannuksela, Jari/0000-0001-9379-1304
CR Adams A, 2008, COMPUT GRAPH FORUM, V27, P597, DOI 10.1111/j.1467-8659.2008.01157.x
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2011 IEEE INT C MULT
   [Anonymous], VIRT REAL C VR
   [Anonymous], 3 INT C COMP VIS THE
   [Anonymous], 2006, WORKSH EDG COMP US N
   [Anonymous], 2007, 2007 IEEE WORKSH MOT
   [Anonymous], 2 INT S UB COMP SYST
   [Anonymous], MOBILE PHONE PROGRAM
   [Anonymous], INT WORKSH COMP VIS
   [Anonymous], 2010, PROC 18 ACM INT C MU
   [Anonymous], P SPIE EL IM 2009
   [Anonymous], P SPIE EL IM 2007
   [Anonymous], I3D 05 ACM SIGGRAPH
   [Anonymous], 2011, P SPIE
   Bilcu Radu Ciprian, 2008, 2008 15th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2008), P1312, DOI 10.1109/ICECS.2008.4675101
   Capin T, 2008, IEEE COMPUT GRAPH, V28, P74, DOI 10.1109/MCG.2008.83
   Dabrowski J.R., 2001, P SIGCHI C HUMAN FAC, P317
   DiVerdi S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P75
   Fung J, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P9, DOI 10.1109/ICME.2008.4607358
   Ha SJ, 2008, IEEE T CONSUM ELECTR, V54, P16, DOI 10.1109/TCE.2008.4470018
   Hannuksela J, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P575, DOI 10.1109/ICIAP.2007.4362839
   Hannuksela J, 2007, COMPUT VIS IMAGE UND, V108, P188, DOI 10.1016/j.cviu.2006.10.014
   Hannuksela J, 2010, PROC SPIE, V7542, DOI 10.1117/12.839449
   Haro A, 2005, LECT NOTES COMPUT SC, V3766, P79, DOI 10.1007/11573425_8
   Hwang J., 2006, VRST '06: Proc. ACM Symp. on Virtual Reality Software and Technol, P356
   Kalva H, 2011, MULTIMED TOOLS APPL, V51, P801, DOI 10.1007/s11042-010-0656-2
   Kim SP, 1993, IEEE T IMAGE PROCESS, V2, P534, DOI 10.1109/83.242363
   Mohring Mathias., 2004, Proc. of Workshop on Virtual and Augmented Reality of the GIFachgruppe AR/VR, P193
   Nazhandali L, 2005, CONF PROC INT SYMP C, P197, DOI 10.1109/ISCA.2005.26
   Pulli K, 2012, COMMUN ACM, V55, P61, DOI 10.1145/2184319.2184337
   Pulli K, 2009, 2009 INTERNATIONAL SYMPOSIUM ON UBIQUITOUS VIRTUAL REALITY (ISUVR 2009), P3, DOI 10.1109/ISUVR.2009.12
   Rakhmatov D., 2003, ACM Transactions on Embedded Computing Systems, V2, P277
   Singhal N, 2010, IEEE IMAGE PROC, P4481, DOI 10.1109/ICIP.2010.5651740
   Tian YS, 2012, MULTIMED TOOLS APPL, V60, P519, DOI 10.1007/s11042-011-0821-2
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   Winkler S, 2007, LECT NOTES COMPUT SC, V4555, P605
   Xiong YG, 2010, IEEE T CONSUM ELECTR, V56, P298, DOI 10.1109/TCE.2010.5505931
NR 38
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 31
EP 51
DI 10.1007/s11042-012-1252-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200003
DA 2024-07-18
ER

PT J
AU Kim, HJ
   Park, SB
   Jo, GS
AF Kim, Hyun-Jun
   Park, Seung-Bo
   Jo, Geun-Sik
TI Affective social network-happiness inducing social media platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Affective computing; Emotion inducement; Microblogging;
   Automatic emotion annotation
ID PERSONALITY
AB We propose a human emotion regarding social network, namely, the Affective Social Network. Our suggestion firstly builds a user's emotion profile in terms of the personality, mood and emotion by analysing the user's activities in social network. This subsequently builds an Emotional Relationship Matrix (ERM) which represents the depth of the emotional relationship based on the emotion profile. From our proposal, the more elaborate services based on the current user's emotional state can be provided to users. By considering emotional aspects in a social network, we can effectively answer which users or media contents will show the best results for inducing users' emotional states. From the experiments, we verified that message containing emotional words and users' relationship in a social network has significant correlations.
C1 [Kim, Hyun-Jun] INHA Univ, Dept Comp Sci & Informat Engn, Intelligent E Commerce Lab, Inchon, South Korea.
   [Park, Seung-Bo] INHA Univ, Grad Sch Educ, Inchon, South Korea.
   [Jo, Geun-Sik] INHA Univ, Dept Comp Sci & Informat Engn, Inchon, South Korea.
C3 Inha University; Inha University; Inha University
RP Kim, HJ (corresponding author), INHA Univ, Dept Comp Sci & Informat Engn, Intelligent E Commerce Lab, 253 YongHyun Dong, Inchon, South Korea.
EM danniskim@gmail.com; molaal@eslab.inha.ac.kr; gsjo@inha.ac.kr
RI Kim, Hyun Jun/O-6262-2016
CR Baldi P, 2003, MODELING INTERNET WE, P125
   Bray T, 1996, COMPUT NETWORKS ISDN, V28, P993, DOI 10.1016/0169-7552(96)00061-X
   Chou HTG, 2012, CYBERPSYCH BEH SOC N, V15, P117, DOI 10.1089/cyber.2011.0324
   DORNBUSH S, 2005, INT C MOB TECHN APPL
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   Ekman P., 1994, The nature of emotion: Fundamental questions
   GARFIELD E, 1972, SCIENCE, V178, P471, DOI 10.1126/science.178.4060.471
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Healey J, 1998, INT CONF ACOUST SPEE, P3749, DOI 10.1109/ICASSP.1998.679699
   ISEN AM, 1983, ORGAN BEHAV HUM PERF, V31, P194, DOI 10.1016/0030-5073(83)90120-4
   Java A., 2006, P 15 INT WORLD WID W
   Khooshabeh P, 2011, ACM C HUM FACT COMP
   Kim H.-J, 2011, WORKSH PERS MOB APPL
   Knoke D, 2000, SOCIAL NETWORK ANAL
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   LAZARUS RS, 1991, AM PSYCHOL, V46, P819, DOI 10.1037/0003-066X.46.8.819
   Nicholson J, 2000, NEURAL COMPUT APPL, V9, P290, DOI 10.1007/s005210070006
   Nielek R, 2010, EMOTION AWARE MOBILE
   Ortony A., 1988, COGNITIVE STRUCTURE
   Page L., 1998, P 7 INT WORLD WID WE, P161
   Park SB, 2011, LECT NOTES ARTIF INT, V6592, P130, DOI 10.1007/978-3-642-20042-7_14
   Pennebaker JW, 2001, CURR DIR PSYCHOL SCI, V10, P90, DOI 10.1111/1467-8721.00123
   Picard R.W., 1995, AFFECTIVE COMPUTING
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Rusting CL, 1998, PSYCHOL BULL, V124, P165, DOI 10.1037/0033-2909.124.2.165
   Schuller B, 1999, ACOUSTIC SPEECH SIGN, V2, P1
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   WILSON I, 2000, AAAI SPRING S ART IN
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang Y, 2010, PROC INT CONF DATA, P1157, DOI 10.1109/ICDE.2010.5447819
NR 31
TC 11
Z9 15
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 355
EP 374
DI 10.1007/s11042-012-1157-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400011
DA 2024-07-18
ER

PT J
AU Zhou, YR
   Zhang, Q
AF Zhou, Yiran
   Zhang, Qi
TI An efficient FMO-based error-resilient scheme for video surveillance
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error resilience; FMO; Error sensitivity; Encoding domain; H.264/AVC;
   Video surveillance coding
ID TRANSMISSION; MACROBLOCK; H.264/AVC
AB The encoded video bitstreams have to suffer from quality degradation when transmitted over unreliable channels. In this paper, a novel flexible macroblock ordering (FMO)-based error-resilient scheme is proposed to cope with this problem, which is aimed at the video surveillance scenarios. This scheme could not only meet the need of prioritized transmission environment, but also take advantage of FMO's inherent error-resilient function. A motion region extraction algorithm is first advised and utilized, and each motion region's error sensitivity is then estimated based on both pictures' features and transmission condition. According to the error sensitivity value, the optimal FMO encoding mode for each motion region is selected, which enables the error-resilient intensity to be more adaptive. The intra refresh enhancement is introduced at the same time to further improve the error-resilient performance of the proposed FMO structure. To reduce the complexity, most information for calculations is derived from the encoding process. Experiments demonstrate that the proposed scheme performs better than the conventional schemes, and improves the video quality efficiently.
C1 [Zhou, Yiran; Zhang, Qi] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Zhou, YR (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian, Peoples R China.
EM zyr82@sina.com
FU "the Fundamental Research Funds for the Central Universities" of China
   [2011QN123]
FX This article is supported by "the Fundamental Research Funds for the
   Central Universities" of China under Contract 2011QN123 (Dalian Maritime
   University). The authors also would like to thank Dr. Hong JIN for her
   helpful review.
CR Cajote RD, 2010, P INT S COMM INF TEC, P1131, DOI [10.1109/ISCIT.2010.5665157, DOI 10.1109/ISCIT.2010.5665157]
   Cajote RD, 2008, IEEE INT SYMP CIRC S, P3566, DOI 10.1109/ISCAS.2008.4542230
   Chen H, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P868, DOI 10.1109/ICALIP.2008.4589969
   Ferré P, 2008, IEEE T VEH TECHNOL, V57, P2596, DOI 10.1109/TVT.2007.909258
   Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   Ghandi MM, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/85870
   Hu HM, 2009, J VIS COMMUN IMAGE R, V20, P35, DOI 10.1016/j.jvcir.2008.09.006
   Im SK, 2007, IET IMAGE PROCESS, V1, P197, DOI 10.1049/iet-ipr:20060262
   Im SK, 2005, PROC SPIE, V5960, P1033, DOI 10.1117/12.632649
   ISO/IEC International Standard, 2001, 144962 ISOIEC
   Jahaniaval A, 2007, IEEE INT S SIGN PROC, P972, DOI [10.1109/ISSPIT.2007.4458056, DOI 10.1109/ISSPIT.2007.4458056]
   Katz B, 2007, IEEE T BROADCAST, V53, P308, DOI 10.1109/TBC.2006.889694
   Kwon SK, 2006, J VIS COMMUN IMAGE R, V17, P186, DOI 10.1016/j.jvcir.2005.05.010
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   Li J, 2005, P INT C WIR NETW COM, V2, P1118, DOI [10.1109/WIRLES.2005.1549569, DOI 10.1109/WIRLES.2005.1549569]
   Luo R., 2008, P IEEE ICACT 2008 FE, P1579, DOI DOI 10.1109/ICACT.2008.4494082
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Panyavaraporn J, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3589307
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Ryu H, 2007, PROC SPIE, V6494, DOI 10.1117/12.702988
   Shih JY, 2010, MULTIMED TOOLS APPL, V47, P461, DOI 10.1007/s11042-009-0333-5
   Song L, 2009, IEEE INT CON MULTI, P742, DOI 10.1109/ICME.2009.5202601
   Sun G, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1735, DOI 10.1109/APCCAS.2008.4746375
   Wang J, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P798, DOI 10.1109/ICASIC.2007.4415751
   Wang XL, 2010, P INT C COMP MOD SIM, V3, P175, DOI [10.1109/ICCMS.2010.408, DOI 10.1109/ICCMS.2010.408]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu ZY, 2006, P INT C IM PROC, V825-8281, DOI [10.1109/ICIP.2006.312529, DOI 10.1109/ICIP.2006.312529]
   Yim C, 2005, LECT NOTES COMPUT SC, V3767, P120
   Zheng JH, 2006, IEEE T BROADCAST, V52, P223, DOI 10.1109/TBC.2006.874745
   Zhu H, 2006, CHINESE J ELECTRON, V15, P151
NR 30
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 339
EP 359
DI 10.1007/s11042-012-1049-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300001
DA 2024-07-18
ER

PT J
AU Stober, S
   Nürnberger, A
AF Stober, Sebastian
   Nuernberger, Andreas
TI Adaptive music retrieval-a state of the art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Adaptive systems; Survey; Overview
ID CONTEXT; SYSTEM; COLLECTIONS; KEY
AB With the development of more and more sophisticated Music Information Retrieval approaches, aspects of adaptivity are becoming an increasingly important research topic. Even though, adaptive techniques have already found their way into Music Information Retrieval systems and contribute to robustness or user satisfaction they are not always identified as such. This paper attempts a structured view on the last decade of Music Information Retrieval research from the perspective of adaptivity in order to increase awareness and promote the application and further development of adaptive techniques. To this end, different approaches from a wide range of application areas that share the common aspect of adaptivity are identified and systematically categorized.
C1 [Stober, Sebastian; Nuernberger, Andreas] Univ Magdeburg, Data & Knowledge Engn Grp, Fac Comp Sci, D-39106 Magdeburg, Germany.
C3 Otto von Guericke University
RP Stober, S (corresponding author), Univ Magdeburg, Data & Knowledge Engn Grp, Fac Comp Sci, Univ Pl 2, D-39106 Magdeburg, Germany.
EM stober@ovgu.de
OI Nurnberger, Andreas/0000-0003-4311-0624
CR [Anonymous], 2006, ISMIR
   [Anonymous], P 7 INT C MUS INF RE
   [Anonymous], P ISMIR
   [Anonymous], P ISMIR
   [Anonymous], P 6 INT WORKSH AD MU
   AstrOm KJ., 1994, ADAPTIVE CONTROL
   Bade K., 2008, Proceedings of the SIAM International Conference on Data Mining, SDM 2008, P13
   Bade K, 2009, P NAG DAGA 2009 INT, P344
   Bade Korinna, 2009, ISMIR, P741
   Baumann S, 2004, P 1 C INT MUS CIM 04
   BELEW RK, 1989, SIGIR FORUM, V23, P11, DOI 10.1145/75335.75337
   Bello J. P., 2005, P 6 INT C MUSIC INFO, P304, DOI 10.5281/zenodo.1417431
   Berenzweig A, 2004, COMPUT MUSIC J, V28, P63, DOI 10.1162/014892604323112257
   Betser M., 2007, Proc. of the 8th International Conference on Music Information Retrieval, P139
   Brossier P.M, 2005, FAST ONSET DETECTION
   Broy Manfred, 2009, P 2009 ACM S APPL CO, P1029, DOI [10.1145/1529282.1529508, DOI 10.1145/1529282.1529508]
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   Brusilovsky P, 2001, USER MODEL USER-ADAP, V11, P87, DOI 10.1023/A:1011143116306
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chordia P, 2007, ISMIR 2007
   Chuan C.H., 2005, P INT C MUSIC INFORM, P296, DOI DOI 10.5281/ZENODO.1417297
   Cunningham S, 2008, P AUD MOSTL 2008 C S
   Dey AK, 2000, COMP HUM INT CHI 200
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Diakopoulos D, 2009, ISMIR 2009
   Elliott G.T., 2006, CHI 06, P736, DOI DOI 10.1145/1125451.1125599
   Ellis D.P., 2003, P INT SOC MUS INF RE, P185
   Ellis DPW, 2002, ISMIR 2002
   Fujihara H, 2006, P IEEE INT C AC SPEE, V5
   GABRYS B, 2005, DO SMART ADAPTIVE SY
   Goto M, 2001, IEEE INT C AC SPEECH, V5
   Grachten M, 2009, ISMIR 2009
   Guan DH, 2006, LECT NOTES COMPUT SC, V4223, P1201
   Harte C., 2005, P AUD ENG SOC, P291
   Hitchner S, 2007, ISMIR 2007
   Hoashi K., 2003, MULTIMEDIA 03, P110
   Hu X., 2006, P ISMIR, P19
   Jones S, 2004, ISMIR 2004
   Julia CF, 2009, ISMIR 2009
   Knees P, 2007, IEEE MULTIMEDIA, V14, P46, DOI 10.1109/MMUL.2007.48
   Lartillot O., 2007, P 10 INT C DIG AUD E, V237, P244, DOI DOI 10.1007/978-3-540-78246-9_31
   Laube V, 2008, P 2 WORKSH LEARN SEM, P19
   Law E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1197
   Lee J H, 2004, ISMIR 2004
   Lee JS, 2006, LECT NOTES COMPUT SC, V4272, P190
   Lee K, 2007, ISMIR 2007
   Leitich S, 2007, ISMIR 2007
   Lerch A., 2006, P 7 INT C MUS INF RE, P212
   Little D., 2007, Proceedings of the Eighth International Conference on Music Information Retrieval, P335
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P1, DOI 10.1007/978-3-642-14267-3
   Loscos A., 2006, P INT C MUS INF RETR, P164
   Lubbers D., 2005, Proceedings of the International Conference on Music Information Retrieval, P590
   Lubbers D, 2009, ISMIR 2009
   MADDAGE NC, 2004, P 12 ANN ACM INT C M, P112, DOI DOI 10.1145/1027527.1027549
   Mandel MI, 2006, MULTIMEDIA SYST, V12, P3, DOI 10.1007/s00530-006-0032-2
   Mandl T, 2002, ISMIR 2002
   Marolt M, 2009, ISMIR 2009
   Martin H Jose Antonio, 2009, Natural Computing, V8, P757, DOI 10.1007/s11047-008-9096-6
   Mauch M., 2010, P 11 INT SOC MUS INF, P135
   Mauch M, 2010, IEEE T AUDIO SPEECH, V18, P1280, DOI 10.1109/TASL.2009.2032947
   McFee B, 2009, ISMIR 2009
   McFee B., 2010, ISMIR, P345
   Michels K., 2006, FUZZY CONTROL
   Moh Y., 2008, P INT SOC MUS INF RE, P167
   Montecchio N, 2009, ISMIR 2009
   Morchen Fabian., 2005, Proceedings of the 6th International Conference on Music Information Retrieval ISMIR'05, P396
   Muller M, 2009, ISMIR 2009
   Neumayer R., 2005, QUEEN MARY, P618
   Niitsuma M., 2008, Proceedings of International Society for Music Information Retrieval Conference, P193
   Noland K., 2006, PROC INT SOC MUSIC I, P121
   Nürnberger A, 2005, STUD FUZZ SOFT COMP, V173, P341
   Oliver Nuria., 2006, P 8 C HUMAN COMPUTER, P21, DOI DOI 10.1111/NYAS.12650
   Orio Nicola, 2006, Foundations and Trends in Information Retrieval, V1, P1, DOI 10.1561/1500000002
   Pampalk E, 2005, LECT NOTES COMPUT SC, V3652, P37, DOI 10.1007/11551362_4
   Pampalk E, 2003, ISMIR 2003
   Pampalk E, 2006, ISMIR 2006, P389
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Pampalk E., 2005, P 6 INT C MUS INF RE, P634, DOI [DOI 10.5281/ZENODO.1414932, 10.5281/zenodo.1414932]
   Papadopoulos H, 2007, INT WORK CONTENT MUL, P53
   Park HS, 2006, LECT NOTES COMPUT SC, V4223, P970
   Pauws S, 2002, ISMIR 2002
   Pauws Steffen., 2005, P ISMIR INT C MUSIC, P638
   Peeters G., 2006, P INT C DIGITAL AUDI, P127
   Pohle T, 2008, P 6 INT WORKSH AD MU
   Pugin L, 2007, ISMIR 2007
   Rauber A, 2002, ISMIR 2002
   Ravelli E, 2008, ISMIR 2008, P527
   Reinhard J, 2008, P 6 INT WORKSH CONT
   Reynolds G., 2007, Proceedings of Audio Mostly Conference: Interaction with Sound, P84
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rolland P, 2001, ISMIR
   Shenoy A, 2005, COMPUT MUSIC J, V29, P75, DOI 10.1162/0148926054798205
   Slaney M., 2008, Proc. ISMIR, P313
   Sotiropoulos DN, 2008, USER MODEL USER-ADAP, V18, P315, DOI 10.1007/s11257-007-9035-8
   Stavness I, 2005, LECT NOTES COMPUT SC, V3711, P291
   Stober S., 2011, P 9 INT WORKSH AD MU
   Stober S, 2009, KI, V23, P54
   Stober S, 2009, P 3 INT WORKSH LEARN, P45
   Stober S, 2008, AD MULT RETR 6 INT W
   Stober Sebastian, 2010, P 7 INT S COMP MUS M
   Stober Sebastian, 2010, P 7 SOUND MUS COMP C
   Su MY, 2009, ISMIR 2009
   Sumi K., 2008, ISMIR 2008 P 9 INT C, P39
   Vignoli Fabio., 2005, PROC INT S MUSIC INF, P272
   Wolff D., 2011, P 9 INT WORKSH AD MU
   Wolter K, 2008, P 6 INT WORKSH AD MU
   You W, 2007, ISMIR 2007
   Zhu Y, 2006, IEEE T MULTIMEDIA, V8, P575, DOI 10.1109/TMM.2006.870727
NR 108
TC 11
Z9 12
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 467
EP 494
DI 10.1007/s11042-012-1042-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600007
DA 2024-07-18
ER

PT J
AU Aranda-Corral, GA
   Borrego-Díaz, J
   Giráldez-Cru, J
AF Aranda-Corral, Gonzalo A.
   Borrego-Diaz, Joaquin
   Giraldez-Cru, Jesus
TI Agent-mediated shared conceptualizations in tagging services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge reconciliation; Multiagentsystems; Formal concept analysis
AB Some of the most remarkable innovative technologies from the Web 2.0 are the collaborative tagging systems. They allow the use of folksonomies as a useful structure for a number of tasks in the social web, such as navigation and knowledge organization. One of the main deficiencies comes from the tagging behaviour of different users which causes semantic heterogeneity in tagging. As a consequence a user cannot benefit from the adequate tagging of others. In order to solve the problem, an agent-based reconciliation knowledge system, based on Formal Concept Analysis, is applied to facilitate the semantic interoperability between personomies. This article describes experiments that focus on conceptual structures produced by the system when it is applied to a collaborative tagging service, Delicious. Results will show the prevalence of shared tags in the sharing of common resources in the reconciliation process.
C1 [Aranda-Corral, Gonzalo A.] Univ Huelva, Dept Informat Technol, Palos De La Frontera 21819, Huelva, Spain.
   [Borrego-Diaz, Joaquin] Univ Seville, Dept Comp Sci & Artificial Intelligence, E-41012 Seville, Spain.
   [Giraldez-Cru, Jesus] Artificial Intelligence Res Inst IIIA CSIC, Bellaterra 08193, Spain.
C3 Universidad de Huelva; University of Sevilla; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Instituto de Investigacion en
   Inteligencia Artificial (IIIA)
RP Aranda-Corral, GA (corresponding author), Univ Huelva, Dept Informat Technol, Crta Palos de La Frontera S-N, Palos De La Frontera 21819, Huelva, Spain.
EM gonzalo.aranda@dti.uhu.es; jborrego@us.es; jgiraldez@iiia.csic.es
RI Borrego-Díaz, Joaquín/M-3295-2014; Aranda-Corral, Gonzalo
   A./B-9618-2012; Giraldez-Cru, Jesus/J-3011-2018
OI Borrego-Díaz, Joaquín/0000-0003-0528-9459; Aranda-Corral, Gonzalo
   A./0000-0003-4318-6573; Giraldez-Cru, Jesus/0000-0001-8963-6299
FU Spanish Ministry of Science and Innovation [TIN2009-09492,
   TIN2010-20967-C04-01]; Junta de Andalucia [TIC-6064]; FEDER
FX This work has been supported by TIN2009-09492 and TIN2010-20967-C04-01
   projects of Spanish Ministry of Science and Innovation and Excellence
   project TIC-6064 of Junta de Andalucia cofinanced with FEDER founds.
CR [Anonymous], ENG TECHNOL
   [Anonymous], 2007, Tagging: People-powered Metadata for the Social Web
   [Anonymous], P 7 INT C CONC LATT
   [Anonymous], P 20 ACM C HYP HYP T
   [Anonymous], KNOWLEDGE ENG NOTES
   [Anonymous], J INF SCI
   [Anonymous], J STAT MECH
   [Anonymous], P 6 INT C CONC LATT
   [Anonymous], 2007, P 16 INT C WORLD WID
   [Anonymous], LECT NOTES ARTIF INT
   Aranda-Corral GA, 2010, LECT NOTES ARTIF INT, V6077, P383, DOI 10.1007/978-3-642-13803-4_48
   Bartolini I, 2013, MULTIMED TOOLS APPL, V63, P357, DOI 10.1007/s11042-011-0948-1
   Carmel D, 2010, VLDB J, V19, P761, DOI 10.1007/s00778-010-0211-9
   Gal A, 2008, LECT NOTES COMPUT SC, V4891, P176
   Ganter B, 1999, Formal concept analysis: Mathematical foundations
   Gligorov Riste, 2011, 6 INT C KNOWL CAPT, P145
   Guigues J.-L., 1986, Math. Sci. Hum., V95, P5
   Haslhofer B, 2012, MULTIMED TOOLS APPL, V70, P847, DOI DOI 10.1007/S11042-012-1098-9
   Jäschke R, 2008, J WEB SEMANT, V6, P38, DOI 10.1016/j.websem.2007.11.004
   Jaschke Robert., 2011, Formal concept analysis and tag recommendations in collaborative tagging systems
   Jung JJ, 2012, COMPUT J, V55, P337, DOI 10.1093/comjnl/bxr102
   Jung JJ, 2009, EXPERT SYST APPL, V36, P10627, DOI 10.1016/j.eswa.2009.02.052
   Lee S, 2013, MULTIMED TOOLS APPL, V64, P7, DOI 10.1007/s11042-011-0850-x
   Onifade OFW, 2010, COMM COM INF SC, V54, P232
   Pammer V, 2012, MULTIMED TOOLS APPL, V59, P441, DOI 10.1007/s11042-011-0761-x
   Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133
NR 26
TC 10
Z9 10
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 5
EP 28
DI 10.1007/s11042-012-1146-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800002
DA 2024-07-18
ER

PT J
AU Wang, G
   Zhang, CH
   Qiu, XF
   Zeng, ZM
AF Wang, Gang
   Zhang, Chunhong
   Qiu, Xiaofeng
   Zeng, Zhimin
TI An efficient relay node selection scheme to improve the performance of
   P2P-based VoIP applications in Chinese internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Delay space; Relay node selection; P2P; VoIP
ID QUALITY; OVERLAY
AB Peer-to-peer (P2P) systems have been widely deployed and used to provide voice-over-IP (VoIP) service in the Internet. However, the current best-effort Internet cannot readily provide the service guarantees that meet the quality standards achieved in the public switched telephone network (PSTN). To address this problem, many studies have demonstrated that exploiting path diversity is a promising approach, such as multi-homing and overlay routing. In this paper, we focus on the overlay scenario and bring forward a previously unexplored approach that exploits the properties of delay space of Internet to select relay node to enhance the performance of P2P-based VoIP applications in Chinese Internet. By conducting intensive Internet measurements, we analyze the properties of delay space of Chinese Internet and show these properties can be readily exploited to select relay node with as small a cost as possible. Exploiting these properties we bring forward an efficient relay node selection scheme to improve the performance of P2P-based VoIP applications in Chinese Internet. Our intensive evaluation by trace-driven simulation shows our scheme is highly efficient and easy to be implemented.
C1 [Wang, Gang; Zhang, Chunhong; Qiu, Xiaofeng; Zeng, Zhimin] Minist Educ, Key Lab Universal Wireless Commun, Beijing, Peoples R China.
   [Wang, Gang; Zhang, Chunhong; Qiu, Xiaofeng; Zeng, Zhimin] Beijing Univ Posts & Telecommun, Mobile Life & New Media Lab, Beijing 100088, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wang, G (corresponding author), Minist Educ, Key Lab Universal Wireless Commun, Beijing, Peoples R China.
EM wifnstone@gmail.com
RI zhang, chunmei/IUQ-7038-2023; Zhang, Chun/GRE-8915-2022
FU International Scientific and Technological Cooperation Projects
   [2010DFA12780]; Key National Science & Technology Specific Projects
   [2010ZX03005-003]; Fundamental Research Funds for the Central
   Universities [2009RC0121]
FX We thank anonymous reviewers for their constructive suggestions. This
   work is supported by the International Scientific and Technological
   Cooperation Projects under No. 2010DFA12780, the Key National Science &
   Technology Specific Projects under No. 2010ZX03005-003 and the
   Fundamental Research Funds for the Central Universities under No.
   2009RC0121.
CR Akella A, 2003, ACM SIGCOMM COMP COM, V33, P353
   Akella A, 2003, SIGCOMM OCT, p316~317
   Amir Y, 2006, IEEE T MULTIMEDIA, V8, P1250, DOI 10.1109/TMM.2006.884609
   ANDERSEN D., 2001, 18 ACM S OP SYST PRI, V35, P131
   [Anonymous], SIGMETRICS PERFORM E
   Bo Zhang, 2010, IEEE/ACM Transactions on Networking, V18, P229, DOI 10.1109/TNET.2009.2024083
   Castro M., 2002, INT WORKSHOP FUTURE, P52
   Fei T, 2006, INFOCOM 2006 25 IEEE, p1~13
   Gummadi KP, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P183
   Gummadi KP, 2002, IMW 2002: PROCEEDINGS OF THE SECOND INTERNET MEASUREMENT WORKSHOP, P5, DOI 10.1145/637201.637203
   Karger David, 1997, P 29 ANN ACM S THEOR, P654, DOI DOI 10.1145/258533.258660
   LEE S, 2006, SIGMETRICS 2006 PERF, P157
   Lumezanu C, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P177
   Lumezanu C, 2009, LECT NOTES COMPUT SC, V5448, P45, DOI 10.1007/978-3-642-00975-4_5
   Markopoulou AP, 2003, IEEE ACM T NETWORK, V11, P747, DOI 10.1109/TNET.2003.818179
   Monnerat L.R., 2006, 20 IEEE INT PAR DIST, P1
   Rajendran RK, 2006, INFOCOM, p1~12
   Ratnasamy S, 2002, IEEE INFOCOM SER, P1190, DOI 10.1109/INFCOM.2002.1019369
   Ren S, 2006, 26 IEEE INT C DISTR, P70
   Schooler E., 2002, 3261 RFC
   Stoica I, 2003, IEEE ACM T NETWORK, V11, P17, DOI 10.1109/TNET.2002.808407
   Tao S, 2005, IEEE INFOCOM SER, P2268
   Zhao BY, 2004, IEEE J SEL AREA COMM, V22, P41, DOI 10.1109/JSAC.2003.818784
NR 23
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 599
EP 625
DI 10.1007/s11042-011-0952-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600005
DA 2024-07-18
ER

PT J
AU Shen, LQ
   Liu, Z
   Zhang, ZY
AF Shen, Liquan
   Liu, Zhi
   Zhang, Zhaoyang
TI A novel H.264 rate control algorithm with consideration of visual
   attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; Visual attention; Frame-level bit allocation; MB-level bit
   allocation
ID BIT ALLOCATION; VIDEO; MODEL; TRANSMISSION
AB In video coding, a well-designed rate control scheme should be concerned with both the objective and subjective quality. However, the existing H.264 rate control algorithms mainly aim at improving the objective quality without considering the human visual system. In this paper, we propose a novel rate control algorithm that takes into account visual attention. In a group of pictures, bits allocated to each frame are related to the local motion attention in it, and more bits are allocated to the frames with strong local motion attention. Similarly, in each frame, more bits are assigned to visually significant macroblocks (MBs), and fewer to visually insignificant MBs. Experiment results show that the proposed algorithm improves the coding quality in frames with strong local motion, and reduces PSNR fluctuation across frames by up to 22.15%. In addition, PSNR in visually important regions is increased by up to 1.45 dB as compared to the standard H.264 rate control scheme that improves the subjective quality. Increased computation complexity of the proposed algorithm is less than 4%, which is negligible.
C1 [Shen, Liquan; Liu, Zhi; Zhang, Zhaoyang] Shanghai Univ, Minist Educ, Key Lab Adv Display & Syst Applicat, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Shen, LQ (corresponding author), Shanghai Univ, Minist Educ, Key Lab Adv Display & Syst Applicat, Shanghai 200072, Peoples R China.
EM jsslq@163.com
RI LIU, Zhi/D-4518-2012; Zhang, Zhaoyang/AFQ-9161-2022; Shen,
   Liquan/D-4832-2012
OI LIU, Zhi/0000-0002-8428-1131; 
FU Shanghai Rising-Star Program [11QA1402400]; Innovation Program of
   Shanghai Municipal Education Commission [10YZ09]; National Natural
   Science Foundation of China [60832003, 60902085, 61171084]
FX The authors are grateful to Ms Xiuya Yuan for her assistance in
   improving the language usage. This work is sponsored by Shanghai
   Rising-Star Program (11QA1402400) and Innovation Program of Shanghai
   Municipal Education Commission (No. 10YZ09), and is supported by the
   National Natural Science Foundation of China under grant No. 60832003,
   60902085 and 61171084.
CR Adiono T, 2000, 2000 IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P461, DOI 10.1109/APCCAS.2000.913536
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen MJ, 2003, IEEE T CONSUM ELECTR, V49, P724, DOI 10.1109/TCE.2003.1233810
   Chen ZZ, 2006, IEEE T MULTIMEDIA, V8, P1117, DOI 10.1109/TMM.2006.884633
   DEUTSCH JA, 1963, PSYCHOL REV, V70, P80, DOI 10.1037/h0039515
   Ding Wei, 1996, CIRCUITS SYSTEMS VID, V6, P12
   Eleftheriadis A., 1994, 1994 IEEE International Symposium on Circuits and Systems (Cat. No.94CH3435-5), P177, DOI 10.1109/ISCAS.1994.409135
   *ISO IEC, 1993, JTC1SC29WG11 ISOIEC
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jo SK, 1996, IEEE T IMAGE PROCESS, V5, P527, DOI 10.1109/83.491326
   Kim WJ, 1999, IEEE T IMAGE PROCESS, V8, P974, DOI 10.1109/83.772244
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   LI ZG, 2003, JVT G012 7 M PATT TH
   Liu SH, 2009, ISPD 2009 ACM INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P175
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   PARK NS, 1995, AS PAC C COMM APCC, P658
   Ramos MG, 1996, P SOC PHOTO-OPT INS, V2727, P1082, DOI 10.1117/12.233181
   Rapantzikos K, 2007, IET IMAGE PROCESS, V1, P237, DOI 10.1049/iet-ipr:20060040
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Shen LQ, 2009, J VIS COMMUN IMAGE R, V20, P28, DOI 10.1016/j.jvcir.2008.08.003
   Song HJ, 2004, IEEE T MULTIMEDIA, V6, P489, DOI 10.1109/TMM.2004.827488
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tian L, 2009, IEEE INT CON MULTI, P45, DOI 10.1109/ICME.2009.5202432
   Yang L, 2009, PICT COD S CHIC US M
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P496, DOI 10.1109/TCSVT.2005.844458
   Zhu ZJ, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/830605
NR 30
TC 33
Z9 37
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 709
EP 727
DI 10.1007/s11042-011-0893-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000006
DA 2024-07-18
ER

PT J
AU Yilmazturk, MC
   Ulusoy, I
   Cicekli, NK
AF Yilmazturk, M. C.
   Ulusoy, I.
   Cicekli, N. K.
TI Online annotation of faces in personal videos by sequential learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal video annotation; Automatic annotation of faces; Sequential
   learning
ID RECOGNITION; RETRIEVAL
AB This paper addresses semi-automatic annotation of faces in personal videos. Different from previous offline annotation systems, this paper studies online annotation of faces. During an annotation session, few annotations are requested from the user only for some part of the video online. These annotations are used to train a system that will perform annotation automatically for the rest of the video. The automatic annotation results are presented to the user during the same session and the user is allowed to correct any automatic annotation mistakes. Thus, only fast and accurate face recognition methods are considered. Instead of batch learning, which has been used in the existing annotation systems, this paper proposes sequential learning methods to be used as face classifiers. Different classification methods are tested with various feature extraction methods using the same database so that a fair comparison is made among them. The results are evaluated in terms of recognition accuracies and execution time requirements.
C1 [Yilmazturk, M. C.; Ulusoy, I.] METU, Dept Elect & Elect Eng, Ankara, Turkey.
   [Cicekli, N. K.] METU, Dept Comp Eng, Ankara, Turkey.
C3 Middle East Technical University; Middle East Technical University
RP Ulusoy, I (corresponding author), METU, Dept Elect & Elect Eng, Ankara, Turkey.
EM ilkay@metu.edu.tr; nihan@ceng.metu.edu.tr
RI , ilkay/AAZ-9415-2020
FU Scientific and Technical Council of Turkey [TUBITAK EEEAG-107E234]
FX This work is partially supported by The Scientific and Technical Council
   of Turkey Grant TUBITAK EEEAG-107E234.
CR [Anonymous], THESIS U KARLSRUHE
   [Anonymous], P 13 EUR SING PROC C
   [Anonymous], BRIT MACH VIS C
   [Anonymous], INT JOINT C ART INT
   [Anonymous], 2000, TECHNICAL REPORT
   [Anonymous], ISCIS 2010 LOND UK
   [Anonymous], 2008, REAL LIF IM WORKSH E
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Arandjelovic O, 2005, PROC CVPR IEEE, P860
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Domeniconi C, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P589, DOI 10.1109/ICDM.2001.989572
   Everingham M, 2009, IMAGE VISION COMPUT, V27, P545, DOI 10.1016/j.imavis.2008.04.018
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744
   Ramanan D, 2007, IEEE 11 INT C ICCV 2, P1
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Satoh S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P163, DOI 10.1109/AFGR.2000.840629
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sivic J, 2005, LECT NOTES COMPUT SC, V3568, P226
   Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhu JK, 2008, IEEE T MULTIMEDIA, V10, P86, DOI 10.1109/TMM.2007.911245
NR 23
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 591
EP 613
DI 10.1007/s11042-011-0884-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000001
DA 2024-07-18
ER

PT J
AU Bertini, M
   Del Bimbo, A
   Ferracani, A
   Landucci, L
   Pezzatini, D
AF Bertini, Marco
   Del Bimbo, Alberto
   Ferracani, Andrea
   Landucci, Lea
   Pezzatini, Daniele
TI Interactive multi-user video retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video retrieval; Usability; Multimedia ontologies; Natural interaction
ID INTERFACES
AB In this paper we present two interactive multi-user systems for video search and browsing. The first is composed by web applications which allows multiuser interaction in a distributed environment; such applications are based on the Rich Internet Application paradigm, designed to obtain the levels of responsiveness and interactivity typical of a desktop application. The second system implements a multiuser collaborative application within a single location, exploiting multi-touch devices. Both systems use the same backend, based on a service oriented architecture (SOA) that provides services for automatic and manual annotation, and an ontology-based video search and browsing engine. Ontology-based browsing let users to inspect the content of video collections; user queries are expanded through ontology reasoning. User-centered field trials of the systems, conducted to assess the user experience and satisfaction, have shown that the approach followed to design these interfaces is extremely appreciated by professional archivists and people working on multimedia.
C1 [Bertini, Marco; Ferracani, Andrea; Pezzatini, Daniele] Univ Florence, Media Integrat & Commun Ctr, Visual Informat & Media Lab, Florence, Italy.
   [Bertini, Marco] Univ Florence, Dept Syst & Informat, Florence, Italy.
C3 University of Florence; University of Florence
RP Bertini, M (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Visual Informat & Media Lab, Florence, Italy.
EM bertini@dsi.unifi.it; delbimbo@dsi.unifi.it; ferracani@dsi.unifi.it;
   landucci@dsi.unifi.it; pezzatini@dsi.unifi.it
RI Bertini, Marco/X-1325-2019
OI Bertini, Marco/0000-0002-1364-218X; DEL BIMBO,
   ALBERTO/0000-0002-1052-8322
FU EU IST IM3I project [222267]
FX The authors thank Giuseppe Becchi for his work on software development.
   This work was partially supported by the EU IST IM3I project
   (http://www.im3i.eu/-contract FP7-222267).
CR Amant RS, 2001, PROC OF INTERNATIONA, V2, P1179
   [Anonymous], 2007, CIVR '07
   [Anonymous], 2010, P 18 ACM INT C MULT
   Apted T, 2009, PROC OF CHI WORKSHOP, P1
   Bailer W, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/856761
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Baraldi S, 2008, MULTIMED TOOLS APPL, V38, P385, DOI 10.1007/s11042-007-0195-7
   Behmo R., 2008, P IEEE C COMP VIS PA, P1
   Bertini M, 2006, LECT NOTES COMPUT SC, V4071, P133
   Bertini M, 2009, IEEE MULTIMEDIA, V16, P42, DOI 10.1109/MMUL.2009.25
   Bevan N, 2007, LECT NOTES COMPUT SC, V4550, P407
   Blackwell A.F., 2004, P ACM SIGCHI C HUMAN, P1473
   Brettlecker G, 2007, LECT NOTES COMPUT SC, V4877, P46
   Bronstein AM, 2010, LECT NOTES COMPUT SC, V6312, P197, DOI 10.1007/978-3-642-15552-9_15
   Bursuc A., 2010, P ACM MULT 2010 INT, P1659
   Card S K., 1999, READINGS INFORM VISU
   Chen F, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P59
   Christel M., 2004, P ACM MULT NEW YORK, P732
   Chua B B., 2004, Beyond the comfort zone: Proceedings of the 21st ASCILITE Conference, P184
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Collins A of Sydney U, 2010, MAKING THE TABLETOP
   Czerwinski M., 2006, PROC CHI 06, P69, DOI DOI 10.1145/1125451.1125471
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dietz P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P219, DOI 10.1145/502348.502389
   Dumas B, 2009, LECT NOTES COMPUT SC, V5440, P3, DOI 10.1007/978-3-642-00437-7_1
   European Broadcasting Union-Common Processes group, EBU TECHNICAL SERVIC
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fergus R, 2003, PROC OF IEEE CONFERE
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Halvorsen P., 2010, P ACM INT MULT C ACM, P1603
   Hansen P, 2005, INFORM PROCESS MANAG, V41, P1101, DOI 10.1016/j.ipm.2004.04.016
   Joshi D., 2006, VLDB, V6, P1163
   Kaltenbrunner M, 2005, PROC OF INTERNATIONA
   Kirakowski J, 2000, QUESTIONNAIRES IN US
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li J., 2006, P 14 ANN ACM INT C M, P911, DOI DOI 10.1145/1180639.1180841
   Morris M. R., 2006, First IEEE International Workshop on Horizontal Interactive Human-Computer Systems 2006
   Natsev A, 2008, PROC OF TRECVID WORK
   Nielsen J., 2000, WHY YOU ONLY NEED TE
   Ryall K, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P89, DOI 10.1109/TABLETOP.2006.12
   Scott SD, 2003, PROC OF EUROPEAN CON
   Shen C, 2006, PROC OF IEEE INTERNA
   Shen C, 2007, LECT NOTES COMPUT SC, V4564, P169
   Shneiderman B., 2010, DESIGNING USER INTER
   Sivic J, 2003, PROC OF INTERNATIONA
   Smeaton AF, 2007, MULTIMEDIA SYST, V12, P375, DOI 10.1007/s00530-006-0064-7
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek C, 2008, PROC OF TRECVID WORK
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek CeesG. M., 2010, Proceedings of the International Conference on Multimedia, P1535, DOI DOI 10.1145/1873951.1874278
   Snoek CGM, 2009, PROC OF TRECVID WORK
   Snoek CGM, 2010, PROC OF TRECVID WORK
   Stewart J., 1999, P CHI 99, P286, DOI [10.1145/302979.303064, DOI 10.1145/302979.303064]
   Taksa Isak, 2008, Journal of Software, V3, P63, DOI 10.4304/jsw.3.1.63-73
   Tse E., 2007, COMPUTERS ENTERTAINM, V5, P12
   Twidale M, 1998, INTERACT COMPUT, V10, P177, DOI 10.1016/S0953-5438(97)00022-2
   U.S. Department of Health and Human Sciences, 2006, RESEARCH BASED WEB D
   Ullmer Brygg., 2003, Proc. of INTERACT, V3, P279
   van Velsen L, 2009, PROC OF 6TH WORKSHOP
   Yang J, 2007, PROC OF INTL WORKSHO
   Yuen J, 2009, IEEE I CONF COMP VIS, P1451, DOI 10.1109/ICCV.2009.5459289
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 62
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 111
EP 137
DI 10.1007/s11042-011-0888-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Choi, YS
   Park, JH
AF Choi, Yong Soo
   Park, Jong Hyuk
TI Image hash generation method using hierarchical histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image hash; Hierarchical hash generation; Robustness; Statistical
   hypothesis testing
ID ROBUST
AB Recently, web applications, such as Stock Image and Image Library, are developed to provide the integrated management for user's images. Image hashing techniques are used for the image registration, management and retrieval as the identifier also, investigations have been performed to raise the hash performance like discernment. This paper proposes GLOCAL image hashing method utilizing the hierarchical histogram which is based on histogram bin population method. So far, many studies have proven that image hashing techniques based on this histogram are robust against image processing and geometrical attacks. We modified existing image hashing method developed by our research team [20]. The main idea of the paper is that it helps generate more fluent hash string if we have specific length of histogram bin. Another operation is empowering weighting factor into hash string at each level. Thus, we can raise the magnitude of hash string generated from same context or features and also strengthen the robustness of generated hash.
C1 [Park, Jong Hyuk] SeoulTech, Dept Comp Sci & Engn, Seoul 139743, South Korea.
   [Choi, Yong Soo] Korea Univ, Grad Sch Informat Secur & Management, Seoul 136701, South Korea.
C3 Seoul National University of Science & Technology; Korea University
RP Park, JH (corresponding author), SeoulTech, Dept Comp Sci & Engn, Seoul 139743, South Korea.
EM ciechoi@korea.ac.kr; parkjonghyuk1@hotmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [KRF-2008-331-D00580]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (KRF-2008-331-D00580).
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bhatacherjee S, 1998, P IEEE C IM PROC
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Johnson M, 2003, P IEEE INT C IM PROC
   Johnson N.L., 1995, CONTINUOUS UNIVARIAT, V2
   Kim HJ, 2007, INT WORKSH UB CONV T
   Kozat SS, 2004, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP.2004.1421855
   Lee Suk-Hwan, 2010, [Computer and Information, 전자공학회논문지 - CI], V47, P1
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Mihcak K, 2001, P ACM WORKSH SEC PRI, P13
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Monga V, 2005, IEEE T INF FOREN SEC, V27, P379
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Xiang S, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P121
NR 20
TC 32
Z9 35
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 181
EP 194
DI 10.1007/s11042-010-0724-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000011
DA 2024-07-18
ER

PT J
AU Valdés, V
   Martínez, JM
AF Valdes, Victor
   Martinez, Jose M.
TI On-line video abstract generation of multimedia news
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Abstraction; Skimming; Summarization; On-line; Real-time;
   Multimedia; News
ID KEY-FRAME-EXTRACTION; MOTION; RETRIEVAL; SCHEME
AB The amount of video content available nowadays makes video abstraction techniques a necessary tool to ease the access to the already huge and ever growing video databases. Nevertheless, many of the existing video abstraction approaches have high computational requirements, complicating the integration and exploitation of current technologies in real environments. This paper presents a novel method for news bulletin abstraction which combines on-line story segmentation, on-line video skimming and layout composition techniques. The developed algorithm provides an efficient, automatic and on-line news abstraction method which takes advantage of the specific characteristics of news bulletins for obtaining representative news abstracts.
C1 [Valdes, Victor; Martinez, Jose M.] Univ Autonoma Madrid, Escuela Politecn Super, E-28049 Madrid, Spain.
C3 Autonomous University of Madrid
RP Valdés, V (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, C Francisco Tomas & Valiente 11, E-28049 Madrid, Spain.
EM victor.valdes@uam.es; josem.martinez@uam.es
RI Martinez, Jose/A-1185-2008
OI Martinez, Jose/0000-0002-2236-1769
FU European Commission [IST-FP6-027685-Mesh]; Spanish Government
   [TIN2007-65400-SemanticVideo]; Comunidad de Madrid [S-0505/TIC-0223
   (ProMultiDis) CM]; Consejeria de Educacion of the Comunidad de Madrid;
   European Social Fund
FX The authors want to thank Wilfried Runde and Jochen Spangenberg from
   Deutsche Welle for their collaboration in order to make the results of
   this work available on the web site. All the news bulletins used as
   content set for this work are (c) Deutsche Welle and/or respective
   copyright holders. (Material has been kindly provided for
   research/academic purposes only. Not for commercial use. No duplication,
   copying, re-use of any kind allowed.) Work supported by the European
   Commission (IST-FP6-027685-Mesh), Spanish Government
   (TIN2007-65400-SemanticVideo), Comunidad de Madrid (S-0505/TIC-0223
   (ProMultiDis) CM), Consejeria de Educacion of the Comunidad de Madrid
   and by The European Social Fund.
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Baoxin Li, 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P202
   Browne P, 2003, TREC VID RETR EV ONL
   Calic J, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P28, DOI 10.1109/ITCC.2002.1000355
   Chaisorn L, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P73, DOI 10.1109/ICME.2002.1035721
   Chaisorn L, 2003, P TRECVID C
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chen F., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P60
   Chien HJ, 1995, MULTIMEDIA 95
   Christel MG, 2006, PROC SPIE, V6073, DOI 10.1117/12.642841
   Chua T.-S., 2004, PROC ACMMM, P656, DOI [10.1145/1027527.1027679, DOI 10.1145/1027527.1027679]
   Ciocca G, 2005, PROC SPIE, V5670, P137, DOI 10.1117/12.586777
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Fayzullin M, 2005, MULTIMED TOOLS APPL, V26, P153, DOI 10.1007/s11042-005-0451-7
   Gunsel B, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P128, DOI 10.1109/ICIP.1998.727150
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Hauptmann A.G., 2007, Proceedings of the international workshop on TRECVID video summarization, P20
   Hauptmann AG, 1998, P IEEE INT FORUM RES, P168, DOI 10.1109/ADL.1998.670392
   HongJiang Zhang, 1994, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.94TH0631-2), P45, DOI 10.1109/MMCS.1994.292432
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   Huang Q, 1999, ICASSP 99
   Jeho Nam, 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P117, DOI 10.1109/MMSP.1999.793807
   Ju SX, 1998, IEEE T CIRC SYST VID, V8, P686, DOI 10.1109/76.718513
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kim JG, 2003, INT J IMAG SYST TECH, V13, P267, DOI 10.1002/ima.10067
   Latecki LJ, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P643, DOI 10.1109/ISSPA.2001.950227
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y., 2001, An Overview of Video Abstraction Techniques
   Li Z, 2005, IEEE T IMAGE PROCESS, V14, P1550, DOI 10.1109/TIP.2005.854477
   Lie WN, 2004, LECT NOTES COMPUT SC, V3332, P246
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Meyer D, 2003, NEUROCOMPUTING, V55, P169, DOI 10.1016/S0925-2312(03)00431-4
   Mills M., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P93, DOI 10.1145/142750.142764
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Naphade MR, 2002, MULTIMEDIA 04, P660
   O'Hare N, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P1028
   Oh J., 2004, VIDEO DATA MANAGEMEN, P321
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Peker KA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2055, DOI 10.1109/ICME.2004.1394669
   Peker KA, 2005, MULTIMEDIA SYSTEMS A, V6015, DOI 601519
   Peker KA, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1053, DOI 10.1109/ICME.2006.262715
   Shipman S, ICCE 07, P1
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   Taniguchi Y., 1995, MULTIMEDIA 95 P 3 AC, P25
   Toklu C, 2000, PROC SPIE, V3972, P554
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Valdes Victor, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P88, DOI 10.1109/WIAMIS.2008.7
   Valdes V., 2008, Proceedings of the TRECVID BBC Rushes Summarization Workshop (TVS 2008) at ACM Multimedia, P134, DOI [10.1145/1463563.1463588, DOI 10.1145/1463563.1463588]
   Valdes V., 2007, Proceedings of 15th ACM International Conference on Multimedia, Workshop on TRECVID Video Summarization, P94
   Valdés V, 2007, LECT NOTES COMPUT SC, V4816, P144
   Valdés V, 2010, MULTIMED TOOLS APPL, V49, P7, DOI 10.1007/s11042-009-0392-7
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang M, 2009, SCHOLARPEDIA, V4, P9431
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wildemuth BM, 2003, ACM-IEEE J CONF DIG, P221, DOI 10.1109/JCDL.2003.1204866
   Wilson KW, 2009, MULTIMEDIA CONTENT A, V7255
   Xiong ZY, 2003, IEEE IMAGE PROC, P5
   Yeh CH, 2006, LECT NOTES COMPUT SC, V4319, P621
   Zhai Y, 2005, LECT NOTES COMPUT SC, V3568, P92
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhu L, 2001, INT CONF ACOUST SPEE, P1413, DOI 10.1109/ICASSP.2001.941194
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 67
TC 8
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 795
EP 832
DI 10.1007/s11042-011-0774-5
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900004
DA 2024-07-18
ER

PT J
AU Lampropoulos, AS
   Lampropoulou, PS
   Tsihrintzis, GA
AF Lampropoulos, Aristomenis S.
   Lampropoulou, Paraskevi S.
   Tsihrintzis, George A.
TI A Cascade-Hybrid Music Recommender System for mobile services based on
   musical genre classification and personality diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Cascade-Hybrid method; Personality diagnosis; Mobile
   services
ID RETRIEVAL
AB In this paper, we present a Cascade-Hybrid Music Recommender System intended to operate as a mobile service. Specifically, our system is a middleware that realizes the recommendation process based on a combination of music genre classification and personality diagnosis. A mobile user is able to query for music files by simply sending an example music file from his/her mobile device. In response to the user query, the system recommends music files that not only belong to the same genre as the user query, but also an attempt has been made to take into account both the user preferences as well as ratings from other users for candidate results. The recommendation mechanism is realized by applying the collaborative filtering technique of personality diagnosis. Using the minimum absolute error and the ranked scoring criteria, our approach is compared to existing recommendation techniques that rely on either collaborative filtering or content-based approaches. The outcome of the comparison clearly indicates that our approach exhibits significantly higher performance.
C1 [Lampropoulos, Aristomenis S.; Lampropoulou, Paraskevi S.; Tsihrintzis, George A.] Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.
C3 University of Piraeus
RP Tsihrintzis, GA (corresponding author), Univ Piraeus, Dept Informat, 80 Karaoli & Dimitriou St, Piraeus 18534, Greece.
EM arislamp@unipi.gr; vlamp@unipi.gr; geoatsi@unipi.gr
RI Tsihrintzis, George/AAR-1626-2021; Lampropoulos, Aristomenis/C-6903-2014
OI Lampropoulos, Aristomenis/0000-0003-0937-663X
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Albanese M, 2010, MULTIMED TOOLS APPL, V50, P563, DOI 10.1007/s11042-010-0480-8
   [Anonymous], 1999, P ACM SIGIR WORKSH R
   [Anonymous], ER WAP PUSH SDK
   [Anonymous], 2007, RECSYS 07 P 2007 ACM
   [Anonymous], 2001, PUSH ACC PROT SPEC W
   [Anonymous], NOK SER 40 DEV PLATF
   [Anonymous], 2001, PUSH ARCH OV WAP 250
   [Anonymous], KANN OP SOURC WAP SM
   Billsus D, 2000, USER MODEL USER-ADAP, V10, P147, DOI 10.1023/A:1026501525781
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R., 2000, Knowledge-based Recommender Systems
   Cohen WW, 2000, COMPUT NETW, V33, P685, DOI 10.1016/S1389-1286(00)00057-8
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hossian M, 2010, MULTIMED TOOLS APPL, V43, P407
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   Lampropoulou P. S., 2006, P KES2006 10 INT C K
   Lampropoulou PS, 2009, INTELL DECIS TECHNOL, V3, P123, DOI 10.3233/IDT-2009-0060
   LAMPROPOULOU PS, 2008, 5 INT C INF TECHN NE
   Pazzani M, 1997, MACH LEARN, V27, P313, DOI 10.1023/A:1007369909943
   Pennock D. M., 2000, P 16 C UNC ART INT, P473
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Rojsattarat E, 2003, HYBRID RECOMMENDATIO, P337
   Rudstrom A, 2004, UBICOMP 2004 ADJUNCT
   Smyth B, 2000, KNOWL-BASED SYST, V13, P53, DOI 10.1016/S0950-7051(00)00046-0
   Tosi D, 2004, FOURTH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING WORKSHOPS, PROCEEDINGS, P193, DOI 10.1109/WISEW.2003.1286802
   Tran T., 2000, Knowledge-Based Electronic Markets. Papers from the AAAI Workshop (Technical Report WS-00-04), P78
   TZANETAKIS, 2000, ORG SOUND, V4, P169
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Yoon WJ, 2006, LECT NOTES ARTIF INT, V4093, P279
NR 32
TC 27
Z9 35
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 241
EP 258
DI 10.1007/s11042-011-0742-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800012
DA 2024-07-18
ER

PT J
AU Jang, EG
   Koh, BS
   Choi, YR
AF Jang, Eun-Gyeom
   Koh, Byong-Soo
   Choi, Yong-Rak
TI A study on block-based recovery of damaged digital forensic evidence
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evidence image; Data recovery; Integrity guarantee; Computer forensics
AB In digital forensic, evidence images are stored on the disk by a forensic tool. However, the stored images can be damaged due to unexpected internal and external electromagnetic effects. Existing forensic tools only provide integrity and authenticity of the evidence images by utilizing legacy cryptographic methods, i.e., applying hash values and digital signatures. Accordingly, such integrity and authenticity applied to those evidence images can be easily corrupted when the disk is damaged. In this paper, we focus on such limitations of the existing forensic tools and introduce a new scheme that can recover and protect the evidence images on the disk. Specifically, evidence images are divided into blocks; linkage relations between those blocks are formed; and a meta-block is applied to restore the damaged blocks. Blocks in the damaged areas detected using CRC information are subject to a multi-dimensional block operation for recovery of damaged blocks and protection for evidence images.
C1 [Jang, Eun-Gyeom; Choi, Yong-Rak] Daejeon Univ, Dept Comp Engn, Taejon 300716, South Korea.
   [Koh, Byong-Soo] 8F DMC R&D Ctr, Seoul 121270, South Korea.
C3 Daejeon University
RP Jang, EG (corresponding author), Daejeon Univ, Dept Comp Engn, 96-3 Yongun Dong, Taejon 300716, South Korea.
EM jangegu@nate.com; bskoh@digicaps.com; yrchoi@dju.ac.kr
RI Wang, Deguang/E-3981-2012
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [2010-0022858]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2010-0022858)
CR [Anonymous], 2003, EV GRAD BITSTR BACK
   [Anonymous], 2002, HARD DISK WRIT BLOCK
   [Anonymous], 2008, ENCASE STUD GUID VER
   Baryamereeba V., 2006, Asian Journal of Information Technology, V5, P790
   Beebe NL, 2005, DIGIT INVEST, V2, P147, DOI 10.1016/j.diin.2005.04.002
   Casey E, 2004, COMPUTER INTERNET, P199
   Casey E., 2002, Handbook of computer crime investigation forensic tools and technology
   Freiling F, 2006, AUTOMATING ANAL COMP, P21
   Rubin P, 2004, DD CONVERT COPY FILE
NR 9
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 407
EP 422
DI 10.1007/s11042-011-0738-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700010
DA 2024-07-18
ER

PT J
AU Trojahn, TH
   Gonçalves, JL
   Mattos, JCB
   Agostini, LV
   Da Rosa, LS
AF Trojahn, Tiago Henrique
   Goncalves, Juliano Lucas
   Balzano Mattos, Julio Carlos
   Agostini, Luciano Volcan
   Da Rosa, Leomar Soares, Jr.
TI Evaluating two implementations of the component responsible for decoding
   video and audio in the Brazilian digital TV middleware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media processing; Middleware; libVLC library; Xine library
AB The project Ginga Code Development Network (GingaCDN) was created to implement a reference version of Ginga, the Brazilian Digital Television System (SBTVD) middleware, supporting the declarative GingaNCL and the procedural GingaJ environments in the same middleware. To reach that, a common core is being implemented, named Ginga Common Core (GingaCC). One of the main components of the GingaCC is the one responsible to decode audio and video streams, called Media Processing. In this work, two Media Processing implementations using libVLC and Xine graphical libraries are investigated. Performance tests and results of both Media Processing implementations running in two different desktop architectures are discussed.
C1 [Trojahn, Tiago Henrique; Goncalves, Juliano Lucas; Balzano Mattos, Julio Carlos; Agostini, Luciano Volcan; Da Rosa, Leomar Soares, Jr.] Univ Fed Pelotas, Technol Dev Ctr, Pelotas, Brazil.
C3 Universidade Federal de Pelotas
RP Gonçalves, JL (corresponding author), Univ Fed Pelotas, Dept Informat, Pelotas, Brazil.
EM thtrojahn@inf.ufpel.edu.br; juliano@inf.ufpel.edu.br;
   julius@inf.ufpel.edu.br; agostini@inf.ufpel.edu.br;
   leomarjr@inf.ufpel.edu.br
RI Agostini, Luciano/N-1102-2019; da Rosa Junior, Leomar/G-9212-2012;
   Agostini, Luciano/G-8626-2011
OI Agostini, Luciano/0000-0002-3421-5830
CR [Anonymous], 2010, NER AAC COD
   [Anonymous], 2010, X264
   [Anonymous], 2010, JMF 1 0 PROGRAMMERS
   [Anonymous], 2010, INT COR 2 SOL PROC U
   [Anonymous], 2010, LIBVLC
   [Anonymous], 2008, AD FLASH HD GALL
   [Anonymous], 2010, JAV DTV API 1 0
   [Anonymous], 2010, INT COR 2 DUO PROC E
   [Anonymous], 2010, WMV HD CONTENT SHOWC
   [Anonymous], 2009, MIDDLEWARE GINGAJ
   [Anonymous], 2010, NASA HIGH DEF VID
   [Anonymous], 2008, ITU T AAP REC H 761
   Digital Video Broadcasting Project Office, 2009, GEM SPEC LIST
   Ferreira C, 2001, THESIS FEDERAL U SAO
   Filho G, 2007, J BRAZ COMPUT SOC, V2, P47
   Filho S, 2007, IEEE INT COMP SOFTW, P119
   Leite L, 2005, J COMPUT ENG DIGIT S, V2, P30
   Moreno M, 2006, THESIS PONTIFICAL CA
   SET, 2000, COMP STUD DIG TV STA
   Soares L, 2007, J BRAZ COMPUT SOC, V1, P37
NR 20
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 373
EP 392
DI 10.1007/s11042-011-0753-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700008
DA 2024-07-18
ER

PT J
AU Li, Z
   Liu, GZ
AF Li, Zhi
   Liu, Guizhong
TI Video scene analysis in 3D wavelet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D DWT; Cut; Flashlight; Dissolve; Fade
ID SHOT-CHANGE DETECTION; SEGMENTATION; ALGORITHM
AB This paper proposes a novel scene analysis algorithm based on three-dimensional discrete wavelet transform (3D DWT). Based on the correlation among the adjacent frames, video frames can be considered as four categories: abrupt scene transition, motion scene, gradual scene transition and static scene, which are ranked from low to high according to the strength of the correlation. Through the investigation of the particular temporal and spatial distribution of each category, the correlation among adjacent frames could be described by the 3D DWT coefficients related statistical features, which are the energy of high-frequency coefficients difference, the sum of high-frequency coefficients magnitudes and the difference of low-frequency coefficients magnitudes. The energy of high-frequency coefficients difference is first used to detect the abrupt scene transition including cut and flashlight. Then all the three features are input to SVM for the purpose of analyzing the residual scenes and detecting the gradual scene transition, such as dissolve and fade. Experimental results show the method to be effective not only for the abrupt scene transition detection, but also for the gradual scene transition detection.
C1 [Li, Zhi; Liu, Guizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM lizhi1030@mail.xjtu.edu.cn; liugz@mail.xjtu.edu.cn
RI Li, Zhi/GQP-7357-2022
OI Li, Zhi/0000-0003-2427-4455
FU National 973 Project [2007CB311002]; National 863 Project
   [2009AA01Z409]; National Natural Science Foundation of China (NSFC)
   [60903121]
FX This work is supported in part by the National 973 Project (No.
   2007CB311002), National 863 Project (No. 2009AA01Z409), and National
   Natural Science Foundation of China Project (NSFC, No. 60903121).
CR ALATTAR AM, 1993, IEEE INT S CIRC SYST, V1, P13
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   ARMAN F, 1993, P SOC PHOTO-OPT INS, V1908, P2, DOI 10.1117/12.143638
   Babu RV, 2002, INT CONF ACOUST SPEE, P3788
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Coudert F, 1998, P SOC PHOTO-OPT INS, V3527, P283, DOI 10.1117/12.325822
   Fernando W. A. C., 1999, IEEE INT C IM PROC K, P299
   Fernando WAC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P709, DOI 10.1109/ISCAS.2000.858850
   Fernando WAC, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P255, DOI 10.1109/ISCAS.1999.779990
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Guimaraes SJF, 2003, PATTERN RECOGN LETT, V24, P947, DOI 10.1016/S0167-8655(02)00218-0
   Hampapur A., 1995, Multimedia Tools and Applications, V1, P9, DOI 10.1007/BF01261224
   Heng WJ, 2003, SIGNAL PROCESS-IMAGE, V18, P203, DOI 10.1016/S0923-5965(02)00139-X
   Hsu C.W., 2004, PRACTICAL GUIDE SUPP
   *ISO IEC, 2003, 154441 ISOIEC
   Jamrozik ML, 2002, IEEE IMAGE PROC, P113
   Joyce RA, 2006, IEEE T MULTIMEDIA, V8, P130, DOI 10.1109/TMM.2005.861285
   Klock H, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P776, DOI 10.1109/ICIP.1997.638611
   Krämer P, 2006, INT J INTELL SYST, V21, P765, DOI 10.1002/int.20159
   Lam C. F., 1998, Multimedia Information Analysis and Retrieval. IAPR International Workshop, MINAR'98. Proceedings, P159, DOI 10.1007/BFb0016496
   Li Y, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P260
   Li Z, 2008, IEEE IMAGE PROC, P1536, DOI 10.1109/ICIP.2008.4712060
   Luo L, 2004, SIGNAL PROCESS-IMAGE, V19, P601, DOI 10.1016/j.image.2004.05.004
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MENG JH, 1995, P SOC PHOTO-OPT INS, V2419, P14, DOI 10.1117/12.206359
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   NAKAJIMA Y, 1994, IEICE T INF SYST, VE77D, P1355
   OCONNOR N, 2003, P 3 INT WORKSH CONT, P381
   Park JH, 2003, LECT NOTES ARTIF INT, V2843, P426
   Pei SC, 2002, IEEE T MULTIMEDIA, V4, P309, DOI 10.1109/TMM.2002.802841
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Primaux L, 2004, TREC VIDEO RETRIEVAL
   Qian XM, 2006, IEEE T CIRC SYST VID, V16, P1245, DOI 10.1109/TCSVT.2006.881858
   Shen K, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB252
   Sifakis E, 2001, SIGNAL PROCESS-IMAGE, V16, P963, DOI 10.1016/S0923-5965(00)00056-4
   Truong B. T., 2001, P IEEE INT C MULT EX, P60
   Wang J., 2005, IEEE 2nd International Conference on Mobile Technology, Applications and Systems, P1
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Wei Jyh Heng, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P289, DOI 10.1109/ICIP.1999.817119
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yi XQ, 2005, IEEE INT SYMP CIRC S, P3443
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhang D, 2001, LECT NOTES COMPUT SC, V2195, P63
   ZHANG HJ, 1993, ACM MULTIMEDIA SYSTE, V1, P10
NR 47
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 419
EP 437
DI 10.1007/s11042-010-0594-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700002
DA 2024-07-18
ER

PT J
AU Niu, YZ
   Liu, F
   Li, XQ
   Gleicher, M
AF Niu, Yuzhen
   Liu, Feng
   Li, Xueqing
   Gleicher, Michael
TI Image resizing via non-homogeneous warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image resizing; Image retargeting; Similarity transformation;
   Patch-linking scheme; Structure preserving; Linear system
AB Image resizing aims to adapt images to displays with different sizes and aspect ratios. In this paper, we provide a new image resizing approach for efficiently determining the non-homogeneous warp that better preserves the global image configuration and concentrates the distortion in regions of the image where they are least-likely to be noticed. Considering the different properties of large displays and small displays, we design different strategies for upsizing and downsizing. We define a variety of quadratic metrics to measure image distortion. We introduce a patch-linking scheme that can better preserve the global image configuration. We formulate image resizing as a quadratic minimization problem, which can be efficiently solved. We experiment with our method on a variety category of images and compare our results to the state of the art.
C1 [Niu, Yuzhen; Li, Xueqing] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
   [Liu, Feng; Gleicher, Michael] Univ Wisconsin, Dept Comp Sci, Madison, WI 53706 USA.
C3 Shandong University; University of Wisconsin System; University of
   Wisconsin Madison
RP Niu, YZ (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
EM yuzhen@cs.wisc.edu; fliu@cs.wisc.edu; xqli@sdu.edu.cn;
   gleicher@cs.wisc.edu
FU NSF [IIS-0416284]
FX We would like to thank the reviewers for their insightful and
   constructive comments. This research was sponsored in part by NSF grant
   IIS-0416284.
CR [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], ICCV 01
   [Anonymous], ACM TRANS GRAPH
   [Anonymous], 2005, Fundamentals of Computer Graphics
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Deselaers T, 2008, CVPR 08 P IEEE COMPU, P1
   Fan Xin., 2003, P ACM MULTIMEDIA, P247
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Shreiner D., 2005, OPENGL PROGRAMMING G, V5th
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang YS, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618473
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
NR 24
TC 20
Z9 23
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 485
EP 508
DI 10.1007/s11042-010-0613-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700005
DA 2024-07-18
ER

PT J
AU Feng, J
   Xiong, NX
   Yang, LT
   Yang, Y
AF Feng, Jiao
   Xiong, Naixue
   Yang, Laurence T.
   Yang, Yan
TI A low distortion image enhancement scheme based on multi-resolutions
   analysis in next generation network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Medical image; Wavelet transform; Grad-contrast
ID CONTRAST ENHANCEMENT; QUALITY; ALGORITHM
AB With the advent of Next Generation Network (NGN), services that are currently provided by multiple specific network-centric architectures. NGN provides AAA (Anytime, Anywhere and Always on) access to users from different service providers with consistent and ubiquitous provision of services as necessary. This special issue of NGN includes pervasive, grid, and peer-to-peer computing to provide computing and communication services at anytime and anywhere. In fact, the application of NGN includes digital image processing, multimedia systems/services, and so on. Here we focus on the digital image processing technology in NGN environments. Low-contrast structure and heavy noise in NGN environments can be found in many kinds of digital images, which makes the images vague and uncertainly, especially in x-ray images. As result, some useful tiny characteristic are weakened-which are difficult to distinguish even by naked eyes. Based on the combination of no-linear grad-contrast operator and multi-resolution wavelet analysis, a kind of image enhancement processing algorithm for useful tiny characters is presented. The algorithm can enhance the tiny characters while confine amplifying noise. The analysis of the results shows that local regions of the image are enhanced by using the concept of the grad contrast to make image clearer adaptively. Experiments were conducted on real pictures, and the results show that the algorithm is flexible and convenient.
C1 [Xiong, Naixue] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.
   [Feng, Jiao] Nanjing Univ Informat Sci & Technol, Comp & Software Inst, Nanjing, Jiangsu, Peoples R China.
   [Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 1C0, Canada.
   [Yang, Yan] Western Illinois Univ, Dept Comp Sci, Macomb, IL 61455 USA.
C3 University System of Georgia; Georgia State University; Nanjing
   University of Information Science & Technology; Saint Francis Xavier
   University - Canada; Western Illinois University
RP Xiong, NX (corresponding author), Georgia State Univ, Dept Comp Sci, 34 Peachtree St,Suite 1428, Atlanta, GA 30303 USA.
EM jf.nuist@gmail.com; nxiong@cs.gsu.edu; ltyang@stfx.ca; Y-Yang2@wiu.edu
RI Laurence T. Yang, FCAE/AAA-1898-2019; xiong, naixue/M-4277-2019
OI Laurence T. Yang, FCAE/0000-0002-7986-4244; xiong,
   naixue/0000-0002-0394-4635
FU National Natural Science Foundation of China [40471101]; Research
   Foundation of Nanjing University of Information Science and Technology
FX Thank for the support of the National Natural Science Foundation of
   China (under Grant No. 40471101) and support of Research Foundation of
   Nanjing University of Information Science and Technology.
CR Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], WAVELETS SUBBAND COD
   [Anonymous], IEEE TRANCE ASSP
   [Anonymous], HDB MED IMAGING
   [Anonymous], CBMS LECT SERIES
   [Anonymous], P 7 IEEE WORKSH APPL
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   d'Agostino AG, 2006, EUR RADIOL, V16, P2137, DOI 10.1007/s00330-006-0218-1
   DAVIS TJ, 1995, NATURE, V373, P595, DOI 10.1038/373595a0
   Dilmanian FA, 2000, PHYS MED BIOL, V45, P933, DOI 10.1088/0031-9155/45/4/309
   GORDON R, 1984, APPL OPTICS, V23, P560, DOI 10.1364/AO.23.000560
   Hel-Or Y, 2008, IEEE T IMAGE PROCESS, V17, P443, DOI 10.1109/TIP.2008.917204
   Heric D., 2005, WSEAS Transactions on Computers, V4, P1305
   Julius Hossain M, 2008, EURASIP J ADV SIG PR, V2008, P1
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Liu XW, 2006, IEEE T IMAGE PROCESS, V15, P3066, DOI 10.1109/TIP.2006.877511
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Miller M, 2008, IEEE T IMAGE PROCESS, V17, P1500, DOI 10.1109/TIP.2008.926146
   MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944
   NEYCENSSAC F, 1993, CVGIP-GRAPH MODEL IM, V55, P447, DOI 10.1006/cgip.1993.1034
   Scheunders P, 2007, IEEE T IMAGE PROCESS, V16, P1865, DOI 10.1109/TIP.2007.899598
   Tsai DY, 2008, J DIGIT IMAGING, V21, P338, DOI 10.1007/s10278-007-9044-5
   Vickers VE, 1996, OPT ENG, V35, P1921, DOI 10.1117/1.601006
   Wang YP, 2003, IEEE T MED IMAGING, V22, P685, DOI 10.1109/TMI.2003.812255
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yin HX, 2005, P ANN INT IEEE EMBS, P5699
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P1093, DOI 10.1109/TIP.2008.924386
   Zhang L, 2002, PATTERN RECOGN LETT, V23, P1771, DOI 10.1016/S0167-8655(02)00151-4
NR 31
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 227
EP 243
DI 10.1007/s11042-010-0583-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100001
DA 2024-07-18
ER

PT J
AU Omoomi, M
   Samavi, S
   Dumitrescu, S
AF Omoomi, Masood
   Samavi, Shadrokh
   Dumitrescu, Sorina
TI An efficient high payload ±1 data embedding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Information hiding; Embedding efficiency; Steganalysis
ID LSB STEGANOGRAPHY; STEGANALYSIS
AB Embedding of confidential data in the least significant bit of an image is still an attractive method of steganography. Utilizing the full capacity of cover images by embedding one bit of data per pixel, using methods such as LSB flipping or LSB matching, usually decreases the security, making the algorithm vulnerable to steganalytic attacks. In this paper, we propose a novel efficient high payload +/- 1 steganographic method based on a special two variable binary function. This function uses the information of the least two significant bit planes of the cover image for the embedding and extraction purposes. Embedding efficiency, defined as the number of embeddable bits per one change in the cover medium, is a good criterion for concurrent evaluation of the capacity and security. Rather than randomly selecting +1 or -1, we achieve higher embedding efficiencies by choosing the correct modification component. In the generalized form of the proposed method, n bits of data are embedded in n pixels of the cover medium, by causing one unit change in only one third of these pixels. Analytical and experimental results demonstrated that the proposed method provides higher embedding efficiency than the other LSB embedding schemes. The proposed method is also applicable to other digital cover media.
C1 [Omoomi, Masood; Samavi, Shadrokh; Dumitrescu, Sorina] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Omoomi, Masood; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
C3 McMaster University; Isfahan University of Technology
RP Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM samavi@mcmaster.ca
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Bierbrauer J., 1998, On Crandall's problem
   Bierbrauer J, 2008, LECT NOTES COMPUT SC, V4920, P1, DOI 10.1007/978-3-540-69019-1_1
   Crandall R., 1998, SOME NOTES STEGANOGR
   Dijk M. M., 2001, P 22 S INF THEOR BEN, P147
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   FRIDRICH J, 2008, LECT NOTES COMPUT SC, V4437, P282
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   HARMSEN J, 2003, THESIS RENSSELAER PO
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khatirinejad M, 2009, DISCRETE APPL MATH, V157, P971, DOI 10.1016/j.dam.2008.02.004
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   *USDA, NRCS PHOT HOM
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Westfeld A., 2001, P 4 INT WORKSHOP INF, V2137, P289
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 22
TC 15
Z9 18
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 201
EP 218
DI 10.1007/s11042-010-0517-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700001
DA 2024-07-18
ER

PT J
AU Ling, HF
   Wang, LY
   Zou, FH
   Yan, WQ
AF Ling, Hefei
   Wang, Liyun
   Zou, Fuhao
   Yan, Weiqi
TI Fine-search for image copy detection based on local affine-invariant
   descriptor and spatial dependent matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy detection; Local invariant descriptor; Spatial dependent matching;
   Fine search
ID RECOGNITION; SCHEME
AB Copies are somehow a subset of near-duplicates, but the approaches extensively employed in near-duplicate retrieval only obtain rough and imprecise query results. Therefore a fine-search scheme is proposed to refine these rough results and attempt to completely detect the real copies accurately. This scheme first employs a local affine-invariant descriptor based on polar-mapping and discrete Fourier transform. Then a spatial dependent matching method is proposed combining nearest neighbor distance ratio with the spatial relationships among the local features. Experimental results demonstrate that the employed descriptor is more robust, distinctive and suitable for copy detection in comparison with the SIFT descriptor. And the spatial dependent matching is able to improve the recall and precision, and lower the false positives and ambiguities.
C1 [Ling, Hefei; Wang, Liyun; Zou, Fuhao] Huazhong Univ Sci & Technol, Coll Comp Sci, Wuhan 430074, Peoples R China.
   [Yan, Weiqi] Queens Univ Belfast, Inst ECIT, Belfast BT7 1NN, Antrim, North Ireland.
C3 Huazhong University of Science & Technology; Queens University Belfast
RP Ling, HF (corresponding author), Huazhong Univ Sci & Technol, Coll Comp Sci, Wuhan 430074, Peoples R China.
EM lhefei@hust.edu.cn; yuner1130@hotmail.com; fuhao_zou@hust.edu.cn;
   w.yan@qub.ac.uk
RI Ling, Hefei/H-1687-2011
FU NSF of China [60873226, 60803112]; National 863 Hi-Tech Grant
   [2009AA01Z411]; Electronic Development Fund [[2007]329]
FX This work is supported by NSF of China Grants 60873226, 60803112,
   National 863 Hi-Tech Grant 2009AA01Z411, and the Electronic Development
   Fund Grant [2007]329.
CR ALEJANDRO J, 2002, P 10 ACM INT C MULT, P423
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   [Anonymous], TRECVID WORKSH
   [Anonymous], BINARIES AFFINE COVA
   [Anonymous], P 14 ANN ACM INT C M
   BERRANI SA, 2003, P ACM INT WORKSH MUL, P70
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Chang EY, 1998, P SOC PHOTO-OPT INS, V3527, P58, DOI 10.1117/12.325852
   Chang EY, 1999, P SOC PHOTO-OPT INS, V3846, P281, DOI 10.1117/12.360433
   Choksuriwong A, 2005, IEEE IMAGE PROC, P713
   Derrode S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P877, DOI 10.1109/MMCS.1999.778603
   Foo J., 2007, P 18 C AUSTRALASIAN, P63
   Götze N, 2000, INT C PATT RECOG, P948
   Hsiao JH, 2007, IEEE T IMAGE PROCESS, V16, P2069, DOI 10.1109/TIP.2007.900099
   Joly A, 2005, IEEE IMAGE PROC, P537
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Ke Y, 2004, PROC CVPR IEEE, P506
   Ke Y., 2004, ACM MULTIMEDIA 04, P869
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CS, 2005, MULTIMEDIA SYST, V11, P159, DOI 10.1007/s00530-005-0199-y
   Maani E, 2008, IEEE IMAGE PROC, P1716, DOI 10.1109/ICIP.2008.4712105
   Meng Y, 2003, P SOC PHOTO-OPT INS, V5021, P176, DOI 10.1117/12.476312
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   SHENG Y, 1986, J OPT SOC AM A, V3, P771, DOI 10.1364/JOSAA.3.000771
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   YAN M, 2003, IEEE C COMP VIS PATT, P416
   Yuan JS, 2004, INT C PATT RECOG, P866, DOI 10.1109/ICPR.2004.1334665
   ZHENG QF, 2006, P ACM INT C MULT SAN, P77
   2007, J SYST SOFTW, V80, P1057
NR 33
TC 8
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 551
EP 568
DI 10.1007/s11042-009-0439-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000018
DA 2024-07-18
ER

PT J
AU Jiang, XH
   Sun, TF
   Wang, SL
AF Jiang, Xinghao
   Sun, Tanfeng
   Wang, Shilin
TI An automatic video content classification scheme based on combined
   visual features model with modified DAGSVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Visual features; Video content classification; Combined visual features
   model; Directed acyclic graph support vector machine
AB Automatic video content classification attracts much attention from researchers in multimedia analysis because the management of video content is a challenging task. In this paper, a visual feature representation composed of editing, color, texture and motion features is proposed which is shown to be effective in differentiating among various video contents. A modified Directed Acyclic Graph Support Vector Machine (DAGSVM) model as the classifier is also presented. Experiments show that the features extracted have improved the discriminative ability between different video contents and the computational complexity has also been reduced. By introducing the DAG policy, the performance of the classifier has been enhanced and the classification results demonstrate the precision and effectiveness of this approach, compared with the other two classification methods. In addition, the proposed algorithm can be applied to video searching and harmful-video content filtering, etc.
C1 [Jiang, Xinghao; Sun, Tanfeng; Wang, Shilin] Shanghai Jiao Tong Univ, Sch Informat Secur Engn, Shanghai 200030, Peoples R China.
   [Jiang, Xinghao; Sun, Tanfeng; Wang, Shilin] Shanghai Informat Secur Management & Technol Res, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Sun, TF (corresponding author), Shanghai Jiao Tong Univ, Sch Informat Secur Engn, Shanghai 200030, Peoples R China.
EM xhjiang@sjtu.edu.cn; tfsun@sjtu.edu.cn; wsl@sjtu.edu.cn
RI Wang, Shilin/ACN-3143-2022; Tanfeng, Sun/J-7469-2015
CR Chang C.C., LIBSVM: a library for support vector machines
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   Geetha M.K., 2007, INT C COMP INT MULT, V3, P277
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   LEFVRE S, 2007, J REAL-TIME IMAGE PR, V2, P23
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Truong BT, 2000, INT C PATT RECOG, P230, DOI 10.1109/ICPR.2000.902901
   XI Z, 2004, CHINESE J COMPUTERS, V27, P1027
   Xu LQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P485
NR 9
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 105
EP 120
DI 10.1007/s11042-010-0463-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500009
DA 2024-07-18
ER

PT J
AU Chen, L
   Harper, MP
AF Chen, Lei
   Harper, Mary P.
TI Utilizing gestures to improve sentence boundary detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture; Nonverbal communication; Multimodal processing; Sentence
   boundary detection
ID SPEECH
AB An accurate estimation of sentence units (SUs) in spontaneous speech is important for (1) helping listeners to better understand speech content and (2) supporting other natural language processing tasks that require sentence information. There has been much research on automatic SU detection; however, most previous studies have only used lexical and prosodic cues, but have not used nonverbal cues, e. g., gesture. Gestures play an important role in human conversations, including providing semantic content, expressing emotional status, and regulating conversational structure. Given the close relationship between gestures and speech, gestures may provide additional contributions to automatic SU detection. In this paper, we have investigated the use of gesture cues for enhancing the SU detection. Particularly, we have focused on: (1) collecting multimodal data resources involving gestures and SU events in human conversations, (2) analyzing the collected data sets to enrich our knowledge about co-occurrence of gestures and SUs, and (3) building statistical models for detecting SUs using speech and gestural cues. Our data analyses suggest that some gesture patterns influence a word boundary's probability of being an SU. On the basis of the data analyses, a set of novel gestural features were proposed for SU detection. A combination of speech and gestural features was found to provide more accurate SU predictions than using only speech features in discriminative models. Findings in this paper support the view that human conversations are processes involving multimodal cues, and so they are more effectively modeled using information from both verbal and nonverbal channels.
C1 [Chen, Lei] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47905 USA.
   [Harper, Mary P.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
   [Harper, Mary P.] Johns Hopkins Univ, Human Language Technol Ctr Excellence, Baltimore, MD 21211 USA.
C3 Purdue University System; Purdue University; University System of
   Maryland; University of Maryland College Park; Johns Hopkins University
RP Chen, L (corresponding author), Educ Testing Serv ETS, Princeton, NJ 08541 USA.
EM LChen@ets.org; mharper@umd.edu
CR [Anonymous], P IEEE WORKSH CUES C
   [Anonymous], RESAMPLING TECHNIQUE
   Argyle Michael, 1975, BODILY COMMUNICATION
   BEEFERMAN D, 1998, P INT C AC SPEECH SI
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Buntine W., 1992, Statistics and Computing, V2, P63, DOI 10.1007/BF01889584
   CASSELL J, 1999, P AAAI C ART INT
   Chai J., 2004, P C INTELLIGENT USER, P70
   CHEN C, 1999, P EUR C SPEECH PROC
   CHEN L, 2004, P INT C MULT INT ICM
   CHEN L, 2006, P INT C MULT INT ICM
   CHEN L, 2005, P JOINT WORKSH MACH
   Chen S., 1999, A Gaussian prior for smoothing maximum entropy models
   *EARS, 2002, DARPA EARS PROGR
   EISENSTEIN J, 2006, P C N AM CHAPT ASS C
   Eisenstein J., 2005, GESTURAL CUES SENTEN
   EISENSTEIN J, 2007, P C ANN M ASS COMP L
   Ekman P., 1965, Affect, cognition, and personality, P390
   FAYYAD UM, 1992, MACH LEARN, V8, P87, DOI 10.1007/BF00994007
   GAROFOLO J, 2004, P C LANG RES EV LREC
   Gotoh Y., 2000, P INT SPEECH COMM AS
   HUANG Z, 2005, P NIST RT 05 WORKSH
   Huang Z., 2006, P C LANG RES EV LREC
   HUANG Z, 2007, P EMP METH NAT LANG
   KENDON A, 1974, NONVERBAL COMMUNICAT, P119
   Lafferty John D, 2001, CONDITIONAL RANDOM F
   *LDC, 2004, M REC QUICK TRANSCR
   *LDC, 2004, SIMPL METADATA ANN S
   Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd
   LIU Y, 2005, P INT C AC SPEECH SI
   LIU Y, 2004, THESIS PURDUE U
   LIU Y, 2004, P EMP METH NAT LANG
   LIU Y, 2005, P INT C SPEECH LISB
   MCCALLUM A, 2005, MALLET MACHINE LEARN
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Mehrabian A., 1972, Nonverbal communication
   MORENCY LP, 2007, P IEEE COMP VIS PATT
   Morgan N, 2003, INT CONF ACOUST SPEE, P740
   QU S, 2006, P INT C MULT INT ICM
   Quek F., 2002, ACM Transactions on Computer-Human Interaction, V9, P171, DOI 10.1145/568513.568514
   QUEK F, 2002, KDI CROSS MODEL ANAL
   Quilan J.R., 1993, C4.5: Programs for machine learning
   ROARK B, 2006, P INT C AC SPEECH SI
   ROSE T, 2004, P INT C MULT INT ICM
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Shriberg E, 2000, SPEECH COMMUN, V32, P127, DOI 10.1016/S0167-6393(00)00028-5
   STEVENSONM M, 2000, P C N AM CHAPT ASS C
   STOCKLE A, 2002, P INT C SPOK LANG PR
   Strassel S., 2003, SIMPLE METADATA ANNO, V5.0
   SUNDARAM R, 2001, P SPEECH TRANSCR WOR
   Witten I. H., 2005, DATA MINING PRACTICA
   XIONG Y, 2005, P INT C MULT INT ICM
   ZHANG L, 2005, MAXIMUM ENTROPY MODE
NR 54
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 1035
EP 1067
DI 10.1007/s11042-009-0436-z
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100010
DA 2024-07-18
ER

PT J
AU Ciobanu, L
   Côrte-Real, L
AF Ciobanu, Lucian
   Corte-Real, Luis
TI Successive refinement of side information for multi-view distributed
   video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed video coding (DVC); Wyner-Ziv (WZ); Side information
   generation; Multi-view registration (MVR); Overlapped views; Motion
   compensated extrapolation (MCE); Scale-Invariant feature transform
   (SIFT)
ID REGISTRATION; POINTS
AB Inter-camera registration in multi-view systems with overlapped views has a particularly long and sophisticated research history within the computer vision community. Moreover, when applied to Distributed Video Coding, in systems with at least one moving camera it represents a real challenge due to the necessary data at decoder for generating the side information without any a priori knowledge of each instant camera position. This paper proposes a solution to this problem based on successive multi-view registration and motion compensated extrapolation for on-the-fly re-correlation of two views at decoder. This novel technique for side information generation is codec-independent, robust and flexible with regard to any free motion of the cameras. Furthermore, it doesn't require any additional information from encoders nor communication between cameras or offline training stage. We also propose a metric for an objective assessment of the multi-view correlation performance.
C1 [Ciobanu, Lucian; Corte-Real, Luis] Univ Porto, Fac Engn, P-4100 Oporto, Portugal.
   [Ciobanu, Lucian; Corte-Real, Luis] INESC, Oporto, Portugal.
C3 Universidade do Porto; INESC TEC; Universidade do Porto
RP Ciobanu, L (corresponding author), Univ Porto, Fac Engn, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM lciobanu@inescporto.pt; lreal@inescporto.pt
RI Corte-Real, Luís/I-4852-2012
OI Corte-Real, Luis/0000-0003-2116-7056; Ciobanu,
   Lucian/0000-0003-1102-8589
FU Fundacao para a Ciencia e a Tecnologia, Portugal
FX The first author acknowledges the Fundacao para a Ciencia e a
   Tecnologia, Portugal, for the financial support.
CR Aaron A., 2004, P PICTURE CODING S P
   AARON A, 2004, P IEEE INT C IM PROC
   Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765
   ARTIGAS X, 2006, 7 NORD SIGN PROC S N
   ASCENSO J, 2007, INT C IM PROC ICIP 2
   Benedek C, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P439
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BRIVIO PA, 1992, INT J REMOTE SENS, V13, P1853, DOI 10.1080/01431169208904234
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   BROWN M, 2003, P IEEE INT C COMP VI
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Cheng S, 2005, IEEE T SIGNAL PROCES, V53, P3269, DOI 10.1109/TSP.2005.851138
   Dufaux F, 2007, SPIE DEF SEC S DSS 2
   Fonseca LMG, 1997, X BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P219, DOI 10.1109/SIGRA.1997.625182
   FORSSEN PE, 2007, INT C COMP VIS ICCV
   GONCALVES H, 2008, SPIE, V7109
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   GROWE S, 1997, INT C IM PROC, V97, P26
   GUO X, 2006, SPIE
   Izquierdo E, 2003, IEEE T MULTIMEDIA, V5, P293, DOI 10.1109/TMM.2003.814910
   LEMOIGNE J, 1998, GEOSC REM SENS S P 1, V1, P315
   Likar B, 1999, MED PHYS, V26, P1678, DOI 10.1118/1.598660
   LOWE D, SCALE INVARIANT FEAT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   OUARET M, 2007, EUR C SIGN PROC EUSI
   OUARET M, 2006, ACM INT WORKSH VID S
   Puri R, 2003, P INT C IM PROC ICIP
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Szlávik Z, 2007, ISPRS J PHOTOGRAMM, V61, P298, DOI 10.1016/j.isprsjprs.2006.09.014
   TIPDECHO T, 2002, GRASS US C 2002 TREN
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   YEO C, 2007, VCIP 2007 SAN JOS 28
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 33
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2010
VL 48
IS 3
SI SI
BP 411
EP 436
DI 10.1007/s11042-009-0315-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 587VP
UT WOS:000277023100004
DA 2024-07-18
ER

PT J
AU Cheng, H
   Hua, KA
   Yu, N
AF Cheng, Hao
   Hua, Kien A.
   Yu, Ning
TI An automatic feature generation approach to multiple instance learning
   and its applications to image databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image categorization; Multiple-instance learning; Instance-level
   clustering; Category pattern mining; Pattern feature generation;
   Bag-pattern distance; Multi-class classification
AB Automatic content-based image categorization is a challenging research topic and has many practical applications. Images are usually represented as bags of feature vectors, and the categorization problem is studied in the Multiple-Instance Learning (MIL) framework. In this paper, we propose a novel learning technique which transforms the MIL problem into a standard supervised learning problem by defining a feature vector for each image bag. Specifically, the feature vectors of the image bags are grouped into clusters and each cluster is given a label. Using these labels, each instance of an image bag can be replaced by a corresponding label to obtain a bag of cluster labels. Data mining can then be employed to uncover common label patterns for each image category. These label patterns are converted into bags of feature vectors; and they are used to transform each image bag in the data set into a feature vector such that each vector element is the distance of the image bag to a distinct pattern bag. With this new image representation, standard supervised learning algorithms can be applied to classify the images into the pre-defined categories. Our experimental results demonstrate the superiority of the proposed technique in categorization accuracy as compared to state-of-the-art methods.
C1 [Cheng, Hao; Hua, Kien A.; Yu, Ning] Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Cheng, H (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
EM haocheng@eecs.ucf.edu; kienhua@eecs.ucf.edu; nyu@eecs.ucf.edu
CR Andrews S., 2002, NIPS, P577
   Bakar Z.A., 2006, 2006 IEEE conference on cybernetics and intelligent systems, P1
   Bay S. D., 2003, KDD, P29, DOI [10.1145/956750.956758, DOI 10.1145/956750.956758]
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   BORGHT C.V., 2002, Cahiers critiques de therapie familiale et de pratiques de reseaux no, P1
   Burdick D, 2001, PROC INT CONF DATA, P443, DOI 10.1109/ICDE.2001.914857
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHEN X, 2005, IEEE INT SYM MULTIM, P37
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   CHENG H, 2007, ICTAI 07, P362
   Cheng Hao., 2009, SIMILARITY SEARCH PO
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dooly DR, 2003, J MACH LEARN RES, V3, P651, DOI 10.1162/jmlr.2003.3.4-5.651
   HAMERLY G, 2003, ADV NEURAL INFORM PR, P36
   MARON O, 1998, ICML, P341
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moore D. S., 1993, INTRO PRACTICE STAT
   Schrijver A., 1998, THEORY LINEAR INTEGE
   Shekhar S, 2003, GEOINFORMATICA, V7, P139, DOI 10.1023/A:1023455925009
   Vu K., 2006, P ACM SIGMOD INT C M, P527, DOI DOI 10.1145/1142473.1142532
   Wang J, 2000, P 17 INT C MACH LEAR, P1119
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
   Zhou ZH., 2007, ICML '07, V227, P1167
NR 26
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 507
EP 524
DI 10.1007/s11042-009-0335-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200008
DA 2024-07-18
ER

PT J
AU Giro-i-Nieto, X
   Camps, N
   Marques, F
AF Giro-i-Nieto, Xavier
   Camps, Neus
   Marques, Ferran
TI GAT: a Graphical Annotation Tool for semantic regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotation; Region; Ontology; Navigation; Semantic; Hierarchical
ID IMAGE
AB This article presents GAT, a Graphical Annotation Tool based on a region-based hierarchical representation of images. The proposed solution uses Partition Trees to navigate through the image segments which are automatically defined at different spatial scales. Moreover, the system focuses on the navigation through ontologies for a semantic annotation of objects and of the parts that compose them. The tool has been designed under usability criteria to minimize the user interaction by trying to predict the future selection of regions and semantic classes. The implementation uses MPEG-7/XML input and output data to allow interoperability with any type of Partition Tree. This tool is publicly available and its source code can be downloaded under a free software license.
C1 [Giro-i-Nieto, Xavier; Camps, Neus; Marques, Ferran] Tech Univ Catalonia UPC, Barcelona 08034, Catalonia, Spain.
C3 Universitat Politecnica de Catalunya
RP Giro-i-Nieto, X (corresponding author), Tech Univ Catalonia UPC, Campus Nord UPC,Modul D5,Jordi Girona 1-3, Barcelona 08034, Catalonia, Spain.
EM xavier.giro@upc.edu; ferran.marques@upc.edu
RI Giró-i-Nieto, Xavier/M-5834-2013
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332
CR Adamek T, 2007, LECT NOTES COMPUT SC, V4816, P15
   Akrivas G, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE SYSTEMS, PROCEEDINGS, P109, DOI 10.1109/ICAIS.2002.1048064
   Alatan AA, 1998, IEEE T CIRC SYST VID, V8, P802, DOI 10.1109/76.735378
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   ARNDT R, 2008, COMM SESIGNING WELL, P30, DOI DOI 10.1007/978-3-540-76298-0_3
   Ballester C, 2003, ESAIM CONTR OPTIM CA, V9, P1, DOI 10.1051/cocv:2002069
   BLOEHDORN S, 2005, P 2 EUR SEM WEB C HE, DOI DOI 10.1007/11431053_40
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   CALDERERO F, 2008, P CBMI 2008 INT 6 IN
   DASIOPOULOU S, 2008, CAPTURING MPEG 7 SEM, P113
   Dimitrova N., 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, P113, DOI 10.1145/266714.266876
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   KRUSE S, 1998, PICT COD S PORTL US, P169
   MARCOTEGUI B, 1999, P ICIP 99 IEEE INT C
   MARQUES F, 2000, P INT C IM PROC ICIP, V1, P312, DOI DOI 10.1109/ICIP.2000.900957
   Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   *MONT BAY AQ RES I, 2009, VID ANN REF SYST
   Naphade MR, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P46, DOI 10.1109/ICIP.2001.958047
   Papadopoulos GT, 2006, LECT NOTES COMPUT SC, V4306, P199
   Petridis K., 2006, P 10 INT C KNOWL BAS
   Rehatschek H., 2007, RECONFIGURATIONS INT, P253
   ROSENFELD A, 1981, IEEE T SYST MACHINES, V11, P822
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   SAATHOFF C, 2008, P SAMT 2008 DEM POST
   Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Smith JR, 2000, P SOC PHOTO-OPT INS, V4210, P49, DOI 10.1117/12.403831
   TRONCY R, 2007, IMAGE ANNOTATION SEM
   Vilaplana V, 2008, IEEE T IMAGE PROCESS, V17, P2201, DOI 10.1109/TIP.2008.2002841
   Volkmer T., 2005, PROC 13 ANN ACM INT, P892, DOI DOI 10.1145/1101149.1101341
   XUE B, 2007, P IEEE INT C IM PROC, V2, P249, DOI DOI 10.1109/ICIP.2007.4379139
NR 35
TC 12
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 155
EP 174
DI 10.1007/s11042-009-0389-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300002
DA 2024-07-18
ER

PT J
AU Kludas, J
   Bruno, E
   Marchand-Maillet, S
AF Kludas, Jana
   Bruno, Eric
   Marchand-Maillet, Stephane
TI Can feature information interaction help for information fusion in
   multimedia problems?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi modal information fusion; Feature selection and construction;
   Feature information interaction
ID ALGORITHMS; RETRIEVAL
AB This article presents the information-theoretic based feature information interaction, a measure that can describe complex feature dependencies in multivariate settings. According to the theoretical development, feature interactions are more accurate than current, bivariate dependence measures due to their stable and unambiguous definition. In experiments with artificial and real data we compare first the empirical dependency estimates of correlation, mutual information and 3-way feature interaction. Then, we present feature selection and classification experiments that show superior performance of interactions over bivariate dependence measures for the artificial data, for real world data this goal is not achieved yet.
C1 [Kludas, Jana; Bruno, Eric; Marchand-Maillet, Stephane] Univ Geneva, CUI, CH-1227 Carouge, Switzerland.
C3 University of Geneva
RP Kludas, J (corresponding author), Univ Geneva, CUI, 7 Route Drize, CH-1227 Carouge, Switzerland.
EM jana.kludas@unige.ch; eric.bruno@unige.ch; marchand@cui.unige.ch
CR [Anonymous], P IEEE WORKSH NEUR N
   [Anonymous], NSFKITP0454 UCSB
   Bell A. J., 2003, 4 INT S IND COMP AN, P921
   BENITEZ AB, 2002, WORKSH MULT DAT MIN, P23
   Bruno E, 2008, IEEE T PATTERN ANAL, V30, P1520, DOI 10.1109/TPAMI.2007.70801
   Chechik G., 2002, ADV NEURAL INF PROCE, V15, P857
   Dass SC, 2005, LECT NOTES COMPUT SC, V3546, P1049
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Freitas AA, 2001, ARTIF INTELL REV, V16, P177, DOI 10.1023/A:1011996210207
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   JAJUGA K, 2006, STUD CLASSIF DATA AN, V15, P39
   Jakulin A, 2003, LECT NOTES ARTIF INT, V2838, P229
   Joachims T., 2002, LEARNING CLASSIFY TE
   Kokar M. M., 2004, Information Fusion, V5, P189, DOI 10.1016/j.inffus.2003.11.001
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   PAZZANI MJ, 1996, LEARNING DATA AI STA
   PEREZ I, 1997, THESIS
   Poh N, 2005, IEEE T SIGNAL PROCES, V53, P4384, DOI 10.1109/TSP.2005.857006
   Tao Liu, 2004, Fourth IEEE International Conference on Data Mining, P162, DOI 10.1109/ICDM.2004.10096
   TUMER K, 1999, COMBINING ARTIFICIAL
   VASCONCELOS N, 2002, EUR C COMP VIS COP, P297
   VINOKUROW A, 2003, 4 INT S IND COMP AN
   WESTERVELD T, 2007, ACM SIGIR FORUM, V41, P58
   WESTERVELD T, 2004, INT C IM VID RETR CI
   Wu LZ, 2002, IEEE T NEURAL NETWOR, V13, P972, DOI 10.1109/TNN.2002.1021897
   WU Y, 2004, MULTIMEDIA 04, P572
   YAN R, 2003, MULTIMEDIA 03, P339
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 28
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 57
EP 71
DI 10.1007/s11042-008-0251-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400004
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Li, HF
AF Li, Hua-Fu
TI Pattern discovery and change detection of online music query streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data mining; Music query streams; Melody structure mining;
   Change detection
AB Mining of music data is one of the most important problems in multimedia data mining. In this paper, two research issues of mining music data, i.e., online mining of music query streams and change detection of music query streams, are discussed. First, we proposed an efficient online algorithm, FTP-stream (Frequent Temporal Pattern mining of streams), to mine all frequent melody structures over sliding windows of music melody sequence streams. An effective bit-sequence representation is used in the proposed algorithm to reduce the time and memory needed to slide the windows. An effective list structure is developed in the FTP-stream algorithm to overcome the performance bottleneck of 2-candidate generation. Experiments show that the proposed algorithm FTP-stream only needs a half of memory requirement of original melody sequence data, and just scans the music query stream once. After mining frequent melody structures, we developed a simple online algorithm, MQS-change (changes of Music Query Streams), to detect the changes of frequent melody structures in current user-centered music query streams. Two music melody structures (set of chord-sets and string of chord-sets) are maintained and four melody structure changes (positive burst, negative burst, increasing change and decreasing change) are monitored in a new summary data structure, MSC-list (a list of Music Structure Changes). Experiments show that the MQS-change algorithm is an effective online method to detect the changes of music melody structures over continuous music query streams.
C1 Kainan Univ, Dept Comp Sci, Tao Yuan, Taiwan.
C3 Nan Kai University Technology
RP Li, HF (corresponding author), Kainan Univ, Dept Comp Sci, Tao Yuan, Taiwan.
EM hfli@mail.knu.edu.tw
FU National Science Council, Taiwan, Republic of China [NSC
   96-2218E-424-001-]
FX The authors thank the reviewers' precious comments for improving the
   quality of the paper. We would like to thank Dr. Yun Chi for
   contributing the source codes of Moment algorithm (MomentFP). The
   research is supported in part by the National Science Council, Project
   No. NSC 96-2218E-424-001-, Taiwan, Republic of China.
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Babcock B., 2002, P 21 ACM SIGMOD SIGA, P1, DOI [DOI 10.1145/543613.543615, 10.1145/543613]
   Bakhmutova IV, 1997, COMPUT MUSIC J, V21, P58, DOI 10.2307/3681219
   Chang J.H., 2003, 9 ACM C KNOWL DISC D, P487, DOI [10.1145/956750.956807, DOI 10.1145/956750.956807]
   Chang JH, 2004, J INF SCI ENG, V20, P753
   Chi Y, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P59, DOI 10.1109/ICDM.2004.10084
   Dong G., 2003, P ACM SIGMOD MPDS
   Gaber MM, 2005, SIGMOD REC, V34, P18, DOI 10.1145/1083784.1083789
   Hsu JL, 2001, IEEE T MULTIMEDIA, V3, P311, DOI 10.1109/6046.944475
   Jones GeorgeThaddeus., 1974, Music Theory
   Li HF, 2005, J UNIVERS COMPUT SCI, V11, P1411
   Li HF, 2005, PATTERN RECOGN LETT, V26, P1658, DOI 10.1016/j.patrec.2005.01.016
   LI HF, 2004, P ICME
   Shan MK, 2003, IEICE T INF SYST, VE86D, P655
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
NR 15
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 287
EP 304
DI 10.1007/s11042-008-0229-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500006
DA 2024-07-18
ER

PT J
AU Pañeda, XG
   Melendi, D
   Vilas, M
   García, R
   García, V
   Rodríguez, I
AF Paneda, Xabiel Garcia
   Melendi, David
   Vilas, Manuel
   Garcia, Roberto
   Garcia, Victor
   Rodriguez, Isabel
TI FESORIA:: An integrated system for analysis, management and smart
   presentation of audio/video streaming services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE presentation; management; analysis; audio; video streaming; system
ID VIDEO
AB Due to the elevated consumption of resources, the high cost of the production of contents and the quality of service required in audio/video streaming services, it is extremely important to optimize all the elements involved in the deployment of these services. With this goal in mind, provider companies have developed their management and presentation tools. At the same time, some specific tools for audio/video streaming analysis have appeared. Data are collected from servers and proxies by analyzing their log files in order to generate different types of reports. In spite of their utility, there is a disconnection between these types of tools. In this way, several important relationships between collected data are lost and the influence of other important aspects such as the behaviour of the users and their relationship with the subject or the length of the contents is not considered. This generates inaccurate analyses and the impossibility to improve the presentation, for example by generating recommendations using the information gathered from the analysis tool. Fesoria is a system which combines both characteristics. It is an analysis tool and, at the same time, a system to manage the whole audio/video service. Fesoria is able to process the logs gathered from the streaming servers and proxies, and combine the extracted information with other types of data, such as content metadata, content distribution networks architecture, user preferences, etc. All this information is analyzed in order to generate reports on service performance, access evolution and users' preferences, and thus to improve the presentation of the services. The system has been used in real audio/video services since 2001 with satisfactory results.
C1 [Paneda, Xabiel Garcia; Melendi, David; Vilas, Manuel; Garcia, Roberto; Garcia, Victor; Rodriguez, Isabel] Univ Oviedo, Dept Comp Sci, Asturias 33204, Spain.
C3 University of Oviedo
RP Pañeda, XG (corresponding author), Univ Oviedo, Dept Comp Sci, Campus Viesques Sn Gijon Xixon, Asturias 33204, Spain.
EM xabiel@uniovi.es; melendi@uniovi.es; vilasmanuel@uniovi.es;
   garciaroberto@uniovi.es; victor@uniovi.es; rodriguezisabel@uniovi.es
RI Melendi, David/H-5592-2013; GARCIA, VICTOR G./HOF-9077-2023; Garcia,
   Roberto/KVY-3276-2024
OI Melendi, David/0000-0001-8251-5646; Garcia, Roberto/0000-0002-5042-8684;
   Garcia-Garcia, Victor/0000-0003-2473-807X; Garcia-Paneda, Xicu
   Xabiel/0000-0001-6381-5459
CR ALMEDIA JM, 2001, WORKSH NETW OP SYST
   ARIAS JR, 2002, ACM INT MULT C JUAN
   *AUDIOVIDEOWEB, 2007, AUD VID HOST SERV
   CASALE G, 2005, IEEE QEST 05 TOR 19
   Cherkasova L, 2004, IEEE ACM T NETWORK, V12, P781, DOI 10.1109/TNET.2004.836125
   CHESIRE M, 2001, S INT TECHN SYST SAN
   Cranor CD, 2001, IEEE INTERNET COMPUT, V5, P66, DOI 10.1109/4236.939452
   *DCMI, 2006, DUBL COR MET EL SET
   García R, 2007, SIMUL MODEL PRACT TH, V15, P672, DOI 10.1016/j.simpat.2007.02.004
   *KEYN, 2006, KEYN STREAM PERSP
   Li M., 2005, ACM Transactions on Internet Technology, V5, P601, DOI 10.1145/1111627.1111629
   LOGUINOV D, 2001, ACM SIGCOMM INT MEAS
   Luna CE, 2003, IEEE T CIRC SYST VID, V13, P141, DOI 10.1109/TCSVT.2002.808439
   MELENDI D, 2003, C IB TEL CITA MONT U
   MELENDI D, 2006, CHARACTERIZATION REA
   NESVADBAL J, 2005, IEEE INT C MULT EXPO
   PANEDA XG, 2004, 6 INT C ENT INF SYST
   PANEDA XG, 2003, LNCS, V2720
   *REALNETWORKS, 2002, HEL UN SERV ADM GUID
   *RFC 1157, 1990, RFC 1157 SIMPL NETW
   *SAWM, 2007, SAWM AN TOOL
   SIEVER E, 2000, LINUX NUTSHELL
   Terada N, 2005, IEEE PACIF, P621
   van der Kuyl AC, 2005, BMC EVOL BIOL, V5, DOI 10.1186/1471-2148-5-29
   VELOSO E, 2002, INT MEAS WORKSH MARS
   *VIR IP TV, 2007, RICH MED MAN SOFTW I
   WANG B, 2002, OPTIMAL PROXY CACHE
   Watson AB, 1999, PROC SPIE, V3644, P168, DOI 10.1117/12.348437
   WINKLER S, 2001, 4 INT S WIR PERS MUL, P553
   *WORLD WID WEB CON, 2000, SIMPL OBJ ACC PROT S
   *WORLD WID WEB CON, 2002, WEB SERV ACT
   Wright J, 2005, IEEE SPECTRUM, V42, P24, DOI 10.1109/MSPEC.2005.1413727
   YU H, 2006, EUROSYS2006 BELG 18
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 3
BP 379
EP 412
DI 10.1007/s11042-007-0173-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 328BF
UT WOS:000257771600004
DA 2024-07-18
ER

PT J
AU Won, Y
   Kim, D
   Park, J
   Lee, S
AF Won, Youjip
   Kim, Doohan
   Park, Jinyoun
   Lee, Sichang
TI HERMES: embedded file system design for A/V application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; A/V workload; file system; disk scheduling; embedded system
AB Embedded systems such as PVR, set-top box, HDTV put unique demand on I/O subsystem design. Underlying software, particularly file system, needs to be elaborately designed so that it can meet tight constraints of consumer electronics platform: performance, price, reliability, and etc. In this work, we develop state-of-art file system elaborately tailored for A/V workload. There are two design objectives in our file system: performance and support for logical level abstraction. For performance, we develop a number of novel features: extent based allocation, single level file structure with block index augmentation scheme, aggressive free block allocation to minimize disk fragmentation, elaborate file system meta data layout, separation of name space data and file data and etc. HERMES enables the user to view file as a collection of semantic units (frame or audio samples). HERMES file system encompasses most of state-of-the-art file system technologies published in preceding works. Via extensive physical experiment, we verify that HERMES file system successfully addresses the original issues: good scalability, predictable I/O latency (minimizing variability in I/O latency), efficient disk head movement and etc. This is the result of harmonious effort of large I/O size, aggressive free block allocation algorithm, data block placement strategy, file organization, layout of HERMES file system and etc. The result of performance experiments indicate that HERMES file system prototype successfully meets the file system constraints for high volume and high bandwidth multimedia application. HERMES file system exhibits superior performance to EXT2 file system (Linux) and XFS file system (SGI).
C1 [Won, Youjip] Hanyang Univ, ECE Div, Seoul 133791, South Korea.
   [Kim, Doohan] Samsung Elect, Suwon, South Korea.
   [Park, Jinyoun] LG Elect, Digital Media Lab, Seoul, South Korea.
   [Lee, Sichang] Tellion, Network R & D Ctr, Seoul, South Korea.
C3 Hanyang University; Samsung; Samsung Electronics; LG Electronics
RP Won, Y (corresponding author), Hanyang Univ, ECE Div, Seoul 133791, South Korea.
EM yjwon@ece.hanyang.ac.kr
CR AHN BS, 2004, P 12 ANN ACM INT C M, P588
   *B YOUNG U PERF EV, DTB LIN DISK TRAC BU
   BOLOSKY WJ, 1997, ACM SIGOPS OPERAT SY, V31
   CHEN M, 1993, ACM MULTIMEDIA 93, P235
   CHIUEH T, 1997, P INT C MULT COMP SY
   Cho KW, 2002, LECT NOTES COMPUT SC, V2490, P484
   DIMITRIJEVIC Z, 2003, P INT IPSI 2003 C OC
   GANGER G, 1998, CSETR35898 U MICH DE
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   Haskin RL, 1998, IBM J RES DEV, V42, P185, DOI 10.1147/rd.422.0185
   KIM T, 2005, LECT NOTE COMPUTER S
   LEE W, 1997, P CIKM LAS VEGAS NEV
   McVoy Larry., 1996, P USENIX 1996 ANN TE
   Mokbel MF, 2004, PROC INT CONF DATA, P498, DOI 10.1109/ICDE.2004.1320022
   OZDEN B, 1994, P VLDB 94
   PARK J, 2001, P INT C DISTR MULT S
   RANGAN PV, 1992, IEEE COMMUN MAG, V30, P56, DOI 10.1109/35.144778
   Rompogiannakis Y., 1998, Proceedings ACM Multimedia 98, P297, DOI 10.1145/290747.290785
   SHENOY PJ, 1998, P ACM SPIE MULT COMP, P124
   Shenoy PrashantJ., 1998, SIGMETRICS 98, P44
   Sweeney A., 1996, P USENIX ANN TECHN C
   TWEEDIE S, 1998, LINUXEXPO 98
   WANG C, 1999, P 7 ACM MULT
   WIJAYARATNE R, 2001, ACM MULTI
   Won Y, 2000, MULTIMEDIA SYST, V8, P105, DOI 10.1007/s005300050154
   WON Y, 2000, P ACM MULT C 00 LOS
   Won YJ, 2001, GLOB TELECOMM CONF, P2435, DOI 10.1109/GLOCOM.2001.966214
   ZIMMERMAN R, 2003, P ACM MULT C, P75
   FILE SYSTEM BENCHMAR
NR 29
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2008
VL 39
IS 1
BP 73
EP 100
DI 10.1007/s11042-007-0156-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 311TE
UT WOS:000256622500003
DA 2024-07-18
ER

PT J
AU Correa, P
   Marqués, F
   Marichal, X
   Macq, B
AF Correa, Pedro
   Marques, Ferran
   Marichal, Xavier
   Macq, Benoit
TI 3D posture estimation using geodesic distance maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Natural Interaction
CY APR, 2004
CL Florence, ITALY
DE motion capture; silhouette analysis; gestural interfaces; geodesic
   distance
ID MOTION
AB This paper presents a novel technique for three-dimensional (3D) human motion capture using a set of two non-calibrated cameras. The user's five extremities (head, hands and feet) are extracted, labeled and tracked after silhouette segmentation. As they are the minimal number of points that can be used in order to enable whole body gestural interaction, we will henceforth refer to these features as crucial points. Features are subsequently labelled using 3D triangulation and inter-image tracking. The crucial point candidates are defined as the local maxima of the geodesic distance with respect to the center of gravity of the actor region that lie on the silhouette boundary. Due to its low computational complexity, the system can run at real-time paces on standard personal computers, with an average error rate range between 4% and 9% in realistic situations, depending on the context and segmentation quality.
C1 [Correa, Pedro; Macq, Benoit] UCL, Lab Telecommun & Teledetect, Louvain, Belgium.
   [Marques, Ferran] Tech Univ Catalonia UPC, Image Proc Grp, Barcelona, Spain.
   [Marichal, Xavier] Alterface SA, Louvain, Belgium.
C3 Universite Catholique Louvain; Universitat Politecnica de Catalunya
RP Correa, P (corresponding author), UCL, Lab Telecommun & Teledetect, Louvain, Belgium.
EM correa@tele.ucl.ac.be; ferran.marques@upc.edu;
   xavier.marichal@alterface.com; macq@tele.ucl.ac.be
CR [Anonymous], IEEE WORKSH APPL COM
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hernández PC, 2007, IEEE T MULTIMEDIA, V9, P754, DOI 10.1109/TMM.2007.893342
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lanier J, 2001, SCI AM, V284, P66, DOI 10.1038/scientificamerican0401-66
   Marichal X, 2003, P SOC PHOTO-OPT INS, V5150, P41, DOI 10.1117/12.509861
   Perrone C, 1996, COMPUT NETWORKS ISDN, V28, P1307, DOI 10.1016/0169-7552(96)00053-0
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 10
TC 4
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2008
VL 38
IS 3
BP 365
EP 384
DI 10.1007/s11042-007-0191-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 300ZV
UT WOS:000255866300005
DA 2024-07-18
ER

PT J
AU Lian, SG
   Sun, JH
   Liu, GJ
   Wang, ZQ
AF Lian, Shiguo
   Sun, Jinsheng
   Liu, Guangjie
   Wang, Zhiquan
TI Efficient video encryption scheme based on advanced video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia content protection; video encryption; digital right
   management; AVC
ID IMAGE
AB A video encryption scheme combining with advanced video coding (AVC) is presented and analyzed in this paper, which is different from the ones used in MPEG1/2 video encryption. In the proposed scheme, the intra-prediction mode and motion vector difference are encrypted with the length-kept encryption algorithm (LKE) in order to keep the format compliance, and the residue data of the macroblocks are encrypted with the residue data encryption algorithm (RDE) in order to keep low cost. Additionally, a key distribution scheme is proposed to keep the robustness to transmission errors, which assigns sub-keys to different frames or slices independently. The encryption scheme's security, time efficiency and error robustness are analyzed in detail. Experimental results show that the encryption scheme keeps file format unchanged, is secure against replacement attacks, is efficient in computing, and is robust to some transmission errors. These properties make it a suitable choice for real-time applications, such as secure IPTV, secure videoconference or mobile/wireless multimedia, etc.
C1 [Lian, Shiguo; Sun, Jinsheng; Liu, Guangjie; Wang, Zhiquan] Nanjing Univ Sci & Technol, Dept Automat, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Lian, SG (corresponding author), Nanjing Univ Sci & Technol, Dept Automat, Nanjing 210094, Peoples R China.
EM sg_lian@163.com
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   *CENELEC, 1992, 50094 EN CENELEC
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Chiaraluce F, 2002, IEEE T CONSUM ELECTR, V48, P838, DOI 10.1109/TCE.2003.1196410
   IAIN E, 2002, H 264 MPEG 4 10
   *ITU T REC, 2002, H264 ITU T REC
   KUDELSKI A, 1994, Patent No. 5375168
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Lian SG, 2004, LECT NOTES COMPUT SC, V3332, P65
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Mollin R.A., 2006, An introduction to cryptography
   Podesser M, 2002, 400 ROM P 5 IEEE NOR
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Qiao LT, 1997, ISCE '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CONSUMER ELECTRONICS, P226, DOI 10.1109/ISCE.1997.658393
   Romeo A., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P261, DOI 10.1109/ICECS.1999.812273
   Shi CG, 1999, INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, VOL VI, PROCEEDINGS, P2822
   SHI T, 2006, P SPIE, V6072
   Tang L., 1996, P 4 ACM INT MULT C A, P219
   Tosun AS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P119, DOI 10.1109/ICME.2000.869559
   *US DEP COMM, 1994, FIPS PUB, V1401
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Wu CP, 2001, PROC SPIE, V4314, P128, DOI 10.1117/12.435392
   YEN JC, 1999, IEEE WORKSH SIGN PRO, P430
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 24
TC 27
Z9 54
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 75
EP 89
DI 10.1007/s11042-007-0150-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000004
DA 2024-07-18
ER

PT J
AU Cai, Y
   Chen, Z
   Tavanapong, W
AF Cai, Ying
   Chen, Zhan
   Tavanapong, Wallapak
TI Caching collaboration and cache allocation in peer-to-peer video systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE peer-to-peer video services; file lookup; caching collaboration; cache
   allocation
ID PROXY
AB Providing scalable video services in a peer-to-peer (P2P) environment is challenging. Since videos are typically large and require high communication bandwidth for delivery, many peers may be unwilling to cache them in whole to serve others. In this paper, we address two fundamental research problems in providing scalable P2P video services: (1) how a host can find enough video pieces, which may scatter among the whole system, to assemble a complete video; and (2) given a limited buffer size, what part of a video a host should cache and what existing data should be expunged to make necessary space. We address these problems with two new ideas: Cell caching collaboration and Controlled Inverse Proportional (CIP) cache allocation. The Cell concept allows cost-effective caching collaboration in a fully distributed environment and can dramatically reduce video lookup cost. On the other hand, CIP cache allocation challenges the conventional caching wisdom by caching unpopular videos in higher priority. Our approach allows the system to retain many copies of popular videos to avoid creating hot spots and at the same time, prevent unpopular videos from being quickly evicted from the system. We have implemented a Gnutella-like simulation network and use it as a testbed to evaluate the proposed technique. Our extensive study shows convincingly the performance advantage of the new scheme.
C1 [Cai, Ying; Chen, Zhan; Tavanapong, Wallapak] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
C3 Iowa State University
RP Cai, Y (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM yingcai@cs.iastate.edu; zchen@cs.iastate.edu; tavanapo@cs.iastate.edu
CR ACHARYA S, 2000, P ACM IEEE NOSSDAV
   ADLER M, 2005, P INFOCOM 05
   AGGARWAL G, 2003, P ACM SPAA 03
   [Anonymous], 2003, P ATAPCC KARLSR BW G
   [Anonymous], P ACM SIGCOMM 02
   [Anonymous], P SIGCOMM 01, DOI DOI 10.1145/383059.383071
   Antony I., 2001, LECT NOTES COMPUTER, P329, DOI DOI 10.1007/3-540-45518-3_18
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   BYERS J, 2003, P IPTPS 03 FEB
   CAI Y, 2005, P 5 IEEE INT C PEEP
   Chu Y., 2001, P ACM SIGCOMM, P55
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Clarke I., 2000, ICSI WORKSH DES ISS
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   DABEK F, 2001, P 18 ACM S OP SYST P, P202
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   EAGER DL, 1999, P IS T SPIE C MULT C, P301
   GANGULY S, 2005, P INFOCOMM 05
   Gifford D. K., 1979, Proceedings of the Seventh Symposium on Operating Systems Principles, P150, DOI 10.1145/800215.806583
   Gruber S, 2000, COMPUT NETW, V33, P657, DOI 10.1016/S1389-1286(00)00058-X
   Hefeeda M., 2003, Proceedings of the eleventh ACM international conference on Multimedia, ser. MULTIMEDIA '03, P45, DOI [DOI 10.1145/957013.957022, 10.1145/957013.957022]
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   KARGER D, 2003, MITLCSTR911 MIT LCS
   KUBIATOWICZ J, 2000, P ACM ASPLOS NOV
   LV Q, 2002, P ACM INT C SUP JUN
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   NAKAO A, 2003, P ACM SIGCOMM AUG, P11
   PADMANABHAN PCV, 2002, P ACM IEEE NOSSDAV M, P177
   Paknikar S., 2000, Proceedings ACM Multimedia 2000, P13, DOI 10.1145/354384.354397
   Park YW, 2000, P INT COMP SOFTW APP, V24, P389, DOI 10.1109/CMPSAC.2000.884754
   Ramesh S, 2001, IEEE INFOCOM SER, P85, DOI 10.1109/INFCOM.2001.916690
   RAO A, 2003, P IPTSP 03 FEB
   Ratnasamy S., 2001, Proceedings of the 2001 conference on applications, technologies, architectures, and protocols for computer communications, P161
   REJAIE R, 1999, P INT WEB COACH WORK
   ROWSTRON A, 2001, P 18 ACM S OP SYST P, P188
   SAROIU S, 2002, P SPIE C MULT COMP N
   Sen S, 1999, IEEE INFOCOM SER, P1310, DOI 10.1109/INFCOM.1999.752149
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Tang C., 2003, Proceedings of the 2003 conference on Applications, technologies, architectures, and protocols for computer communications, P175, DOI DOI 10.1145/863955.863976
   Thomas R. H., 1979, ACM Transactions on Database Systems, V4, P180, DOI 10.1145/320071.320076
   TRAN DA, 2004, IEEE J SEL AREA COMM, V22, P91
   WU KL, 2001, P 10 INT C WORLD WID, P36
   Xu DY, 2002, INT CON DISTR COMP S, P363, DOI 10.1109/ICDCS.2002.1022274
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
NR 45
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 117
EP 134
DI 10.1007/s11042-007-0136-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600002
DA 2024-07-18
ER

PT J
AU Wang, HF
   Liu, QS
   Lu, HQ
AF Wang, Haifeng
   Liu, Qingshan
   Lu, Hanqing
TI An improved variable-size block-matching algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE variable-size block matching; threshold; illumination removal;
   macro-mode prediction; motion estimation
ID MOTION ESTIMATION; SEARCH ALGORITHM
AB In this paper, we proposed an improved "bottom-up" variable-size block matching method. Different from previous work, the proposed method does not need any threshold during the matching, and we just keep all the motion vectors leading to the minimum matching error. A Marco-block mode prediction method is put forward to speed up the motion estimation procedure without introducing any loss to the prediction precision. The improved variable-size block matching algorithm can achieve exactly the same prediction precision as full-search based fixed-size block matching algorithm. In order to reduce the effect of illumination change on mode selection, we proposed an illumination removal method, which acts as a post-processing step to prevent the macro-blocks from over-splitting. Experiments show its encouraging performance.
C1 Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Wang, HF (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100080, Peoples R China.
EM hfwang@nlpr.ia.ac.cn; qsliu@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn
RI WANG, Haifeng/F-1342-2016
CR [Anonymous], 144962 ISOIEC
   CHAN MH, 1990, IEE PROC-I, V137, P205, DOI 10.1049/ip-i-2.1990.0029
   Chen SX, 2002, NEW CARBON MATER, V17, P6
   FERRI FJ, 1998, P IEEE C PATT REC, V1, P286
   *ISO IEC, 1993, 111722 ISOIEC
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   MARTIN GR, 1996, P IS T SPIE S EL IM
   Rhee I, 2000, IEEE T CIRC SYST VID, V10, P42, DOI 10.1109/76.825857
   SULLIVAN GJ, 1991, GLOB TEL C 1991 GLOB, V1, P85
   TEKALP AM, 1995, DIGITAL VIDEO PROCES, P95
   TOURAPIS AM, 2004, JVTM012
   TU YK, 2003, MULTIMEDIA EXPO 2003, V2, P789
   WANG Z, 2004, ICCCAS 2004 2004 INT, V2, P910
   XIN J, 2003, P IEEE INT C MULT EX, V3, P525
   YANG Y, 1998, P 1998 INT C
   ZHOU Z, 2004, ISCAS2004 MAY
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu Ce, 2004, IEEE T CIRCUITS SYST, V14
NR 19
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 221
EP 237
DI 10.1007/s11042-006-0091-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700006
DA 2024-07-18
ER

PT J
AU Williams, A
   Yoon, P
AF Williams, Adam
   Yoon, Peter
TI Content-based image retrieval using joint correlograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE content-based image retrieval; color histograms; correlograms
ID COLOR
AB The comparison of digital images to determine their degree of similarity is one of the fundamental problems of computer vision. Many techniques exist which accomplish this with a certain level of success, most of which involve either the analysis of pixel-level features or the segmentation of images into sub-objects that can be geometrically compared. In this paper we develop and evaluate a new variation of the pixel feature and analysis technique known as the color correlogram in the context of a content-based image retrieval system. Our approach is to extend the autocorrelogram by adding multiple image features in addition to color. We compare the performance of each index scheme with our method for image retrieval on a large database of images. The experiment shows that our proposed method gives a significant improvement over histogram or color correlogram indexing, and it is also memory-efficient.
C1 Trinity Coll, Dept Comp Sci, Hartford, CT 06106 USA.
C3 Trinity College
RP Yoon, P (corresponding author), Trinity Coll, Dept Comp Sci, Hartford, CT 06106 USA.
EM peter.yoon@trincoll.edu
CR Chang CY, 2000, IEEE T IMAGE PROCESS, V9, P1937, DOI 10.1109/83.877214
   Ciocca G, 1999, INFORM PROCESS MANAG, V35, P605, DOI 10.1016/S0306-4573(99)00021-7
   Flickner M., 1995, Query by image and video content: the QBIC system
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pass G., 1996, Proceedings ACM Multimedia 96, P65, DOI 10.1145/244130.244148
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   SCALAROFF S, 1997, IEEE WORKSH CONT BAS
   STRICKER M, 1994, COMPUTER VISION PATT, P704
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
NR 13
TC 24
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 239
EP 248
DI 10.1007/s11042-006-0087-2
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700007
DA 2024-07-18
ER

PT J
AU Bertolotti, P
   Gaggi, O
AF Bertolotti, Paola
   Gaggi, Ombretta
TI A study on multimedia documents behavior: a notion of equivalence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia documents; study of multimedia documents' behavior; SMIL
   language; multimedia document equivalence
ID PRESENTATIONS
AB In this paper we address the problem of comparing multimedia documents, which can be described according to different reference models. If we consider pre- sentations as collections of media items and constraints among them, expressed ac- cording to their reference model, they must be translated to a common formalism in order to compare their temporal behavior and detect if they have a common component (i.e., intersection), if one of them is included in another one (i.e., inclusion), or if they have the same temporal evolution along time (i.e., equivalence). In this paper, we propose the use of automata, to describe the temporal evolution of a document, and the SMIL language as a case study, since this standard allows to describe the same behavior with different sets of tags. In case of behaviorally equivalent SMIL documents, we propose an algorithm to extract the canonical form that represents this behavior.
C1 Univ Padua, Dipartimento Matemat Pura & Applicata, I-35121 Padua, Italy.
   Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
C3 University of Padua; University of Turin
RP Bertolotti, P (corresponding author), Univ Padua, Dipartimento Matemat Pura & Applicata, Via Trieste 63, I-35121 Padua, Italy.
EM bertolot@di.unito.it; gaggi@math.unipd.it
CR ALLEN JF, 1983, COMMUN ACM, V26, P11
   ALUR R, 1994, THEORETICAL COMPUTER, V126, P235
   BERTOLOTTI P, 2005, 8205 U TUR DEP COMP
   BOLL S, 1999, P MULT C ORL FLOR US
   Celentano A, 2004, MULTIMEDIA SYST, V10, P72, DOI 10.1007/s00530-004-0138-3
   HARDMAN L, 1994, COMMUN ACM, V37, P2
   HAUSMANN JH, 2002, P WORKSH GRAPH TRANS
   JOURDAN M, 1998, ACM MULTIMEDIA 1998, P267
   Lo Presti S, 2002, J NETW COMPUT APPL, V25, P319, DOI 10.1006/jnca.2002.0135
   SAMPAIO PNM, 2000, P ACM MULT LOS ANG U
   Stotts PD, 1998, ACM T INFORM SYST, V16, P1, DOI 10.1145/267954.267955
   *W3C SYNCHR MULT W, 2001, SYNCHR MULT INT LANG
   P INT COMP S WORKSH
NR 13
TC 2
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2007
VL 33
IS 3
BP 301
EP 324
DI 10.1007/s11042-007-0102-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 156SW
UT WOS:000245671200004
DA 2024-07-18
ER

PT J
AU Fayzullin, M
   Subrahmanian, VS
   Albanese, M
   Cesarano, C
   Picariello, A
AF Fayzullin, Marat
   Subrahmanian, V. S.
   Albanese, Massimiliano
   Cesarano, Carmine
   Picariello, Antonio
TI Story creation from heterogeneous data sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia; heterogenous; databases; summarization; stories;
   storytelling; framework; algorithms
AB There are numerous applications where there is a need to rapidly infer a story about a given subject from a given set of potentially heterogeneous data sources. In this paper, we formally define a story to be a set of facts about a given subject that satisfies a "story length" constraint. An optimal story is a story that maximizes the value of an objective function measuring the goodness of a story. We present algorithms to extract stories from text and other data sources. We also develop an algorithm to compute an optimal story, as well as three heuristic algorithms to rapidly compute a suboptimal story. We run experiments to show that constructing stories can be efficiently performed and that the stories constructed by these heuristic algorithms are high quality stories. We have built a prototype STORY system based on our model-we briefly describe the prototype as well as one application in this paper.
C1 Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy.
   Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
C3 University of Naples Federico II; University System of Maryland;
   University of Maryland College Park
RP Picariello, A (corresponding author), Univ Naples Federico II, Dipartimento Informat & Sistemist, Via Claudio 21, I-80125 Naples, Italy.
EM picus@unina.it
RI Albanese, Massimiliano/H-5093-2019; Subrahmanian,
   Venkatramanan/ABA-7399-2021; Picariello, Antonio/G-9062-2012;
   PICARIELLO, Antonio/L-6820-2015
OI Albanese, Massimiliano/0000-0002-2675-5810; PICARIELLO,
   Antonio/0000-0003-4804-1007
CR Agrawal R, 2000, LECT NOTES COMPUT SC, V1777, P365
   [Anonymous], 2002, Foundations of Genetic Programming
   Bers MarinaUmaschi., 1998, P SIGCHI C HUMAN FAC, P603, DOI 1145/274644.274725
   Callan J., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P532, DOI 10.1145/584792.584880
   DEOLIVERIRA IL, 1998, P INT JOINT C NEUR N, V2, P1194
   Fayzullin M, 2005, MULTIMED TOOLS APPL, V26, P153, DOI 10.1007/s11042-005-0451-7
   Francis W.N., 1979, DEP LINGUISTICS
   GUODONG Z, 2003, P INT C NAT LANG PRO, P465
   JAMIL HM, 1995, P 12 INT LOG PROGR S, P130
   MACHADO I, 2000, P CVE 2000
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   NEUHOFF DL, 1975, IEEE T INFORM THEORY, V21, P222, DOI 10.1109/TIT.1975.1055355
   Oyama S, 2004, IEEE T KNOWL DATA EN, V16, P17, DOI 10.1109/TKDE.2004.1264819
   Rosso P, 2003, 2003 INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING, PROCEEDINGS, P120
   Theune M., 2003, P 1 INT C INTERACTIV, P204
NR 15
TC 7
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2007
VL 33
IS 3
BP 351
EP 377
DI 10.1007/s11042-007-0100-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 156SW
UT WOS:000245671200006
DA 2024-07-18
ER

PT J
AU Yuen, JCH
   Chan, E
   Lam, KY
AF Yuen, Joe C. H.
   Chan, Edward
   Lam, Kam-Yiu
TI Real time video frames allocation in mobile networks using cooperative
   pre-fetching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE real-time system; distributed real-time video playback; scheduling and
   mobile network
AB In this paper, we study the bandwidth allocation problem for serving video requests in a mobile real-time video player system. One of the main issues to maintain the quality of services (QoS) in mobile video playback is to ensure sufficient number of video frames available at the client side while a video is being played. However, due to the limited bandwidth of a mobile network and variable workload streaming video, this is not easy to achieve in practice. In addition, the communication link between mobile clients and a video server is subject to frequent errors and temporary disconnection. In this paper, we propose to use the notion of buffered bandwidth in addition to the network bandwidth to support real-time playback of videos at mobile clients. Based on this, we designed a bandwidth allocation scheme called Cooperative Pre-Fetching (CP) in which the amount of bandwidth to be allocated to serve a video request depends on the current buffer level of the video at the client relative to the target buffer level of the client. In determining the target buffer level, we consider the errors in communication to the client as well as the other clients who are concurrently served by the system. The buffered video frames at the clients are then used to minimize the impact of error in communications on the overall QoS of video playbacks in the whole system.
C1 City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Lam, KY (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM csjyuen@cityu.edu.hk; csedchan@cityu.edu.hk; cskylam@cityu.edu.hk
RI Lam, Kam Yiu/W-3711-2018; Lam, Alfred/C-1652-2008
OI Lam, Alfred/0000-0003-2771-564X; Lam, Kam-Yiu/0000-0003-0673-3566
CR Antoniou Z, 2002, IEEE ACM T NETWORK, V10, P630, DOI 10.1109/TNET.2002.803901
   BHAGWAT P, 1997, P 1997 IEEE INF APR
   BHARGHAVAN V, 1999, IEEE PERS COMMUN FEB
   Chang RI, 1999, IEEE INFOCOM SER, P447, DOI 10.1109/INFCOM.1999.751377
   Chen JC, 1999, IEEE T MULTIMEDIA, V1, P187, DOI 10.1109/6046.766739
   Duffield NG, 1998, IEEE ACM T NETWORK, V6, P717, DOI 10.1109/90.748084
   Feng WC, 1997, IEEE INFOCOM SER, P58, DOI 10.1109/INFCOM.1997.635114
   Fitzek FHP, 2001, IEEE J SEL AREA COMM, V19, P2015, DOI 10.1109/49.957315
   FRITCHMAN BD, 1967, IEEE T INFORM THEORY, V13, P221, DOI 10.1109/TIT.1967.1053975
   GALL D, 1991, COMMUN ACM, P46
   Hsu C.-Y., 1999, IEEE J SEL AREAS COM, V17
   Kim SH, 2000, PROG PHOTOVOLTAICS, V8, P3, DOI 10.1002/(SICI)1099-159X(200001/02)8:1<3::AID-PIP299>3.0.CO;2-1
   KRUNZ M, 1998, J TELECOMMUNICATION, V9
   LAKSHMAN TV, 1999, IEEE ACM T NETW, V7
   Ng TSE, 1998, IEEE INFOCOM SER, P1103, DOI 10.1109/INFCOM.1998.662920
   PANWAR SS, 1988, J ACM, V35, P832, DOI 10.1145/48014.48019
   RAMMANATHAN P, 1998, P 4 ACM IEEE INT C M
   REISSLEIN M, 1998, IEEE NETW, V12
   REXFORD J, 1999, IEEE ACM T NETW, V7
   Saha D, 1997, IEEE J SEL AREA COMM, V15, P1132, DOI 10.1109/49.611164
   SHAKKOTTAI S, 1999, P 2 ACM WIR MOB MULT
   Wu-Chi Feng, 2000, Proceedings 20th IEEE International Conference on Distributed Computing Systems, P56, DOI 10.1109/ICDCS.2000.840907
   YUEN J, 2002, P IEEE INT C MULT EX
NR 23
TC 8
Z9 9
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2007
VL 32
IS 3
BP 329
EP 352
DI 10.1007/s11042-006-0055-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 137TK
UT WOS:000244314900005
DA 2024-07-18
ER

PT J
AU DeMenthon, D
   Doermann, D
AF DeMenthon, Daniel
   Doermann, David
TI Video retrieval of near-duplicates using κ-nearest neighbor retrieval of
   spatio-temporal descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based indexing and retrieval; video retrieval of
   near-duplicates; action recognition; space-time segmentation;
   spatio-temporal descriptors; object motion
ID MEAN SHIFT
AB This paper describes a novel methodology for implementing video search functions such as retrieval of near-duplicate videos and recognition of actions in surveillance video. Videos are divided into half-second clips whose stacked frames produce 3D space-time volumes of pixels. Pixel regions with consistent color and motion properties are extracted from these 3D volumes by a threshold-free hierarchical space-time segmentation technique. Each region is then described by a high-dimensional point whose components represent the position, orientation and, when possible, color of the region. In the indexing phase for a video database, these points are assigned labels that specify their video clip of origin. All the labeled points for all the clips are stored into a single binary tree for efficient k-nearest neighbor retrieval. The retrieval phase uses video segments as queries. Half-second clips of these queries are again segmented by space-time segmentation to produce sets of points, and for each point the labels of its nearest neighbors are retrieved. The labels that receive the largest numbers of votes correspond to the database clips that are the most similar to the query video segment. We illustrate this approach for video indexing and retrieval and for action recognition. First, we describe retrieval experiments for dynamic logos, and for video queries that differ from the indexed broadcasts by the addition of large overlays. Then we describe experiments in which office actions (such as pulling and closing drawers, taking and storing items, picking up and putting down a phone) are recognized. Color information is ignored to insure independence of action recognition to people's appearance. One of the distinct advantages of using this approach for action recognition is that there is no need for detection or recognition of body parts.
C1 Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP DeMenthon, D (corresponding author), Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.
EM daniel@cfar.umd.edu
CR ALLMEN M, 1993, CVGIP-IMAG UNDERSTAN, V58, P338, DOI 10.1006/ciun.1993.1046
   [Anonymous], IEEE COMPUT
   [Anonymous], 1985, IJCAI
   [Anonymous], P 13 INT C MACH LEAR
   Bay S. D., 1999, Intelligent Data Analysis, V3, P191, DOI 10.1016/S1088-467X(99)00018-9
   Bruno E, 2000, LECT NOTES COMPUT SC, V1929, P327
   BRUNO E, 2002, P INT C PATT REC ICP
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DELBIMBO A, 2000, ICPR, V1, P851
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   DEMENTHON D, 2002, SMVP 2002 STAT METH
   Dimitrova N, 1997, P SOC PHOTO-OPT INS, V3022, P59, DOI 10.1117/12.263444
   DIMITROVA N, 1995, ACM T INFORM SYST, V13, P408, DOI 10.1145/211430.211433
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fablet R, 2002, IEEE T IMAGE PROCESS, V11, P393, DOI 10.1109/TIP.2002.999674
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hampapur A, 1997, P SOC PHOTO-OPT INS, V3022, P188, DOI 10.1117/12.263407
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Kobla V, 1998, J ELECTRON IMAGING, V7, P294, DOI 10.1117/1.482645
   Leung Y, 2000, IEEE T PATTERN ANAL, V22, P1396, DOI 10.1109/34.895974
   LIENHART R, 1998, P SOC PHOTO-OPT INS, V3312, P271
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Merkwirth C, 2000, PHYS REV E, V62, P2089, DOI 10.1103/PhysRevE.62.2089
   Nelson RC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P614, DOI 10.1109/ICCV.1998.710781
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711
   Ricquebourg Y, 2000, IEEE T PATTERN ANAL, V22, P797, DOI 10.1109/34.868682
   Sahouria E, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P526, DOI 10.1109/ICIP.1997.638824
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   SUN H, 2000, IEEE INT C PATT REC, V1, P843
   Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868
   UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R
NR 33
TC 6
Z9 10
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2006
VL 30
IS 3
BP 229
EP 253
DI 10.1007/s11042-006-0029-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 089WS
UT WOS:000240913200002
DA 2024-07-18
ER

PT J
AU Chan, SSM
   Li, Q
   Pino, JA
AF Chan, Shermann S. M.
   Li, Qing
   Pino, Jose A.
TI VideoAcM: a transitive and temporal access control mechanism for
   collaborative video database production applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Workshop on Multimedia and Web Design
CY DEC 13, 2004
CL Miami, FL
DE transitive and temporal access control model; client-data access
   control; data-data access control; authorization rule; video database
ID CONTROL MODEL; SYSTEMS
AB Access control models play an important role in database management systems. In general, there are three basic access control models: Discretionary Access Control (DAC), Mandatory Access Control (MAC), and Non-Discretionary Access Control (NAC). Currently, the majority of commercial DBMSs provide only DAC, and some temporal access control models have been derived based on either DAC or NAC. In the context of video database applications, since the structure of video data is complex in nature, it requires a specific and tailor-made access control mechanism which should include MAC as well as DAC and NAC. However, only few efforts have been put on access control models for video database systems. In this paper, a transitive and temporal access control mechanism for collaborative video database production applications has been proposed, which subsumes the properties of DAC, MAC, and NAC. Moreover, our proposed mechanism is integrated with the intellectual property concerns by constructing an access control hierarchy of video data with authorization rules. In particular, our mechanism can derive novel authorization rules not only on conventional client-data access control, but also on data-data access control. Besides video data, the proposed model is applicable to other data types which exhibit a hierarchical data structure.
C1 Waseda Univ, Fac Human Sci, Media Res Inst, Tokorozawa, Saitama 3591192, Japan.
   City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   Univ Chile, Dept Comp Sci, Santiago, Chile.
C3 Waseda University; City University of Hong Kong; Universidad de Chile
RP Chan, SSM (corresponding author), Waseda Univ, Fac Human Sci, Media Res Inst, 2-579-15 Mikajima, Tokorozawa, Saitama 3591192, Japan.
EM shermann@aoni.waseda.jp; itqli@cityu.edu.hk; jpino@dcc.uchile.cl
RI Li, Qing/JMH-1365-2023; Pino Urtubia, Jose/G-6404-2016
OI Li, Qing/0000-0003-3370-471X; Pino Urtubia, Jose/0000-0002-8466-6453
CR Adam NR, 2002, IEEE T KNOWL DATA EN, V14, P296, DOI 10.1109/69.991718
   [Anonymous], 2000, P 5 ACM WORKSH ROL B
   AREF WG, 2002, P INT WORKSH MULT IN
   Bertino E., 2001, ACM Transactions on Information and Systems Security, V4, P191, DOI 10.1145/501978.501979
   Bertino E, 2003, ACM T INFORM SYST, V21, P155, DOI 10.1145/763693.763695
   Bertino E, 1996, IEEE T KNOWL DATA EN, V8, P67, DOI 10.1109/69.485637
   Bertino E, 1998, ACM T DATABASE SYST, V23, P231, DOI 10.1145/293910.293151
   BERTINO E, 2000, P ACM INT C INF KNOW
   Chan SSM, 2002, IEEE T MULTIMEDIA, V4, P146, DOI 10.1109/TMM.2002.1017730
   Ellis C. A., 1991, Communications of the ACM, V34, P39, DOI 10.1145/99977.99987
   Guerrero LA, 2001, INFORM SOFTWARE TECH, V43, P457, DOI 10.1016/S0950-5849(01)00154-9
   Sandhu R, 2001, LECT NOTES COMPUT SC, V2052, P22
   Sandhu R., 1996, IEEE Computer, V29, P38
   ZHAO B, 2001, PUBLICATIONS TELECOM
   1997, P 2 ACM WORKSH ROL B
   2001, P 6 ACM S ACC CONTR
   1995, P 1 ACM WORKSH ROL B
   1998, P 3 ACM WORKSH ROL B
   1999, P 4 ACM WORKSH ROL B
NR 19
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2006
VL 29
IS 1
BP 29
EP 53
DI 10.1007/s11042-006-7812-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 061AH
UT WOS:000238843100003
DA 2024-07-18
ER

PT J
AU Praveenkumar, S
   Kalva, H
   Furht, B
AF Praveenkumar, Sanigepalli
   Kalva, Hari
   Furht, Borko
TI Error resilient video over multimedia broadcast multicast services
   (MBMS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MBMS; error resilient video; multimedia; multicasting; broadcasting
AB With available data rates for mobile devices constantly increasing, services such as video broadcast and multicast are becoming feasible. A new standard called Multimedia Broadcast Multicast Services (MBMS) is being developed by 3GPP to enable new class of spectrum-efficient multimedia services. Multicast services are expected to serve a diverse user base with varying connectivity and capabilities. We analyze the problem of video error resilience in MBMS services that is critical to maintain consistent quality for end users. The existing error resilience techniques for IP multicasting are not applicable in the MBMS environment. In this paper, we present error resilience techniques that are applicable within the context of the MBMS standard. We propose an Intra Block Refresh method for MBMS services and the results show improved performance. We develop a methodology that can be applied to adapting traditional error resilience tools for the MBMS environment.
C1 Florida Atlantic Univ, Boca Raton, FL 33431 USA.
   Motorola Inc, Schaumburg, IL 60196 USA.
C3 State University System of Florida; Florida Atlantic University
RP Kalva, H (corresponding author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.
EM s.praveen@motorola.com; hari@cse.fau.edu; borko@cse.fau.edu
CR Agashe P, 2004, IEEE COMMUN MAG, V42, P83, DOI 10.1109/MCOM.2003.1267104
   Bansal P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P693
   CARLE G, 1997, IEEE NETWORK     DEC
   CHUNGHOW JTH, 2000, P INT C IMAGE PROCES, V3, P544
   JAMES B, 1999, IEEE T
   Majumdar A, 2002, IEEE T CIRC SYST VID, V12, P524, DOI 10.1109/TCSVT.2002.800315
   PENG G, 2002, COMP ERROR CONTROL T
   PENG G, 2001, EXPT EVALUATION ERRO
   PRAVEENKUMAR S, 2004, WORKSH WIR MULT P IE
   PRAVEENKUMAR S, 2005, IN PRESS ICCE
   Wang J, 2004, IEEE COMMUN MAG, V42, P76, DOI 10.1109/MCOM.2003.1267103
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 13
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 187
EP 201
DI 10.1007/s11042-006-6142-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600006
DA 2024-07-18
ER

PT J
AU Hua, KA
   Tran, DA
AF Hua, KA
   Tran, DA
TI Range multicast for video on demand
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia communications; video on dmand; VCR-like interactivity;
   overlay multicast; caching
ID DELIVERY
AB We explore a communication paradigm for video on demand, called Range Multicast. This scheme is a shift from the conventional thinking about multicast where every receiver must obtain the same data packet at any time. A range multicast allows new members to join at their specified time and still receive the entire video stream without consuming additional server bandwidth. Clients enjoy better service latency since they can join an existing multicast instead of waiting for the next available server stream. We also present techniques to support video-cassette-recorder-like interactivity in this environment. Unlike existing methods which require clients to cache data in a private buffer, the Range Multicast solution utilizes the shared network storage to make more efficient and cost-effective use of the caching space. Furthermore, since a range multicast can accommodate clients with different play points in the video, a client has a better chance to join an on-going multicast for normal playback after finishing a VCR operation. This strategy avoids the need for a new server stream. and thus further alleviates the server load. Our simulation results confirm the aforementioned benefits.
C1 Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.
   Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
C3 State University System of Florida; University of Central Florida;
   University System of Ohio; University of Dayton
RP Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA.
EM kienhua@cs.ucf.edu; duc.tran@notes.udayton.edu
OI Tran, Duc/0000-0001-8129-0940
CR Abram-Profeta EL, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P66, DOI 10.1109/MMCS.1998.693626
   ACHARYA S, 2000, P IEEE NOSSDAV, P3
   Almeroth KC, 1996, IEEE J SEL AREA COMM, V14, P1110, DOI 10.1109/49.508282
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   BRADSHAW MK, 2001, P ACM MULT OCT, P280
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Chen M.S., 1995, PROC 2 INT IEEE C MU, P73
   CHEN MS, 1994, P ACM MULT, P391
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Dan A, 1996, P SOC PHOTO-OPT INS, V2667, P344, DOI 10.1117/12.235887
   DAN A, 1995, J PARALLEL DISTR COM, V30, P168, DOI 10.1006/jpdc.1995.1135
   Deering Steve E, 1989, RFC1112: Host Extensions for IP Multicasting
   Dey-Sircar J. K., 1994, Proceedings ACM Multimedia '94, P25, DOI 10.1145/192593.192615
   Fei ZM, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P949, DOI 10.1109/MMCS.1999.778617
   Feng WC, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P127, DOI 10.1109/MMCS.1996.534964
   FRANCIS P, 1999, YALLCAST EXTENDING I
   GRUBER S, 2000, P 9 INT WWW C, P657
   Hua K., 1997, PROC SIGCOMM, P89
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   Hua KA, 2000, P SOC PHOTO-OPT INS, V3969, P2
   HUA KA, 2003, ACM S APPL COMP MELB, P935
   JAIN S, 2000, 020604 UWCSE
   Jannotti J, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P197
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Liao W, 1997, IEEE MULTIMEDIA, V4, P51, DOI 10.1109/93.641879
   Liebeherr J, 2001, GLOB TELECOMM CONF, P1651, DOI 10.1109/GLOCOM.2001.965860
   Pareto V., 1897, Cours Economie Politique
   Pâris JF, 2001, IEEE IPCCC, P347, DOI 10.1109/IPCCC.2001.918672
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   Pendarakis D, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 3RD USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P49
   QUINN B, 2001, IN PRESS IP MULTICAS
   Ramesh S, 2001, IEEE INFOCOM SER, P85, DOI 10.1109/INFCOM.2001.916690
   Sen S, 1999, IEEE INFOCOM SER, P455, DOI 10.1109/INFCOM.1999.751378
   Shenoy PJ, 1999, MULTIMEDIA SYST, V7, P241, DOI 10.1007/s005300050126
   TANTAOUI MA, 2002, ACM C MULT JUAN LES, P29
   TRAN DA, 2002, P IEEE INT C COMM NE
   WU KL, 2001, P 10 INT C WORLD WID, P36
   YU PS, 1995, MULTIMEDIA SYST, V3, P137, DOI 10.1007/BF02176235
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
   [No title captured]
NR 41
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 367
EP 391
DI 10.1007/s11042-005-3819-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300004
DA 2024-07-18
ER

PT J
AU Truong, BT
   Venkatesh, S
   Dorai, C
AF Truong, BT
   Venkatesh, S
   Dorai, C
TI Extraction of film takes for cinematic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE take extraction; film structure; video analysis
AB In this paper, we focus on the 'reverse editing' problem in movie analysis, i.e., the extraction of film takes, original camera shots that a film editor extracts and arranges to produce a finished scene. The ability to disassemble final scenes and shots into takes is essential for nonlinear browsing, content annotation and the extraction of higher order cinematic constructs from film. A two-part framework for take extraction is proposed. The first part focuses on the filtering out action-driven scenes for which take extraction is not useful. The second part focuses on extracting film takes using agglomerative hierarchical clustering methods along with different similarity metrics and group distances and demonstrates our findings with 10 movies.
C1 Curtin Univ Technol, Dept Comp Sci, Perth, WA 6845, Australia.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 Curtin University; International Business Machines (IBM)
RP Curtin Univ Technol, Dept Comp Sci, GPO Box U1987, Perth, WA 6845, Australia.
EM truongbt@cs.curtin.edu.au; svetha@cs.curtin.edu.au; dorai@watson.ibm.com
OI Venkatesh, Svetha/0000-0001-8675-6631
CR Adams B, 2002, IEEE T MULTIMEDIA, V4, P472, DOI 10.1109/TMM.2002.802016
   [Anonymous], 1993, Cluster Analysis
   [Anonymous], 2001, HPL2001191
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   Ba Tu Truong, 2000, Proceedings ACM Multimedia 2000, P219, DOI 10.1145/354384.354481
   Beaver FrankE., 1994, Dictionary of Film Terms: the Aesthetic Companion to Film Analysis
   Corridoni JM, 1998, PATTERN RECOGN, V31, P2027, DOI 10.1016/S0031-3203(98)00061-2
   DIMITROVA N, 1999, IEEE ICIP 1999, V3, P314
   Doulamis ND, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P875, DOI 10.1109/ICIP.1998.723660
   DREW MS, 2000, ACM MULT 2000 LOS AN
   Farin D, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P89, DOI 10.1109/ICME.2002.1035725
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kobayashi S., 1998, COLORIST PRACTICAL H
   MILLER DJ, 1979, INT J BEHAV DEV, V2, P159, DOI 10.1177/016502547900200204
   MORIAYAMA T, 2002, ACM MULT WORKSH 2000, P191
   NAM J, 1999, 7 ACM C MULT ACMMM 9, V2, P53
   NGO CW, 2001, ACM MULTIMEDIA, P51
   Rui Y, 1999, MULTIMEDIA SYST, V7, P359, DOI 10.1007/s005300050138
   SHARFF S, 1982, ELEMENTS CINEMA CINE
   TEKALP EA, 2003, IEEE T IMAGE PROCESS
   Truong BT, 2003, IEEE T CIRC SYST VID, V13, P5, DOI 10.1109/TCSVT.2002.808084
   TRUONG BT, 2004, IEEE MULT MOD 2004 B
   TRUONG BT, 2002, ACM MULT 2002 FRANC, P339
   Veneau E, 2000, INT C PATT RECOG, P254, DOI 10.1109/ICPR.2000.902907
   WANG J, 2003, IN PRESS VISUAL COMP
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Zettl H., 1999, SIGHT SOUND MOTION
   Zhao L, 2001, PROC SPIE, V4315, P262, DOI 10.1117/12.410935
   Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 32
TC 4
Z9 4
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2005
VL 26
IS 3
BP 277
EP 298
DI 10.1007/s11042-005-0892-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 942YO
UT WOS:000230319000003
DA 2024-07-18
ER

PT J
AU Chen, JH
   Zhou, JL
   Yu, SS
   Xu, J
   Zhong, L
   Zheng, JH
AF Chen, JH
   Zhou, JL
   Yu, SS
   Xu, J
   Zhong, L
   Zheng, JH
TI A very low bit rate video coding combined with fast adaptive block size
   motion estimation and nonuniform scalar quantization multiwavelet
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE motion estimation; video compression; scalar quantization; wavelet
   transform coding
ID SUCCESSIVE ELIMINATION ALGORITHM; COMPENSATION; CODER
AB We describe a very low bit rate video coding framework in which motion correlation between successive video frames is exploited in the multiwavelet transform domain. Some complicated techniques, such as spatial prediction in intra coding, adaptive block size motion estimation, more than one previous frames for prediction in inter frames, and content adaptive binary arithmetic coding (CABAC) are used in H.26L standard. The testing results show that H.26L can greatly outperform MPEG-4 ASP in both PSNR and visual quality. However, the encoding of H.26L costs too much time for it is complex to use fast motion search in adaptive block size motion estimation, and CABAC needs much time to generate the code list for entropy coding. Whereas, only four types of symbol are generated after zero tree wavelet coding so that the entropy coding can cost less time than CABAC. Moreover, if we select 8x8 sized block as a basic mode, which can be united into the large size mode if neighbored 8x8 sized blocks have same reference frame and motion vector, then the fast motion estimation can be feasible. Accordingly, a fast motion search algorithm, multiwavelet transform, and a novel adaptive quantization schemer are applied to the proposed coding frame. Experimental results reveal 0.2-0.5 dB increase in coded PSNR at low bit rates over the state-of-the-art H.26L recommendation, and similar improvements over MPEG-4 at high bit rates, with a considerable improvement in subjective reconstruction quality, while simultaneously supporting a scalable representation.
C1 Huazhong Univ Sci & Technol, Comp Sch Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Chen, JH (corresponding author), Huazhong Univ Sci & Technol, Comp Sch Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM chenjz70@263.net
RI 金华, 郑/GWM-7529-2022; Xu, Jun/F-5929-2012
CR Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   Jou JM, 1999, IEEE T CIRC SYST VID, V9, P843, DOI 10.1109/76.785721
   KARLSSON G, 1988, P 1988 IEEE ICASSP, P110
   Khan E, 2001, ELECTRON LETT, V37, P40, DOI 10.1049/el:20010028
   Kim JN, 1999, IEEE T CONSUM ELECTR, V45, P417
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Marpe D, 1999, IEEE T CIRC SYST VID, V9, P85, DOI 10.1109/76.744277
   Martucci SA, 1997, IEEE T CIRC SYST VID, V7, P109, DOI 10.1109/76.554422
   *MPEG VID GROUP, 2001, JTCISC29WG11N4355 IS
   PODILCHUK CI, 1995, IEEE T IMAGE PROCESS, V4, P125, DOI 10.1109/83.342187
   POPESCU BP, 2001, 2001 IEEE INT C AC S, V3, P1793
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 1999, IEEE T IMAGE PROCESS, V8, P1161, DOI 10.1109/83.784429
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Strela V, 1999, IEEE T IMAGE PROCESS, V8, P548, DOI 10.1109/83.753742
   Su JK, 2000, IEEE T IMAGE PROCESS, V9, P1509, DOI 10.1109/83.862628
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   TSUNASHIMA K, 1994, IEEE T COMMUN, V42, P1894, DOI 10.1109/TCOMM.1994.582899
   Voukelatos SP, 1997, IEEE T CIRC SYST VID, V7, P424, DOI 10.1109/76.564121
   Xu JB, 1999, IEEE T CIRC SYST VID, V9, P1025, DOI 10.1109/76.795056
   Yang XG, 2000, IEEE T IMAGE PROCESS, V9, P778, DOI 10.1109/83.841519
   Zhang YQ, 1992, IEEE T CIRC SYST VID, V2, P285, DOI 10.1109/76.157160
NR 24
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 123
EP 144
DI 10.1007/s11042-005-6852-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600006
DA 2024-07-18
ER

PT J
AU Wong, HS
   Ip, HHS
   Iu, LPL
   Cheung, KKT
   Guan, L
AF Wong, HS
   Ip, HHS
   Iu, LPL
   Cheung, KKT
   Guan, L
TI Transformation of compressed domain features for content-based image
   indexing and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based image retrieval; evolutionary computation; genetic
   algorithm
ID COLOR; SHAPE; TEXTURE
AB In this paper, we address the problem of image content characterization in the compressed domain for the facilitation of similarity matching in content-based image retrieval. Specifically, given the disparity of the content characterization power of compressed domain approaches and those based on pixel-domain features, with the latter being usually considered as the more superior one, our objective is to transform the selected set of compressed domain feature histograms in such a way that the retrieval result based on these features is compatible with their spatial domain counterparts. Since there are a large number of possible transformations, we adopt a genetic algorithm approach to search for the optimal one, where each of the binary strings in the population represents a candidate transformation. The fitness of each transformation is defined as a function of the discrepancies between the spatial-domain and compressed-domain retrieval results. In this way, the GA mechanism ensures that transformations which best approximate the performance of spatial domain retrieval will survive into the next generation and are allowed through the operations of crossover and mutation to generate variations of themselves to further improve their performances.
C1 City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
   Ryerson Polytech Univ, Dept Elect & Comp Engn, Toronto, ON M5B 2K3, Canada.
C3 City University of Hong Kong; Toronto Metropolitan University
RP City Univ Hong Kong, Dept Comp Sci, 83 Tat Chee Av, Kowloon Tong, Hong Kong, Peoples R China.
EM cshswong@cityu.edu.hk
RI Iu, Lawrence/K-7441-2019
OI Iu, Lawrence/0000-0001-6898-5043; WONG, Hau-San/0000-0002-1530-7529; IP,
   Ho Shing Horace/0000-0002-1509-9002
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   [Anonymous], INT J DIGITAL LIB
   Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, P3, DOI 10.1109/4235.585888
   Back T., 1996, EVOLUTIONARY ALGORIT
   Chang SF, 1997, COMMUN ACM, V40, P63, DOI 10.1145/265563.265573
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   Corridoni JM, 1999, MULTIMEDIA SYST, V7, P175, DOI 10.1007/s005300050120
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Eakins JP, 1998, IEEE MULTIMEDIA, V5, P53, DOI 10.1109/93.682526
   FOGEL DB, 1995, GENETIC ALGORITHMS S
   Grosky W. I., 1994, IEEE Multimedia, V1, P12, DOI 10.1109/93.295262
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Howe NR, 2000, PROC CVPR IEEE, P239, DOI 10.1109/CVPR.2000.854798
   Hsu CC, 1996, IEEE T KNOWL DATA EN, V8, P522, DOI 10.1109/69.536245
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Huet B, 1999, IEEE T PATTERN ANAL, V21, P1363, DOI 10.1109/34.817414
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MEHROTRA R, 1995, COMPUTER, V28, P57, DOI 10.1109/2.410154
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   Pala P, 1999, PATTERN RECOGN, V32, P517, DOI 10.1016/S0031-3203(98)00041-7
   Pennebaker W.B., 1993, JPEG: Still Image Compression Standard
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Roussas G. G., 1997, A Course in Mathematical Statistics, VSecond Edition
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Shneier M, 1996, IEEE T PATTERN ANAL, V18, P849, DOI 10.1109/34.531805
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
NR 35
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 5
EP 26
DI 10.1007/s11042-005-6847-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600001
DA 2024-07-18
ER

PT J
AU Golshani, F
   Vissicaro, P
   Park, Y
AF Golshani, F
   Vissicaro, P
   Park, Y
TI A multimedia information repository for cross cultural dance studies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st Workshop on Multimedia Semantics
CY NOV 28-29, 2002
CL Milovy, CZECH REPUBLIC
DE multimedia information systems; dance studies; multimedia content
   analysis
ID RETRIEVAL
AB Multimedia technologies provide effective means for studying the evolution of dance across time and space. The study may be at the micro level which analyzes the development of an individual's performance and the movements of the dancer(s) in 3D space and over the length of the dance. However, at the macro level, diffusion of dance throughout the world over a span of time may be investigated in order to trace particular dance repertoires that may have traveled across various cultures and traditions. Although clearly different with respect to the expected objectives, both micro level analysis and macro level analysis require detailed comparison of patterns on the basis of certain characteristics that are deemed significant for a given dance. These characteristics are diverse in nature and may include such parameters as design formations, use of space ( including level, direction, etc.), dynamics, paraphernalia (e. g., swords, sticks, etc.), sound, and color. We present the design of a multimedia information system with two complimentary aims. The first is to automate, to the greatest degree possible, the process of comparison and analysis of dance and human movement. Much of the information about dance exists in the form of video, images, audio and written commentaries, all collected into a digital library. As dance related materials are added, a wide variety of routines are needed to extract the necessary low level features from the multimedia objects. These low level features are then interpreted to human understandable features and patterns, which will be used for analysis by specialists. The second aim is to bring artists and technologists closer in a meaningful way.
C1 Wright State Univ, Dayton, OH 45435 USA.
   Arizona State Univ, Dept Dance, Tempe, AZ 85287 USA.
   Johnson Controls Inc, Milwaukee, WI 53201 USA.
C3 University System of Ohio; Wright State University Dayton; Arizona State
   University; Arizona State University-Tempe; Johnson Controls
   Incorporated
RP Wright State Univ, Dayton, OH 45435 USA.
EM golshani@cs.wright.edu; pegge@asu.edu; youngchoon.park@jci.com
CR Bradski G. R., INTEL TECHNOLOGY J Q
   FEITEN B, 1994, COMPUT MUSIC J, V18, P53, DOI 10.2307/3681185
   GOLSHANI F, 2002, P WORKSH MULT SEM MI, P76
   HIRATA K, 1993, NEC RES DEV, V34, P263
   HORPRASERT T, 1999, P IEEE FRAM RAT WORK
   KOHOL K, 2003, THESIS ARIZONA STATE
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   PARK Y, 2002, THESIS ARIZONA STATE
   PARK Y, 2003, TUTORIAL PROGRAMMERS
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TEGOLO D, 1994, P SOC PHOTO-OPT INS, V2185, P59, DOI 10.1117/12.171781
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
NR 12
TC 11
Z9 12
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2004
VL 24
IS 2
BP 89
EP 103
DI 10.1023/B:MTAP.0000036838.87602.71
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 843OT
UT WOS:000223094200002
DA 2024-07-18
ER

PT J
AU Hondroulis, A
   Harizakis, C
   Triantafillou, P
AF Hondroulis, A
   Harizakis, C
   Triantafillou, P
TI Optimal cache memory exploitation for continuous media: To cache or to
   prefetch?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 7th Workshop on Multimedia Information Systems
CY NOV 07-09, 2001
CL Capri, ITALY
DE caching; prefetching; video streams; multimedia servers; modeling;
   simulation; statistical analysis
ID STORAGE SERVERS
AB Network continuous-media applications are emerging with a great pace. Cache memories have long been recognized as a key resource (along with network bandwidth) whose intelligent exploitation can ensure high performance for such applications. Cache memories exist at the continuous-media servers and their proxy servers in the network. Within a server, cache memories exist in a hierarchy (at the host, the storage-devices, and at intermediate multi-device controllers). Our research is concerned with how to best exploit these resources in the context of continuous media servers and in particular, how to best exploit the available cache memories at the drive, the disk array controller, and the host levels. Our results determine under which circumstances and system configurations it is preferable to devote the available memory to traditional caching (a.k.a. "data sharing") techniques as opposed to prefetching techniques. In addition, we show how to configure the available memory for optimal performance and optimal cost. Our results show that prefetching techniques are preferable for small-size caches (such as those expected at the drive level). For very large caches (such as those employed at the host level) caching techniques are preferable. For intermediate cache sizes (such as those at multi-device controllers) a combination of both strategies should be employed.
C1 Tech Univ Crete, Dept Elect & Comp Engn, Khania, Greece.
   Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   Univ Patras, Dept Comp Engn & Informat, GR-26110 Patras, Greece.
C3 Technical University of Crete; Stanford University; University of Patras
RP Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM axon@cs.stanford.edu; harizak@orion.speech.gr; peter@ceid.upatras.gr
RI TRIANTAFILLOU, Peter/AAJ-6176-2021
CR ANDERSON D, 1998 NSIC NASD WORKS
   BERSON S, 1994, P ACM SIGMOD, P79
   DAN A, 1998, 19347 IBM RC
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   GEMMELL DJ, 1995, IEEE COMPUTER    MAY, P40
   GHANDEHARIZADEH S, 1996, DISK SCHEDULING DATA
   Golubchik L, 1996, MULTIMEDIA SYST, V4, P140, DOI 10.1007/s005300050019
   GRAY J, SPRING 1998 NSIC NAS
   GROSS D, 1985, FUNDAMENTALS QUEUING
   KAMATH M, 1994, 9411 U MASS
   KEETON K, 1998, SIGMOD RECORD, V27
   Kleinrock L., 1975, QUEUING SYSTEMS
   OZDEN B, 1996, P INT C MULT COMP SY
   Papoulis A, 1984, PROBABILITY RANDOM V, V2, P1984
   PATTERSON D, 1998, SIGMOD 98 JUN
   REDDY ALN, 1994, IEEE COMPUTER    MAR, P69
   RIEDEL E, 1998, P INT C VLDB
   RUEMMLER C, 1994, IEEE COMPUTER    MAR, P17
   SHI W, 1998, THESIS U SO CALIFORN
   Triantafillou P, 1998, PARALLEL COMPUT, V24, P21, DOI 10.1016/S0167-8191(97)00115-4
   TRIANTAFILLOU P, 2000, IEEE INT C MULT COMP
NR 21
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2004
VL 23
IS 3
BP 203
EP 220
DI 10.1023/B:MTAP.0000031757.02159.ac
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 829BJ
UT WOS:000222017700003
DA 2024-07-18
ER

PT J
AU Canós, JH
   De Zulueta, F
AF Canós, JH
   De Zulueta, F
TI Using hypermedia to improve safety in underground metropolitan
   transportation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE emergency management; hypermedia; safety systems
ID DESIGN
AB One of the main concerns in the organization and management of public transportation is passenger safety before an emergency. This is even more critical in the case of subway transportation, where risks are higher in the case of fire. Handling a critical emergency is a stressing task, in which large amounts of information must be used in order to make the right decision in a very short time.
   In this paper, we describe a pioneering application of hypermedia technology consisting of the integration of all the information needed to handle emergencies in a large hypermedia document. It reduces the response time remarkably by integrating text, graphics, sound, video and 3D models in a user-friendly interface. The authors and the Safety Office of Metro Valencia, the public transportation company of Valencia, developed it jointly between 1998 and 2000. We outline some of the technical decisions made during the project, as well as some of the lessons learned concerning the development of large hypermedia projects.
C1 Univ Politecn Valencia, Dept Sistemes Informat & Computacio, E-46022 Valencia, Spain.
   Univ Politecn Valencia, Dept Comunicacio Audiovisual Documentacio & Hist, E-46022 Valencia, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Canós, JH (corresponding author), Univ Politecn Valencia, Dept Sistemes Informat & Computacio, Camino Vera S-N, E-46022 Valencia, Spain.
RI Canos-Cerda, Jose H./L-7499-2014
OI Canos-Cerda, Jose H./0000-0001-8139-5195
CR BECK E, 1999, EXTREME PROGRAMMING
   GARZOTTO F, 1995, COMMUN ACM, V38, P74, DOI 10.1145/208344.208349
   ISAKOWITZ T, 1995, COMMUN ACM, V38, P34, DOI 10.1145/208344.208346
   Koch N., 1999, A Comparative Study of Methods for Hypermedia Development
   *METR VAL SAF OFF, 1998, EM PLAN
   NANARD J, 1995, COMMUN ACM, V38, P49, DOI 10.1145/208344.208347
   Schwabe D, 1998, THEOR PRACT OBJ SYST, V4, P207, DOI 10.1002/(SICI)1096-9942(1998)4:4<207::AID-TAPO2>3.0.CO;2-2
   Schwabe Daniel., 1996, Proceedings of the the seventh ACM conference on Hypertext (HYPERTEXT96), P116
NR 8
TC 7
Z9 7
U1 0
U2 5
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2004
VL 22
IS 1
BP 75
EP 87
DI 10.1023/B:MTAP.0000008660.05189.48
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 754MK
UT WOS:000187320800004
DA 2024-07-18
ER

PT J
AU Golubchik, L
   Lui, JCS
AF Golubchik, L
   Lui, JCS
TI Performance tradeoffs in scheduling techniques for mixed workloads
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia scheduling; performance evaluation; QoS guarantees for mixed
   workloads
AB Many modern multimedia applications require the retrieval of different "classes" of data with drastically different characteristics. For instance, digital libraries type systems must be designed to deliver not only text files and still images, but voice and video as well. These applications can benefit from the sharing of resources such as disk and network bandwidth, instead of the conservative approach of partitioning the resources according to the characteristics of each type of data being retrieved. Continuous and non-continuous media applications, require different performance metrics to be achieved, so that the necessary quality of service (QoS) is satisfied. As a consequence, the proper managing of resources is a major issue in order to provide the complete sharing of resources and yet reaching the QoS goals. This work focuses on multimedia storage systems that are capable of serving a mixture of continuous and non-continuous workloads. Our main objective is to expose and investigate the tradeoffs involved in managing the system resources, in particular, I/O bandwidth. The performance metrics of interest are the mean and variance of response time for non-continuous media requests and the probability of missing an imposed deadline for continuous media workloads. Different scheduling algorithms are considered and tradeoffs to achieve performance goals are studied, including those involving buffer sizing.
C1 Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
   Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   Univ Fed Rio de Janeiro, CS Dept, COPPE, PESC, BR-21941 Rio De Janeiro, Brazil.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 University of Southern California; Chinese University of Hong Kong;
   Universidade Federal do Rio de Janeiro; International Business Machines
   (IBM)
RP Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
EM leana@cs.usc.edu; cslui@cse.cuhk.edu.hk
RI de Souza e Silva, Edmundo/AAG-7454-2019
OI de Souza e Silva, Edmundo/0000-0003-0912-7860
CR BERSON S, 1994, INT C MAN DAT MINN M, P79
   BERSON S, 1995, P ACM SIGMOD INT C M, P364
   CHANG E, 1996, P SPIE C VIS COMM IM, P47
   CHEN M, 1993, ACM MULTIMEDIA 93, P235
   Ghandeharizadeh SA, 1998, PARALLEL COMPUT, V24, P91, DOI 10.1016/S0167-8191(97)00118-X
   Golubchik L, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P292, DOI 10.1109/MMCS.1999.778387
   Kleinrock L., 1975, Queueing Systems-Volume 1: Theory, V1
   LAVENBERG SS, 1983, COMPUTER PERFORMANCE
   Nerjes G, 2000, MULTIMED TOOLS APPL, V11, P9, DOI 10.1023/A:1009669215773
   NERJES G, 1997, P IEEE INT WORKSH RE
   ROMBOYANNAKIS Y, 1998, P ACM MULT C
   RUEMMLER C, 1994, COMPUTER, V27, P17, DOI 10.1109/2.268881
   Santos JR, 2000, PERF E R SI, V28, P44, DOI 10.1145/345063.339352
   SHENOY PJ, 1998, ACM SIGMETRICS C JUN
   TOBAGI FA, 1993, ACM MULT C, P393
   WOLF J, 1995, P ACM SIGMETRICS PER
   YU PS, 1992, 3 INT WORKSH NETW OP, P44
   Zhang Z.-L., 1997, IEEE J SELECTED AREA, V15
NR 18
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2003
VL 21
IS 2
BP 147
EP 172
DI 10.1023/A:1025568625411
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 718BJ
UT WOS:000185125000003
DA 2024-07-18
ER

PT J
AU Qian, F
   Li, MJ
   Zhang, HJ
   Ma, WY
   Zhang, B
AF Qian, F
   Li, MJ
   Zhang, HJ
   Ma, WY
   Zhang, B
TI Alternating feature spaces in relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image retrieval; relevance feedback; complementary features;
   representative training samples
ID CLASSIFICATION
AB Image retrieval using relevance feedback can be treated as a two-class learning and classification process. The user-labelled relevant and irrelevant images are regarded as positive and negative training samples, based on which a classifier is trained dynamically. Then the classifier in turn classifies all images in the database. In practice, the number of training samples is very small because the users are often impatient. On the other hand, the positive samples usually are not representative since they are the nearest ones to the query and thus less informative. The insufficiency of training samples both in quantities and varieties constrains the generalization ability of the classifier significantly. In this paper, we propose a novel relevance feedback approach, which aims to collect more representative samples and hence improve the performance of classifier. Image labeling and classifier training are conducted in two complementary image feature spaces. Since the samples distribute differently in two spaces, the positive samples may be more informative in one feature space than in another. The two complementary feature spaces are alternated iteratively during the feedback process. To choose appropriate complementary feature spaces, we present two methods to measure the complementarities between two feature spaces quantitatively. Our experimental result on 10,000 images indicates that the proposed feedback approach significantly improves image retrieval performance.
C1 Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Tsinghua University; Microsoft Research Asia; Microsoft
RP Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
CR [Anonymous], P IEEE C COMP VIS PA
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   COX IJ, 2000, IEEE T IMAGE PROCESS
   HONG P, 2000, IEEE INT C IM PROC V
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   ISHIKAWA Y, 1998, P 24 VLDB C NEW YORK
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Lei Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P721, DOI 10.1109/ICIP.2001.958595
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   QIAN F, 2001, 3 INT WORKSH MULT IN
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   RUI Y, 2000, P IEEE C COMP VIS PA
   STRICKER M, 1995, SPIE P, V2420
   Su Z., 2001, SPIE ELECT IMAGING
   Tieu Kinh, 2000, P IEEE C COMP VIS PA
   TONG S, 2001, P ACM MULT 2001 OTT
   VASCONCELOS N, 1999, NIPS 99 DENV COL
   XU K, 2000, THESIS RUTGERS U
   Zhang L, 1999, IEEE T NEURAL NETWOR, V10, P925, DOI 10.1109/72.774263
   ZHANG L, 2001, CHINESE J SOFTWARE, V12, P1479
NR 21
TC 3
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2003
VL 21
IS 1
BP 35
EP 54
DI 10.1023/A:1025030131788
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709HD
UT WOS:000184619000003
DA 2024-07-18
ER

PT J
AU Kwon, JB
   Yeom, HY
AF Kwon, JB
   Yeom, HY
TI A statistical admission control scheme for continuous media servers
   using caching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE continuous media servers; admission control; QoS; caching; storage
   systems
ID STORAGE
AB In continuous media servers, disk load can be reduced by using buffer cache. In order to utilize the saved disk bandwidth by caching, a continuous media server must employ an admission control scheme to decide whether a new client can be admitted for service without violating the requirements of clients already being serviced. A scheme providing deterministic QoS guarantees in servers using caching has already been proposed. Since, however, deterministic admission control is based on the worst case assumption, it causes the wastage of the system resources. If we can exactly predict the future available disk bandwidth, both high disk utilization and hiccup-free service are achievable. However, as the caching effect is not analytically determined, it is difficult to predict the disk load without substantial computation overhead. In this paper, we propose a statistical admission control scheme for continuous media servers where caching is used to reduce disk load. This scheme improves disk utilization and allows more streams to be serviced while maintaining near-deterministic service. The scheme, called Shortsighted Prediction Admission Control ( SPAC), combines exact prediction through on-line simulation and statistical estimation using a probabilistic model of future disk load in order to reduce computation overhead. It thereby exploits the variation in disk load induced by VBR-encoded objects and the decrease in client load by caching. Through trace-driven simulations, it is demonstrated that the scheme provides near-deterministic QoS and keeps disk utilization high.
C1 Sunmoon Univ, Dept Comp Sci, Asan 336708, Chungnam, South Korea.
C3 Sun Moon University
RP Kwon, JB (corresponding author), Sunmoon Univ, Dept Comp Sci, Kalsan Ri 100, Asan 336708, Chungnam, South Korea.
EM jbkwon@dcslab.snu.ac.kr; yeom@dcslab.snu.ac.kr
CR ANDERSON ER, 1992, ENVIRON CLAIM J, V4, P311
   Cao P, 1997, PROCEEDINGS OF THE USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS, P193
   DAN A, 1995, COMPCON '95 - TECHNOLOGIES FOR THE INFORMATION SUPERHIGHWAY, DIGEST OF PAPERS, P217
   GEMMELL DJ, 1995, COMPUTER, V28, P40, DOI 10.1109/2.384117
   GEMMELL J, 1992, ACM T INFORM SYST, V10, P51, DOI 10.1145/128756.128758
   Gollapudi S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P186, DOI 10.1109/MMCS.1996.534973
   Hogg R., 1993, Probability and statistical inference
   KNIGHTLY EW, 1995, IEEE INFOCOM SER, P1137, DOI 10.1109/INFCOM.1995.515991
   LEE KO, 1999, P IEEE INT C MULT CO
   Ng RT, 1996, MULTIMEDIA SYST, V4, P55, DOI 10.1007/s005300050012
   NG RT, 1996, MULTIMEDIA INFORMATI, P147
   Ozden B, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P172, DOI 10.1109/MMCS.1996.534971
   Patterson DavidA., 1996, Computer architecture: a quantitative approach, V2nd
   Vin H. M., 1994, Proceedings ACM Multimedia '94, P33, DOI 10.1145/192593.192616
   VIN HM, 1993, IEEE J SEL AREA COMM, V11, P153, DOI 10.1109/49.210554
   YU PS, 1992, P 3 INT WORKSH NETW, P38
   INFORMATIK MPEG 1 TR
NR 17
TC 1
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2003
VL 19
IS 3
BP 279
EP 296
DI 10.1023/A:1023229414510
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 665BD
UT WOS:000182099000004
DA 2024-07-18
ER

PT J
AU Martínez, JM
   Cabrera, J
   Bescós, J
   Cisneros, G
   Ménendez, JM
AF Martínez, JM
   Cabrera, J
   Bescós, J
   Cisneros, G
   Ménendez, JM
TI MISS:: A generic model for MetaInformation SubSystems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE metadata system model; software and system architecture; information
   model; MPEG-7; browsing and retrieval
AB This paper presents an approach to a flexible model for building an indexing subsystem based on metadata: the MetaInformation Subsystem ( MISS). The MISS model consists of a software architecture, a system architecture, and an information model. The software architecture relies on a model ( based on four levels: database, storage & retrieval, functional core, and application) used for the development of applications for information systems to search in and populate a database. The system architecture consists of a Browsing Application and a Populating Application, both built on top of a Metadata Database via the proposed software architecture. The Browsing Application is in charge of managing the user's interaction with the subsystem ( navigation, search, and retrieval), whereas the Populating Application provides a mechanism to insert metadata and data views into the MISS databases. Finally, the proposed information model ( the Metadata Information Model-MIM) consists of the metadata content, its structure, and the representation model, being in connection with the MPEG-7 standardisation work and providing impact to this Forum. In order to validate it, MISS has been used in the implementation of the Browsing and Retrieval System of the HYPERMEDIA ACTS 361 Project "Continuous Audiovisual Market in Europe" ( publicly demonstrated in several workshops and in Telecom Americas 2000), obtaining very good results in terms of functionality, flexibility and reliability.
C1 Univ Politecn Madrid, ETSIng Telecomunicac, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
C3 Universidad Politecnica de Madrid
EM jms@gti.ssr.upm.es
RI QUESADA, JULIAN CABRERA/Y-7544-2019; Menéndez, José
   Manuel/AAS-8430-2020; Menendez, Jose-Manuel/L-1159-2014; Bescos,
   Jesus/C-4327-2014; Martinez, Jose/A-1185-2008
OI QUESADA, JULIAN CABRERA/0000-0002-7154-2451; Menéndez, José
   Manuel/0000-0003-0584-2250; Menendez, Jose-Manuel/0000-0003-0584-2250;
   Bescos, Jesus/0000-0001-6238-6859; Martinez, Jose/0000-0002-2236-1769
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Amato G, 1998, MULTIMED TOOLS APPL, V7, P9, DOI 10.1023/A:1009618102731
   BESCOS J, 2000, IN PRESS P INT C IM, P4
   Cisneros G, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P1052, DOI 10.1109/MMCS.1999.778656
   Elmagarmid A., 1997, VIDEO DATABASE SYSTE
   HALASZ F, 1994, COMMUN ACM, V37, P30, DOI 10.1145/175235.175237
   Hibino S., 1996, Proceedings ACM Multimedia 96, P75, DOI 10.1145/244130.244149
   Martinez J., 1998, THESIS U POLITECNICA
   Martinez JM, 1998, MULTIMED TOOLS APPL, V6, P239, DOI 10.1023/A:1009656230643
   MARTINEZ JM, 1999, MPEG VANC M JUL
   MARTINEZ JM, 1998, LECT NOTES COMPUTER, V1513, P499
   *MPEG MMDS GROUP, 1999, MPEG VANC M JUL
   *MPEG REQ GROUP, 1999, MPEG SEOUL M MARCH
   *MPEG REQ GROUP, 2000, MPEG GEN M MAY JUN
   *MPEG REQ GROUP, 1998, MPEG ATL CIT M OCT
   *MPEG REQ GROUP, 2000, MPEG BEIJ M JUL
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Steinmetz R., 1995, MULTIMEDIA COMPUTING
   VANBEEK P, 2000, MPEG 7 MULTIMEDIA DE
   *WORLD WID WEB CON, 2000, XML SCHEM 2
   *WORLD WID WEB CON, 2000, XML SCHEM 1
   Yu HH, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P517, DOI 10.1109/MMCS.1997.609764
NR 22
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2003
VL 19
IS 3
BP 203
EP 240
DI 10.1023/A:1023221229531
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 665BD
UT WOS:000182099000001
DA 2024-07-18
ER

PT J
AU Singh, G
   Singh, G
   Tuli, N
   Mantri, A
AF Singh, Gurwinder
   Singh, Gurjinder
   Tuli, Neha
   Mantri, Archana
TI Hyperspace AR: an augmented reality application to enhance spatial
   skills and conceptual knowledge of students in trigonometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Spatial skills; Trigonometry; Visualization;
   Engineering education
ID EDUCATION; GEOMETRY; MOBILE
AB The mathematics curriculum has become more dynamic, rigorous, and interdisciplinary in recent years. Therefore, complementing the academic concepts with practical and experiential learning is essential to optimize the learning outcomes. When daunting scientific principles and topics are implemented by traditional diagrams and equations, most students have trouble visualizing; restricting their ability to grasp the idea in detail. Augmented reality has recently become an engineering education method to teach abstract concepts as it enhances the visualization and understanding of technical concepts. In this paper, an augmented reality-based application, 'Hyperspace', was developed to enhance undergraduate students' spatial skills and conceptual knowledge in trigonometry. Hyperspace provides students with features such as augmenting three-dimensional trigonometric functions. These trigonometric functions are dynamically generated using procedural content generation algorithms and computer graphics in augmented reality. An experimental study was conducted to evaluate the effectiveness of Hyperspace on the spatial skills and conceptual knowledge of the students. In total, 127 first-year engineering students took part in the study, and they were randomly assigned to two groups. The students of one group were taught using an AR-based application, and students of the other group were taught using a traditional approach. The experimental outcomes indicate that the augmented reality-based application 'Hyperspace' has significantly enhanced the spatial skills and conceptual knowledge of students when learning about trigonometry.
C1 [Singh, Gurwinder; Singh, Gurjinder; Mantri, Archana] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Punjab, India.
   [Tuli, Neha] Sri Sai Coll Engn & Technol, Dept Comp Sci & Engn, Badhani, Punjab, India.
C3 Chitkara University, Punjab; Sri Sai College of Engineering & Technology
RP Singh, G (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Punjab, India.
EM sgurwinderr@gmail.com; gurjinder.singh@chitkara.edu.in;
   nehatuli1107@gmail.com; archana.mantri@chitkara.edu.in
RI Singh, Gurwinder/E-1406-2018; Singh, Gurjinder/AFO-0692-2022
OI Singh, Gurwinder/0000-0001-6611-3567; Singh,
   Gurjinder/0000-0002-0108-3042
CR Achuthan K, 2018, EDUC INF TECHNOL, V23, P2499, DOI 10.1007/s10639-018-9727-1
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Atit K, 2020, INT J STEM EDUC, V7, DOI 10.1186/s40594-020-00234-3
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Ibáñez MB, 2020, COMPUT EDUC, V145, DOI 10.1016/j.compedu.2019.103734
   Brooks AL, 2019, Interactivity, game creation, design, learning, and innovation, V265, DOI [10.1007/978-3-030-06134-0, DOI 10.1007/978-3-030-06134-0]
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Chin KY, 2020, IEEE T LEARN TECHNOL, V13, P52, DOI 10.1109/TLT.2019.2926267
   Conley Q, 2020, COMPUT EDUC, V153, DOI 10.1016/j.compedu.2020.103895
   Demitriadou E, 2020, EDUC INF TECHNOL, V25, P381, DOI 10.1007/s10639-019-09973-5
   Dutta R, 2022, SMART LEARN ENVIRON, V9, DOI 10.1186/s40561-022-00189-8
   Faridi H, 2021, COMPUT APPL ENG EDUC, V29, P258, DOI 10.1002/cae.22342
   Gargrish Shubham, 2020, Indo - Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN 2020). Proceedings, P164, DOI 10.1109/Indo-TaiwanICAN48429.2020.9181362
   Gecu-Parmaksiz Z, 2019, BRIT J EDUC TECHNOL, V50, P3376, DOI 10.1111/bjet.12740
   Gold ZS, 2021, EARLY EDUC DEV, V32, P49, DOI 10.1080/10409289.2019.1709382
   Campos JSG, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0169-7
   de Ravé EG, 2016, MULTIMED TOOLS APPL, V75, P9641, DOI 10.1007/s11042-016-3384-4
   Hanid MFA, 2022, EDUC INF TECHNOL, V27, P9485, DOI 10.1007/s10639-022-10994-w
   Hawes Z, 2020, PSYCHON B REV, V27, P465, DOI 10.3758/s13423-019-01694-7
   Huang KT, 2019, CYBERPSYCH BEH SOC N, V22, P105, DOI 10.1089/cyber.2018.0150
   Hwang GJ, 2020, INT J MOB LEARN ORG, V14, P161, DOI 10.1504/IJMLO.2020.106166
   Ibáñez MB, 2018, COMPUT EDUC, V123, P109, DOI 10.1016/j.compedu.2018.05.002
   Jesionkowska J, 2020, EDUC SCI, V10, DOI 10.3390/educsci10080198
   Johnson L, 2013, Reshaping Learning, DOI [10.1007/978-3-642-32301-0, DOI 10.1007/978-3-642-32301-0]
   Jones K.E., 2009, Island Bats: Evolution, Ecology, and Conservation, P1, DOI [10.1109/FIE.2009.5350598, DOI 10.1109/FIE.2009.5350598, 10.1109/fie.2009.5350598]
   Kaur DP, 2021, IETE J RES, V67, P155, DOI 10.1080/03772063.2018.1532822
   Kumar A, 2022, EDUC INF TECHNOL, V27, P6015, DOI 10.1007/s10639-021-10858-9
   Lin HCK, 2015, INTERACT LEARN ENVIR, V23, P799, DOI 10.1080/10494820.2013.817435
   Lozada-Yanez R., 2019, International Education Studies, V12, P54, DOI DOI 10.5539/IES.V12N9P54
   Maeda Y., 2011 ASEE Annual Conference Exposition Proceedings, Vancouver, BC, 2011, p22.1273.1, DOI DOI 10.18260/1-2--18522
   Marino MT, 2018, The Wiley International Handbook of Educational Foundations, P245, DOI [10.1002/9781118931837.ch15, DOI 10.1002/9781118931837.CH15]
   Martín-Gutiérrez J, 2015, PROCEDIA COMPUT SCI, V77, P33, DOI 10.1016/j.procs.2015.12.356
   Herrera LM, 2019, INT J INTERACT DES M, V13, P1385, DOI 10.1007/s12008-019-00595-2
   Muñoz-Cristóbal JA, 2015, IEEE T LEARN TECHNOL, V8, P83, DOI 10.1109/TLT.2014.2370634
   Papanastasiou G, 2019, VIRTUAL REAL-LONDON, V23, P425, DOI 10.1007/s10055-018-0363-2
   Pochtoviuk SI, 2019, CEUR WORKSHOP PROCEE, V2547, P92
   Rebollo C, 2022, MULTIMED TOOLS APPL, V81, P14851, DOI 10.1007/s11042-021-10821-3
   Reyes-Aviles F, 2018, COMPUT APPL ENG EDUC, V26, P602, DOI 10.1002/cae.21912
   Rittle-Johnson B, 2018, EARLY CHILD RES Q, V46, P166, DOI 10.1016/j.ecresq.2018.03.006
   Rojas-Sola JI, 2018, COMPUT APPL ENG EDUC, V26, P1725, DOI 10.1002/cae.22039
   Rossano V, 2020, IEEE ACCESS, V8, P107772, DOI 10.1109/ACCESS.2020.3000990
   Siang CV, 2017, 2017 IEEE CONFERENCE ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IC3E), P73, DOI 10.1109/IC3e.2017.8409241
   Singh G, 2021, COMPUT APPL ENG EDUC, V29, P229, DOI 10.1002/cae.22333
   Singh G, 2019, COMPUT APPL ENG EDUC, V27, P1361, DOI 10.1002/cae.22156
   Sorby S, 2018, LEARN INDIVID DIFFER, V67, P209, DOI 10.1016/j.lindif.2018.09.001
   Thornton T., 2012, Technology and Engineering Teacher, V8, P18
   Tumkor S, 2018, COMPUT APPL ENG EDUC, V26, P1734, DOI 10.1002/cae.21942
   Verdine BN, 2017, MONOGR SOC RES CHILD, V82, P7, DOI [10.1111/mono.12285, 10.1111/mono.12280]
   Wijaya TT, 2020, INT J EMERG TECHNOL, V15, P215, DOI 10.3991/ijet.v15i10.13099
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
NR 50
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17870-w
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500005
DA 2024-07-18
ER

PT J
AU Zhang, XC
   Di, JL
   Niu, Y
AF Zhang, Xuncai
   Di, Jiali
   Niu, Ying
TI Image encryption scheme based on double permutation and DNA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Block; Space-filling curves; Hamming distance; DNA
   coding
ID SPACE-FILLING CURVE
AB This paper mainly contributes a bit-level and pixel-level double-permutation image encryption scheme based on DNA coding technology, which can effectively solve the problem that adjacent pixels in an image are difficult to be completely disordered. Firstly, the Hamming distance between image pixel and a value at the same position in a chaotic sequence is calculated and the result is used to be the cyclic shift distance of the pixel to achieve bit-level permutation; secondly, the modified Z curve is used for the first global permutation process, and the image is further permutated by the method of block restructuring to compensate for the shortage of modified Z curve permutation; thirdly, pixel pairs are selected and the pixel pairs are used as information and control positions respectively to DNA encode the image by dynamically selecting the DNA encoding rules, and then diffusing the encoded image following the rules of DNA base manipulation; finally, the diffused image is decoded to complete the image encryption process. We perform simulation experiments on the image encryption algorithm and analyze its security performance, and we could get the conclusion that the encryption algorithm can encrypt images quickly and effectively, the obtained cipher images are highly resistant to noise attacks, cropping attacks, and different attacks, meanwhile, the cipher images have a lower correlation between pixels.
C1 [Zhang, Xuncai; Di, Jiali] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
   [Niu, Ying] Zhengzhou Univ Light Ind, Sch Architecture Environm Engn, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry; Zhengzhou University of Light
   Industry
RP Niu, Y (corresponding author), Zhengzhou Univ Light Ind, Sch Architecture Environm Engn, Zhengzhou 450002, Peoples R China.
EM niuying@zzuli.edu.cn
OI Niu, Ying/0000-0001-6851-8605
FU National Natural Science Foundation of China [62072417, 62102374];
   National Natural Science Foundation of China [202102210177,
   212102210028]; Henan provincial science and technology research project
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62072417 and 62102374, and in part by
   the Henan provincial science and technology research project under
   Grants 202102210177 and 212102210028.
CR Aydos M, 2014, PAMUKKALE U J ENG SC, V20, P31, DOI 10.5505/pajes.2014.18209
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chen WM, 2011, IET IMAGE PROCESS, V5, P349, DOI 10.1049/iet-ipr.2009.0362
   Demirtas M, 2022, OPTIK, V265, DOI 10.1016/j.ijleo.2022.169430
   El-Deen A., 2014, J ELECT COMMUN ENG, V9, P69, DOI https://doi.org/10.9790/2834-09146973
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Ketan S., 2014, Int J Sci Res, V3, P2319
   Kulkarni NS, 2008, 32 NAT SYST C, P467
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Manali T., 2014, Int J Comput Sci Eng Inform Technol Res (IJCSEITR), V4, P245
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Munir R, 2012, P 3 MAK INT C EL ENG, P1
   Murali P, 2019, MULTIMED TOOLS APPL, V78, P2135, DOI 10.1007/s11042-018-6234-8
   Niu Y, 2020, IEEE ACCESS, V8, P196326, DOI 10.1109/ACCESS.2020.3034666
   Sambas A, 2022, IEEE ACCESS, V10, P68057, DOI 10.1109/ACCESS.2022.3181424
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sun YY, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0084655, 10.1371/journal.pone.0086232]
   Suresh V, 2012, DEFENCE SCI J, V62, P46, DOI 10.14429/dsj.62.1441
   Ting KC., 2022, Lect Notes Electr Eng, V770, P551, DOI [10.1007/978-981-16-2406-3_42, DOI 10.1007/978-981-16-2406-3_42]
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XZ, 2021, IEEE T IND INFORM, V17, P5419, DOI 10.1109/TII.2020.3022369
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P2479, DOI 10.1016/j.cnsns.2009.10.001
   Wang XY, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111629
   Wang XY, 2020, IEEE ACCESS, V8, P160897, DOI 10.1109/ACCESS.2020.3020835
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yang RE, 2014, INT CONF MEAS, P323, DOI 10.1109/ICMTMA.2014.80
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhao Y, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091127
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zou CY, 2022, APPL MATH COMPUT, V430, DOI 10.1016/j.amc.2022.127291
NR 38
TC 0
Z9 0
U1 23
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 18
PY 2023
DI 10.1007/s11042-023-17392-5
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CO5S9
UT WOS:001126208400001
DA 2024-07-18
ER

PT J
AU Singh, D
   Kumar, S
AF Singh, Deep
   Kumar, Sandeep
TI A multiphase encryption scheme using RSA, modified RMAC and Chen's
   hyperchaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image security; Encryption algorithm; RSA; Modified RMAC; Chen's
   hyperchaotic system
ID COLOR IMAGE ENCRYPTION; PERMUTATION
AB In the present time of increasing digital communication, the images are widely used over the multimedia networks for sharing of information. At the same time to ensure the security of images during transmission of data becomes a great challenge for cryptographers. In this paper, a new multi-phases image encryption algorithm based on the RSA cryptosystem and modified random matrix affine cipher (MRMAC) is proposed. The Chen's hyperchaotic system and Arnold cat map are used to create more distraction from the relationship between the original image and ciphered image. The Chen's hyperchaotic system is used for diffusion, whereas the Arnold cat map is used for increasing the confusion among pixels. In this proposed algorithm the image ciphering is carried out in different phases. Firstly the given image is encrypted using RSA algorithm with large primes. Secondly, in modified RMAC, random blocks of random entries using Chen's hyperchaotic system are generated and are diffused with image pixels using bitwise XOR operation. Also, we create confusion of pixels within these diffused blocks, and confusion of blocks as well using parameters of MRMAC. The randomness in the algorithm is improved using MRMAC is advantage against differential attacks. Further, the Arnold cat map is used to enhance the level of confusion. Since, it is tremendously difficult to factorize the product of large prime numbers, therefore, the security of data in RSA algorithm increases tremendously. For the proper decryption of ciphered images, one must have exact values of keys and their correct order. It is impossible to guess the decrypted image even with a very small change in a single key. The results obtained in statistical and security analysis shows that the proposed algorithm has a huge key space, extreme security and key sensitivity, which proves that scheme is efficient and highly secure.
C1 [Singh, Deep; Kumar, Sandeep] Cent Univ Punjab, Dept Math & Stat, Bathinda 151401, India.
   [Singh, Deep] Cent Univ Jammu, Dept Math, Jammu 181143, India.
C3 Central University of Punjab; Central University of Jammu
RP Kumar, S (corresponding author), Cent Univ Punjab, Dept Math & Stat, Bathinda 151401, India.
EM deepsinghspn@gmail.com; sandeepkumarsvr@gmail.com
FU Central University of Punjab, Bathinda [2022/1194]; DST, India
   [SR/FST/MS-1/2021/104(C)]; UGC, New Delhi
FX The first author is thankful to Central University of Punjab, Bathinda
   for providing financial support through RSM grant no.:
   CUPB/Acad./2022/1194, and to DST, India for support through grant no.:
   SR/FST/MS-1/2021/104(C) under DST-FIST project. The second author is
   thankful for the financial assistance from the UGC, New Delhi, in the
   form of a Junior Research Fellowship (JRF). The authors would like to
   thank the anonymous reviewer for their extensive comments and valuable
   suggestions which greatly improved the quality and the presentation of
   the paper.
CR Abbas NA, 2016, EGYPT INFORM J, V17, P139, DOI 10.1016/j.eij.2015.10.001
   Alexan W, 2023, IEEE ACCESS, V11, P11541, DOI 10.1109/ACCESS.2023.3242311
   Alexan W, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14030443
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Chen ZZ, 2022, OPTIK, V267, DOI 10.1016/j.ijleo.2022.169676
   Darari R., 2020, Contemp Math and Applications (ConMathA), V2, P109, DOI [10.20473/conmatha.v2i2.23855, DOI 10.20473/CONMATHA.V2I2.23855]
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   El-Deen A., 2014, J ELECT COMMUN ENG, V9, P69, DOI https://doi.org/10.9790/2834-09146973
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Fu C, 2017, 2017 18TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNDP 2017), P121, DOI 10.1109/SNPD.2017.8022710
   Geetha S, 2018, INT J INF SECUR PRIV, V12, P42, DOI 10.4018/IJISP.2018070104
   Ghorbani A, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168961
   Gong LH, 2016, INT J THEOR PHYS, V55, P3234, DOI 10.1007/s10773-016-2954-6
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hellman M. E., 1978, IEEE Communications Society Magazine, V16, P24, DOI 10.1109/MCOM.1978.1089772
   Huang X, 2018, Entropy, V20
   Jiao KX, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/9721675
   Jin X, 2022, IEEE T COGN DEV SYST, V14, P1678, DOI 10.1109/TCDS.2021.3135948
   Jin X, 2022, IEEE T CIRC SYST VID, V32, P7632, DOI 10.1109/TCSVT.2022.3180274
   Jin X, 2022, NEUROCOMPUTING, V491, P414, DOI 10.1016/j.neucom.2022.04.015
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P40993, DOI 10.1007/s11042-022-13001-z
   Jin X, 2022, MULTIMED TOOLS APPL, V81, P35733, DOI 10.1007/s11042-021-11126-1
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Koul N, 2022, IEEE ACCESS, V10, P102087, DOI 10.1109/ACCESS.2022.3209376
   Kumar S.N., 2015, International Transaction of Electrical and Computer Engineers System, V3, P1
   Lin RG, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5586959
   Lone PN, 2021, J MOD OPTIC, V68, P507, DOI 10.1080/09500340.2021.1924885
   Mir UH, 2022, INF SECUR J, V31, P49, DOI 10.1080/19393555.2021.1963018
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Petitcolas F.A., 2011, Encyclopedia of cryptography and security, P675
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Sharma Madhu, 2022, Soft Computing: Theories and Applications: Proceedings of SoCTA 2021. Lecture Notes in Networks and Systems (425), P835, DOI 10.1007/978-981-19-0707-4_75
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Xu QY, 2020, PHYS SCRIPTA, V95, DOI 10.1088/1402-4896/ab52bc
   Yakubu H., 2018, International Journal of Communication and Computer Technologies, V6, P1
   Ye GD, 2021, NONLINEAR DYNAM, V104, P2807, DOI 10.1007/s11071-021-06422-2
   Ye GD, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420502338
   Zhang J, 2016, Mathematical problems in engineering, V2016
   Zhao G, 2010, 2010 2 INT C SIGNAL, V2, pV2
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu HG, 2014, OPTIK, V125, P6672, DOI 10.1016/j.ijleo.2014.06.149
NR 45
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17727-2
EA DEC 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800007
DA 2024-07-18
ER

PT J
AU Lone, MR
   Sandhu, AK
AF Lone, Mohd Rafi
   Sandhu, Amanpreet Kaur
TI Enhancing image quality: A nearest neighbor median filter approach for
   impulse noise reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Median filter; Salt-and-pepper; Denoising; Impulse noise; Noise
   reduction
ID PEPPER NOISE; MEAN FILTER; SALT; REMOVAL; DENSITY
AB Impulse noise is a challenging problem that degrades the quality of an image. In last few decades, Median filtering denoising method has been widely used for impulse noise. Several well-known and efficient algorithms and techniques exist to effectively remove either Gaussian noise or Impulse noise, independently However, in order to remove high noise densities, there has been a shift in the process of filtering methods. New methods adopted are usually computationally expensive. In this paper, Nearest Neighbour median Filter method has been proposed for impulse noise reduction. The proposed method exploited correlation between the pixels of an image. The main objective of proposed approach is detection and reduction of impulse noise in corrupted images without any loss of information. The performance of proposed denoising technique is compared with existing methods on the basis of Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Virtual Information Fidelity (VIF) and computational complexity. From the experimental analysis, it is evident that the proposed denoising method removes impulse noise very effectively, especially at higher noise density levels (more than 70%). Moreover, computational complexity of proposed approach is lesser as compared to state-of-the art methods.Graphical abstractGraphical abstract of Nearest Neighbour median Filter
C1 [Lone, Mohd Rafi] VIT Bhopal Univ, Bhopal Indore Highway, Kothrikalan Sehore 466114, Madhya Pradesh, India.
   [Sandhu, Amanpreet Kaur] Chandigarh Univ, Univ Inst Comp, Punjab, India.
C3 VIT Bhopal University; Chandigarh University
RP Sandhu, AK (corresponding author), Chandigarh Univ, Univ Inst Comp, Punjab, India.
EM aman123.brar@gmail.com
CR Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   Golilarz NA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00728
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Enginoglu S, 2019, MULTIMED TOOLS APPL, V78, P35401, DOI 10.1007/s11042-019-08110-1
   Erkan U, 2019, IEEE ACCESS, V7, P167847, DOI 10.1109/ACCESS.2019.2953924
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Hsieh MH, 2013, ENG APPL ARTIF INTEL, V26, P1333, DOI 10.1016/j.engappai.2012.10.012
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   Hussain A, 2009, LECT NOTES COMPUT SC, V5496, P277, DOI 10.1007/978-3-642-01811-4_25
   Jain P, 2015, INFORM SCIENCES, V294, P164, DOI 10.1016/j.ins.2014.09.060
   Jaiswal A, 2014, AEU-INT J ELECTRON C, V68, P699, DOI 10.1016/j.aeue.2014.02.003
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Khan KB, 2018, IIUM ENG J, V19, P68, DOI 10.31436/iiumej.v19i2.835
   Kim DG, 2021, IEEE ACCESS, V9, P6438, DOI 10.1109/ACCESS.2020.3048181
   Kumar N., 2020, Int. J. Adv. Sci. Technol, V29, P1495
   Lee C.-S., 2000, Fuzzy Techniques in Image Processing, P172
   Lee CS, 2005, IEEE T SYST MAN CY B, V35, P694, DOI 10.1109/TSMCB.2005.845397
   Leng KQ, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P149, DOI 10.1109/SIPROCESS.2017.8124523
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAL, P710
   Lone MR, 2022, J KING SAUD UNIV-COM, V34, P9942, DOI 10.1016/j.jksuci.2021.12.020
   Lu JY, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3195492
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Petrou M., 2010, Image Processing: The Fundamentals, V2nd, DOI [10.1002/9781119994398, DOI 10.1002/9781119994398]
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Selvi AS, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4501
   Seshadrinathan K, 2008, IEEE IMAGE PROC, P1200, DOI 10.1109/ICIP.2008.4711976
   Singh A, 2020, IEEE ACCESS, V8, P112985, DOI 10.1109/ACCESS.2020.3003874
   Singh D, 2021, MATER TODAY-PROC, V46, P6445, DOI 10.1016/j.matpr.2021.03.494
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Thanh Dang N. H., 2020, Procedia Computer Science, V171, P292, DOI 10.1016/j.procs.2020.04.031
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang JH, 2002, IEEE T SYST MAN CY B, V32, P230, DOI 10.1109/3477.990880
   Wang Y, 2016, IEEE SIGNAL PROC LET, V23, P1582, DOI 10.1109/LSP.2016.2607785
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 14
PY 2023
DI 10.1007/s11042-023-17693-9
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ4D9
UT WOS:001122246300002
DA 2024-07-18
ER

PT J
AU Marín-Lora, C
   Chover, M
   Martín, MY
   García-Rytman, L
AF Marin-Lora, Carlos
   Chover, Miguel
   Martin, Micaela Yanet
   Garcia-Rytman, Linda
TI Creating a treadmill running video game with smartwatch interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Treadmill; Running; Exergame; Smartwatch; Interaction; Mobile; Cadence;
   Gestures
ID PHYSICAL-ACTIVITY; VIRTUAL-REALITY; ENVIRONMENTS; EXERCISE; CHILDREN
AB In recent years, indoor or at-home sports have experienced significant growth. However, monotony is a common challenge in these static physical activities. Exergames, a genre of video games that combines physical activity and entertainment, have emerged as an attractive solution. Nevertheless, running on a treadmill and engaging in other activities simultaneously presents additional challenges. The balance and concentration required during running while interacting with a video game demand a special focus on the design of the Exergame. This paper presents a mobile Exergame designed specifically for treadmill running, utilizing interaction with a smartwatch. The game offers natural environments where, through smartwatch technology, it interprets the player's movements, transforming them into running speed and interactive actions by detecting gestures within the game. The main objective is to provide users with a satisfying gaming experience tailored to the characteristics of treadmill running. Particular emphasis has been placed on prioritizing the playful component of this Exergame, recognizing its relevance in the context of treadmill running. To evaluate the achievement of objectives and the proposed hypothesis, a comparative study was conducted between the proposed Exergame and a treadmill running simulator. Participants experienced both experiences and subsequently completed the Game Experience Questionnaire (GEQ), specifically the In-game GEQ version. The results obtained indicate that participants had a better gaming experience in the Exergame than in the simulator. These findings highlight the importance of prioritizing the playful component in Exergames and provide guidelines for future improvements and developments in the field.
C1 [Marin-Lora, Carlos; Chover, Miguel; Martin, Micaela Yanet; Garcia-Rytman, Linda] Univ Jaume 1, Inst New Imaging Technol, Ave Vicent Sos Baynat S-N, Castellon de La Plana 12071, Spain.
   [Marin-Lora, Carlos; Martin, Micaela Yanet] Valgrai Valencian Grad Sch & Res Network Artificia, Cami Vera S-N, Valencia 46022, Spain.
C3 Universitat Jaume I
RP Marín-Lora, C (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Ave Vicent Sos Baynat S-N, Castellon de La Plana 12071, Spain.; Marín-Lora, C (corresponding author), Valgrai Valencian Grad Sch & Res Network Artificia, Cami Vera S-N, Valencia 46022, Spain.
EM cmarin@uji.es
FU Ministerio de Ciencia e Innovacin
FX No Statement Available
CR Ahn M., 2009, Proceedings of the Conference on Advance in Computer Entertainment Technology, P345, DOI DOI 10.1145/1690388.1690455
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Aliprantis J., 2019, Int. J. Comput. Methods Herit. Sci, V3, P118, DOI DOI 10.4018/IJCMHS.2019070107
   Alturki R, 2019, EAI SPRINGER INNOVAT, P67, DOI 10.1007/978-3-319-96139-2_7
   [Anonymous], 2015, Narrative as virtual reality 2: revisiting immersion and interactivity in literature and electronic media, DOI DOI 10.1353/BOOK.72246
   Araújo D, 2019, PSYCHOL SPORT EXERC, V42, P138, DOI 10.1016/j.psychsport.2018.12.020
   Bailey Joshua, 2017, Int J Exerc Sci, V10, P1067
   Berglund Erik, 2023, HCI in Games: 5th International Conference, HCI-Games 2023, Held as Part of the 25th HCI International Conference, HCII 2023, Proceedings. Lecture Notes in Computer Science (14046), P237, DOI 10.1007/978-3-031-35930-9_16
   Bernabeu JP, 2016, Desarrollo de un videojuego en Unity controlado mediante un smartwatch
   Bicycling, 2022, The bike shortage isn't going away just yet
   Casiez G., 2012, P SIGCHI C HUMAN FAC, P2527, DOI DOI 10.1145/2207676.2208639
   Cavagna GA, 1997, PFLUG ARCH EUR J PHY, V434, P678, DOI 10.1007/s004240050451
   Martí ACI, 2015, NUTR HOSP, V31, P841, DOI 10.3305/nh.2015.31.2.7929
   Cherni H., 2021, Int. J. Virtual Real, V21, P1, DOI [10.20870/IJVR.2021.21.1.3046, DOI 10.20870/IJVR.2021.21.1.3046]
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Costa Marcos Tulio Silva, 2019, Clin Pract Epidemiol Ment Health, V15, P15, DOI 10.2174/1745017901915010015
   Ding H, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P141, DOI 10.1145/2809695.2809708
   Ericsson, 2022, Number of smartphone subscriptions worldwide from 2016 to 2027
   Gao Yue., 2012, P SIGCHI C HUMAN FAC, P1863, DOI [10.1145/2207676.2208323, DOI 10.1145/2207676.2208323]
   Han H, 2020, J SPORT SCI, V38, P383, DOI 10.1080/02640414.2019.1702281
   Hinckley K., 2014, IEEE Comput Graphics Appl, V34, P38
   HOGBERG P, 1952, Arbeitsphysiologie, V14, P437
   Huang HC, 2019, GAMES HEALTH J, V8, P220, DOI 10.1089/g4h.2018.0057
   Nguyen HV, 2018, GAMES HEALTH J, V7, P246, DOI 10.1089/g4h.2017.0165
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Janssen M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181167
   Javidi B, 2020, ADV OPT PHOTONICS, V12, P1237, DOI 10.1364/AOP.390929
   Boulos MKN, 2021, INT J HEALTH GEOGR, V20, DOI 10.1186/s12942-021-00266-0
   Kappen DL, 2019, INT J HUM-COMPUT INT, V35, P140, DOI 10.1080/10447318.2018.1441253
   Khundam C., 2021, IEEE Trans Neural Syst Rehabil Eng, V29, P1133
   Kim D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193086
   Lamontagne A, 2019, 2019 INT C VIRT REH, P1
   Lee M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072095
   Liang Y, 2014, GAMES HEALTH J, V3, P122, DOI 10.1089/g4h.2013.0070
   Lohman J, 2022, IEEE T HUM-MACH SYST, V52, P613, DOI 10.1109/THMS.2022.3175407
   Marin-Lora C, 2022, P INT C UB COMP AMB, P949
   Marín-Lora C, 2022, MULTIMED TOOLS APPL, V81, P43373, DOI 10.1007/s11042-022-13168-5
   Marín-Lora C, 2020, ADV ENG SOFTW, V140, DOI 10.1016/j.advengsoft.2019.102732
   Marshall J, 2021, IEEE T GAMES, V13, P160, DOI 10.1109/TG.2020.2995370
   Martin M, 2022, P INT C UB COMP AMB, P145
   Martin MY, 2022, CEUR WORKSHOP PROC
   Matallaoui A, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P3316
   McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243
   Meulenberg CJW, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.840863
   Mungoli N, 2020, Doctoral dissertation
   Nascimento TH, 2020, P INT COMP SOFTW APP, P1661, DOI 10.1109/COMPSAC48688.2020.00-17
   Nascimento TH, 2018, P INT COMP SOFTW APP, P253, DOI 10.1109/COMPSAC.2018.10239
   Neumann DL, 2018, SPORTS, V6, DOI 10.3390/sports6030071
   Nurkkala V.-M., 2014, J. Commun. Comput, V11, P403
   Oh Y., 2010, Proceedings of Meaningful Play 2010, P1
   Pallavicini F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P195, DOI 10.1145/3341215.3355736
   Pyo S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094223
   Qin Y, 2021, TELEMAT INFORM, V62, DOI 10.1016/j.tele.2021.101620
   Rauschnabel PA, 2022, COMPUT HUM BEHAV, V133, DOI 10.1016/j.chb.2022.107289
   Remolar I, 2015, MULTIMED TOOLS APPL, V74, P4561, DOI 10.1007/s11042-013-1822-0
   Ring P, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P627, DOI 10.1109/VRW58643.2023.00156
   Strava, 2021, Strava's Year In Sport 2021 charts trajectory of ongoing sports boom
   Swinnen N, 2022, DISABIL REHABIL-ASSI, V17, P376, DOI 10.1080/17483107.2020.1785566
   Unity 3D, 2023, Unity as a library
   van Oeveren BT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184273
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Walsh K.R., 2002, Communications of the Associations of the Information Systems, V8 issue1, p, P20, DOI DOI 10.17705/1CAIS.00820
   Wehden LO, 2021, MEDIA COMMUN-LISBON, V9, P5, DOI 10.17645/mac.v9i1.3170
   Westmattelmann D, 2021, ECIS
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 65
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17752-1
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200004
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, QR
   Li, DS
   Gao, Y
   Chen, AL
AF Wang, Qianrui
   Li, Dengshi
   Gao, Yu
   Chen, Aolei
TI SVMFI: speaker video multi-frame interpolation with the guidance of
   audio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Audio; Speaker video; Video frame interpolation
AB Due to network constraints like latency and bandwidth, speaker videos often suffer from low frame rates and frequent frame drops. Video frame interpolation is used to increase the frame rate and recover the dropped frames. However, the frequent occlusions and large motions in speaker videos make the motion estimation of existing methods inaccurate, leading to unsatisfactory performance. To address this issue, this paper proposes an audio-guided video frame interpolation network for speaker video to interpolate multi-frames. Specifically, we first extract audio features and multi-scale spatial features through Audio Encoder and Video Encoder, respectively. Then, a Decoder is utilized to estimate optical flows and intermediate frame features. Subsequently, the multi-scale spatial features are used to predict optical flows through the guidance of audio through Adaptive Instance Normalization in Audio-Guided Flow Prediction Module(AGFPM). Finally, these different optical flows are utilized to warp the input frames, the warped frames and the predicted frame features are fed into Synthesis Network(SynNet), which synthesize final intermediate frames. Furthermore, to enhance synchronization of audio and video, we employ audio-video loss(avloss) to further improve the quality of generated intermediate frames. Extensive experiments have been conducted on the Voxceleb2 and HDTF datasets. The experimental results demonstrate the effectiveness of our method through quantitative and qualitative evaluations.
C1 [Wang, Qianrui; Li, Dengshi; Gao, Yu; Chen, Aolei] Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
C3 Jianghan University
RP Li, DS (corresponding author), Jianghan Univ, Sch Artificial Intelligence, Wuhan 430056, Peoples R China.
EM Piscesrr@stu.jhun.edu.cn; reallds@jhun.edu.cn; gaoyu122@stu.jhun.edu.cn;
   charluelexia@stu.jhun.edu.cn
FU Natural Science Foundation of China
FX No Statement Available
CR Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Cheng H, 2021, IEEE Trans Multimed
   Cheng XH, 2022, IEEE T PATTERN ANAL, V44, P7029, DOI 10.1109/TPAMI.2021.3100714
   Cheng XH, 2020, AAAI CONF ARTIF INTE, V34, P10607
   Choi M, 2020, AAAI CONF ARTIF INTE, V34, P10663
   Chung Joon Son, 2018, arXiv
   Duarte A, 2019, INT CONF ACOUST SPEE, P8633, DOI 10.1109/icassp.2019.8682970
   Dutta S, 2022, IEEE COMPUT SOC CONF, P1725, DOI 10.1109/CVPRW56347.2022.00180
   Figueirêdo P, 2023, IEEE WINT CONF APPL, P218, DOI 10.1109/WACV56688.2023.00030
   Fu Z, 2021, arXiv
   Hu MS, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2145, DOI 10.1145/3503161.3547875
   Hu MS, 2022, IEEE T CIRC SYST VID, V32, P3390, DOI 10.1109/TCSVT.2021.3110796
   Hu MS, 2020, INT CONF ACOUST SPEE, P4347, DOI [10.1109/ICASSP40776.2020.9053223, 10.1109/icassp40776.2020.9053223]
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang Z., 2020, arXiv
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Jiashuo Yu, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P6241, DOI 10.1145/3503161.3547869
   Junheum Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P109, DOI 10.1007/978-3-030-58568-6_7
   Kalluri T, 2023, IEEE WINT CONF APPL, P2070, DOI 10.1109/WACV56688.2023.00211
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kong LT, 2022, PROC CVPR IEEE, P1968, DOI 10.1109/CVPR52688.2022.00201
   Lee H, 2020, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR42600.2020.00536
   Li DS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042053
   Liang Liao, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P837, DOI 10.1145/3503161.3547849
   Liang Liao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P683, DOI 10.1007/978-3-030-58583-9_41
   Liao L, 2021, PROC CVPR IEEE, P6535, DOI 10.1109/CVPR46437.2021.00647
   Liao L, 2019, IEEE ACCESS, V7, P36921, DOI 10.1109/ACCESS.2019.2905268
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu L., 2022, P IEEECVF C COMPUTER, P3532
   Meister S, 2018, AAAI CONF ARTIF INTE, P7251
   Niklaus S, 2021, IEEE WINT CONF APPL, P1098, DOI 10.1109/WACV48630.2021.00114
   Niklaus S, 2020, PROC CVPR IEEE, P5436, DOI 10.1109/CVPR42600.2020.00548
   Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Oh TH, 2019, PROC CVPR IEEE, P7531, DOI 10.1109/CVPR.2019.00772
   Park J., 2021, P IEEECVF INT C COMP, P14539
   Shi ZH, 2022, PROC CVPR IEEE, P17461, DOI 10.1109/CVPR52688.2022.01696
   Shi ZH, 2022, IEEE T MULTIMEDIA, V24, P426, DOI 10.1109/TMM.2021.3052419
   Sim Hyeonjun, 2021, P IEEECVF INT C COMP, P14489
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen YD, 2019, ADV NEUR IN, V32
   Wu HN, 2023, IEEE T CIRC SYST VID, V33, P4840, DOI 10.1109/TCSVT.2023.3249741
   Wu HN, 2022, LECT NOTES COMPUT SC, V13666, P538, DOI 10.1007/978-3-031-20068-7_31
   Xia Y, 2022, PROC CVPR IEEE, P19957, DOI 10.1109/CVPR52688.2022.01936
   Xu HM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3893, DOI 10.1145/3394171.3413581
   Xu XY, 2019, ADV NEUR IN, V32
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Yin F, 2022, LECT NOTES COMPUT SC, V13677, P85, DOI 10.1007/978-3-031-19790-1_6
   Zhang ZM, 2023, Arxiv, DOI arXiv:2303.03988
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
NR 56
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17728-1
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200008
DA 2024-07-18
ER

PT J
AU Zafar, S
   Idrees, B
   Rashid, T
AF Zafar, Sohail
   Idrees, Bazgha
   Rashid, Tabasam
TI An algorithm for construction of substitution box based on subfield of
   galois field GF(2<SUP>16</SUP>) and dynamic linear fractional
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE S-Box; Galois field; Image encryption; Linear fractional transformation
ID STATISTICS; MOTION
AB In block encryption algorithms the only nonlinear component, which creates confusion and diffusion, is substitution box (S-Box). Therefore, carefully selection of S-Box is an important task. In this article, an algorithm is presented for the construction of 8x8 S-Box based on all subfields of Galois Field GF(2(16)) and linear fractional transformation. Pro-posed algorithm is easy and simple but significantly complex for the attackers as it utilizes all subfields of GF(216) corresponding to all primitive irreducible polynomials for making GF(2(16)) . An illustrating S-Box is also developed which is showing good structural charac-teristics such as it has no fixed point with 108.5 nonlinearity and 0.5020 strict avalanche. In the last, illustrated S-Box is applied on images for checking the performance under various criteria available in the literature. Obtained results of analyses are compared to well-known S-Boxes and found better in the comparison.
C1 [Zafar, Sohail; Idrees, Bazgha; Rashid, Tabasam] Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
C3 University of Management & Technology (UMT)
RP Zafar, S (corresponding author), Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
EM sohailahmad04@gmail.com; ms.bazgha@gmail.com; tabasam.rashid@umt.edu.pk
RI Rashid, Tabasam/C-4855-2015
OI Rashid, Tabasam/0000-0002-8691-1088
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Barsoum E, 2018, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2018.00191
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gong HF, 2011, IEEE I CONF COMP VIS, P619, DOI 10.1109/ICCV.2011.6126296
   Gui LY, 2018, LECT NOTES COMPUT SC, V11208, P823, DOI 10.1007/978-3-030-01225-0_48
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Gupta S, 2023, Multimedia Tools Appl, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ingram JN, 2008, EXP BRAIN RES, V188, P223, DOI 10.1007/s00221-008-1355-3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Koppula Hema, 2013, P ICML, P792
   Koppula HS, 2013, IEEE INT C INT ROBOT, P2071, DOI 10.1109/IROS.2013.6696634
   Kundu JN, 2019, AAAI CONF ARTIF INTE, P8553
   Lebailly T., 2021, Lecture Notes in Computer Science, V12623, P651, DOI [DOI 10.1007/978-3-030-69532-3_39, 10.1007/978-3-030-69532-3_39]
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Liu ZG, 2019, PROC CVPR IEEE, P9996, DOI 10.1109/CVPR.2019.01024
   Mao W, 2019, IEEE I CONF COMP VIS, P9488, DOI 10.1109/ICCV.2019.00958
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Pavlovic V, 2001, ADV NEUR IN, V13, P981
   Ruiz AH, 2019, IEEE I CONF COMP VIS, P7133, DOI 10.1109/ICCV.2019.00723
   Schaal S, 2002, APPL INTELL, V17, P49, DOI 10.1023/A:1015727715131
   Sidenbladh H, 2002, LECT NOTES COMPUT SC, V2350, P784
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Urtasun R., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P238, DOI DOI 10.1109/CVPR.2006.15
   Wang BR, 2019, IEEE I CONF COMP VIS, P7123, DOI 10.1109/ICCV.2019.00722
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Yadav GK, 2023, APPL INTELL, V53, P18027, DOI 10.1007/s10489-022-04419-x
   Yadav GK, 2020, 2020 IEEE 4 C INFORM, P1
NR 34
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17763-y
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800006
DA 2024-07-18
ER

PT J
AU Singh, N
   Tripathi, P
AF Singh, Nutan
   Tripathi, Priyanka
TI An efficient model for detecting real-time facemask based on different
   Classification Algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; Transfer learning; K-NN; SGD; SVM; CNN;
   MobileNetV2; VGG-19; InceptionV3
ID MASK DETECTION
AB Nowadays, there is such an outbreak of corona in the whole world that people are taking many precautions to avoid it, but according to the Guidelines of WHO, wearing a mask and maintaining distance is the best way to escape from this epidemic. It has been said that those who do not wear facemasks are at risk of infection. In technology, computer vision-based facemask detection uses a different learning algorithm to recognize face masks in real time. This research compares the performance of seven machine learning, deep learning, and transfer learning algorithms, such as K-NN, SGD, SVM, CNN, MobileNetV2, InceptionV3, and VGG-19, to discover the best algorithm for detecting who is wearing a masked face in a real-time environment. In addition, we got a higher accuracy of 100% in the InceptionV3 algorithm, that InceptionV3 tends to be faster when compared to another algorithms.
C1 [Singh, Nutan; Tripathi, Priyanka] Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Singh, N (corresponding author), Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Chhattisgarh, India.
EM nsingh.phd2021.mca@nitrr.ac.in
OI Singh, Nutan/0000-0002-3636-5330
CR Ab Wahab MN, 2021, IEEE ACCESS, V9, P134065, DOI 10.1109/ACCESS.2021.3113337
   Ahmed I, 2021, IEEE INTERNET THINGS, V8, P15855, DOI 10.1109/JIOT.2020.3034074
   Almghraby M, 2021, Int J Eng Adv Technol, V10, P104
   Alsubai S, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104545
   [Anonymous], Transfer learning and fine-tuning | TensorFlow Core
   [Anonymous], Kaggle: Your Home for Data Science
   [Anonymous], 2017, HANDS ON MACHINE LEA
   [Anonymous], RMFD Dataset | Papers With Code
   [Anonymous], Technical guidance
   [Anonymous], Face mask detection dataset | kaggle
   [Anonymous], WIDER FACE: A face detection benchmark
   Asif Sohaib, 2021, 2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD), P70, DOI 10.1109/ICAIBD51990.2021.9459008
   Bhatia P, 2018, PROCEEDINGS OF THE 2018 3RD INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2018), P191, DOI 10.1109/ICICT43934.2018.9034420
   Bhavsar K, 2022, MACHINES, V10, DOI 10.3390/machines10030176
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Elaggoune H, 2022, MULTIMED TOOLS APPL, V81, P9403, DOI 10.1007/s11042-021-11849-1
   Ghimire P, 2021, Comparative study of face mask recognition using deep learning and machine learning classifiers, P1, DOI [10.1109/icses52305.2021.9633928, DOI 10.1109/ICSES52305.2021.9633928]
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Jogin Manjunath, 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P2319, DOI 10.1109/RTEICT42901.2018.9012507
   Kansal I, 2021, 2021 9 INT C REL INF, P1, DOI [10.1109/ICRITO51393.2021.9596407, DOI 10.1109/ICRITO51393.2021.9596407]
   Kaur Gagandeep, 2022, Neurosci Inform, V2, P100035, DOI 10.1016/j.neuri.2021.100035
   Khan MJ, 2022, VISUAL COMPUT, V38, P509, DOI 10.1007/s00371-020-02031-z
   Koklu M, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103216
   Li WL, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2220527
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Mbunge E., 2021, Sustainable Operations and Computers, V2, P235, DOI [10.1016/j.susoc.2021.08.001, DOI 10.1016/J.SUSOC.2021.08.001]
   Mercaldo F, 2021, J AM MED INFORM ASSN, V28, P1548, DOI 10.1093/jamia/ocab052
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Nowrin A, 2021, IEEE ACCESS, V9, P106839, DOI 10.1109/ACCESS.2021.3100070
   Oumina A., 2020, 2020 IEEE 2 INT C EL, P1, DOI [10.1109/ICECOCS50124.2020.9314511, DOI 10.1109/ICECOCS50124.2020.9314511]
   Prusty Manas Ranjan, 2021, Intell Based Med, V5, P100037, DOI 10.1016/j.ibmed.2021.100037
   Rokhana R, 2021, 2021 INT EL S IES, P636, DOI [10.1109/IES53407.2021.9594022, DOI 10.1109/IES53407.2021.9594022]
   SaiSupriya N., 2021, ADV PARALLEL COMPUT, V38, P118, DOI DOI 10.3233/APC210022
   Sakshi Sneha, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P212, DOI 10.1109/ICACITE51222.2021.9404731
   Sanjaya S.A., 2020, 2020 INT C DAT AN BU, P1, DOI DOI 10.1109/ICDABI51230.2020.9325631
   Saravanan TM, 2022, MATER TODAY-PROC, V58, P150, DOI 10.1016/j.matpr.2022.01.165
   Sen Pratap Chandra, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P99, DOI 10.1007/978-981-13-7403-6_11
   Setyanto A, 2021, 2021 4 INT C INF COM, P119, DOI [10.1109/ICOIACT53268.2021.9564011, DOI 10.1109/ICOIACT53268.2021.9564011]
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sreekala K, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/2086613
   Su XP, 2022, MULTIMED TOOLS APPL, V81, P4475, DOI 10.1007/s11042-021-11772-5
   Tomás J, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9081050
   Umer M, 2023, IMAGE VISION COMPUT, V133, DOI 10.1016/j.imavis.2023.104657
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   WHO | World Health Organization, About us
   Xiao J, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012041
   Zhang X., 2017, Journal of Signal and Information Processing, V08
NR 47
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 2
PY 2023
DI 10.1007/s11042-023-17634-6
EA DEC 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AV0F5
UT WOS:001121103400002
DA 2024-07-18
ER

PT J
AU Bi, S
   Li, XL
AF Bi, Sheng
   Li, Xiangli
TI Semi-supervised clustering ensemble based on genetic algorithm model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nonnegative matrix factorization; Clustering ensemble; Semi-supervised
   learning
AB Clustering ensemble can be regarded as a mathematical optimization problem, and the genetic algorithm has been widely used as a powerful tool for solving such optimization problems. However, the existing research on clustering ensemble based on the genetic algorithm model has mainly focused on unsupervised approaches and has been limited by parameters like crossover probability and mutation probability. This paper presents a semi-supervised clustering ensemble based on the genetic algorithm model. This approach utilizes pairwise constraint information to strengthen the crossover process and mutation process, resulting in enhanced overall algorithm performance. To validate the effectiveness of the proposed approach, extensive comparative experiments were conducted on 9 diverse datasets. The results of the experiments demonstrate the superiority of the proposed algorithm in terms of clustering accuracy and robustness. In summary, this paper introduces a novel semi-supervised approach based on the genetic algorithm model. The utilization of pair-wise constraint information enhances the algorithm's performance, making it a promising solution for real-world clustering problems.
C1 [Bi, Sheng; Li, Xiangli] Guilin Univ Elect Technol, Sch Math & Comp Sci, Guilin 541004, Peoples R China.
   [Li, Xiangli] Guangxi Key Lab Geotech Engn, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology
RP Li, XL (corresponding author), Guilin Univ Elect Technol, Sch Math & Comp Sci, Guilin 541004, Peoples R China.; Li, XL (corresponding author), Guangxi Key Lab Geotech Engn, Guilin 541004, Peoples R China.
EM lixiangli@guet.edu.cn
FU National Natural Science Foundation of China [11961010, 61967004];
   National Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China (11961010, 61967004).
CR Abdala DD, 2014, CHIL COMP SCI SOC SC
   Abedallah L, 2012, P 14 INT C DAT WAR K
   Akyüz S, 2017, SIG PROCESS COMMUN
   [Anonymous], 2001, P 18 INT C MACH LEAR
   Azadeh A, 2011, J INTELL MANUF, V22, P229, DOI 10.1007/s10845-009-0284-8
   Bache K, 2013, UCI machine learning repository
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   He SZ, 2020, COGN COMPUT, V12, P1265, DOI 10.1007/s12559-020-09762-0
   Hu J, 2017, KNOWL-BASED SYST, V132, P144, DOI 10.1016/j.knosys.2017.06.020
   Huang D, 2021, Matlab source code for multi-diversified ensemble clustering (mdec)
   Huang D, 2020, IEEE T KNOWL DATA EN, V32, P1212, DOI 10.1109/TKDE.2019.2903410
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jenssen R, 2013, IEEE SIGNAL PROC MAG, V30, P30, DOI 10.1109/MSP.2013.2249692
   Karypis G, 2010, Appl Phys Lett, V97
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li FJ, 2015, INT CONF MACH LEARN, P58, DOI 10.1109/ICMLC.2015.7340898
   Lui KC, 2020, Adv Mat Res
   Minaei-Bidgoli B, 2014, ARTIF INTELL REV, V41, P27, DOI 10.1007/s10462-011-9295-x
   Paledi U, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04361-6
   SHANMUGAM K, 1973, IEEE T SYST MAN CYB, VSMC3, P202, DOI 10.1109/TSMC.1973.5408507
   Singh V, 2010, MACH LEARN, V79, P177, DOI 10.1007/s10994-009-5158-y
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Tao M, 2007, Trecvid workshop participants notebook papers
   Topchy A, 2004, SIAM PROC S, P379
   Vega-Pons S, 2011, INT J PATTERN RECOGN, V25, P337, DOI 10.1142/S0218001411008683
   Yan S, 2020, Int J Comput Intell Syst
   Yang F, 2017, NEUROCOMPUTING, V235, P59, DOI 10.1016/j.neucom.2017.01.001
   Yang WL, 2021, KNOWL-BASED SYST, V231, DOI 10.1016/j.knosys.2021.107457
   Yang ZR, 2010, IEEE T NEURAL NETWOR, V21, P734, DOI 10.1109/TNN.2010.2041361
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Yu ZW, 2016, IEEE T KNOWL DATA EN, V28, P701, DOI 10.1109/TKDE.2015.2499200
   [张鼎 Zhang Ding], 2022, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V58, P570
   Zhang XR, 2008, IEEE T GEOSCI REMOTE, V46, P2126, DOI 10.1109/TGRS.2008.918647
NR 35
TC 0
Z9 0
U1 8
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 1
PY 2023
DI 10.1007/s11042-023-17662-2
EA DEC 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z5LL9
UT WOS:001112488100005
DA 2024-07-18
ER

PT J
AU Bhavani, SA
   Karthikeyan, C
AF Bhavani, Siriki Atchuta
   Karthikeyan, C.
TI Robust 3D face recognition in unconstrained environment using distance
   based ternary search siamese network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D face recognition; 3D point clouds; Face feature extraction; Enhanced
   Trilateral filtering; Fuzzy boosted histogram equalization; Siamese
   neural network; Twofold channel attention module
ID WAVELET
AB Face recognition has recently become most important and popular in biometrics and computer vision applications. Nowadays, 3D face recognition fascinates researchers with the presence of 2D information and 3D face depth information. Many existing studies reported 2D face recognition, but its performance is reduced due to the influence of poses, illumination, expression, etc. Hence, this article introduces a novel deep learning (DL) model for effective 3D face recognition using point clouds. Initially, image denoising using enhanced trilateral filtering (En-TF) technique, contrast enhancement using fuzzy boosted histogram equalization (Fuzzy-BHE) technique and point cloud extraction are performed in the pre-processing stage to enhance the visual quality of the face image. Then, 3D face recognition is performed using a DL based distance ternary search Siamese neural network (DTS_SiaNet) technique. Within the SiaNet, a dual twofold channel attention convolutional neural network (TCAtt-CNN) technique is introduced to extract essential features from the face image data. In addition, an enhanced snake optimizer (En-SOp) technique is proposed for hyperparameter tuning of the network model. The proposed method is implemented in the Python platform, and the recognition is processed using the MIT-CBCL face recognition and Texas 3D face databases. For the MIT-CBCL database, the proposed method obtains an accuracy of 99.4%, kappa of 97.4%, true positive rate (TPR) of 94.6%, false acceptance ratio (FAR) of 0.0028 and time complexity of 58.3 s. For the Texas 3D face database, the proposed method obtains an accuracy of 99.31%, sensitivity of 97.5%, and F-measure of 97.2%.
C1 [Bhavani, Siriki Atchuta; Karthikeyan, C.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Bhavani, SA (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram 522302, Andhra Pradesh, India.
EM bhavani18.siriki@gmail.com; charthik2k@gmail.com
RI C, Karthikeyan Dr./M-5711-2018
CR Alamgir FM, 2023, MULTIMED TOOLS APPL, V82, P2437, DOI 10.1007/s11042-022-13378-x
   Albiero Vitor, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P7613, DOI 10.1109/CVPR46437.2021.00753
   Alfarisi O, 2021, arXiv
   Alghaili M., 2020, Sci Program, V2020, P1
   Anghelone D, 2022, arXiv
   [Anonymous], Texas 3D Face recognition database
   [Anonymous], MIT-CBCL database
   Atik ME, 2021, Innovations in smart cities applications, V4, P797
   Bah I, 2022, Intelligence Robotics, V2, P72, DOI [10.20517/ir.2021.16, DOI 10.20517/IR.2021.16]
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P30237, DOI 10.1007/s11042-020-09008-z
   Brownlee J., 2019, Machine Learning Mastery
   Moreano JAC, 2020, J ADV INFORM TECHNOL, V11, P143, DOI 10.12720/jait.11.3.143-148
   Dalali S, 2016, PROCEDIA COMPUT SCI, V93, P344, DOI 10.1016/j.procs.2016.07.219
   Dutta K, 2020, MULTIMED TOOLS APPL, V79, P31329, DOI 10.1007/s11042-020-09554-6
   Farkhod A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22228704
   Ghosh S, 2021, PATTERN RECOGN LETT, V144, P13, DOI 10.1016/j.patrec.2021.01.012
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hangaragi Shivalila, 2023, Procedia Computer Science, P741, DOI 10.1016/j.procs.2023.01.054
   Hashim FA, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108320
   Huang YH, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108580
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   Ju YJ, 2022, IEEE WINT CONF APPL, P1173, DOI 10.1109/WACV51458.2022.00124
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Kasemsumran P., 2015, J Image Graphics, V3, P6, DOI [10.18178/joig.3.1.6-10, DOI 10.18178/JOIG.3.1.6-10]
   Kneis Bryan, 2020, WIMS 2020: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics, P255, DOI 10.1145/3405962.3405995
   Li MH, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104669
   Mahesh VGV, 2021, IEEE ACCESS, V9, P52509, DOI 10.1109/ACCESS.2021.3069881
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Olivetti EC, 2020, LECT N MECH ENG, P665, DOI 10.1007/978-3-030-31154-4_56
   Qiu K, 2018, IEEE INT VEH SYM, P716, DOI 10.1109/IVS.2018.8500465
   Raju K., 2022, A Fusion Artif. Intell. Internet Things Emerg. Cyber Syst., V6, P203, DOI [10.1007/978-3-030-76653-5, DOI 10.1007/978-3-030-76653-5]
   Serengil S.I., 2020, 2020 INNOVATIONS INT, P1, DOI DOI 10.1109/ASYU50717.2020.9259802
   Sharma S, 2022, ARCH COMPUT METHOD E, V29, P3475, DOI 10.1007/s11831-021-09705-4
   Shi LL, 2020, OPTIK, V220, DOI 10.1016/j.ijleo.2020.165157
   Singhal N., 2021, Jordanian J Comput Inf Technol, V7, P1
   Singhal Prateek, 2022, Proceedings of Second Doctoral Symposium on Computational Intelligence: DoSCI 2021. Advances in Intelligent Systems and Computing (1374), P103, DOI 10.1007/978-981-16-3346-1_9
   Song D, 2016, J SENSORS, V2016, DOI 10.1155/2016/6859364
   Subramani B, 2018, INT J IMAG SYST TECH, V28, P217, DOI 10.1002/ima.22272
   Tabassum F, 2022, J KING SAUD UNIV-COM, V34, P546, DOI 10.1016/j.jksuci.2020.02.002
   Tiwari H., 2022, P IEEECVF WINTER C A, P813
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Tripathi P, 2021, BILDVERARBEITUNG MED, P310
   Wanxin Cui, 2019, 2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS), P746, DOI 10.1109/ICICAS48597.2019.00161
   Wu FZ, 2019, PROC CVPR IEEE, P959, DOI 10.1109/CVPR.2019.00105
   Xiong JB, 2021, SHOCK VIB, V2021, DOI 10.1155/2021/8883571
   Xu YQ, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108210
   Yakar M, 2023, SURV REV, V55, P416, DOI 10.1080/00396265.2022.2119747
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Zhou JC, 2019, COGN COMPUT SYST, V1, P97, DOI 10.1049/ccs.2019.0010
   Zhu YP, 2021, INT C PATT RECOG, P5690, DOI 10.1109/ICPR48806.2021.9413051
   Zou GF, 2020, MULTIMED TOOLS APPL, V79, P23571, DOI 10.1007/s11042-020-09076-1
   Zou HY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10202539
NR 53
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17545-6
EA NOV 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300008
DA 2024-07-18
ER

PT J
AU Kumar, R
   Kumar, S
AF Kumar, Rahul
   Kumar, Shailender
TI A survey on intelligent human action recognition techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Human Activity Recognition; Deep Learning; Machine Learning; Pretrained
   Models; Handcrafted Feature
ID OPTICAL-FLOW; FEATURES; SPACE; REPRESENTATIONS; ARCHITECTURES;
   DESCRIPTOR; ALGORITHM; NETWORKS; SYSTEM; VIDEOS
AB Human Action Recognition is an essential research area in computer vision due to its automated nature of video monitoring. Human Action Recognition has several applications, including robotics, video monitoring, health care, elderly monitoring, crowd behavior and the detection of aberrant activity. This study seeks to offer the reader an up-to-date overview of intelligent human activity recognition literature and current advancements in this area. This work discusses the recent state-of-the-art research for activity recognition techniques and challenges associated with identifying human activity and discusses publicly available datasets. This work consists of an in-depth survey of numerous works published from 2010 to 2022 focusing on intelligent techniques. This article describes all steps of human action recognition along with their techniques. This study comes with the Datasets for Human Action Recognition, Handcrafted-Feature technique, Machine Learning (ML), Deep-Learning (DL), Hybrid Deep Learning and limitation of this area. This study offers a comparative analysis between ML and DL approaches to show their effectiveness in action recognition. This study examines some unexplored areas in human action recognition that can be unearthed to create a more resilient system in the presence of issues. Previous research has demonstrated that deep learning surpasses standard machine learning for recognizing human activities. This study also emphasizes the most pressing issues and research direction. All relevant datasets are described in detail. Furthermore, our opinions and suggestions for future research have been shared. Compared to past surveys, this study offers a more systematic description of Human Action Recognition methods regarding comparability, problems, and the most recent evaluation technique.
C1 [Kumar, Rahul; Kumar, Shailender] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 42, India.
C3 Delhi Technological University
RP Kumar, R (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi 42, India.
EM rahulkumar_phdco2k19@dtu.ac.in
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahsan U, P IEEE C COMP VIS PA
   Al-Azzawi NA, 2020 12 INT C INF TE, P152
   Al-Faris M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060046
   Andrade-Ambriz YA, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116287
   Chaaraoui AA, 2013, PATTERN RECOGN LETT, V34, P1799, DOI 10.1016/j.patrec.2013.01.021
   [Anonymous], Generating sequences with recurrent neural networks
   Banerjee A, 2021, IEEE T CIRC SYST VID, V31, P2206, DOI 10.1109/TCSVT.2020.3019293
   Barkoky A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103371
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bilal M, 2022, J SUPERCOMPUT, V78, P2873, DOI 10.1007/s11227-021-03957-4
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Calderara Simone, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P121, DOI 10.1109/AVSS.2008.32
   Carreira J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1808.01340
   Carreira J, 2019, Arxiv, DOI arXiv:1907.06987
   Challa SK, 2022, VISUAL COMPUT, V38, P4095, DOI 10.1007/s00371-021-02283-3
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cho K., 2014, ARXIV14061078
   Dai C, Appl Soft Comput
   Damen D, 2022, INT J COMPUT VISION, V130, P33, DOI 10.1007/s11263-021-01531-2
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Das S, 2019, IEEE WINT CONF APPL, P71, DOI 10.1109/WACV.2019.00015
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Dobhal T, 2015, PROCEDIA COMPUT SCI, V58, P178, DOI 10.1016/j.procs.2015.08.050
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Estevam V, 2021, NEUROCOMPUTING, V439, P159, DOI 10.1016/j.neucom.2021.01.036
   Gammulle H, 2019, LECT NOTES COMPUT SC, V11361, P331, DOI 10.1007/978-3-030-20887-5_21
   Gao XL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040947
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gorelick L., 2005, The tenth IEEE international conference on computer vision (ICCV'05)
   Gowda SN, 2017, IEEE COMPUT SOC CONF, P1589, DOI 10.1109/CVPRW.2017.203
   Guangchun C, 2015, Advances in human action recognition: A survey
   Gupta A, 2009, PROC CVPR IEEE, P2012, DOI 10.1109/CVPRW.2009.5206492
   Gupta N, 2022, ARTIF INTELL REV, V55, P4755, DOI [10.1080/19475683.2022.2040587, 10.1007/s10462-021-10116-x]
   Gupta S, 2013, Sobel edge detection algorithm
   Hasan M, IEEE Trans Multimed, V17, P11
   Heilbron FC, IEEE C COMPUTER VISI
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang GB, P IEEE C COMPUTER VI, P2518
   Huang Y, P EUROPEAN C COMPUTE
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Ijjina EP, 2016, APPL SOFT COMPUT, V46, P936, DOI 10.1016/j.asoc.2015.08.025
   Ijsselmuiden J, 2010, LECT NOTES ARTIF INT, V6359, P426, DOI 10.1007/978-3-642-16111-7_49
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Iosifidis A, IEEE Trans Inf Forensics Secur, V7, P530
   Iosifidis A, 2012, IEEE IJCNN
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jalal A, 2014, SENSORS-BASEL, V14, P11735, DOI 10.3390/s140711735
   Jaouedi N, J King Saud Univ-Comput Inf Sci, P32
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Jiang H, IEEE COMP SOC C COMP, P1646
   Jiang N., 2023, ICASSP 2023 2023 IEE, P1, DOI [10.1109/ICASSP49357.2023.10096404, DOI 10.1109/ICASSP49357.2023.10096404]
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Jobanputra C, 2019, PROCEDIA COMPUT SCI, V155, P698, DOI 10.1016/j.procs.2019.08.100
   Joo SW, IEEE C COMP VIS PATT, P107
   Junejo IN, 2014, VISUAL COMPUT, V30, P259, DOI 10.1007/s00371-013-0842-0
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Khare M, 2022, MULTIMED TOOLS APPL, V81, P34863, DOI 10.1007/s11042-021-11828-6
   Khelalef A, 2019, PATTERN RECOGN IMAGE, V29, P702, DOI 10.1134/S1054661819040084
   Kitani K.M., 2007, MOTION VIDEO COMPUTI, P9, DOI DOI 10.1109/WMVC.2007.34
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I., 2004, Local descriptors for spatio-temporal recognition. In: International workshop on spatial coherence for visual motion analysis
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Le QV, IEEE C COMP VIS PATT, P3361
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Li Ang, 2020, arXiv
   Li C, IEEE INT C MULT EXP, P585
   Li C, 2021, MULTIMED TOOLS APPL, V80, P32111, DOI 10.1007/s11042-021-11193-4
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Li R, Single image Dehazing via conditional generative adversarial network
   Li XY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1059, DOI 10.1145/3123266.3123365
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Lu YA, 2012, INT C INTEL HUM MACH, P76, DOI 10.1109/IHMSC.2012.114
   Lv M, Neurocomputing, V362
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Marjaneh S, 2017, Single image action recognition by predicting space-time saliency
   Merlo E, 2023, Arxiv, DOI arXiv:2304.09789
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Minnen D, 2003, PROC CVPR IEEE, P626
   Monfort M, 2019, Arxiv, DOI [arXiv:1801.03150, 10.48550/arXiv.1801.03150, DOI 10.48550/ARXIV.1801.03150]
   Moore D, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P770
   Muhammad K, Future Gener Comput Syst, V125, P167
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Nasir IM, 2023, EXPERT SYST APPL, V227, DOI 10.1016/j.eswa.2023.120311
   Ng A, CS294A Lect Note, V72, P1
   Nguyen NT, 2005, PROC CVPR IEEE, P955
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nikpour B, 2023, PATTERN RECOGN, V139, DOI 10.1016/j.patcog.2023.109428
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Patrona F, 2018, PATTERN RECOGN, V76, P612, DOI 10.1016/j.patcog.2017.12.007
   Putra PU, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262181
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P549, DOI 10.1109/TCSVT.2019.2894161
   Radford A., 2015, ARXIV151106434
   Rahman SA, 2014, EXPERT SYST APPL, V41, P574, DOI 10.1016/j.eswa.2013.07.082
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Rani SD, P INT C RECENT TREND
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Reddy KK, 2012, Machine Vision and Applications, DOI DOI 10.1007/S00138-012-0450-4
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sadek S, EURASIP J Adv Signal Process
   Sahoo SP, 2019, INT CONF ADVAN COMPU, P1012, DOI [10.1109/icaccs.2019.8728473, 10.1109/ICACCS.2019.8728473]
   Salehinejad Hojjat., Recent Advances in Recurrent Neural Networks
   Sánchez-Caballero A, 2022, MULTIMED TOOLS APPL, V81, P24119, DOI 10.1007/s11042-022-12091-z
   Savadi Hosseini M, Int J Eng, V33, P959
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sheikh Y, 2005, IEEE I CONF COMP VIS, P144
   Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Shi YF, 2004, PROC CVPR IEEE, P862
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K., Advances in neural information processing systems, P568
   Singh PK, 2022, ARCH COMPUT METHOD E, V29, P2309, DOI 10.1007/s11831-021-09681-9
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tanberk S, 2020, IEEE ACCESS, V8, P19799, DOI 10.1109/ACCESS.2020.2968529
   Tasnim N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062675
   Teoh SH, Int J Future Comput Commun, V1, P323
   Thi TH, IEEE INT C ADV VID S, P204
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Ullah A, 2019, IEEE T IND ELECTRON, V66, P9692, DOI 10.1109/TIE.2018.2881943
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Usmani A, 2023, MULTIMED TOOLS APPL, V82, P46845, DOI 10.1007/s11042-023-15024-6
   Verma P, 2020, MULTIMEDIA SYST, V26, P671, DOI 10.1007/s00530-020-00677-2
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vishwakarma DK, 2016, ROBOT AUTON SYST, V77, P25, DOI 10.1016/j.robot.2015.11.013
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Weimer D, 2016, CIRP ANN-MANUF TECHN, V65, P417, DOI 10.1016/j.cirp.2016.04.072
   Weinland D., 2007, IEEE11th international conference on computer vision, Rio de Janeiro
   Wensel J, 2022, Arxiv, DOI arXiv:2208.07929
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xu WR, 2017, INT CONF ACOUST SPEE, P1607, DOI 10.1109/ICASSP.2017.7952428
   Yadav SK, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107948
   Yadav SK, 2022, SOFT COMPUT, V26, P877, DOI 10.1007/s00500-021-06238-7
   Yang Y, 2019, PATTERN RECOGN, V85, P60, DOI 10.1016/j.patcog.2018.07.030
   Yin M, 2023, EXPERT SYST APPL, V226, DOI 10.1016/j.eswa.2023.120080
   Yuan CF, 2013, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2013.99
   Zadeh MZ, Self-supervised human activity recognition by augmenting generative adversarial networks, P11755
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang CL, 2022, APPL INTELL, V52, P12771, DOI 10.1007/s10489-021-03068-w
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
NR 174
TC 0
Z9 0
U1 13
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17529-6
EA NOV 2023
PG 57
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900008
DA 2024-07-18
ER

PT J
AU Tang, KF
   Xu, C
   Chen, M
AF Tang, Kaifeng
   Xu, Chi
   Chen, Ming
TI Bi-directional attention based RGB-D fusion for category-level object
   pose and shape estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object pose estimation; Object shape estimation; Attention; RGB-D image;
   Robotic vision
AB RGB-D images contain color and geometric information which are complementary for object pose and shape estimation. Normally, dense-fusion scheme is used to fuse the features extracted from the RGB-D channels for pose estimation of instance-level objects. However, for category-level objects, the effectiveness of dense-fusion feature is unfortunately affected by the significant intra-class variations between color and geometry. To address this problem, we propose AttentionFusion, a bi-directional attention-based RGB-D fusion framework for category-level object pose and shape estimation. In this framework, the complex contextual relationship between the color and geometric features is effectively explored by bi-directional cross-attention mechanism on a global scale for feature fusion. Based on the fused feature, 6D pose of the category-level object instance is refined iteratively, and object shape is also estimated precisely. Experimental results show that, the proposed method can achieve state-of-the-art performance for object pose and shape estimation on REAL275 datasets.
C1 [Tang, Kaifeng; Xu, Chi; Chen, Ming] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Tang, Kaifeng; Xu, Chi; Chen, Ming] China Univ Geosci, Hubei Key Lab Adv Control & Intelligent Automat Co, Wuhan, Hubei, Peoples R China.
   [Tang, Kaifeng; Xu, Chi; Chen, Ming] Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Hubei, Peoples R China.
C3 China University of Geosciences; China University of Geosciences
RP Xu, C (corresponding author), China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.; Xu, C (corresponding author), China Univ Geosci, Hubei Key Lab Adv Control & Intelligent Automat Co, Wuhan, Hubei, Peoples R China.; Xu, C (corresponding author), Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan, Hubei, Peoples R China.
EM tkf@cug.edu.cn; xuchi@cug.edu.cn; cugchenming@cug.edu.cn
FU National Natural Science Foundation of China [62273318]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62273318.
CR Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2753, DOI 10.1109/ICCV48922.2021.00277
   Chen Wang, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10059, DOI 10.1109/ICRA40945.2020.9196679
   Chen W, 2021, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR46437.2021.00163
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Dengsheng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11970, DOI 10.1109/CVPR42600.2020.01199
   Di Y, 2022, PROC CVPR IEEE, P6771, DOI 10.1109/CVPR52688.2022.00666
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Duffhauss F, 2023, IEEE ROBOT AUTOM LET, V8, P5315, DOI 10.1109/LRA.2023.3293317
   Fan D, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108310
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Georgakis G, 2019, IEEE I CONF COMP VIS, P8966, DOI 10.1109/ICCV.2019.00906
   Gu FW, 2023, MULTIMED TOOLS APPL, V82, P40761, DOI 10.1007/s11042-023-15168-5
   Gu FW, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3170972
   Guo FT, 2023, IEEE T IMAGE PROCESS, V32, P4989, DOI 10.1109/TIP.2023.3308750
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y., 2020, P IEEE CVF C COMP VI, DOI DOI 10.1109/CVPR42600.2020.01165
   He YS, 2022, PROC CVPR IEEE, P6804, DOI 10.1109/CVPR52688.2022.00669
   He YS, 2021, PROC CVPR IEEE, P3002, DOI 10.1109/CVPR46437.2021.00302
   Hinterstoisser S, AS C COMP VIS DAEJ K, P548, DOI [10.1007/978-3-642-37331-2sps42, DOI 10.1007/978-3-642-37331-2SPS42]
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hodan T, 2015, IEEE INT C INT ROBOT, P4421, DOI 10.1109/IROS.2015.7354005
   Kehl W, 2016, LECT NOTES COMPUT SC, V9907, P205, DOI 10.1007/978-3-319-46487-9_13
   Konishi Y, 2019, IEEE INT C INT ROBOT, P3451, DOI [10.1109/iros40897.2019.8967967, 10.1109/IROS40897.2019.8967967]
   Li GW, 2023, IEEE WINT CONF APPL, P5674, DOI 10.1109/WACV56688.2023.00564
   Li JB, 2022, INT CONF ACOUST SPEE, P8007, DOI 10.1109/ICASSP43922.2022.9747085
   Lin JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3540, DOI 10.1109/ICCV48922.2021.00354
   Liu CP, 2023, APPL INTELL, V53, P23711, DOI 10.1007/s10489-023-04688-0
   Liu J, 2023, IEEE T IND INFORM, V19, P11171, DOI 10.1109/TII.2023.3244348
   Liu JR, 2022, IEEE T CIRC SYST VID, V32, P6728, DOI 10.1109/TCSVT.2022.3169144
   Liu PL, 2023, IEEE INT CONF ROBOT, P2898, DOI 10.1109/ICRA48891.2023.10160688
   Liu PL, 2024, IEEE T AUTOM SCI ENG, V21, P1793, DOI 10.1109/TASE.2023.3248843
   Meng Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P530, DOI 10.1007/978-3-030-58589-1_32
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi CR, 2017, ADV NEUR IN, V30
   Rad M, 2018, PROC CVPR IEEE, P4663, DOI 10.1109/CVPR.2018.00490
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Saleh M, 2022, arXiv
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tremblay J, 2018, Arxiv, DOI arXiv:1809.10790
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang H, 2022, IEEE INT C INT ROBOT, P10651, DOI 10.1109/IROS47612.2022.9981242
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wang JZ, 2021, IEEE INT C INT ROBOT, P4807, DOI 10.1109/IROS51168.2021.9636212
   Wang Yaming, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P75, DOI 10.1007/s12652-022-03874-1
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu CR, 2022, MACHINES, V10, DOI 10.3390/machines10121107
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Zeng Andy, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1386, DOI 10.1109/ICRA.2017.7989165
   Zhou CQ, 2022, PROC CVPR IEEE, P8521, DOI 10.1109/CVPR52688.2022.00834
   Zhou GL, 2021, IEEE T MULTIMEDIA, V23, P1630, DOI 10.1109/TMM.2020.3001533
   Zhou H, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108468
   Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430
   Zou L, 2022, IEEE T IMAGE PROCESS, V31, P6907, DOI 10.1109/TIP.2022.3216980
NR 64
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17626-6
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900007
DA 2024-07-18
ER

PT J
AU Dua, S
   Kumar, A
   Dua, M
   Dhingra, D
AF Dua, Shelza
   Kumar, Atul
   Dua, Mohit
   Dhingra, Deepti
TI ICFCM-MIE: Improved Cosine Fractional Chaotic Map based Medical Image
   Encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic Map; Medical Image Encryption; DNA operation; Improved Cosine
   Fractional Chaotic Map
ID SYSTEM; TRANSFORM; ALGORITHM
AB Advanced healthcare applications such as telemedicine, smart health, and e-health transmit digital images over an open and insecure communication network. Hence, it becomes mandatory to protect these images from eavesdropping to protect patients' sensitive data. In last two decades, researchers have proposed many chaotic map based medical image cryptosystems. However, many of these systems have used chaotic maps that have a small chaotic range, and suffer from the issue of blank and stable windows. Motivated by the fact, the work in this paper proposes a new chaotic map referred to as an Improved Cosine Fractional Chaotic Map (ICFCM). This proposed map has wider and uniform chaotic range, more positive Lyapunov exponent, and does not have blank and stable windows. Also, we design a medical image encryption scheme using combination of ICFCM and DNA operation. The scheme takes four steps to encrypt an image. In the first step, three intermediate keys (Key1, Key2, Key3) are produced. The second step generates three chaotic sequences using three different chaotic maps the novel ICFCM, Tangent over Cosine Cosine (ToCC) map, and Chebyshev map. The third phase performs Deoxyribonucleic Acid (DNA) encoding and diffusion using DNA operation. In the last phase, the three components of the color cipher image are created by applying the DNA addition operation between DNA encoded image color components, and distinct DNA encoded chaotic sequences for each component. The use of three different chaotic sequences to encrypt three different color components, respectively, gives resistance against various attacks. The value of the security parameters Number of Pixels Change Rate (NPCR), Unified Average Changing Intensity (UACI), and Information entropy, obtained by the proposed scheme are, 99.67,33.63, and 7.9993, respectively.
C1 [Dua, Shelza] Natl Inst Technol Kurukshetra, Dept Elect & Commun Engn, Kurukshetra, India.
   [Kumar, Atul; Dua, Mohit; Dhingra, Deepti] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Kurukshetra
RP Dua, S (corresponding author), Natl Inst Technol Kurukshetra, Dept Elect & Commun Engn, Kurukshetra, India.
EM shelza_ecn@yahoo.com; atul.kumar1995@gmail.com;
   er.mohitdua@nitkkr.ac.in; deeptimona@nitkkr.ac.in
RI DHINGRA, DEEPTI/KPA-9641-2024; DUA, MOHIT/A-1409-2016
OI DHINGRA, DEEPTI/0000-0002-3443-4232; DUA, MOHIT/0000-0001-7071-8323;
   Kumar, Atul/0000-0002-6895-0104
CR Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Al-Hazaimeh O. M., 2022, Bulletin of Electrical Engineering and Informatics, V11, P2151
   Alexan W, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15051081
   Alexan W, 2023, IEEE ACCESS, V11, P11541, DOI 10.1109/ACCESS.2023.3242311
   Ali TS, 2022, MULTIMED TOOLS APPL, V81, P20585, DOI 10.1007/s11042-022-12268-6
   Arif J, 2022, IEEE ACCESS, V10, P12966, DOI 10.1109/ACCESS.2022.3146792
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Bentoutou Y, 2020, ADV SPACE RES, V66, P176, DOI 10.1016/j.asr.2019.09.027
   Box Debra., 2013, Procedia Technology, V9, P1093
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chen X., 2017, Biomedical Research (India), V28, P8834
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Dou YQ, 2021, MULTIMED TOOLS APPL, V80, P24437, DOI 10.1007/s11042-021-10850-y
   Dua Mohit, 2022, International Journal of Information Technology, V14, P1627, DOI 10.1007/s41870-022-00885-1
   Dua M, 2020, J AMB INTEL HUM COMP, V11, P3771, DOI 10.1007/s12652-019-01580-z
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Erkan U, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119076
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Jeevitha S, 2021, J AMB INTEL HUM COMP, V12, P3373, DOI 10.1007/s12652-020-02399-9
   Kaur G, 2022, VISUAL COMPUT, V38, P1027, DOI 10.1007/s00371-021-02066-w
   Kumar A, 2023, APPL ACOUST, V203, DOI 10.1016/j.apacoust.2022.109196
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P27785, DOI 10.1007/s11042-021-10970-5
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Kumar Krishna, 2022, Cyber Warfare, Security and Space Research: First International Conference, SpacSec 2021, Revised Selected Papers. Communications in Computer and Information Science (1599), P87, DOI 10.1007/978-3-031-15784-4_7
   Lai Q, 2023, APPL MATH COMPUT, V442, DOI 10.1016/j.amc.2022.127738
   Lai Q, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118845
   Li MZ, 2022, COGN COMPUT SYST, V4, P378, DOI 10.1049/ccs2.12070
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   Liu QL, 2020, APPL MATH MODEL, V85, P273, DOI 10.1016/j.apm.2020.04.015
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Ma KY, 2021, MULTIMED TOOLS APPL, V80, P24737, DOI 10.1007/s11042-021-10847-7
   Mansoor S, 2023, MULTIMED TOOLS APPL, V82, P28769, DOI 10.1007/s11042-023-14542-7
   Mansouri A, 2021, INFORM SCIENCES, V563, P91, DOI 10.1016/j.ins.2021.02.022
   Mansouri A, 2021, MULTIMED TOOLS APPL, V80, P21955, DOI 10.1007/s11042-021-10757-8
   Masood F, 2022, WIRELESS PERS COMMUN, V127, P1405, DOI 10.1007/s11277-021-08584-z
   Mfungo DE, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13127113
   Munir N, 2022, MULTIMED TOOLS APPL, V81, P6571, DOI 10.1007/s11042-021-11810-2
   NIH Image Gallery, 2015, Ebola Virus Particles
   NIH Image Gallery, 2017, Beta-Amyloid Plaques and Tau in the Brain
   NIH Image Gallery, 2015, Poliovirus
   NIH Image Gallery, 2015, Fragment of a DNA binding protein
   Nusse HE, 1994, Dynamics: numerical explorations, P229, DOI [10.1007/978-1-4684-0231-5_6, DOI 10.1007/978-1-4684-0231-5_6]
   Pak C, 2021, MULTIMED TOOLS APPL, V80, P25367, DOI 10.1007/s11042-021-10660-2
   Pankaj S, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00324-4
   Ping P, 2022, MULTIMED TOOLS APPL, V81, P7323, DOI 10.1007/s11042-021-11799-8
   Rathore V, 2021, MULTIMED TOOLS APPL, V80, P22275, DOI 10.1007/s11042-021-10719-0
   Rupa C, 2023, IEEE J BIOMED HEALTH, V27, P1154, DOI 10.1109/JBHI.2022.3178629
   Shakiba A, 2019, MULTIMED TOOLS APPL, V78, P34773, DOI 10.1007/s11042-019-08071-5
   Shankar K, 2018, IEEE ACCESS, V6, P77145, DOI 10.1109/ACCESS.2018.2874026
   Sharma M, 2020, MULTIMED TOOLS APPL, V79, P355, DOI 10.1007/s11042-019-08079-x
   Sridevi A, 2022, MULTIMED TOOLS APPL, V81, P16987, DOI 10.1007/s11042-022-12471-5
   Talhaoui MZ, 2021, VISUAL COMPUT, V37, P1757, DOI 10.1007/s00371-020-01936-z
   Telem ANK, 2021, MULTIMED TOOLS APPL, V80, P19011, DOI 10.1007/s11042-021-10549-0
   Hoang TM, 2022, MULTIMED TOOLS APPL, V81, P26535, DOI 10.1007/s11042-022-12139-0
   van Deursen N, 2013, COMPUT SECUR, V37, P31, DOI 10.1016/j.cose.2013.04.005
   Wang J., 2021, Multimed Tools Appl
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wu WQ, 2023, MULTIMED TOOLS APPL, V82, P10367, DOI 10.1007/s11042-022-13675-5
   Yasser S, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P227, DOI [10.1109/ITCE48509.2020.9047752, 10.1109/itce48509.2020.9047801]
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Zhang B, 2023, MULTIMED TOOLS APPL, V82, P15735, DOI 10.1007/s11042-022-13744-9
   Zhang J, 2021, MULTIMED TOOLS APPL, V80, P27155, DOI 10.1007/s11042-021-10960-7
   Zheng J, 2021, MULTIMED TOOLS APPL, V80, P20883, DOI 10.1007/s11042-021-10751-0
   Zolfaghari B, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5030057
NR 69
TC 0
Z9 0
U1 10
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17438-8
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200009
DA 2024-07-18
ER

PT J
AU Olim, SC
   Nisi, V
   Romao, T
AF Olim, Sandra Camara
   Nisi, Valentina
   Romao, Teresa
TI Periodic fable discovery: an augmented reality serious game to introduce
   and motivate young children towards chemistry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented reality; Serious games; Chemistry; Periodic table; Children
ID PERCEIVED DIFFICULTY; SCIENCE-EDUCATION; COMPUTER GAMES; PROMOTE;
   SUPPORT; SYSTEM; USABILITY; DESIGN
AB Children's interest in new technologies and games creates opportunities to use these tools to facilitate their thinking processes for scientific content and education, especially to support abstract reasoning in the areas of Science, Technology, Engineering, Maths (STEM). Chemistry concepts, in particular, can benefit from being presented through hybrid physical/digital interfaces. However, the actual impact of immersive gaming technologies on learning and teaching chemistry to young children can benefit from further evaluations. We developed the "Periodic Fable Discovery" AR game to fill this gap. "Periodic Fable Discovery" is an AR serious game that uses a tangible interface and storytelling to introduce and teach basic chemistry concepts to young children from 9 to 13 years old. After designing and implementing the game, we conducted a study with 30 children, using a mixed-method approach, comparing the AR game versus a traditional method of teaching activity. The results show a significant positive learning outcome, higher motivation and engagement in the AR experience.
C1 [Olim, Sandra Camara] Nova Univ Lisbon, FCT NOVA, Lisbon, Portugal.
   [Olim, Sandra Camara; Nisi, Valentina] ITI LARSYS, Madeira, Portugal.
   [Nisi, Valentina] Inst Super Tecn, ITI LARSyS, Lisbon, Portugal.
   [Romao, Teresa] NOVA Univ Lisbon, NOVA LINCS, FCT, Costa Da Caparica, Portugal.
C3 Universidade Nova de Lisboa; Universidade de Lisboa
RP Olim, SC (corresponding author), Nova Univ Lisbon, FCT NOVA, Lisbon, Portugal.; Olim, SC (corresponding author), ITI LARSYS, Madeira, Portugal.
EM s.olim@campus.fct.unl.pt; valentina.nisi@tecnico.ulisboa.pt;
   tir@fct.unl.pt
RI Camara Olim, Sandra/KBQ-5198-2024; Nisi, Valentina/G-8658-2018
OI Camara Olim, Sandra/0000-0003-0098-4495; Romao,
   Teresa/0000-0002-3678-5626; Nisi, Valentina/0000-0002-8051-3230
FU LARSyS-FCT; NOVA LINCS [UIDB/04516/2020]; FCT [PD/BD/150286/2019]
FX This work was supported by LARSyS-FCT Plurianual funding 2020-2023 and
   FCT Ph.D. Grant PD/BD/150286/2019. Also co-funded by NOVA LINCS
   (UIDB/04516/2020) with the financial support of FCT. IP. Our gratitude
   also goes to the students, teachers and coordinators at Doutorecos,
   Associacao Olhar and Madeira CAB. We would like also to thank Goncalo
   Martins, Michaela Sousa, Rui Trindade and Manuel Fontes for their
   ongoing support.
CR AI-VS, 2020, AR VR Molecules Editor
   Alchemie, 2020, MODELar
   Anderson A., 2019, Virtual reality, augmented reality and artificial intelligence in special education: A practical guide to supporting students with learning differences, DOI [10.4324/9780429399503, DOI 10.4324/9780429399503]
   Anikina OV, 2015, PROCD SOC BEHV, V166, P475, DOI 10.1016/j.sbspro.2014.12.558
   [Anonymous], 2020, Schell Games: Happy Atoms
   [Anonymous], 2007, Journal of Science Education and Technology, DOI [DOI 10.1007/S10956-006-9037-Z, 10.1007/s10956-006-9037-z]
   [Anonymous], 2016, Innovating Education and Educating for Innovation: The Power of Digital Technologies and Skills, DOI DOI 10.1787/9789264265097-EN
   Arnseth HC, 2008, PEDAGOG CULT SOC, V16, P289, DOI 10.1080/14681360802346663
   Asyiah EN, 2019, J PHYS CONF SER, V1402, DOI 10.1088/1742-6596/1402/5/055045
   Augmentifyit, 2020, Aumentifylt AR Elements, The periodic table of me
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Barendregt W, 2006, BEHAV RES METHODS, V38, P382, DOI 10.3758/BF03192791
   Bower M, 2014, EDUC MEDIA INT, V51, P1, DOI 10.1080/09523987.2014.889400
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Butterworth M, 1994, Principles of developmental psychology, P51
   Cai S, 2014, COMPUT HUM BEHAV, V37, P31, DOI 10.1016/j.chb.2014.04.018
   Campos Pedro, 2011, International Journal of Virtual Reality, V10, P33
   Capsulate AT, 2020, Capsulate toys
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Chen R, 2008, CAADRIA 2008 ASS COM, P350
   Chen SY, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106418
   Chi SH, 2017, INT J SCI EDUC, V39, P2171, DOI 10.1080/09500693.2017.1366675
   Chu JH, 2016, P 2016 ACM C COMP PU, P27
   Colakoglu OM, 2010, TURK ONLINE J DISTAN, V11, P73
   Cortex P, 2020, Dskalos-Chemistry
   Davydov V.V., 1995, EDUC RESEARCHER, V24, P12
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/014492901101008659, 10.1080/01449290110108659]
   Duan XY, 2020, KSII T INTERNET INF, V14, P1673, DOI 10.3837/tiis.2020.04.014
   Dunleavy M., 2014, Handbook of Research on Educational Communications and Technology, P735, DOI [DOI 10.1007/978-1-4614-3185-5_59, 10.1007/978-1-4614-3185-5_59]
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Fatemah A, 2020, J CHEM EDUC, V97, P992, DOI 10.1021/acs.jchemed.9b00690
   FitzGerald E., 2015, Augmented reality and mobile learning: international journal of mobile and blended learning, V5, P43, DOI [10.4018/ijmbl.2013100103, DOI 10.4018/IJMBL.2013100103]
   Games S, 2021, HoloLAB Champions
   Green M.E., 2006, Proceedings of World Conference on E-learning in Corporate, Government, Healthcare, and Higher Education, P45
   Habig S, 2020, BRIT J EDUC TECHNOL, V51, P629, DOI 10.1111/bjet.12891
   Helmenstine T, 2019, Science notes learn science do science
   Hinske Steve, 2008, Proceedings of the 7th ACM Conference on Designing Interactive Systems. DIS 2008, P78, DOI 10.1145/1394445.1394454
   Irwansyah FS, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012068
   Jesionkowska J, 2020, EDUC SCI, V10, DOI 10.3390/educsci10080198
   Kalley M., 2001, INT J EARLY YEARS ED, V9, P165, DOI DOI 10.1080/09669760120086929
   Kalmpourtzis George, 2018, Educational Game Design Fundamentals: A Journey to Creating Intrinsically Motivating Learning Experiences
   Kamarainen AM, 2013, COMPUT EDUC, V68, P545, DOI 10.1016/j.compedu.2013.02.018
   Keller J.M., 1987, Nonprofit Management Leadership, V26, P1, DOI [10.1002/pfi.4160260802, DOI 10.1002/PFI.4160260802]
   Kelly A.E., 2003, EDUC RESEARCHER, V32, P3, DOI [10.3102/0013189X032001003, DOI 10.3102/0013189X032001003]
   Klopfer E., 2010, New directions for youth development, V128, P85, DOI [10.1002/yd.378, DOI 10.1002/YD.378]
   Kolb David A, 2014, EXPERIENTIAL LEARNIN, DOI [10.1002/job.4030080408, DOI 10.1016/B978-0-7506-7223-8.50017-4]
   Kuang Y, 2019, INT CONF COMP SCI ED, P172, DOI 10.1109/iccse.2019.8845339
   Lam MC, 2020, TEM J, V9, P351, DOI 10.18421/TEM91-48
   Lampropoulos G, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136809
   Li MC, 2013, J SCI EDUC TECHNOL, V22, P877, DOI 10.1007/s10956-013-9436-x
   Liu Y, 2016, CHEM EDUC RES PRACT, V17, P439, DOI 10.1039/c6rp00013d
   Loorbach N, 2015, BRIT J EDUC TECHNOL, V46, P204, DOI 10.1111/bjet.12138
   Luraschi M, 2012, CHIMIA, V66, P820, DOI 10.2533/chimia.2012.820
   Lutfi A, 2019, Jurnal Penelitian Pendidikan Sains, V8, P1684, DOI [10.26740/jpps.v8n2.p1684-1689, DOI 10.26740/JPPS.V8N2.P1684-1689]
   Maguire M, 2001, INT J HUM-COMPUT ST, V55, P587, DOI 10.1006/ijhc.2001.0503
   Maier P, 2009, P INT C CHEM ENG ICC
   MALONE TW, 1981, COGNITIVE SCI, V5, P333, DOI 10.1207/s15516709cog0504_2
   Martin F, 2018, ONLINE LEARN, V22, P205, DOI 10.24059/olj.v22i1.1092
   Martín-Gutiérrez J, 2015, COMPUT HUM BEHAV, V51, P752, DOI 10.1016/j.chb.2014.11.093
   Martins AI, 2015, PROCEDIA COMPUT SCI, V67, P293, DOI 10.1016/j.procs.2015.09.273
   Marvel S, 2020, Immersive chemistry
   Master mind toys, 2020, Professor Maxwell, 4D AR Science Kit
   Morais C, 2015, J CHEM EDUC, V92, P58, DOI 10.1021/ed5002416
   Mughal F., 2011, International Journal of Learning and Development, V1, P27, DOI [10.5296/ijld.v1i2.1179, DOI 10.5296/IJLD.V1I2.1179]
   Nechypurenko PP, 2018, CEUR WORKSHOP P
   Nordin N., 2019, University carnival on e-learning (IUCEL), V2019, P54
   Núñez M, 2008, MATH COMPUT SCI ENG, P271
   Or ANST, 2020, Ansto XR
   Osborne J., 2008, SCI ED EUROPE CRITIC
   Patall EA, 2018, LEARN INSTR, V58, P220, DOI 10.1016/j.learninstruc.2018.07.004
   Peleg R, 2017, CHEM EDUC RES PRACT, V18, P304, DOI 10.1039/c6rp00215c
   Plunkett KN, 2019, J CHEM EDUC, V96, P2628, DOI 10.1021/acs.jchemed.9b00607
   Popar, 2020, Popar periodic table of elements
   Prensky M., 2003, Computers in Entertainment (CIE), V1, P21, DOI DOI 10.1145/950566.950596
   Radu I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300774
   Rapetti E, 2015, data and reflection from the higher education context, V5, P303
   Rastegarpour H, 2012, PROCD SOC BEHV, V31, P597, DOI 10.1016/j.sbspro.2011.12.111
   Read Janet., 2002, INTERACTION DESIGN AND CHILDREN, SHAKER PUBLISHING, V2, P1
   Redondo B, 2020, EARLY CHILD EDUC J, V48, P147, DOI 10.1007/s10643-019-00999-5
   Rivera H, 2020, FRONT EDUC, V5, DOI 10.3389/feduc.2020.00025
   Roth W.M., 1995, Authentic school science: knowledge and learning in open-inquiry laboratories, DOI DOI 10.1007/978-94-011-0495-1
   Salmi H, 2017, INT J SCI EDUC PART, V7, P253, DOI 10.1080/21548455.2016.1254358
   Savi R., 2010, Renote, V8, P1
   Sawyer Ben., 2002, Serious Games
   Schell J, 2008, The art of game design: a book of lenses, DOI [10.1201/b17723, DOI 10.1201/B17723]
   Sharlin E, 2004, PERS UBIQUIT COMPUT, V8, P338, DOI 10.1007/s00779-004-0296-5
   Shavelson R.J., 2003, EDUC RESEARCHER, V32, P25
   Shirazi S, 2017, INT J SCI EDUC, V39, P1891, DOI 10.1080/09500693.2017.1356943
   Sirakaya M., 2018, CONT ED TECHNOLOGY, V9, P297, DOI DOI 10.30935/CET.444119
   SolbesMatarredona J, 2007, Didactica de las ciencias experimentales y sociales
   Srisawasdi N, 2019, J SCI EDUC TECHNOL, V28, P152, DOI 10.1007/s10956-018-9754-0
   Swamy KLN, 2018, IEEE INT CONF ADV LE, P252, DOI 10.1109/ICALT.2018.00065
   Timovski R, 2020, INT C INF TECHN DEV, V148, P148
   Tingyan Bi, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P3364, DOI 10.1109/CECNET.2011.5769496
   TM A, 2019, Arloon Plants
   Treagust DF, 2003, INT J SCI EDUC, V25, P1353, DOI 10.1080/0950069032000070306
   University PC, 2018, Chemistry AR (BETA)
   Garzón JCV, 2017, BIOCHEM MOL BIOL EDU, V45, P417, DOI 10.1002/bmb.21063
   VisioneeringLearning, 2020, 360ED Elements AR
   Wang Y., 2019, ResearchGate, DOI [10.2991/aebmr.k.191225.223, DOI 10.2991/AEBMR.K.191225.223]
   Wu HK, 2004, SCI EDUC, V88, P465, DOI 10.1002/sce.10126
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yogman M, 2018, PEDIATRICS, V142, DOI 10.1542/peds.2018-2058
   Zheng M, 2017, J MOL GRAPH MODEL, V73, P18, DOI 10.1016/j.jmgm.2017.01.019
   Zimmerman HT, 2016, ADV INTELL SYST COMP, V406, P101, DOI 10.1007/978-3-319-26518-6_4
   Zurita G, 2004, J COMPUT ASSIST LEAR, V20, P235, DOI 10.1111/j.1365-2729.2004.00089.x
NR 108
TC 1
Z9 1
U1 12
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17526-9
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500009
DA 2024-07-18
ER

PT J
AU Bhonde, SB
   Wagh, SK
   Prasad, JR
AF Bhonde, Swati B.
   Wagh, Sharmila K.
   Prasad, Jayashree R.
TI Meticulous predictive modelling for classification of cancerous
   molecular profiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cancer prediction; Random forest; Decision tree; t-SNE algorithm;
   Feature scaling; TCGA dataset
AB Functional genomic data has recently been used to aid in the effective and early detection of cancer. The Microarray in genomic data evidence has two main problems, according to previous research, one is high dimensionality and another is limited sample size. Several researchers have used various statistical and machine learning-based methods to study and assess the cancer classification challenge but attaining the highest accuracy is still remaining as a future scope. While classifying the cancer type, leaving a large number of non-informative genes in the study might lead to skewed results and lower power which hinders the methodology overall accuracy. So to overcome it, the dimensional reduction takes place by t-SNE with Kullback divergence and Shannon entropy for an effective prediction. Generally, for classification, decision trees are employed which are prone to over fitting, especially when a tree is particularly deep. Hence, a Decisive random forest classifier is utilized for the cancer prediction with the resources updated and classify them efficiently. The performance of the proposed method was compared with that of other SOTA approaches such as BERT, XLNet, RoBERTa and BART and the results showed that the proposed method outperformed the other methods. The result obtained by the proposed model efficiently predicted the cancer with high accuracy of 99%, high Recall is 99.8%, high precision is 99% and high F1-Score is 99.6%.
C1 [Bhonde, Swati B.] Smt Kashibai Navale Coll Engn, Pune, India.
   [Wagh, Sharmila K.] MESs Wadia Coll Engn, Pune, India.
   [Prasad, Jayashree R.] MIT ADT Univ, Pune, India.
RP Bhonde, SB (corresponding author), Smt Kashibai Navale Coll Engn, Pune, India.
EM swati.bhonde@gmail.com; sharmila.wagh123@gmail.com;
   jayashreeprasad@gmail.com
CR Abdel-Azim G., 2016, Appl Math Info Sci, V10, P1541, DOI [10.18576/amis/100432, DOI 10.18576/AMIS/100432]
   [Anonymous], Circulation. Cardiovascular quality and outcomes, DOI [DOI 10.1101/159756, 10.1101/159756]
   Arora I, 2021, METHODS, V187, P92, DOI 10.1016/j.ymeth.2020.09.008
   Baek S, 2020, COMPUT STRUCT BIOTEC, V18, P1429, DOI 10.1016/j.csbj.2020.06.012
   Brechtmann F, 2018, AM J HUM GENET, V103, P907, DOI 10.1016/j.ajhg.2018.10.025
   Chen H., 2017, Int J Comput Appl, V163, P47
   Chen HH, 2016, J BIOMED INFORM, V62, P12, DOI 10.1016/j.jbi.2016.05.007
   Danaee P, 2017, BIOCOMPUT-PAC SYM, P219
   Eulenberg P, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00623-3
   Federico A, 2020, NANOMATERIALS-BASEL, V10, DOI 10.3390/nano10050903
   García-Díaz P, 2020, GENOMICS, V112, P1916, DOI 10.1016/j.ygeno.2019.11.004
   Goel V, 2020, ADV INTELL SYST COMP, V1016, P153, DOI 10.1007/978-981-13-9364-8_12
   Gupta S, 2018, CURR BIOINFORM, V13, P216, DOI 10.2174/1574893612666170529120424
   He BS, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00817
   Jiang ZH, 2017, PATTERN RECOGN LETT, V90, P1, DOI 10.1016/j.patrec.2017.02.015
   Kasongo SM, 2021, IEEE ACCESS, V9, P113199, DOI 10.1109/ACCESS.2021.3104113
   Lewis M, 2020, P 58 ANN M ASS COMP, P7871, DOI DOI 10.18653/V1/2020.ACL-MAIN.703
   Mabu AM, 2020, J INFORM OPTIM SCI, V41, P723, DOI 10.1080/02522667.2018.1555311
   Malakar S, 2020, NEURAL COMPUT APPL, V32, P2533, DOI 10.1007/s00521-018-3937-8
   Peiris H, 2022, LECT NOTES COMPUT SC, V13435, P162, DOI 10.1007/978-3-031-16443-9_16
   Ramanan M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108058
   Ramirez R, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.00203
   Schrammen PL, 2022, J PATHOL, V256, P50, DOI 10.1002/path.5800
   Shukla AK, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100661
   Trivizakis E, 2020, INT J ONCOL, V57, P43, DOI 10.3892/ijo.2020.5063
   Xia CQ, 2018, IEEE ACM T COMPUT BI, V15, P1315, DOI 10.1109/TCBB.2017.2712607
   Zhang Q, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.532403
NR 27
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17261-1
EA NOV 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200008
DA 2024-07-18
ER

PT J
AU Dallakoti, R
   Alsadoon, A
   Prasad, PWC
   Al Aloussi, S
   Rashid, TA
   Alsadoon, OH
   Alrubaie, A
   Haddad, S
AF Dallakoti, Roshan
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al Aloussi, Sarmad
   Rashid, Tarik A.
   Alsadoon, Omar Hisham
   Alrubaie, Ahmad
   Haddad, Sami
TI Mixed reality in surgical telepresence: a novel extended mean value
   cloning with automatic trimap generation and accurate alpha matting for
   visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video composition; Mean value cloning; Contour flow; Automatic trimap
   generation; Gradient mixing; Image matting
AB The aim of this research is to propose an extended mean value cloning algorithm with automatic trimap generation and accurate alpha matting. This implementation improves the visualization accuracy of the merged video by reducing the discolored and smudging artefacts of the remote surgeon's boundary. It also makes the merge robust for the illumination changes by taking less processing time in real time surgery. The proposed system uses automatic trimap generation from the source video for accurate foreground extraction. Extended mean value cloning with gradient mixing is then applied for the cloning with optimized alpha matting for accurate and realistic video composition. The proposed system improved the visualization accuracy by providing almost 99.7% visibility of the pixels compared to the state-of-the-art solution, which provides 99.1% visibility of pixels. The overlay error was reduced from 0.93 mm to 0.63 mm. The processing time was also reduced. The proposed solution processed 8 frames per second, which is less time than the state-of-the-art solution, which processed 5 frames per second. The extended mean value cloning smooths the differences that presented in the target and source frames for seamless and realistic blending of pixels. The automatic trimap generation reduced the risk of false foreground selection and the generated optimal trimaps improved the alpha matte quality, which is optimized to reduce the smudging artefacts completely and to produce accurate visualization of the final merged image.
C1 [Dallakoti, Roshan; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, Australia.
   [Al Aloussi, Sarmad] Massasoit Community Coll, Comp Technol & Informat Management Dept, Brockton, MA USA.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, KRG, Iraq.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, Australia.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Sydney, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Western Sydney University; University of
   Kurdistan Hewler; Al-Iraqia University; University of New South Wales
   Sydney; Florey Institute of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp Math & Engn, Wagga Wagga, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./HLX-0184-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; withana, chandana/0000-0002-3007-687X
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Anton D, 2018, FUTURE GENER COMP SY, V82, P77, DOI 10.1016/j.future.2017.12.055
   Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Cai ZQ, 2019, MEMET COMPUT, V11, P53, DOI 10.1007/s12293-018-0275-4
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Chen T, 2013, IEEE T IMAGE PROCESS, V22, P2532, DOI 10.1109/TIP.2013.2251642
   Cho D, 2017, IEEE T PATTERN ANAL, V39, P1504, DOI 10.1109/TPAMI.2016.2606397
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Henry C, 2019, EXPERT SYST APPL, V133, P242, DOI 10.1016/j.eswa.2019.05.019
   Hettig J, 2018, INT J COMPUT ASS RAD, V13, P1717, DOI 10.1007/s11548-018-1825-4
   Hu QP, 2018, MULTIMED TOOLS APPL, V77, P24477, DOI 10.1007/s11042-018-5737-7
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Li JJ, 2019, IEEE ACCESS, V7, P19332, DOI 10.1109/ACCESS.2019.2896084
   Pawin P., 2019, Songklanakarin J Sci Technol (SJST), V41, P436
   Perkins SL, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P269, DOI 10.1109/ISMAR-Adjunct.2017.92
   Shen YH, 2015, INT CONF CONTR AUTO, P118, DOI 10.1109/ICCAIS.2015.7338644
   Venkata HS, 2019, COMPUT METH PROG BIO, V177, P253, DOI 10.1016/j.cmpb.2019.05.025
   Wang J, 2019, IEEE Trans Image Process
   Wang P, 2019, INT J ADV MANUF TECH, V102, P1339, DOI 10.1007/s00170-018-03237-1
   Xie ZF, 2010, VISUAL COMPUT, V26, P1123, DOI 10.1007/s00371-010-0466-6
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17331-4
EA NOV 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, XQ
   Zheng, JB
   Li, CF
   Wu, B
   Wu, HF
   Montewka, J
AF Chen, Xinqiang
   Zheng, Jinbiao
   Li, Chaofeng
   Wu, Bing
   Wu, Huafeng
   Montewka, Jakub
TI Maritime traffic situation awareness analysis via high-fidelity ship
   imaging trajectory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Maritime traffic situation awareness; Ship trajectory; Fog removal;
   Trajectory outlier removal; Smart ship
ID PREDICTION
AB Situation awareness provides crucial yet instant information to maritime traffic participants, and significant attentions are paid to implement traffic situation awareness task via various maritime data source (e.g., automatic identification system, maritime surveillance video, radar, etc.). The study aims to analyze traffic situation with the support of ship imaging trajectory. First, we employ the dark channel prior model to remove fog in maritime videos to obtain high-resolution ship images (i.e., fog-free maritime images). Second, we track ships in each maritime image with the scale adaptive kernel correlation filter (SAMF), and thus obtain raw ship imaging trajectories. Third, we cleanse abnormal ship trajectory samples via curve-fitting and down sampling method, and thus further maritime traffic situation analysis is implemented. We analyze maritime traffic situation in three typical videos (i.e., three typical maritime traffic scenarios), and experimental results suggested that the proposed framework can extract high-resolution ship imaging trajectory for fulfilling the task of accurate maritime traffic situation awareness.
C1 [Chen, Xinqiang; Zheng, Jinbiao; Li, Chaofeng] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
   [Wu, Bing] Wuhan Univ Technogloy, Intelligent Transportat Syst Res Ctr ITSC, Wuhan 430063, Peoples R China.
   [Wu, Bing] Wuhan Univ Technol, State Key Lab Maritime Technol & Safety, Wuhan 430063, Peoples R China.
   [Wu, Huafeng] Shanghai Maritime Univ, Merchant Marine Coll, Shanghai 201306, Peoples R China.
   [Montewka, Jakub] Gdyn Maritime Univ, Res Grp Maritime Transportat Risk & Safety, Morska 81-87, PL-81225 Gdynia, Poland.
C3 Shanghai Maritime University; Wuhan University of Technology; Shanghai
   Maritime University
RP Wu, B (corresponding author), Wuhan Univ Technogloy, Intelligent Transportat Syst Res Ctr ITSC, Wuhan 430063, Peoples R China.; Wu, B (corresponding author), Wuhan Univ Technol, State Key Lab Maritime Technol & Safety, Wuhan 430063, Peoples R China.
EM bing.wu@whut.edu.cn
RI Montewka, Jakub/C-7537-2012
OI Montewka, Jakub/0000-0002-6817-8628
FU This work was jointly supported by National Key Ramp;D Program of China
   (2021YFC2801002), National Natural Science Foundation of China
   (52102397, 52071200, 62176150), China Postdoctoral Science Foundation
   (2022M712027), Fund of National Engineering Resear [2021YFC2801002];
   National Key Ramp;D Program of China [52102397, 52071200, 62176150];
   National Natural Science Foundation of China [2022M712027]; China
   Postdoctoral Science Foundation [A2022003]; Fund of National Engineering
   Research Center for Water Transport Safety
FX This work was jointly supported by National Key R & D Program of China
   (2021YFC2801002), National Natural Science Foundation of China
   (52102397, 52071200, 62176150), China Postdoctoral Science Foundation
   (2022M712027), Fund of National Engineering Research Center for Water
   Transport Safety (A2022003).
CR Chen JS, 2021, IEEE T GEOSCI REMOTE, V59, P1143, DOI 10.1109/TGRS.2020.3000903
   Chen X, 2022, PREPRINT, DOI [10.1109/TITS.2022.3167650, DOI 10.1109/TITS.2022.3167650]
   Chen XQ, 2022, OCEAN COAST MANAGE, V228, DOI 10.1016/j.ocecoaman.2022.106326
   Chen XQ, 2020, IEEE SENS J, V20, P14317, DOI 10.1109/JSEN.2020.3007809
   Chen XQ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7191296
   Du L, 2020, OCEAN ENG, V201, DOI 10.1016/j.oceaneng.2020.107110
   Guo SQ, 2021, OCEAN ENG, V234, DOI 10.1016/j.oceaneng.2021.109256
   Hong Z, 2021, IEEE J Sel Top Appl Earth Obs Remote Sens, VPP, P1
   Li MX, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107816
   Liu RW, 2021, OCEAN ENG, V235, DOI 10.1016/j.oceaneng.2021.109435
   Murray B, 2022, J OCEAN ENG SCI, V7, P1, DOI 10.1016/j.joes.2021.03.001
   Murray B, 2020, OCEAN ENG, V209, DOI 10.1016/j.oceaneng.2020.107478
   Prasad DK, 2020, IEEE T INTELL TRANSP, V21, P5295, DOI 10.1109/TITS.2019.2954464
   Prasad DK, 2017, IEEE T INTELL TRANSP, V18, P1993, DOI 10.1109/TITS.2016.2634580
   Shan YX, 2021, IEEE T CIRC SYST VID, V31, P315, DOI 10.1109/TCSVT.2020.2978194
   Shao S, 2019, IEEE SENS J, V19, P4940, DOI 10.1109/JSEN.2019.2903399
   Sharma A, 2019, SAFETY SCI, V120, P745, DOI 10.1016/j.ssci.2019.08.016
   Shi J., 2021, IEEE J Sel Top Appl Earth Observ Remote Sens, VPP, P1
   Shu YQ, 2018, OCEAN ENG, V169, P529, DOI 10.1016/j.oceaneng.2018.09.022
   Shu YQ, 2017, OCEAN ENG, V131, P1, DOI 10.1016/j.oceaneng.2016.12.027
   Sui ZY, 2020, OCEAN ENG, V214, DOI 10.1016/j.oceaneng.2020.107848
   Szlapczynski R, 2018, OCEAN ENG, V158, P263, DOI 10.1016/j.oceaneng.2018.03.092
   Wu B, 2021, RELIAB ENG SYST SAFE, V209, DOI 10.1016/j.ress.2021.107466
   Wu B, 2021, MARIT POLICY MANAG, V48, P299, DOI 10.1080/03088839.2020.1791994
   Xiao Z, 2020, IEEE T INTELL TRANSP, V21, P1796, DOI 10.1109/TITS.2019.2908191
   Yang X, 2023, IEEE T PATTERN ANAL, V45, P2384, DOI 10.1109/TPAMI.2022.3166956
   Yang X, 2022, INT J COMPUT VISION, V130, P1873, DOI 10.1007/s11263-022-01618-4
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Yu Y, 2021, OCEAN COAST MANAGE, V203, DOI 10.1016/j.ocecoaman.2020.105446
   Zhang MY, 2022, IEEE ACCESS, V10, P86647, DOI 10.1109/ACCESS.2022.3199352
   Zhang W, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3077679
NR 31
TC 0
Z9 0
U1 10
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17456-6
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500015
DA 2024-07-18
ER

PT J
AU Moufassih, M
   Tarahi, O
   Hamou, S
   Agounad, S
   Azami, HI
AF Moufassih, Mustapha
   Tarahi, Ousama
   Hamou, Soukaina
   Agounad, Said
   Azami, Hafida Idrissi
TI Boosting motor imagery brain-computer interface classification using
   multiband and hybrid feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain-computer interfaces; Motor imagery; Spatial filtering; Riemannian
   geometry
ID COMMON SPATIAL-PATTERN; FEATURE-SELECTION; EEG CLASSIFICATION;
   PERFORMANCE; FILTERS; SIGNAL
AB Brain-computer interface (BCI) is a new promising technology for control and communication, the BCI system aims to decode the measured brain activity into a command signal. This paper proposes a hybrid approach to improve the classification performance of motor imagery BCI (MI BCI). Our proposed method aims to take the advantage of two principal feature extraction approaches. The first approach named Multi-Band common spatial patterns (MBCSP) consists of decomposing the MI trial into multiple sub-bands, for each sub-band CSP is applied to extract the features. Then, the subject-specific frequency bands are selected. Simultaneously, the selected frequency bands are used as input to the second approach named boosted tangent space mapping (BTSM), which extracts the features from each sub-band. An automatic feature selection algorithm is introduced to select the subject-specific frequency bands and to reduce the high dimensionality space of extracted features. Finally, the LogitBoost (LB) classifiers are learned on the extracted features by each approach and the linear combination of these classifiers is used to identify the class of MI trial. The proposed model is evaluated on three public MI-BCI datasets, including multiclass motor imagery datasets (BCI competition IV dataset 2a and BCI competition III dataset 3a) and binary class motor imagery dataset (BCI competition III dataset 4a), The average accuracy attained on the three datasets are respectively 73.61%, 86.66%, and 86.68%. The conducted comparative study between the proposed approach and some state-of-the-the art methods showed a statistically significant improvement (p-value < 0.05) of the classification performance of MI BCI. The experiment results showed a significant improvement when using the proposed hybrid approach against the use of a single-feature extraction method.
C1 [Moufassih, Mustapha; Tarahi, Ousama; Hamou, Soukaina; Agounad, Said; Azami, Hafida Idrissi] Ibn Zohr Univ, Lab Metrol & Informat Proc, Fac Sci, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Moufassih, M (corresponding author), Ibn Zohr Univ, Lab Metrol & Informat Proc, Fac Sci, Agadir 80000, Morocco.
EM mustapha.moufassih@edu.uiz.ac.ma
FU We would like to address our acknowledgments to the National Centre of
   Scientific and Technical Research of Morocco (CNRST), the Ministry of
   Higher Education, Scientific Research and Innovation (MHESRI), and
   Digital Development Agency of Morocco (ADD) for; National Centre of
   Scientific and Technical Research of Morocco (CNRST); Ministry of Higher
   Education, Scientific Research and Innovation (MHESRI); Digital
   Development Agency of Morocco (ADD)
FX We would like to address our acknowledgments to the National Centre of
   Scientific and Technical Research of Morocco (CNRST), the Ministry of
   Higher Education, Scientific Research and Innovation (MHESRI), and
   Digital Development Agency of Morocco (ADD) for funding this project
   through AL-KHAWARIZMI program of Morocco.
CR Abdulkader SN, 2015, EGYPT INFORM J, V16, P213, DOI 10.1016/j.eij.2015.06.002
   Agounad S, 2022, 2022 27 INT C AUT CO, P1, DOI [10.1109/ICAC55051.2022.9911068, DOI 10.1109/ICAC55051.2022.9911068]
   Agounad S, 2022, J KING SAUD UNIV-COM, V34, P9428, DOI 10.1016/j.jksuci.2022.09.020
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Ang KK, 2006, IEEE IJCNN, P742
   Ang KK, 2008, IEEE IJCNN, P2390, DOI 10.1109/IJCNN.2008.4634130
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Baniqued PDE, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00820-8
   Barachant A., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P472, DOI 10.1109/MMSP.2010.5662067
   Barachant A, 2013, NEUROCOMPUTING, V112, P172, DOI 10.1016/j.neucom.2012.12.039
   Barachant A, 2012, IEEE T BIO-MED ENG, V59, P920, DOI 10.1109/TBME.2011.2172210
   Barachant A, 2010, LECT NOTES COMPUT SC, V6365, P629, DOI 10.1007/978-3-642-15995-4_78
   Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441
   Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051
   Boothby WM, 2003, An Introduction to Differentiable Manifolds and Riemannian Geometry, V120, P1
   Bowman A., 1997, Applied Smoothing Techniques for Data Analysis: The Kernel Approach with S-Plus Illustrations
   Brunner C., 2008, Inst. Knowl. Discov. GrazUniv.Technol., V16, P1, DOI DOI 10.1109/TBME.2004.827081
   Chaudhary U, 2016, NAT REV NEUROL, V12, P513, DOI 10.1038/nrneurol.2016.113
   Davoudi A, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa61bb
   Divya V, 2023, Comput Syst Sci Eng, V45
   Fletcher PT, 2004, LECT NOTES COMPUT SC, V3117, P87
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   FUKUNAGA K, 1970, IEEE T COMPUT, VC 19, P311, DOI 10.1109/T-C.1970.222918
   Gaur P, 2018, EXPERT SYST APPL, V95, P201, DOI 10.1016/j.eswa.2017.11.007
   Ghojogh B, 2022, Arxiv, DOI arXiv:1903.11240
   Guo Y, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101917
   Higashi H, 2013, IEEE T BIO-MED ENG, V60, P1100, DOI 10.1109/TBME.2012.2215960
   Horev I, 2016, ASIAN C MACHINE LEAR, P1
   Islam MR, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aac313
   Jasper H., 1949, Arch. F. uR. Psychiatr. Und Z. Neurol., V183, P163, DOI DOI 10.1007/BF01062488
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   KOLES Z J, 1990, Brain Topography, V2, P275, DOI 10.1007/BF01129656
   KOLES ZJ, 1991, ELECTROEN CLIN NEURO, V79, P440, DOI 10.1016/0013-4694(91)90163-X
   Koles ZJ, 1998, ELECTROEN CLIN NEURO, V107, P343, DOI 10.1016/S0013-4694(98)00084-4
   Kumar S, 2017, COMPUT BIOL MED, V91, P231, DOI 10.1016/j.compbiomed.2017.10.025
   Kwak N, 2002, IEEE T PATTERN ANAL, V24, P1667, DOI 10.1109/TPAMI.2002.1114861
   Lamba M, 2023, MULTIMED TOOLS APPL, V82, P29629, DOI 10.1007/s11042-023-14918-9
   Lesenfants D, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/035002
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539
   Lu HP, 2010, IEEE T BIO-MED ENG, V57, P2936, DOI 10.1109/TBME.2010.2082540
   Luo J, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105464
   McFarland DJ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/3/036007
   Mishuhina V, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107918
   Moufassih M, 2022, 2022 2 INT C INN RES, P1, DOI [10.1109/IRASET52964.2022.9738394, DOI 10.1109/IRASET52964.2022.9738394]
   Muller K-R, 2022, BCI Competition III Dataset IVa
   Müller-Gerking J, 1999, CLIN NEUROPHYSIOL, V110, P787, DOI 10.1016/S1388-2457(98)00038-8
   Ousama T, 2022, 2022 2 INT C INN RES, P1, DOI [10.1109/IRASET52964.2022.9738119, DOI 10.1109/IRASET52964.2022.9738119]
   Park SH, 2018, IEEE T NEUR SYS REH, V26, P498, DOI 10.1109/TNSRE.2017.2757519
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Pfurtscheller G, 1998, IEEE Trans Rehabil Eng, V6, P316, DOI 10.1109/86.712230
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G, 2022, BCI Competition III Dataset IIIa
   Pires G, 2011, J NEUROSCI METH, V195, P270, DOI 10.1016/j.jneumeth.2010.11.016
   Raheja S, 2023, NEURAL COMPUT APPL, V35, P13755, DOI 10.1007/s00521-021-06376-x
   Ramos-Murguialday A, 2013, ANN NEUROL, V74, P100, DOI 10.1002/ana.23879
   Saha S, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.578875
   Singh A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020379
   Sommer S., 2020, Riemannian geometric statistics in medical image analysis, P3
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Viera AJ, 2005, FAM MED, V37, P360
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101
   WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B
   Xie XF, 2017, IEEE T NEUR SYS REH, V25, P504, DOI 10.1109/TNSRE.2016.2587939
   Yger F, 2015, EUR SIGNAL PR CONF, P2721, DOI 10.1109/EUSIPCO.2015.7362879
   Zhang Y, 2015, J NEUROSCI METH, V255, P85, DOI 10.1016/j.jneumeth.2015.08.004
NR 70
TC 3
Z9 3
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17118-7
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500020
DA 2024-07-18
ER

PT J
AU Veena, A
   Gowrishankar, S
AF Veena, A.
   Gowrishankar, S.
TI Automatic context-based health informatics system for diagnosing spinal
   deformity using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pre-processing; Segmentation; Hybrid (CNN-LSTM); Top-hat filter; Otsu
   method
ID SURGERY; SEGMENTATION; OUTCOMES
AB Abnormal spinal alignment, which caused low back pain, also it's one of the most common musculoskeletal ailments. As a result, it is a source of not just productivity loss but also personal anguish. By utilizing Convolutional Neural Network, the prediction of spinal deformity emerged to be a reliable model in medical imaging applications. One of the most difficult aspects of disease segmentation and categorization is detecting spinal deformities. However, the deep learning method aids in accurate and quick diagnosis. To classify normal as well as abnormal spinal X-ray images automatically, the deep learning approach is utilized. This research is utilized to detect X-ray image datasets, and a unique hybrid Convolution Neural Network-based Long Short-Term Memory classifier is applied. This proposed method extracts an automatic set of features for classifying spinal deformity abnormality. When compared to existing deep learning-based classifiers, a high computational spinal deformity prediction is proposed i.e., a hybrid Convolution Neural Network-based Long Short-Term Memory segmentation-based classifier. The analysis proved that the presented model is superior to existing spinal deformity prediction representations like accuracy 97.462%, recall 93.627%, precision 99.721%, specificity 93.289%, F1_score 97.182%, training time 102.50s, and Area Under ROC Curve 95.25% are concerned.
C1 [Veena, A.] Dr Ambedkar Inst Technol, Dept Comp Sci & Engn, Bengaluru 560056, Karnataka, India.
   [Gowrishankar, S.] Visvesvaraya Technol Univ VTU, Belagavi 590018, Karnataka, India.
C3 Visvesvaraya Technological University
RP Veena, A (corresponding author), Dr Ambedkar Inst Technol, Dept Comp Sci & Engn, Bengaluru 560056, Karnataka, India.
EM veenaa1@acm.org; gowrishankarnath@acm.org
RI S, Gowrishankar/AAI-5635-2020
OI S, Gowrishankar/0000-0002-9718-4365
CR Ahammad SH, 2020, IEEE SENS J, V20, P10092, DOI 10.1109/JSEN.2020.2992879
   Alsiddiky A, 2020, IEEE ACCESS, V8, P145278, DOI 10.1109/ACCESS.2020.3012719
   Antico M, 2021, IEEE Access
   Ayhan S, 2018, GLOB SPINE J, V8, P803, DOI 10.1177/2192568218772568
   Azad MA, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3634
   Babaee M, 2017, Intl Clin Neurosci J
   Bao HD, 2019, EUR SPINE J, V28, P2179, DOI 10.1007/s00586-019-06043-9
   Bari TJ, 2019, SPINE DEFORM, V7, P331, DOI 10.1016/j.jspd.2018.08.002
   Chen B, 2019, IEEE ACCESS, V7, P124596, DOI 10.1109/ACCESS.2019.2938402
   Daniels AH, 2019, SPINE DEFORM, V7, P481, DOI 10.1016/j.jspd.2018.09.013
   Dashti SMS, 2023, arXiv
   Delgarmi M, 2021, bioRxiv
   Diebo BG, 2018, SPINE, V43, P1176, DOI 10.1097/BRS.0000000000002583
   Dufvenberg M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10214967
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Galbusera F, 2019, EUR SPINE J, V28, P951, DOI 10.1007/s00586-019-05944-z
   Haldeman S, 2018, EUR SPINE J, V27, P889, DOI 10.1007/s00586-018-5724-8
   He Z, 2021, MED PHYS, V48, P1571, DOI 10.1002/mp.14719
   Kim JS., 2018, Spine deformity, V6, P762, DOI DOI 10.1016/J.JSPD.2018.03.003
   Kim KC, 2020, IEEE ACCESS, V8, P84618, DOI 10.1109/ACCESS.2020.2992081
   Mandel W, 2021, IEEE T MED IMAGING, V40, P491, DOI 10.1109/TMI.2020.3030741
   Matsukura Y, 2021, J CLIN MED, V10, DOI 10.3390/jcm10204737
   Nagamatsu M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101744
   Naresh-Babu J, 2023, GLOB SPINE J, V13, P1490, DOI 10.1177/21925682211037935
   Qadri SF, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010069
   Ramasamy M., 2020, IITM J Manage IT, V11, P22
   Tseng KK, 2021, J SUPERCOMPUT, V77, P3594, DOI 10.1007/s11227-020-03407-7
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17572-3
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500028
DA 2024-07-18
ER

PT J
AU Cui, JZ
   Li, XF
   Zhang, XL
   Huang, S
   Feng, YC
AF Cui, Jianzhao
   Li, Xiongfei
   Zhang, Xiaoli
   Huang, Sa
   Feng, Yuncong
TI Electronic explosives inspection: a fine-grained X-ray benchmark and
   few-shot prohibited phone detection model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security inspection; Electronic explosives; Imbalanced classification;
   Cost sensitive; Abnormal detection
AB Under the X-ray scanning, mobile phone explosive modified at the battery is stealthy, which increases the difficulty of security inspections to detect prohibited phones. This critical issue has not received enough attention. In this paper, we contribute the first modified mobile phone X-ray image benchmark for object recognition, named MPXray. MPXray focuses on the detection of prohibited items that are imbalanced and fine-grained. To deal with such anomaly detection task where few abnormal samples are obtained, we propose a few-shot prohibited phone detection (FSPPD) model based on contrastive learning. FSPPD uses an unsupervised sampling module(USM) to obtain anchors that are more representative of the data distribution, so as to construct balanced input for contrastive learning. For handling hard-to-classify caused by fine-grained samples, an anchor-wise contrastive loss(AW-CL) is designed to supervise models speed up the proximity between intra-class samples and separation between between-class samples. FSPPD is more suitable for applications where electronic products need to be checked individually. We evaluate our model on MPXray, from both the classification perspective and anomaly detection perspective. Experimental results show that our model achieves better recall for modified mobile phones. Additionally, we verify the generalization ability of the proposed model on the CIFAR10 dataset. Compared with widely used algorithms, our model achieves certain superiority in recall metrics.
C1 [Cui, Jianzhao; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Cui, Jianzhao; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Huang, Sa] Second Hosp Jilin Univ, Dept Radiol, Changchun 130041, Peoples R China.
   [Feng, Yuncong] Changchun Univ Technol, Coll Comp Sci & Engn, Changchun 130012, Peoples R China.
   [Feng, Yuncong] Changchun Univ Technol, Artificial Intelligence Res Inst, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Changchun
   University of Technology; Changchun University of Technology
RP Huang, S (corresponding author), Second Hosp Jilin Univ, Dept Radiol, Changchun 130041, Peoples R China.
EM cuijz19@mails.jlu.edu.cn; xiongfei@jlu.edu.cn; zhangxiaoli@jlu.edu.cn;
   huangsa@jlu.edu.cn; fengyuncong@ccut.edu.cn
RI zhang, zheng/KHY-8870-2024; Zhang, Xiaoli/ABC-2210-2021; zhang,
   yuanyuan/KHV-4459-2024; Li, Xintong/KHD-6915-2024; chen,
   huan/KEC-2019-2024; WANG, YILUN/KFB-0627-2024; wang, jin/KHD-7243-2024;
   WEI, ZHEN/KHU-7176-2024; Li, Bo/KHX-7246-2024; Liu,
   Junjie/KHV-6949-2024; zhang, zhang/KGK-5266-2024; Zhang,
   Yi/KHW-2039-2024; li, yuanfang/KHV-1697-2024
OI Huang, Sa/0000-0003-1465-7567
FU Scientific and Technological Developing Scheme of Jilin Province
   [20220203035SF]; National Natural Science Foundation of China
   [61801190]; Nature Science Foundation of Jilin Province [20180520029JH];
   Outstanding Young Talent Foundation of Jilin Province [20180101055JC];
   China Postdoctoral Science Foundation [2017M611323]; Industrial
   Technology Research and Development Funds of Jilin Province
   [JJKH20200997KJ]; "Thirteenth Five-Year Plan" Scientific Research
   Planning Project of Education Department of Jilin Province
   [JJKH20200997KJ, JJKH20200678KJ]; Fundamental Research Funds for the
   Central Universities ofJilin University
FX This work was supported by [Scientific and Technological Developing
   Scheme of Jilin Province] (Grant numbers [20220203035SF])This work was
   supported by [National Natural Science Foundation of China] (Grant
   numbers [61801190])This work was supported by [Nature Science Foundation
   of Jilin Province](Grant numbers [20180101055JC])This work was supported
   by [Outstanding Young Talent Foundation of Jilin Province] (Grant
   numbers [20180520029JH])This work was supported by [China Postdoctoral
   Science Foundation] (Grant numbers [2017M611323])This work was supported
   by [Industrial Technology Research and Development Funds of Jilin
   Province](Grant numbers [JJKH20200997KJ])This work was supported by
   ["Thirteenth Five-Year Plan" Scientific Research Planning Project of
   Education Department of Jilin Province] (Grant numbers [JJKH20200678KJ]
   and [JJKH20200997KJ])Partial financial support was received from
   [Fundamental Research Funds for the Central Universities ofJilin
   University]
CR Abati D, 2019, Arxiv, DOI arXiv:1807.01653
   Abdelaziz M, 2021, MULTIMED TOOLS APPL, V80, P10491, DOI 10.1007/s11042-020-09875-6
   Akcay S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108245
   Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   An J., 2015, Special Lecture on IE, V2, P1
   Arora Sanjeev, 2019, ICML
   Bendre N, 2020, arXiv
   Bergman L, 2020, Arxiv, DOI arXiv:2005.02359
   Bhowmik N, 2019, Arxiv, DOI arXiv:1909.11508
   Cao KD, 2019, ADV NEUR IN, V32
   Cao SS, 2019, CHIN AUTOM CONGR, P4360, DOI [10.1109/CAC48633.2019.8996933, 10.1109/cac48633.2019.8996933]
   Ding CB, 2022, PROC CVPR IEEE, P7378, DOI 10.1109/CVPR52688.2022.00724
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Guo XF, 2017, LECT NOTES COMPUT SC, V10635, P373, DOI 10.1007/978-3-319-70096-0_39
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hassan T, 2020, ACCV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jewell JT, 2022, IEEE WINT CONF APPL, P2856, DOI 10.1109/WACV51458.2022.00291
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Li CL, 2021, PROC CVPR IEEE, P9659, DOI 10.1109/CVPR46437.2021.00954
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu Y., 2021, arXiv
   Liu ZB, 2018, MULTIMED TOOLS APPL, V77, P10835, DOI 10.1007/s11042-017-5359-5
   Lopez-Martin M, 2022, INFORM FUSION, V79, P200, DOI 10.1016/j.inffus.2021.09.014
   Mei S, 2018, IEEE T INSTRUM MEAS, V67, P1266, DOI 10.1109/TIM.2018.2795178
   Mery D, 2020, IEEE ACCESS, V8, P145620, DOI 10.1109/ACCESS.2020.3015014
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   Miao CJ, 2019, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR.2019.00222
   Nasrabadi N.M, 2007, Pattern recognition and machine learning, V16
   Ouali Y, 2021, ECMLPKDD
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pang GS, 2021, Arxiv, DOI arXiv:2108.00462
   Perera P, 2019, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2019.00301
   Pourhashemi R, 2022, MULTIMED TOOLS APPL, V81, P31493, DOI 10.1007/s11042-022-13020-w
   Ravi S, 2016, PROC INT C LEARN REP
   Ruff L, 2020, Arxiv, DOI arXiv:1906.02694
   Ruff L, 2021, P IEEE, V109, P756, DOI 10.1109/JPROC.2021.3052449
   Saavedra D, 2021, NEURAL COMPUT APPL, V33, P7803, DOI 10.1007/s00521-020-05521-2
   Samuel D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9475, DOI 10.1109/ICCV48922.2021.00936
   Sarker IH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050754
   Sarker IH, 2020, MOBILE NETW APPL, V25, P1151, DOI 10.1007/s11036-019-01443-z
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Sheynin S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8475, DOI 10.1109/ICCV48922.2021.00838
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Suguna SK, 2015, A unified framework for network bandwidth and link latency detector based on cloud computing
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Sydney RCU Centre CMCR Institute SCQCR Hbku, 2019, Deep learning for anomaly detection: a survey
   Tian F, 2014, AAAI CONF ARTIF INTE, P1293
   van den Oord A, 2016, ADV NEUR IN, V29
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang YQ, 2020, Arxiv, DOI arXiv:1904.05046
   Wei YL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P138, DOI 10.1145/3394171.3413828
   Xia X., 2022, Neurocomputing
   Xie JY, 2016, Arxiv, DOI arXiv:1511.06335
   Ye F, 2021, ICIP
   Yu S, 2021, INFORM SCIENCES, V580, P598, DOI 10.1016/j.ins.2021.08.094
   Yu S, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113920
NR 59
TC 0
Z9 0
U1 13
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17388-1
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500005
DA 2024-07-18
ER

PT J
AU Liu, T
   Liu, FQ
   Wan, YY
   Hu, RY
   Zhu, YX
   Li, L
AF Liu, Tong
   Liu, Fangqi
   Wan, Yingying
   Hu, Rongyao
   Zhu, Yongxin
   Li, Li
TI Hierarchical graph learning with convolutional network for brain disease
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Functional connectivity; Graph neural network; Neurological disorders
   diagnosis; Graph learning
ID INDEPENDENT COMPONENT ANALYSIS; CONNECTIVITY
AB In computer-aided diagnostic systems, the functional connectome approach has become a common method for detecting neurological disorders. However, the existing methods either ignore the uniqueness of different subjects across the functional connectivities or neglect the commonality of the same disease for the functional connectivity of each subject, resulting in a lack of capacity of capturing a comprehensive functional model. To solve the issues, we develop a hierarchical graph learning with convolutional network that not only considers the unique information of each subject, but also takes the common information across subjects into account. Specifically, the proposed method consists of two structures, one is the individual graph model which selects the representative brain regions by combining each subject feature and its related brain region-based graph. The other is the population graph model to directly conduct classification performance by updating the information of each subject which considers both the subject itself and the nearest neighbours. Experimental results indicate that the proposed method on four real datasets outperforms the state-of-the-art approaches.
C1 [Liu, Tong; Hu, Rongyao] Massey Univ, Albany Campus, Auckland 0745, New Zealand.
   [Liu, Fangqi; Wan, Yingying] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
   [Zhu, Yongxin] Chinese Acad Sci, Jinan Lab Appl Nucl Sci, Inst High Energy Phys, Beijing 100039, Peoples R China.
   [Li, Li] Beijing Informat Sci & Technol Univ, Comp Sch, Beijing 100101, Peoples R China.
C3 Massey University; University of Electronic Science & Technology of
   China; Chinese Academy of Sciences; Institute of High Energy Physics,
   CAS; Beijing Information Science & Technology University
RP Hu, RY (corresponding author), Massey Univ, Albany Campus, Auckland 0745, New Zealand.; Li, L (corresponding author), Beijing Informat Sci & Technol Univ, Comp Sch, Beijing 100101, Peoples R China.
EM hurongyao123@gmail.com; lili_2018@cau.edu.cn
RI Hu, Rongyao/AAH-3834-2020
OI Hu, Rongyao/0000-0001-9989-1103
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Atwood J, 2016, NIPS, P2001
   Bruna J, 2014, Arxiv, DOI [arXiv:1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Chen Y, 2019, Arxiv, DOI arXiv:1912.07832
   Chou CC, 2018, NAT NEUROSCI, V21, P228, DOI 10.1038/s41593-017-0047-3
   Cummings J, 2019, ALZH DEMENT-TRCI, V5, P272, DOI 10.1016/j.trci.2019.05.008
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong CJ, 2020, PSYCHOL MED, V50, P1490, DOI 10.1017/S0033291719001429
   Du YH, 2020, NEUROIMAGE-CLIN, V28, DOI 10.1016/j.nicl.2020.102375
   Garcia-Bracamonte JE, 2019, IEEE T INSTRUM MEAS, V68, P1353, DOI 10.1109/TIM.2019.2900143
   Farahani FV, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00585
   Farooq A, 2017, IEEE CONF IMAGING SY, P111
   Fesseha A, 2021, INFORMATION, V12, DOI 10.3390/info12020052
   Gao W, 2018, SAUDI J BIOL SCI, V25, P1212, DOI 10.1016/j.sjbs.2017.11.022
   Hallquist MN, 2018, NETW NEUROSCI, V3, P1, DOI 10.1162/netn_a_00054
   Hejazi S, 2023, BRAIN SCI, V13, DOI 10.3390/brainsci13020246
   Hu RY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102782
   Hu RY, 2021, IEEE T MED IMAGING, V40, P3843, DOI 10.1109/TMI.2021.3099641
   Hu RY, 2020, WORLD WIDE WEB, V23, P1945, DOI 10.1007/s11280-019-00766-x
   Jang E, 2017, Arxiv, DOI arXiv:1611.01144
   Ji JZ, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107570
   Ji LX, 2022, NETW NEUROSCI, V6, P702, DOI 10.1162/netn_a_00254
   Jiang H, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104096
   Jiang Y, 2022, BRAIN STRUCT FUNCT, V227, P2285, DOI 10.1007/s00429-022-02521-x
   Kim P., 2017, MATLAB DEEP LEARNING, P121, DOI DOI 10.1007/978-1-4842-2845-6
   Kipf TN, 2016, ARXIV
   Kornfeld S, 2018, NEUROIMAGE-CLIN, V17, P359, DOI 10.1016/j.nicl.2017.10.016
   Ktena SI, 2018, NEUROIMAGE, V169, P431, DOI 10.1016/j.neuroimage.2017.12.052
   Lang S, 2014, NEUROSURGERY, V74, P453, DOI 10.1227/NEU.0000000000000307
   Li H., 2022, IEEE Trans Emerg Top Comput Intell, V7, P1
   Li XX, 2021, MED IMAGE ANAL, V74, DOI 10.1016/j.media.2021.102233
   Li Yandong, 2016, Journal of Computer Applications, V36, P2508, DOI 10.11772/j.issn.1001-9081.2016.09.2508
   Liu J, 2020, NEUROCOMPUTING, V400, P322, DOI 10.1016/j.neucom.2020.03.006
   Peng L, 2023, IEEE T MED IMAGING, V42, P2032, DOI 10.1109/TMI.2022.3188728
   Pijpker PAJ, 2021, INT J COMPUT ASS RAD, V16, P1447, DOI 10.1007/s11548-021-02407-z
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Seewoo BJ, 2021, NEUROSCI RES, V165, P26, DOI 10.1016/j.neures.2020.05.006
   Sompairac N, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20184414
   Tjerkaski J., 2022, Neuroimage: Rep, V2, DOI [10.1016/j.ynirp.2022.100079, DOI 10.1016/J.YNIRP.2022.100079]
   Wang LB, 2021, NETW NEUROSCI, V5, P83, DOI 10.1162/netn_a_00171
   Wang XX, 2018, NEUROSCI LETT, V668, P19, DOI 10.1016/j.neulet.2018.01.010
   Wei PX, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0270556
   Wu F, 2019, PR MACH LEARN RES, V97
   Wu LX, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2022.e12372
   Xiong ZJ, 2020, J CELL MOL MED, V24, P11607, DOI 10.1111/jcmm.15805
   Zamani J, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0267608
   Zhang X, 2022, IEEE J BIOMED HEALTH, V26, P5289, DOI 10.1109/JBHI.2021.3066832
   Zhang YS, 2017, SCI REP-UK, V7, DOI 10.1038/srep40039
   Zhang Y, 2019, PATTERN RECOGN, V88, P421, DOI 10.1016/j.patcog.2018.12.001
   Zhou HY, 2021, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP42928.2021.9506259
   Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390
   Zhu XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107175
NR 51
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17187-8
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Swamidorai, S
   Murthy, TS
   Sriharsha, K
AF Swamidorai, Sindhuja
   Murthy, T. Satyanarayana
   Sriharsha, K., V
TI Translating natural language questions to SQL queries (nested queries)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text-to-SQL nested queries; Spider
ID TEXT-TO-SQL
AB Real world questions are generally complex and need the user to extract information from multiple tables in a database using complex SQL queries like nested queries. Though the overall accuracy in translation of Natural Language queries to SQL queries lies close to 75%, the accuracy of complex queries is still quite less, around 60% in the current state-of-the-art models. In this vein, this study proposes to improve the current IRNet framework for translating natural language queries to nested SQL queries, one type of complex queries. Data oversampling is first used to boost the representation of nested queries in order to achieve this goal. Second, a novel loss function that computes the overall loss while accounting for the complexity of SQL, as measured by the quantity of SELECT columns and keywords in the SQL query. The proposed method exhibited a 5% improvement in prediction of hard and extra hard queries when tested on Spider's development dataset.
C1 [Swamidorai, Sindhuja] UpGrad, Data Sci, St-1, Bengaluru 500075, Karnataka, India.
   [Murthy, T. Satyanarayana] CBIT, Informat Technol, Hyderabad 560071, Telangana, India.
   [Sriharsha, K., V] NIT Trichy, Comp Applicat, Tiruchirappalli 620015, Tamil Nadu, India.
C3 Chaitanya Bharathi Institute of Technology; National Institute of
   Technology (NIT System); National Institute of Technology
   Tiruchirappalli
RP Sriharsha, K (corresponding author), NIT Trichy, Comp Applicat, Tiruchirappalli 620015, Tamil Nadu, India.
EM sindhuja.swamidorai@gmail.com; tsmurthy_it@cbit.ac.in
CR Abbas S., 2022, A Review of NLIDB with Deep Learning: Findings
   Aurelio YS, 2019, NEURAL PROCESS LETT, V50, P1937, DOI 10.1007/s11063-018-09977-1
   Bai T, 2021, IEEE ACCESS, V9, P4233, DOI 10.1109/ACCESS.2020.3048164
   Baig Muhammad Shahzaib, 2022, International Journal of Innovations in Science and Technology, V4, P147
   Bogin B, 2019, Arxiv, DOI arXiv:1905.06241
   Brunner U, 2021, PROC INT CONF DATA, P2177, DOI 10.1109/ICDE51399.2021.00220
   Cai RC, 2021, ADV NEUR IN, V34
   Calimeri F, 2021, THEOR PRACT LOG PROG, V21, P80, DOI 10.1017/S1471068419000449
   Cao R., 2021, arXiv
   Chen Z, 2021, Arxiv, DOI arXiv:2104.04689
   Choi D, 2021, COMPUT LINGUIST, V47, P309, DOI [10.1162/coli_a_00403, 10.1162/COLI_a_00403]
   Clark K, 2020, Arxiv, DOI arXiv:2003.10555
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Gan YJ, 2021, Arxiv, DOI arXiv:2109.05153
   Guo AB, 2021, NEUROCOMPUTING, V465, P359, DOI 10.1016/j.neucom.2021.08.134
   Guo JQ, 2019, Arxiv, DOI [arXiv:1905.08205, 10.48550/arXiv.1905.08205]
   Hui BY, 2022, Arxiv, DOI arXiv:2203.06958
   Li Q, 2020, IEEE T IND INFORM, V16, P2542, DOI 10.1109/TII.2019.2952929
   Lin KV, 2019, Arxiv, DOI arXiv:1905.13326
   Parikh P., 1999, Auto-Query-A simple natural language to SQL query generator for an e-learning platform
   Rubin O, 2021, Arxiv, DOI arXiv:2010.12412
   Scholak T, 2021, Arxiv, DOI arXiv:2109.05093
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0
   Sutskever I, 2014, ADV NEUR IN, V27
   Wang BL, 2021, Arxiv, DOI arXiv:1911.04942
   Wong A., 2021, IEEE International Conference on Recent Advances in Systems Science and Engineering (RASSE), V2021, P1
   Xie TB, 2022, Arxiv, DOI arXiv:2201.05966
   Yu T, 2018, Arxiv, DOI arXiv:1810.05237
   Yu T, 2018, Arxiv, DOI arXiv:1804.09769
   Yu T, 2019, Arxiv, DOI arXiv:1809.08887
   Zenan Ning, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P143, DOI 10.1109/ICPECA51329.2021.9362554
   Zhong V., 2017, arXiv
NR 32
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 21
PY 2023
DI 10.1007/s11042-023-16987-2
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W1VN4
UT WOS:001089581100008
DA 2024-07-18
ER

PT J
AU Lin, XQ
   Liang, YC
   Zhang, Y
   Hu, YL
   Yin, BC
AF Lin, Xuanqi
   Liang, Yuchen
   Zhang, Yong
   Hu, Yongli
   Yin, Baocai
TI IE-GAN: a data-driven crowd simulation method via generative adversarial
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crowd simulation; Deep learning; Generative adversarial networks;
   Pedestrian trajectory
ID HUMAN TRAJECTORY PREDICTION; MODEL; ATTENTION
AB Crowd simulation has been widely used in evacuation exercises, games or movie manufacturing, and many other fields. How to plan reasonable trajectories for pedestrians in a scene is always one of the critical problems in crowd simulation. Traditional simulation methods have the problem of large differences between simulated and actual trajectories, and it is difficult to generate near-real and reasonable multimodal pedestrian trajectories. In this paper, we propose a novel method utilizing generative models for crowd simulation: GAN with Incubator and Extender (IE-GAN). This data-driven model learns the movement laws of pedestrians from real datasets, and simulates a full movement trajectory for the "dummy" without corresponding situations in the dataset through a unique model architecture. In our method, the generated initial trajectory and further trajectories constitute the full trajectory of the "dummy". Incubator networks based on long-term memory network (LSTM) are used to generate the initial trajectory, and the further trajectory is generated by the Extender, which is based on a generative adversarial network (GAN). The experimental results show that the trajectories generated by our model can approach real human's trajectories.
C1 [Lin, Xuanqi; Liang, Yuchen; Zhang, Yong; Hu, Yongli; Yin, Baocai] Beijing Univ Technol, Beijing Artificial Intelligence Inst, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, 100, Ping Leyuan Community, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Zhang, Y (corresponding author), Beijing Univ Technol, Beijing Artificial Intelligence Inst, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, 100, Ping Leyuan Community, Beijing 100124, Peoples R China.
EM sophialin@emails.bjut.edu.cn; ycl@vip.sina.com;
   zhangyong2010@bjut.edu.cn; huyongli@bjut.edu.cn; ybc@bjut.edu.cn
RI Zhang, Yong/AAW-8880-2021
OI Zhang, Yong/0000-0001-6650-6790
FU National Key R&D Program of China [2021ZD0111902]; NSFC [62072015,
   U21B2038, U19B2039]; Beijing Natural Science Foundation [4222021]; R&D
   Program of Beijing Municipal Education Commission [KZ202210005008]
FX This paper is supported by National Key R&D Program of China
   (No.2021ZD0111902), NSFC (No.62072015, U21B2038, U19B2039), Beijing
   Natural Science Foundation (No. 4222021), R&D Program of Beijing
   Municipal Education Commission (No. KZ202210005008).
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Amirian J, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P7, DOI 10.1145/3328756.3328769
   Amirian J, 2019, IEEE COMPUT SOC CONF, P2964, DOI 10.1109/CVPRW.2019.00359
   Antonini G, 2006, TRANSPORT RES B-METH, V40, P667, DOI 10.1016/j.trb.2005.09.006
   Balani N, 2022, MULTIMED TOOLS APPL, V81, P36699, DOI 10.1007/s11042-021-11604-6
   Chen K, 2022, IEEE T INTELL TRANSP, V23, P20046, DOI 10.1109/TITS.2022.3170874
   Duan JH, 2022, AAAI CONF ARTIF INTE, P542
   Fernando T, 2018, NEURAL NETWORKS, V108, P466, DOI 10.1016/j.neunet.2018.09.002
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2014, Arxiv, DOI arXiv:1308.0850
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hug R, 2018, IEEE INT C INTELL TR, P2684, DOI 10.1109/ITSC.2018.8569478
   Kingma D. P., 2014, arXiv
   Konev S., 2022, arXiv
   Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lee N., 2017, DESIRE: Distant future prediction in dynamic scenes with interacting agents, P336
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Liu BX, 2018, SIMUL MODEL PRACT TH, V84, P190, DOI 10.1016/j.simpat.2018.02.007
   Luber M, 2010, IEEE INT CONF ROBOT, P464, DOI 10.1109/ROBOT.2010.5509779
   Lv P, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3250485
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Mohamed Abduallah, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14412, DOI 10.1109/CVPR42600.2020.01443
   Pang SM, 2022, IEEE T INTELL TRANSP, V23, P24609, DOI 10.1109/TITS.2022.3193442
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Shah Ashita, 2022, Soft Computing and Signal Processing: Proceedings of 3rd ICSCSP 2020. Advances in Intelligent Systems and Computing, P553, DOI 10.1007/978-981-16-1249-7_52
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Shi LS, 2021, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR46437.2021.00888
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Wei X, 2018, NEUROCOMPUTING, V310, P125, DOI 10.1016/j.neucom.2018.05.022
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu P, 2022, LECT NOTES COMPUT SC, V13664, P511, DOI 10.1007/978-3-031-19772-7_30
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Ye J., 2007, advances in neural information processing systems, vol20
   Zhang GZ, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P2439, DOI 10.1145/3534678.3539440
   Zhao MB, 2013, IEEE ACM DIS SIM, P125, DOI 10.1109/DS-RT.2013.21
   Zhou L, 2022, APPL INTELL, V52, P11434, DOI 10.1007/s10489-021-02997-w
NR 43
TC 1
Z9 1
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17346-x
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6NT6
UT WOS:001085957900003
DA 2024-07-18
ER

PT J
AU Kuila, S
   Dhanda, N
   Joardar, S
AF Kuila, Sumanta
   Dhanda, Namrata
   Joardar, Subhankar
TI ECG signal classification using DEA with LSTM for arrhythmia detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classificatio; Feature Selection; Extreme Learning Machine; ECG
   segmentation strategy; Long short term memory; Differential Evolution;
   Focal Loss
ID FEATURE-EXTRACTION
AB The Electrocardiogram (ECG) signal analysis is an important and mandatory requirement to detect different heart diseases. After the pre-processing of the raw ECG signal classification and feature extraction are done to detect cardiac arrhythmia. In this study ECG signal classification is done by Differential Evaluation Algorithm (DEA) with Long short-term memory (LSTM). Several deep learning concepts are used for classification of ECG signal and heart arrhythmia detection. Before signal classification ECG signals are pre-processed for feature extraction. Initially ECG signal features are selected and then based on classification requirement the features are reduced for feature extraction. Usually ECG beat data carries a great deal of imbalance category which are rectified by recurrent neural network model with LSTM. The DEA is used to optimize the focal loss (FL). For the classification complex variation of the imbalance ECG beats works with the LSTM with the recommended focal loss. LSTM network gives emphasis on different ECG features and the focal loss is used to solve category imbalance by reducing the weights of the normal ECG beats. The simulation of the experiment is done by MIT-BIH arrhythmia database where the experiment result shows that LSTM network optimized with DEA overcomes the focal loss up to a certain level to avoid the problem of imbalance ECG dataset. In this experiment the accuracy achieved is 98.23%. The study works with the concept of dual structure of recurrent neural network model with multilayered dilated neural network model.
C1 [Kuila, Sumanta; Joardar, Subhankar] Haldia Inst Technol, Haldia, India.
   [Dhanda, Namrata] Amity Univ Uttar Pradesh, Lucknow, India.
C3 Haldia Institute of Technology
RP Kuila, S (corresponding author), Haldia Inst Technol, Haldia, India.
EM sumanta.kuila@gmail.com; ndhanda510@gmail.com;
   subhankarranchi@yahoo.co.in
RI Dhanda, Namrata/JZT-2012-2024
OI Kuila, Sumanta/0000-0002-6088-6806
CR Amrani M, 2018, NEURAL COMPUT APPL, V30, P2047, DOI 10.1007/s00521-018-3616-9
   Andersen RS, 2019, EXPERT SYST APPL, V115, P465, DOI 10.1016/j.eswa.2018.08.011
   [Anonymous], 2018, Int J Adv Soft Comput Appl
   [Anonymous], 2011, Int J Inf Technol Knowl Manag
   Anwar SM, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/1380348
   Atal DK, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105607
   Chen TH, 2013, IEEE J EM SEL TOP C, V3, P75, DOI 10.1109/JETCAS.2013.2242772
   COAST DA, 1990, IEEE T BIO-MED ENG, V37, P826, DOI 10.1109/10.58593
   Diker A, 2020, MED HYPOTHESES, V136, DOI 10.1016/j.mehy.2019.109515
   Fan XM, 2018, IEEE J BIOMED HEALTH, V22, P1744, DOI 10.1109/JBHI.2018.2858789
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Jiang W, 2007, IEEE T NEURAL NETWOR, V18, P1750, DOI 10.1109/TNN.2007.900239
   Kachuee M, 2018, IEEE INT CONF HEALT, P443, DOI 10.1109/ICHI.2018.00092
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Kuila S., 2020, INT J EL COMP ENG SY, V10, P6598, DOI [10.11591/ijece.v10i6.pp6598-6605, DOI 10.11591/IJECE.V10I6.PP6598-6605]
   Kuila S., 2021, J THEOR APPL INF TEC, V99, P1817
   Kuila S, 2022, MULTIMED TOOLS APPL, V81, P25233, DOI 10.1007/s11042-022-11957-6
   Kuila S, 2020, LECT NOTES ELECTR EN, V602, P417, DOI 10.1007/978-981-15-0829-5_41
   Laishram A, 2022, INT J INTERACT MULTI, V7, P69, DOI 10.9781/ijimai.2021.10.009
   LI CW, 1995, IEEE T BIO-MED ENG, V42, P21, DOI 10.1109/10.362922
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Li W, 2019, IEEE ACCESS, V7, P25627, DOI 10.1109/ACCESS.2018.2877793
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Martis RJ, 2013, Int J Neural Syst
   Meng HH, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P7, DOI 10.1109/CSE.2014.36
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Oh SL, 2019, COMPUT BIOL MED, V105, P92, DOI 10.1016/j.compbiomed.2018.12.012
   Osowski S, 2004, IEEE T BIO-MED ENG, V51, P582, DOI 10.1109/TBME.2004.824138
   Pandey SK, 2020, PROCEDIA COMPUT SCI, V167, P2181, DOI 10.1016/j.procs.2020.03.269
   Patro K.K., 2017, Journal of Engineering Science Technology Review, V10, P1, DOI [DOI 10.25103/JESTR.106.01, 10.25103/jestr.106, DOI 10.25103/JESTR.106]
   physicsworld, ABOUT US
   Prasad GK, 2003, TENCON IEEE REGION, P227, DOI 10.1109/TENCON.2003.1273320
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1707.01836
   Saadatnejad S, 2020, IEEE J BIOMED HEALTH, V24, P515, DOI 10.1109/JBHI.2019.2911367
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Singh BN, 2006, DIGIT SIGNAL PROCESS, V16, P275, DOI 10.1016/j.dsp.2005.12.003
   Srivastava V, 2021, INT J INTERACT MULTI, V6, P18, DOI 10.9781/ijimai.2020.11.003
   Yildirim Ö, 2018, COMPUT BIOL MED, V102, P411, DOI 10.1016/j.compbiomed.2018.09.009
   Yu Sung-Nien, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3090
NR 41
TC 2
Z9 2
U1 15
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17095-x
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000016
DA 2024-07-18
ER

PT J
AU Vijay, K
   Samuel, P
   Krishna, BV
   Manikandan, J
AF Vijay, K.
   Samuel, Prithi
   Krishna, Brahmadesam Viswanathan
   Manikandan, J.
TI Exploration of sentiment analysis in twitter propaganda: a deep dive
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; SVM; Random Forest; Ensemble machine
   learning; ANN; LSTM; Bi-LSTM
ID NEURAL-NETWORKS
AB Twitter boasts 319 million daily active users, making it an invaluable asset for public figures and businesses looking to cultivate positive public image. Businesses can leverage sentiment analysis for real-time polling on various social media platforms allowing them to gauge public sentiment and opinion accurately. Recently, academic researchers focused on sentiment analysis as an approach for Twitter propaganda analysis. Text sentiment analysis is an automated process that offers valuable insight into the content of a text segment. It can reveal whether it conveys factual or subjective information and reveal its polarity; for Twitter sentiment classification this goal primarily lies with determining whether tweets have positive or negative undertones; researchers utilize various Machine Learning (ML), Deep Learning (DL) and other models to accomplish this task. Present research work utilising classification algorithms such as Support Vector Machines are among the most frequently utilized ML/DL models for sentiment analysis, along with Random Forest, Ensemble Machine Learning, Artificial Neural Networks, Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM) for effective classification. Also, for preprocessing the tweets API, techniques such as filtering, tokenization, removal of stopwords, stemming and lemmatization have been used. Then preprocessed input is fed as input to the TF-IDF and Bag of Words for vectorize the input. Then classification has been performed with aforementioned models. Finally, performance evaluation metrices have been perfomed, from that out of all these models used for sentiment analysis on Twitter dataset, Bidirectional LSTM has proven itself most accurate at detecting sentiment with an accuracy rate of 98.14%, 98.39% in vectorize techniques includes TF-IDF and Bag of Words-making this tool invaluable when conducting voice analyses on this platform.
C1 [Vijay, K.; Manikandan, J.] Rajalakshmi Engn Coll, Dept Comp Sci & Engn, Chennai, India.
   [Samuel, Prithi] SRM Inst Sci & Technol, Sch Comp, Dept Computat Intelligence, Kattankulathur Campus, Chennai, India.
   [Krishna, Brahmadesam Viswanathan] KCG Coll Technol, Dept Comp Sci & Engn, Chennai, India.
   [Manikandan, J.] St Josephs Coll Engn, Dept Informat Technol, OMR, Chennai, India.
C3 Rajalakshmi Engineering College; SRM Institute of Science & Technology
   Chennai; St. Joseph's College of Engineering, Chennai
RP Vijay, K (corresponding author), Rajalakshmi Engn Coll, Dept Comp Sci & Engn, Chennai, India.
EM vijayk1234k@gmail.com
RI J, Manikandan/JMC-2923-2023; K, Vijay/IUQ-5091-2023; Krishna,
   Brahmadesam Viswanathan/AAP-8312-2021; k, vijay/AAP-8257-2021
OI Krishna, Brahmadesam Viswanathan/0000-0002-1750-9407; k,
   vijay/0000-0001-5957-8737
CR Ahmed K, 2015, IEEE SYS MAN CYBERN, P2174, DOI 10.1109/SMC.2015.380
   Alqarni A, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010016
   [Anonymous], 2006, P 10 C COMPUTATIONAL
   Bhatia P., 2015, Better Document-level Sentiment Analysis from RST Discourse Parsing
   Bibi M, 2022, PATTERN RECOGN LETT, V158, P80, DOI 10.1016/j.patrec.2022.04.004
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Çeliktug MF, 2018, IEEE INT CONF BIG DA, P2098, DOI 10.1109/BigData.2018.8621970
   Chauhan UA, 2020, WORLD WIDE WEB, V23, P1811, DOI 10.1007/s11280-020-00785-z
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Eliaçik AB, 2015, IEEE INT CONF INNOV, P46, DOI 10.1109/INNOVATIONS.2015.7381513
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Goel S, 2018, 2018 11 INT C CONT C, P1
   Gupta B., 2017, International Journal of Computer Applications, V165, P29, DOI DOI 10.5120/IJCA2017914022
   Hsu Dennis, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P915, DOI 10.1145/3110025.3110110
   Hurst M. F., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5296, P27, DOI 10.1117/12.529422
   Jagadeesan M., 2022, 2022 International Conference on Automation, Computing and Renewable Systems (ICACRS), P681, DOI 10.1109/ICACRS55517.2022.10029114
   Jagdale RS, 2016, Int J Comput Sci Mob Computing, V5, P475
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Kaur C, 2020, PROCEEDINGS OF THE 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND SECURITY (ICCCS-2020), DOI 10.1109/icccs49678.2020.9277251
   Kharche SR, 2015, Int J Comput Sci Appl, V8
   Ko Y., 2000, P 18 C COMPUTATIONAL, V1, P453, DOI DOI 10.3115/990820.990886
   Kumar S, 2019, INFORM FUSION, V52, P41, DOI 10.1016/j.inffus.2018.11.001
   Kumar S, 2016, INT CONF RELI INFO, P207, DOI 10.1109/ICRITO.2016.7784953
   Lei Wang, 2017, 2017 9th Computer Science and Electronic Engineering (CEEC). Proceedings, P89, DOI 10.1109/CEEC.2017.8101605
   Ling MJ, 2020, IEEE T COMPUT SOC SY, V7, P983, DOI 10.1109/TCSS.2020.2998092
   Liu B., 2022, Sentiment analysis and opinion mining
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Modak S, 2022, P 3 INT C COMP COMM, P651
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Prithi S, 2016, Review on Grouping Algorithms for Finite State Automata
   Raheja S, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P704, DOI 10.1109/Confluence51648.2021.9377048
   Raj Arockia Y., 2012, American Journal of Applied Sciences, V9, P66, DOI 10.3844/ajassp.2012.66.70
   Rajeswari P., 2018, Int J Eng Technol, V7, P146
   Rathi M, 2018, INT CONF CONTEMP, P365
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5211949
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Saitulasi K, 2021, INT CONF COMP COMMUN, DOI 10.1109/ICCCI50826.2021.9456999
   Sharma R., 2014, Opinion mining of movie reviews at document level
   Shenoy A, 2020, Arxiv, DOI arXiv:2002.08267
   Shrestha N., 2019, International Journal on Soft Computing, Artificial Intelligence and Applications (IJSCAI), V8, P1, DOI 10.5121/ijscai.2019.8101
   Singh VK., 2014, ECTI Transa Comput Info Tech (ECTI-CIT), V8, P67, DOI [10.37936/ecti-cit.201481.54389, DOI 10.37936/ECTI-CIT.201481.54389]
   Sowmia K. R., 2023, Smart Trends in Computing and Communications: Proceedings of SmartCom 2022. Lecture Notes in Networks and Systems (396), P257, DOI 10.1007/978-981-16-9967-2_25
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Subramaniam G., 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P998, DOI 10.1109/ICECDS.2017.8389587
   Surnar A, 2017, Int J Adv Res Comput, V6, P2278
   Tu Z, 2012, P 50 ANN M ASS COMP
   Vijavakumar R., 2022, 2022 International Conference on Electronic Systems and Intelligent Computing (ICESIC), P370, DOI 10.1109/ICESIC53714.2022.9783481
   Vijay K., 2022, Remit Rev, V7, P1
   Vijay P, 2020, Int J Comput Sci Mobile Comput, V9, P96
   Vinodhini G, 2012, International Journal, V2, P282
   Vyas Piyush, 2022, IEEE Transactions on Technology and Society, V3, P100, DOI 10.1109/TTS.2021.3108963
   Wang MD, 2020, INFORMATION, V11, DOI 10.3390/info11020092
   Yang XYL, 2019, PROCEDIA COMPUT SCI, V147, P361, DOI 10.1016/j.procs.2019.01.239
   Ye Wu, 2011, Proceedings of the 2011 International Conference on Future Computer Sciences and Application (ICFCSA 2011), P119, DOI 10.1109/ICFCSA.2011.34
   Yessenalina Ainur., 2010, Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, P1046
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
NR 57
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17383-6
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000006
DA 2024-07-18
ER

PT J
AU Yuan, Y
   He, HJ
   Chen, F
AF Yuan, Yuan
   He, Hongjie
   Chen, Fan
TI JPEG Bitstreams encryption with CPA-secure and file size reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE JPEG encryption; VLC mapping; Chosen plaintext attack; File size
   reduction; Alternating current codes
ID IMAGE
AB An adaptive key of He's scheme is generated based on the minimum coded unit histogram (MCUH) of an original image, which can improve the ability against the known-plaintext attack while achieving file size preservation and format compatibility. However, it is vulnerable to the chosen-plaintext attack (CPA) since the MCUH, which is unchanged during encryption, can be used to reproduce the adaptive key. To change the MCUH and reduce file size, some alternating current codes (ACCs) are randomly removed and reversibly embedded into the image by variable length code (VLC) mapping. Firstly, the threshold T, i.e., the maximum number of ACCs that can be removed while ensuring a reduced file size of encrypted JPEG image, is adaptively calculated after the monotonicity of VLC mapping is discussed. And then, according to the user's key, the actual number of ACCs to be removed is randomly selected in the integer interval [1, T] to reduce the possibility of reproducing the adaptive key under CPA. Experimental results demonstrate that the proposed scheme effectively improves the ability against CPA since the adaptive-key reproduction probability of the proposed scheme is reduced from 100% of He's scheme to smaller than 1.15x10(-1398). Moreover, the file size of the encrypted JPEG generated by the proposed scheme is smaller than that of He's scheme and the original image.
C1 [Yuan, Yuan; He, Hongjie] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Peoples R China.
   [Chen, Fan] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu, Peoples R China.
C3 Southwest Jiaotong University; Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu, Peoples R China.
EM fchen@swjtu.edu.cn
FU This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant U1936113. [U1936113]; National
   Natural Science Foundation of China (NSFC)
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant U1936113.
CR Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Cheng H, 2016, J VIS COMMUN IMAGE R, V40, P111, DOI 10.1016/j.jvcir.2016.06.016
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Du Y, 2022, IEEE T DEPEND SECURE, V19, P1420, DOI 10.1109/TDSC.2020.3013326
   He H, 2023, J Vis Commun Image Represent, V90, P1
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   He JH, 2018, IEEE T MULTIMEDIA, V20, P2645, DOI 10.1109/TMM.2018.2817065
   Hua Z, 2023, IEEE Transactions on Circuits and Systems for Video Technology, V33
   Huang YX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2715, DOI 10.1109/ICASSP39728.2021.9415118
   Independent jpeg group, 2019, About us
   Itier V, 2020, IEEE T CIRC SYST VID, V30, P646, DOI 10.1109/TCSVT.2019.2894520
   Li PY, 2023, IEEE T INTELL TRANSP, V24, P7687, DOI 10.1109/TITS.2022.3217304
   Li PY, 2020, IET SIGNAL PROCESS, V14, P475, DOI 10.1049/iet-spr.2019.0276
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   Li WH, 2007, INT J COMPUT MATH, V84, P1367, DOI 10.1080/00207160701294376
   Minemura K, 2012, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2012.6466845
   Mitchell J, 1992, ITU-T Recommendation T
   Niu XA, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P308, DOI 10.1109/IIH-MSP.2008.207
   Ong S, 2013, IEEE IMAGE PROC, P4574, DOI 10.1109/ICIP.2013.6738942
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Peiya Li, 2021, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 16th International Conference on IIHMSP in Conjunction with the 13th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 211), P140, DOI 10.1007/978-981-33-6420-2_18
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2023, IEEE T MULTIMEDIA, V25, P2528, DOI 10.1109/TMM.2022.3148591
   Qu LF, 2022, IEEE T MULTIMEDIA, V24, P2924, DOI 10.1109/TMM.2021.3090588
   Sheidani S, 2021, IEEE T INF FOREN SEC, V16, P3647, DOI 10.1109/TIFS.2021.3080497
   Shreyamsha Kumar BK, 2010, SIGNAL IMAGE VIDEO P, V4, P419, DOI 10.1007/s11760-009-0131-6
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Yuan Y, 2022, LECT NOTES COMPUT SC, V13180, P58, DOI 10.1007/978-3-030-95398-0_5
   Zhang QC, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886779
   [郑梦阳 Zheng Mengyang], 2018, [信息安全学报, Journal of Cyber Security], V3, P55
NR 34
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17154-3
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000015
DA 2024-07-18
ER

PT J
AU Ren, ZX
   Guo, JF
AF Ren, Zhenxing
   Guo, Jianfeng
TI On fault diagnosis using image-based deep learning networks based on
   vibration signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fault diagnosis; Rotating machinery; Empirical mode decomposition;
   Symmetrized dot pattern; Image similarity; Pattern recognition
ID CONVOLUTIONAL NEURAL-NETWORK; BEARINGS; MOTOR
AB With the development of complex and intelligent mechanical products, the reliability of rotating machinery equipment increasingly gains much attention. As essential parts of rotating machinery equipment, bearing failures are becoming one of the leading root causes of mechanical failures. The critical problem of the bearing fault diagnosis is the method based on mechanical vibration signals. However, an accurate fault diagnosis is constantly challenged due to the nonlinearity and non-stationarity of vibration signals. This work investigates the fault diagnosis of bearing based on vibration signals, and an image-based deep learning method is proposed, in which vibration signals in the time domain are transformed into intrinsic mode functions (IMFs), and uncorrelated IMFs are removed. Rest IMFs reconstruct signals, which are transferred into symmetrized dot pattern (SDP) images. The fault diagnosis is then formulated as an image classification problem and solved with deep learning networks. In this work, the parameters of SDP are selected by optimizing an image similarity to improve the classification accuracy. The presented method is demonstrated with an experimental fault diagnosis of rolling bearings, and results show that the accuracy of the proposed method can be up to 99%.
C1 [Ren, Zhenxing; Guo, Jianfeng] Taiyuan Univ Technol, Coll Data Sci, Jinzhong, Shanxi, Peoples R China.
C3 Taiyuan University of Technology
RP Ren, ZX (corresponding author), Taiyuan Univ Technol, Coll Data Sci, Jinzhong, Shanxi, Peoples R China.
EM renzhenxing@tyut.edu.cn
FU This research is supported by the National Natural Science Foundation of
   China (Grant No. 12204345), Natural Science Foundation of Shanxi
   Province, China (Grant No. 20210302123188), and Natural Science
   Foundation for Young Scientists of Shanxi Province, Ch [12204345];
   National Natural Science Foundation of China [20210302123188]; Natural
   Science Foundation of Shanxi Province, China [202103021223107]; Natural
   Science Foundation for Young Scientists of Shanxi Province, China
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 12204345), Natural Science Foundation of Shanxi
   Province, China (Grant No. 20210302123188), and Natural Science
   Foundation for Young Scientists of Shanxi Province, China (Grant No.
   202103021223107). The authors would like to thank anonymous reviewers
   for carefully reading the paper.
CR Ahmed HOA, 2021, CHIN J MECH ENG-EN, V34, DOI 10.1186/s10033-021-00553-8
   Akhenia P, 2022, P I MECH ENG C-J MEC, V236, P3864, DOI 10.1177/09544062211043132
   Aljemely AH, 2021, APPL INTELL, V51, P6932, DOI 10.1007/s10489-021-02252-2
   Amarouayache IIE, 2020, INT J ADV MANUF TECH, V107, P4077, DOI 10.1007/s00170-020-05315-9
   Bai RF, 2019, CHIN CONT DECIS CONF, P3291, DOI [10.1109/CCDC.2019.8833026, 10.1109/ccdc.2019.8833026]
   Bai RX, 2021, MEASUREMENT, V184, DOI 10.1016/j.measurement.2021.109885
   Benmoussa S., 2020, Artificial Intelligence Techniques for a Scalable Energy Transition: Advanced Methods, Digital Technologies, Decision Support Tools, and Applications, Ved, P157, DOI [10.1007/978-3-030-42726-9_7, DOI 10.1007/978-3-030-42726-9_7]
   Cen J, 2023, P I MECH ENG C-J MEC, V237, P2201, DOI 10.1177/09544062221136490
   Choudhary A, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109196
   Dibaj A, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114094
   Fen W, 2016, 2016 13 INT C UB ROB
   Feng W., 2016, IEEE Int Conf Prognostics Health Manag (ICPHM), V2016, P1
   Fu Q, 2018, IEEE SENS J, V18, P5024, DOI 10.1109/JSEN.2018.2830109
   Gai JB, 2018, SHOCK VIB, V2018, DOI 10.1155/2018/8218657
   Gu YK, 2020, MEASUREMENT, V156, DOI 10.1016/j.measurement.2020.107616
   Han S, 2021, J SENSORS, V2021, DOI 10.1155/2021/6699637
   Hao SJ, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107802
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu MT, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108868
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang NE, 2000, P SOC PHOTO-OPT INS, V4056, P197, DOI 10.1117/12.381681
   Huang WY, 2019, NEUROCOMPUTING, V359, P77, DOI 10.1016/j.neucom.2019.05.052
   Iqbal M, 2022, J VIB ENG TECHNOL, V10, P1613, DOI 10.1007/s42417-022-00468-1
   Khan MA, 2020, J SUPERCOMPUT, V76, P8086, DOI 10.1007/s11227-018-2711-0
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lessmeier C., 2016, KAt-DataCenter website of the Chair of Design and Drive Technology
   Li H, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107293
   Li JM, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107419
   Li YB, 2016, MECH MACH THEORY, V98, P114, DOI 10.1016/j.mechmachtheory.2015.11.010
   Liu J, 2021, J Phys: Conf Ser, V1948
   Long Z, 2022, IEEE T IND INFORM, V18, P1605, DOI 10.1109/TII.2021.3084615
   Long Z, 2021, IEEE SENS J, V21, P21798, DOI 10.1109/JSEN.2021.3102019
   Pang B, 2022, MACHINES, V10, DOI 10.3390/machines10070550
   Plakias S, 2020, NEUROCOMPUTING, V405, P208, DOI 10.1016/j.neucom.2020.04.143
   Ren ZX, 2023, ATMOS POLLUT RES, V14, DOI 10.1016/j.apr.2023.101731
   Ren ZX, 2023, MEAS CONTROL-UK, V56, P844, DOI 10.1177/00202940221135903
   Ren Z, 2013, AT-AUTOM, V61, P155, DOI 10.1524/auto.2013.0023
   Sharma K, 2022, P I MECH ENG J-J ENG, V236, P2439, DOI 10.1177/13506501221082746
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun YJ, 2022, MEASUREMENT, V190, DOI 10.1016/j.measurement.2022.110702
   Sun YJ, 2021, MECH SYST SIGNAL PR, V159, DOI 10.1016/j.ymssp.2021.107817
   Sun YJ, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109100
   Tang Y, 2022, IEEE T IND INFORM, V18, P3702, DOI 10.1109/TII.2021.3112696
   Touzout W, 2020, ADV MECH ENG, V12, DOI 10.1177/1687814020980569
   Wang H, 2020, IEEE T INSTRUM MEAS, V69, P2377, DOI 10.1109/TIM.2019.2956332
   Wang LM, 2018, CHIN J MECH ENG-EN, V31, DOI 10.1186/s10033-018-0202-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie ZJ, 2023, MEAS CONTROL-UK, V56, P518, DOI 10.1177/00202940221107620
   Yang HX, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac41a5
   Yu H, 2020, ISA T, V107, P385, DOI 10.1016/j.isatra.2020.07.025
   Zhao BX, 2020, IEEE T INSTRUM MEAS, V69, P9557, DOI 10.1109/TIM.2020.3005113
   Zhao J, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109088
   Zhu XX, 2019, MEASUREMENT, V138, P526, DOI 10.1016/j.measurement.2019.02.022
   Zhu ZY, 2019, NEUROCOMPUTING, V323, P62, DOI 10.1016/j.neucom.2018.09.050
NR 55
TC 1
Z9 1
U1 13
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17384-5
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600011
DA 2024-07-18
ER

PT J
AU Saini, JK
AF Saini, Jaspal Kaur
TI LSTM based deep learning approach to detect online violent activities
   over dark web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Deep learning; LSTM; Social media; Dark web
AB Dark web discussion forums have become one of the digital communication medium over the public infrastructure of Internet. Monitoring and analysing data from dark web discussion forums and social media platforms can unfold useful insights to the security intelligence.Through our research work we demonstrate the possibility of detecting online terrorist activities from dark web forums using machine learning based and deep learning based algorithms. In order to achieve desired objectives, we presented two specific use cases in this paper :(i) procurement of illegal weapons, (ii) online recruitment of terrorists. LSTM based deep learning classification approach is employed on annotated data for both use cases. We have also compared proposed approach with machine learning classifiers. It is seen that deep learning based text classification is possible with proposed LSTM architecture with acceptable accuracy measures. Automating the process of identifying violent activities over dark web discussion forums is a novel and fruitful contribution of our current work. Machine Learning and Deep Learning algorithms for detecting violent activities can be a powerful tool when developed and used responsibly.
C1 [Saini, Jaspal Kaur] IIIT Una, Una, Himachal Prades, India.
RP Saini, JK (corresponding author), IIIT Una, Una, Himachal Prades, India.
EM sainijassi87@gmail.com
OI Saini, Jaspal Kaur/0000-0003-1142-1356
CR Bowie NG, 2017, PERSPECTIVES TERRORI, V11, P50
   Chen H, 2012, INTEGR SER INFORM SY, V30, P1, DOI 10.1007/978-1-4614-1557-2
   Chollet F., 2017, R interface to keras
   Desmarais B. A., 2011, 2011 European Intelligence and Security Informatics Conference, P171, DOI 10.1109/EISIC.2011.44
   Dhote Y, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1178, DOI 10.1109/ICACCI.2013.6637344
   Domingo JD, 2022, MULTIMED TOOLS APPL, V81, P3351, DOI 10.1007/s11042-021-11112-7
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fernandez M, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P1, DOI 10.1145/3201064.3201082
   Goyal Tamanna, 2019, Proceedings of 2nd International Conference on Communication, Computing and Networking. ICCCN 2018. Lecture Notes in Networks and Systems (LNNS 46), P669, DOI 10.1007/978-981-13-1217-5_66
   Hsiao Hw, 2009, P 11 INT C EL COMM, P341
   Kapil P, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106458
   Katipally R, 2010, P 6 ANN WORKSH CYB S, P51
   Kaur A, 2019, Arxiv, DOI arXiv:1907.12368
   Kengpol A, 2014, COMPUT IND ENG, V75, P55, DOI 10.1016/j.cie.2014.06.003
   Kour H, 2022, MULTIMED TOOLS APPL, V81, P23649, DOI 10.1007/s11042-022-12648-y
   Majeed A, 2022, MULTIMED TOOLS APPL, V81, P43163, DOI 10.1007/s11042-022-13147-w
   Munezero M., 2014, Informatica, V38
   Naik AJ, 2021, MULTIMED TOOLS APPL, V80, P18365, DOI 10.1007/s11042-021-10682-w
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Revelle William, 2024, CRAN
   Rezaeenour J, 2023, MULTIMED TOOLS APPL, V82, P17879, DOI 10.1007/s11042-022-14043-z
   Saini Jaspal Kaur, 2021, International Journal of Information Technology, V13, P697, DOI 10.1007/s41870-021-00620-2
   Saini JK, 2019, CYBERNET SYST, V50, P405, DOI 10.1080/01969722.2018.1553591
   Saini JK, 2023, Multimed Tools Appl, P1
   Thakur D, 2023, ARTIF INTELL REV, V56, P14663, DOI 10.1007/s10462-023-10513-4
   Vinyard Software, 2016, International terrorism: attributes of terrorist events, 1968-1977 [ITERATE 2]
   Wigle John., 2010, Perspectives on Terrorism, V4, P3
   Yechuri PK, 2021, TRAIT SIGNAL, V38, P1809, DOI 10.18280/ts.380625
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhang YL, 2009, ISI: 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P71, DOI 10.1109/ISI.2009.5137274
   Zhou YL, 2005, ACM-IEEE J CONF DIG, P402, DOI 10.1145/1065385.1065505
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17222-8
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400027
DA 2024-07-18
ER

PT J
AU Devi, MMY
   Jeyabharathi, J
   Kirubakaran, S
   Narayanan, S
   Srikanth, T
   Chakrabarti, P
AF Devi, M. M. Yamuna
   Jeyabharathi, J.
   Kirubakaran, S.
   Narayanan, Sreekumar
   Srikanth, T.
   Chakrabarti, Prasun
TI Efficient segmentation and classification of the lung carcinoma via deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Edge-based segmentation; Lung carcinoma; Histogram equalization; and
   Adaptive median filter
ID MODEL
AB Lung malignancy represents a group of diseases that affect people worldwide. According to the reports, 1.69 million people died in 2015. Presymptomatic work raises patient ability and boosts treatment success. The accuracy of disease detection, velocities, and computer technology standards are used to calculate CAD systems. This study investigated the malignant tumor detection method over a few currently used structures. This article discusses lung carcinoma segmentation and the classification of methods. The five steps of the computer-assisted workflow are image acquisition, preprocessing, segmentation, feature extraction, and classification. It focuses on the edge-segmentation process, which is becoming more popular for effective image segmentation in regions. Moreover, the key attributes can be deduced from feature resemblance and transmitted to the classification technique. The lung cancer image's area features are classified using a clustering technique. The lung cancer image's cancer field has been removed using CNN. Moreover, the histogram and adaptive median filter are applied to enhance segmentation performance. The experimental studies utilized basic images acquired from the database and existing health data obtained from the patient. The results demonstrated that the proposed statistical method's performance, which can produce better results than other existing predictions, is superior.
C1 [Devi, M. M. Yamuna] Koneru Lakshmaiah Educ Fdn, Dept CSE, Greenfields campus, Vaddeswaram, India.
   [Jeyabharathi, J.] Kalasalingam Acad Res & Educ, Dept Comp Sci & Engn, Anand Nagar, Krishnankoli 626126, India.
   [Kirubakaran, S.] CMR Coll Engn & Technol, Dept CSE, Hyderabad 501401, India.
   [Narayanan, Sreekumar] Botho Univ, Fac Engn & Technol, Dept Network Infrastruct & Management, Gaborone, Botswana.
   [Srikanth, T.] Malla Reddy Inst Technol & Sci, Dept CSE, Hyderabad, India.
   [Chakrabarti, Prasun] ITM SLS Baroda Univ, Dept Comp Sci & Engn, Vadodara 391510, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Kalasalingam Academy of Research & Education
RP Devi, MMY (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Greenfields campus, Vaddeswaram, India.
EM yd6438584@gmail.com
RI M M, Dr.Yamuna Devi/AGC-9628-2022; kirubakaran, s/ABC-1987-2021;
   srikanth, T/JWA-4876-2024
OI M M, Dr.Yamuna Devi/0000-0002-8258-7882; kirubakaran,
   s/0000-0003-2149-2043; srikanth, T/0000-0003-4184-7614
CR Biswas A, 2020, Computational Network Application Tools for Performance Management, P75
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2021, INT J INF TECH DECIS, V20, P399, DOI 10.1142/S0219622020500522
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Forouzandeh S, 2018, INT J WEB INF SYST, V14, P158, DOI 10.1108/IJWIS-07-2017-0053
   Kamble Bhawana, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P555, DOI 10.1007/978-981-15-0694-9_52
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Matava C, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1481-4
   Niyaz U, 2020, ADV INTELL SYST COMP, V1048, P67, DOI 10.1007/978-981-15-0035-0_6
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Shakeel PM, 2020, NEURAL COMPUT APPL, V32, P777, DOI 10.1007/s00521-018-03972-2
   Sinha P, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1956-4
   Suresh S, 2020, NEURAL COMPUT APPL, V32, P15989, DOI 10.1007/s00521-020-04787-w
   Tiwari Laxmikant, 2020, Computer Vision and Machine Intelligence in Medical Image Analysis. International Symposium, ISCMM 2019. Advances in Intelligent Systems and Computing (AISC 992), P33, DOI 10.1007/978-981-13-8798-2_4
   Veronica BKJ, 2020, MULTIMED TOOLS APPL, V79, P14291, DOI 10.1007/s11042-020-08618-x
   Wang Z, 2020, ANN BIOMED ENG, V48, P312, DOI 10.1007/s10439-019-02349-3
NR 16
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17082-2
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY5Z5
UT WOS:001142522500013
DA 2024-07-18
ER

PT J
AU Yan, G
   Xin, H
   Kuan, Z
AF Yan, Guo
   Xin, Hong
   Kuan, Zhang
TI Application of three-dimensional image technology in the context of the
   metaverse in the production of emotional contrast and special effects in
   animation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Three Dimensional Image Technique; Emotional Support; Special Effect
AB Currently, 3D image technology is being used for animation production. As for the current Traditional animation production technology, most of them still stay in two-dimensional animation production. Although two-dimensional animation is the main form of expression in the current animation field, due to the limitations of its production methods, the emotional contrast and special effects of animated characters in animation are not ideal and cannot be built on strong audience resonance. In order to solve these problems, this paper proposes a design of 3D image technology animation character modeling system under the background of Metaverse. The system mainly consists of a virtual character construction section and a special effects production section. After testing the character modeling rate, model detail detection rate, special effects production ability, and system error rate, the actual feasibility of the system was finally determined. After the completion of the system design, the system performance is compared with the data produced by Traditional animation. The results show that compared with traditional animation, the degree of detail description of this animation has reached 70%, and the ability to describe head and body details has reached 80%. Its average special effect production efficiency is 3 h. Except for the time efficiency of special effect production, other data are better than the Traditional animation production methods. The excellent emotional performance and special effects production of animation have also led to a 90% satisfaction survey result for the 3D imaging technology animation character modeling system. Finally, according to the data, the conclusion is drawn that the 3D image technology animation character modeling system outperforms the traditional animation production methods in the aspects of animation emotion contrast and special effect production, which improves the problems in these two aspects of animation production to a certain extent.
C1 [Yan, Guo; Xin, Hong] Luxun Acad Fine Arts, Media & Animat Coll, Digital Protect & Applicat Paleontol Lab, Dalian 116000, Peoples R China.
   [Kuan, Zhang] Kookmin Univ, Grad Sch TED, Dept Smart Experience Design Interact Design Lab, Seoul 02435, South Korea.
C3 Lu Xun Academy of Fine Arts; Kookmin University
RP Xin, H (corresponding author), Luxun Acad Fine Arts, Media & Animat Coll, Digital Protect & Applicat Paleontol Lab, Dalian 116000, Peoples R China.
EM hongxin@lumei.edu.cn
CR Boopathiraja S, 2021, INT J BIOMED ENG TEC, V35, P191, DOI 10.1504/IJBET.2021.113731
   Chen Y., 2020, Instrumentation, V7, P35
   Gasong BI., 2021, EDCOMTECH, V6, P79
   Gavaskar RG, 2019, IEEE T IMAGE PROCESS, V28, P779, DOI 10.1109/TIP.2018.2871597
   Ghosh S, 2018, IEEE SIGNAL PROC LET, V25, P1555, DOI 10.1109/LSP.2018.2866949
   Guo Q, 2023, ASIAN J SURG, V46, P767, DOI 10.1016/j.asjsur.2022.07.005
   Hoon LN, 2019, J VIS ART DES, V11, P93, DOI 10.5614/j.vad.2019.11.2.2
   Kinsella S, 2020, MECHADEMIA, V13, P40, DOI DOI 10.5749/MECH.13.1.0040
   Maccarone A, 2019, OPT EXPRESS, V27, P28437, DOI 10.1364/OE.27.028437
   Maselli V., 2018, Int J Lit Arts, V6, P54, DOI [10.11648/j.ijla.20180603.12, DOI 10.11648/J.IJLA.20180603.12]
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Morotti E, 2022, VIRTUAL REAL-LONDON, V26, P871, DOI 10.1007/s10055-021-00602-6
   Nanetti A, 2019, SCIRES-IT, V9, P29, DOI 10.2423/i22394303v9n2p29
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Rawlani R, 2019, PLAST RECONSTR SURG, V143, P76, DOI 10.1097/PRS.0000000000005082
   Samah SNSA., 2020, INT J MULTIMED RECEN, V2, P87
   Soltanlou K, 2019, APPL OPTICS, V58, P7716, DOI 10.1364/AO.58.007716
   Song MY, 2020, SAE INT J COMMER VEH, V13, P5, DOI 10.4271/02-13-01-0001
   Sun S., 2021, Adv Vocat Tech Educ, V3, P92, DOI [10.23977/avte.2021.030218, DOI 10.23977/AVTE.2021.030218]
   Tan C, 2019, PHYS CHEM CHEM PHYS, V21, P4145, DOI 10.1039/c8cp04763d
   Tang J, 2021, IEEE-CAA J AUTOMATIC, V8, P1627, DOI 10.1109/JAS.2021.1004129
   Wu YC, 2019, NAT METHODS, V16, P1323, DOI 10.1038/s41592-019-0622-5
   Yick KL, 2019, J AM PODIAT MED ASSN, V109, P98, DOI 10.7547/16-116
NR 23
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16836-2
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T9UR2
UT WOS:001081367600002
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Liu, Z
   Song, YQ
   Han, K
   Qiu, CJ
   Tang, YY
   Zhang, JW
   Liu, Y
AF Zhu, Yan
   Liu, Zhe
   Song, Yuqing
   Han, Kai
   Qiu, Chengjian
   Tang, Yangyang
   Zhang, Jiawen
   Liu, Yi
TI CPSNet: a cyclic pyramid-based small lesion detection network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep lesion detection; Cyclic feature pyramid; Attention mechanism;
   Dilated convolution; CNN
AB The presence of small lesions is an important marker for determining whether a patient will develop malignant tumors. Clinical practitioners could easily overlook the presence of small lesions, meaning automated approaches are essential for screening test results. The use of deep learning-based detectors for this purpose has so far been suboptimal as small lesions easily lose the spatial information during the convolution operation, resulting in unsatisfactory detection accuracy and limited application in clinical decision making. In this paper, we propose a Cyclic Pyramid-based Small lesion detection Network (CPSNet), which iteratively enhances the features in the parallel layer of the Feature Parallel Network (FPN), the features learned in the loop are fused again with the initial FPN to compensate for the inadequacy problem in the initial training. In addition, we propose an aggregated dilation block (ADB) to capture small variations at different scales and a global attention block (GAB) to adaptively recalibrate the channel-based feature responses while focusing on the target spatial information and highlighting the most relevant feature channels. Extensive experiments on eight organs included in the DeepLesion dataset show that our method has a high detection accuracy(mAP=60.4) and a high overall sensitivity(80.5%), which is superior to the state-of-art methods.
C1 [Zhu, Yan] Jiangsu Univ, Dept Med Imaging, Affiliated Hosp, Zhenjiang 212001, Peoples R China.
   [Liu, Zhe; Song, Yuqing; Han, Kai; Qiu, Chengjian; Tang, Yangyang; Liu, Yi] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
   [Zhang, Jiawen] Fudan Univ, Dept Neurosurg, Shanghai, Peoples R China.
C3 Jiangsu University; Jiangsu University; Fudan University
RP Liu, Y (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
EM salary_hi@126.com; lzhe@ujs.edu.cn; yqsong@ujs.edu.cn;
   2112108003@stmail.ujs.edu.cn; 2111908005@stmail.ujs.edu.cn;
   2221908037@stmail.ujs.edu.cn; zhangjw2000@126.com; ly@ujs.edu.cn
FU The authors would like to thank radiologists of the Medical Imaging
   Department of Affiliated Hospital of Jiangsu University. This work was
   supported by the National Natural Science Foundation of China
   (61976106); China Postdoctoral Science Foundation (2017; Medical Imaging
   Department of Affiliated Hospital of Jiangsu University [61976106];
   National Natural Science Foundation of China [2017M611737]; China
   Postdoctoral Science Foundation [DZXX-122]; Six talent peaks project in
   Jiangsu Province [SH2021056]; Key RESEARCH [SH2020011]; Zhenjiang city
   key research and development plan [YJGL-TG-2020-8]; Jiangsu province
   emergency management science and technology project
FX The authors would like to thank radiologists of the Medical Imaging
   Department of Affiliated Hospital of Jiangsu University. This work was
   supported by the National Natural Science Foundation of China
   (61976106); China Postdoctoral Science Foundation (2017M611737); Six
   talent peaks project in Jiangsu Province (DZXX-122); Key RESEARCH and
   development program for social development (SH2021056); Zhenjiang city
   key research and development plan (SH2020011); Jiangsu province
   emergency management science and technology project (YJGL-TG-2020-8).
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cai J, 2020, MED IMAGE COMPUTING, P3
   Cheng JP, 2016, Arxiv, DOI [arXiv:1601.06733, DOI 10.48550/ARXIV.1601.06733]
   Chiao JY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015200
   Duan Kaiwen, arXiv
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo K, 2022, IEEE Trans Multimed
   Guo Kehua, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3185395
   He Chunming, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P22046, DOI 10.1109/CVPR52729.2023.02111
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiancheng Yang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P562, DOI 10.1007/978-3-030-59719-1_55
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SG, 2018, LECT NOTES COMPUT SC, V11071, P693, DOI 10.1007/978-3-030-00934-2_77
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Li H, 2022, LECT NOTES COMPUT SC, V13433, P163, DOI 10.1007/978-3-031-16437-8_16
   Li ZM, 2018, Arxiv, DOI arXiv:1804.06215
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Z, 2022, MULTIMEDIA SYST, V28, P1741, DOI 10.1007/s00530-022-00943-5
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang YB, 2019, I S BIOMED IMAGING, P833, DOI [10.1109/ISBI.2019.8759478, 10.1109/isbi.2019.8759478]
   Tao QY, 2019, LECT NOTES COMPUT SC, V11769, P185, DOI 10.1007/978-3-030-32226-7_21
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yan K, 2017, Arxiv, DOI arXiv:1710.01766
   Yan K, 2018, LECT NOTES COMPUT SC, V11070, P511, DOI 10.1007/978-3-030-00928-1_58
   Yang JC, 2021, LECT NOTES COMPUT SC, V12905, P571, DOI 10.1007/978-3-030-87240-3_55
   Yang JC, 2021, IEEE J BIOMED HEALTH, V25, P3009, DOI 10.1109/JBHI.2021.3049452
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhao PA, 2023, Arxiv, DOI arXiv:2303.15728
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 38
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17024-y
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200002
DA 2024-07-18
ER

PT J
AU Roy, M
   Thounaojam, DM
   Pal, S
AF Roy, Moumita
   Thounaojam, Dalton Meitei
   Pal, Shyamosree
TI PIH-mSCM: a modified spiking cortical model for perceptual image hashing
   and its application to copy detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Perceptual image hashing; Copy detection; Spiking cortical model; Image
   query search; Image retrieval
ID ROBUST; FEATURES
AB For one of the most crucial copyright protection of multimedia content, copy image detection necessitates feature extraction and feature matching. However, matching features necessitate extra computation and storage time, which limits its flexibility. Recent research shows the efficiency of perceptual image hashing in the said case. Consequently, we propose a system that uses the spiking cortical model (SCM) as its foundation and modifies it to create a modified SCM (mSCM) to construct the output time-series waveform. The model is iterated to produce a stable feature vector, which is then used to generate hashes. Excellent resistance against geometric distortions and improved discrimination are provided by the SCM feature vector. Additionally, illustrative experimental findings demonstrate the better stability, resilience, and discrimination of our approach, which enables better copy detection than the state-of-the-art techniques.
C1 [Roy, Moumita; Thounaojam, Dalton Meitei; Pal, Shyamosree] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Comp Vis Lab, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Roy, M (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Comp Vis Lab, Silchar 788010, Assam, India.
EM moumita0101@gmail.com; dalton@cse.nits.ac.in; spal@cse.nits.ac.in
RI Roy, Moumita/AEV-6631-2022
OI Roy, Moumita/0000-0001-6835-5471
CR Aggarwal Ashwani Kumar, 2022, WSEAS Transactions on Signal Processing, P60, DOI 10.37394/232014.2022.18.8
   Aggarwal AK, 2022, INT J BIOL BIOMEDICI, V7
   [Anonymous], 2004, ACMMM
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   DS Maini and Ashwani Kumar Aggarwal, 2018, INT J INNOV ENG TECH, V10, P199, DOI DOI 10.21172/IJIET.102.29
   Fridrich J, 2000, PROC SPIE, V3971, P286, DOI 10.1117/12.384982
   Gharde ND, 2018, MULTIMED TOOLS APPL, V77, P30815, DOI 10.1007/s11042-018-6115-1
   Glumov N. I., 2011, Computer Optics, V35, P262
   Hsiao JH, 2007, IEEE T IMAGE PROCESS, V16, P2069, DOI 10.1109/TIP.2007.900099
   INRIA, About us
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Karsh RK, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0179-0
   Karsh RK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3639-6
   Khan MF, 2021, TURK J ELECTR ENG CO, V29, P648, DOI 10.3906/elk-2002-6
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Kumari T, 2021, 2021 INT C COMP COMM, P1
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Ling HF, 2013, SIGNAL PROCESS, V93, P2328, DOI 10.1016/j.sigpro.2012.08.011
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma YD, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P808, DOI 10.1109/ICIA.2006.305834
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Patil V. H., 2019, Journal Computing, V14, P210
   Paul Madhumita, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P464, DOI 10.1109/ICACTM.2019.8776713
   Petitcolas F, About us
   Roy M, 2022, Multimedia Tools and Applications, P1
   Shapiro LG, About us
   Singh KM, 2019, CURR SCI INDIA, V117, P1340, DOI 10.18520/cs/v117/i8/1340-1344
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Swetha CSLR, 2020, INT C EM TRENDS ADV, P453
   Tang ZJ, 2018, COMPUT J, V61, P1695, DOI 10.1093/comjnl/bxy047
   Tang ZJ, 2016, AEU-INT J ELECTRON C, V70, P833, DOI 10.1016/j.aeue.2016.03.010
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, OPTIK, V125, P5102, DOI 10.1016/j.ijleo.2014.05.015
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   web.archive, Dataset CEI.
   Weber AG., 2018, USC-SIPI Report, V432, P1
   Xiao C, 2011, ACM T DATABASE SYST, V36, DOI 10.1145/2000824.2000825
   Xue MF, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/9795621
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhou GS, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0450-5
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 47
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 4
PY 2023
DI 10.1007/s11042-023-16753-4
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4GC2
UT WOS:001077578000002
DA 2024-07-18
ER

PT J
AU Maheswari, B
   Reeja, SR
AF Maheswari, B.
   Reeja, S. R.
TI Memory-guided visual attention generative adversarial network for
   colorization of nighttime thermal infrared images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-Infrared Images; Thermal Infrared Images; Generative Adversarial
   Networks; Daytime Color; Segmentation Masks; Label Mining; Pixel-Level
   Cross-Entropy Loss; Edge Segmentation
AB Color images offer more information and are more detail-specific compared to typical grayscale images. The frequency level of the images captured by the near-infrared (NIR) image sensors is lower than that of visible light. The photographs are of extremely poor quality and are not visually pleasing due to the lack of natural colors. Since improving the visible quality of the images has become a priority due to this problem, image colorization techniques have been developed and applied. However, it will be extremely complicated because keeping the images' original nature and characteristics is challenging when turning them into color images. As a result, this study introduces a novel image colorization strategy for NTIR images based on the GAN model. The generator module, which includes an encoder for both the DC (daytime color images) and NTIR images, collects the input images and performs a translation on them. The visual attention mechanism is introduced to the generator module to capture the essential semantic data about the images. In order to improve the semantic preservation of small sample categories, the framework also includes a memory-guided sample selection technique with an adaptive visual attention loss function. The proposed framework's memory unit keeps the pseudo-labels that have been extracted and improved by the online semantic distillation module. In addition, the system includes a structured gradient alignment loss function to maintain edge coherence between the translated and input pictures. To apply the proposed model, the cityscape dataset is used. The proposed model is compared to other existing models in terms of non-linear correlation information entropy, precision, recall, means structural similarity, mutual information, entropy, correlation coefficient, average gradient, standard deviation, and sum of correlation of differences and achieved the best results among them. The precision and recall values of the proposed model are 96% and 95% on the Cityscape dataset.
C1 [Maheswari, B.; Reeja, S. R.] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Pradesh, India.
C3 VIT-AP University
RP Maheswari, B (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Pradesh, India.
EM maheswari.21phd7152@vitap.ac.in
RI Bandi, Maheswari/JXM-7990-2024
CR Arazo E, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207304
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Du KN, 2021, IEEE ACCESS, V9, P21604, DOI 10.1109/ACCESS.2021.3055575
   Geng KK, 2020, IEEE ACCESS, V8, P88227, DOI 10.1109/ACCESS.2020.2990636
   Ghose D, 2019, IEEE COMPUT SOC CONF, P988, DOI 10.1109/CVPRW.2019.00130
   Gonzalez-Garcia A, 2018, ADV NEUR IN, V31
   Group FA, 2018, FLIR THERM DAT ALG T
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   Guo M.-H., 2022, arXiv
   Haider A, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103796
   He C., 2023, ARXIV
   He C, 2021, IEEE T CYBERNETICS, V51, P3129, DOI 10.1109/TCYB.2020.2985081
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hernandez-Camara P, 2022, ARXIV
   Hu MH, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190466
   Ju MY, 2023, IEEE T INTELL TRANSP, V24, P1220, DOI 10.1109/TITS.2022.3210693
   Kasgari ATZ, 2021, IEEE T COMMUN, V69, P884, DOI 10.1109/TCOMM.2020.3031930
   Kniaz VV, 2019, LECT NOTES COMPUT SC, V11134, P606, DOI 10.1007/978-3-030-11024-6_46
   Lee HJ, 2020, PROC CVPR IEEE, P4816, DOI 10.1109/CVPR42600.2020.00487
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Li J, 2022, SURF COAT TECH, V439, DOI 10.1016/j.surfcoat.2022.128442
   Liang Y, 2022, MULTIMED TOOLS APPL, V81, P26669, DOI 10.1007/s11042-020-10468-6
   Liu B, 2023, ARXIV
   Liu S, 2023, IEEE T INTELL TRANSP, V24, P15795, DOI 10.1109/TITS.2022.3232242
   Liu S, 2023, INFORM FUSION, V96, P281, DOI 10.1016/j.inffus.2023.02.005
   Liu T, 2018, AGR FOREST METEOROL, V252, P144, DOI 10.1016/j.agrformet.2018.01.021
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Luo FY, 2021, LECT NOTES COMPUT SC, V12890, P388, DOI 10.1007/978-3-030-87361-5_32
   Luo FY, 2022, IEEE T INTELL TRANSP, V23, P15808, DOI 10.1109/TITS.2022.3145476
   Mayer RE, 2020, ETR&D-EDUC TECH RES, V68, P837, DOI 10.1007/s11423-020-09749-6
   Nazeri Kamyar, 2018, Articulated Motion and Deformable Objects. 10th International Conference, AMDO 2018. Proceedings: LNCS 10945, P85, DOI 10.1007/978-3-319-94544-6_9
   Pan XG, 2022, IEEE T PATTERN ANAL, V44, P7474, DOI 10.1109/TPAMI.2021.3115428
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Sajjan S, 2020, IEEE INT CONF ROBOT, P3634, DOI 10.1109/ICRA40945.2020.9197518
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Vollmer M., 2021, Computer Vision A Reference Guide, P666
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wan ZY, 2023, IEEE T PATTERN ANAL, V45, P2071, DOI 10.1109/TPAMI.2022.3163183
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wu CY, 2019, J MATER CHEM C, V7, P11532, DOI 10.1039/c9tc04322e
   Xu GX, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3238511
   Xu JT, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108007
   Yang ZF, 2020, IEEE I C VI COM I PR, P467, DOI [10.1109/vcip49819.2020.9301791, 10.1109/VCIP49819.2020.9301791]
   Yilin Ouyang, 2021, 2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), P70, DOI 10.1109/PRAI53619.2021.9551084
   Zhang LC, 2019, IEEE T IMAGE PROCESS, V28, P1837, DOI 10.1109/TIP.2018.2879249
   Zhang ZY, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9120721
   Zhao JJ, 2020, INT J COMPUT VISION, V128, P818, DOI 10.1007/s11263-019-01271-4
   Zhao YZ, 2021, IEEE T CIRC SYST VID, V31, P3062, DOI 10.1109/TCSVT.2020.3037688
NR 50
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17679
EP 17697
DI 10.1007/s11042-023-17030-0
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001076638500006
DA 2024-07-18
ER

PT J
AU Joshi, KK
   Gupta, K
   Agrawal, J
AF Joshi, Krishna Kumar
   Gupta, Kamlesh
   Agrawal, Jitendra
TI An efficient transfer learning approach for prediction and
   classification of SARS - COVID-19
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Transfer Learning; VGG 16; Covid-19; Confusion Matrix; CLAHE; Weiner
   Filter; ReLU
ID ACUTE RESPIRATORY SYNDROME
AB COVID-19 or Corona Virus Disease is a dangerous disease that spreads quickly and affects human life brutally, becoming the cause of death of millions of people. COVID mainly infects the lungs of human beings and that's why lung images are mostly used for Covid detection. In this research paper, an innovative efficient Transfer Learning approach for Covid -19 prediction is described. The dataset contains Computer Tomography images of the Chest and has been collected from two sources: First SARS-CoV-2 CT has 2482 images of Covid and healthy persons. Non-Covid CT scan images of both SARS-CoV-2 positive and negative patients and second UCSD-AI4H COVID CT scan dataset containing 745 CT scan images of both SARS-CoV-2 positive and negative patients. As datasets containing images are collected from various sources, machine learning pre-processing techniques such as CLAHE, and data augmentation, are applied to enhance contrast, quality, and quantity. Then, a popular pre-trained CNN, called VGG16, is used as the base model, as it has shown its ability on the image dataset in terms of very good accuracy in the prediction and classification of the images related to medical diagnosis. Then we build our sequential model by applying ReLU and Softmax functions and trained it with 21,137,986 parameters. The dataset is divided into three parts in the ratio of 80%, 10%, and 10%, for Training, Testing, and Validation, respectively. The model shows a very good classification of Covid-positive and Covid Negative images as it was able to provide an accuracy of 95%. The Precision was 95%, Recall was 95%, and the F-1 Score was 95%.
C1 [Joshi, Krishna Kumar; Agrawal, Jitendra] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, Madhya Pradesh, India.
   [Gupta, Kamlesh] Rustam Ji Inst Technol, Dept Informat Technol, Gwalior, Madhya Pradesh, India.
C3 Rajiv Gandhi Technological University
RP Joshi, KK (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, Madhya Pradesh, India.
EM krishnakjoshi@gmail.com; kamlesh_rjitbsf@yahoo.co.in;
   jitendra@rgpv.ac.in
CR Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Alzubaidi L, 2021, CANCERS, V13, DOI 10.3390/cancers13071590
   Amin S, 2021, CMC-COMPUT MATER CON, V68, P2231, DOI 10.32604/cmc.2021.016896
   Arun JB., 2013, Int J Eng Res Technol, V2, P3219
   Balkenende L, 2022, SEMIN NUCL MED, V52, P584, DOI 10.1053/j.semnuclmed.2022.02.003
   Bharti R, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8387680
   Brunese Luca, 2020, Procedia Comput Sci, V176, P2212, DOI 10.1016/j.procs.2020.09.258
   Butt UM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9930985
   Callahan A, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0300-0
   Cardarilli GC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94691-7
   Chang V., 2022, Healthcare Anal., V2, DOI [10.1016/j.health.2022.100016, DOI 10.1016/J.HEALTH.2022.100016]
   Chaunzwa TL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84630-x
   Cheng VCC, 2007, CLIN MICROBIOL REV, V20, P660, DOI 10.1128/CMR.00023-07
   Das D, 2022, MULTIMED TOOLS APPL, V81, P21471, DOI 10.1007/s11042-022-11913-4
   Dash AK, 2022, MULTIMED TOOLS APPL, V81, P1055, DOI 10.1007/s11042-021-11388-9
   de Vargas VW, 2023, KNOWL INF SYST, V65, P31, DOI 10.1007/s10115-022-01772-8
   Felix EA, 2019, IET SOFTW, V13, P479, DOI 10.1049/iet-sen.2018.5193
   Gao F, 2021, ULTRASONICS, V112, DOI 10.1016/j.ultras.2020.106344
   Gu Shanqing., 2019, SMU Data Science Review, V2, P1
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Heidari A, 2022, NEURAL COMPUT APPL, V34, P15313, DOI 10.1007/s00521-022-07424-w
   Hilgenfeld R, 2013, ANTIVIR RES, V100, P286, DOI 10.1016/j.antiviral.2013.08.015
   Hosna A, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00652-w
   Hu B, 2021, NAT REV MICROBIOL, V19, P141, DOI 10.1038/s41579-020-00459-7
   Hussain Khalid, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0040-0
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Jiang ZP, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311185
   Jin J, 2021, NAT MED, V27, P264, DOI 10.1038/s41591-020-01191-8
   Kaur H., 2017, Int. J. Eng. Sci. (IJES), V6, P59, DOI [10.9790/1813-0606015963, DOI 10.9790/1813-0606015963]
   Kennedy B, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29608-7
   Kotsiantis SB, 2006, PROC WRLD ACAD SCI E, V12, P278
   Kumar P, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105894
   Kushwaha S, 2020, J IND INTEGR MANAG, V5, P453, DOI 10.1142/S2424862220500268
   La Montagne JR, 2004, J INFECT DIS, V189, P634, DOI 10.1086/382225
   Li H, 2020, J CELL MOL MED, V24, P6558, DOI 10.1111/jcmm.15364
   Liu DQ, 2022, FRONT ENERGY RES, V10, DOI 10.3389/fenrg.2022.850252
   Liu Q, 2020, J INFECT PUBLIC HEAL, V13, P1611, DOI 10.1016/j.jiph.2020.08.001
   Maniatopoulos A, 2021, INFORMATION, V12, DOI 10.3390/info12120513
   Markoulidakis I, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9040081
   Mizrahi B, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20053-y
   Mohan B., 2020, Journal of Infectious Diseases and Epidemiology, V6, P1, DOI DOI 10.23937/2474-3658/1510146
   Mujumdar A, 2019, PROCEDIA COMPUT SCI, V165, P292, DOI 10.1016/j.procs.2020.01.047
   Nashif Shadman, 2018, World Journal of Engineering and Technology, V6, P854
   Oktavianto B., 2018, Int J Appl Eng Res, V13, P1165
   Omarova GS, 2022, INT J ADV COMPUT SC, V13, P412
   Pandey N., 2020, IJEAT, V9, P1995, DOI [10.35940/ijeat.D9057.049420, DOI 10.35940/IJEAT.D9057.049420]
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Pavithra P., 2011, Int J Comput Commun Technol, V2, P29, DOI [10.47893/IJCCT.2011.1067, DOI 10.47893/IJCCT.2011.1067]
   Perumal V, 2021, DIS MARKERS, V2021, DOI 10.1155/2021/5522729
   Pesch IS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04614-9
   Pham TN, 2023, J SUPERCOMPUT, V79, P8966, DOI 10.1007/s11227-022-04979-2
   Ranjbarzadeh R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90428-8
   Reddy ASK, 2023, MULTIMED TOOLS APPL, V82, P12653, DOI 10.1007/s11042-022-13739-6
   Salam MA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0252573
   Sekeroglu B, 2020, SLAS TECHNOL, V25, P553, DOI 10.1177/2472630320958376
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shereen MA, 2020, J ADV RES, V24, P91, DOI 10.1016/j.jare.2020.03.005
   Shimazaki A, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04667-w
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva Pedro, 2020, Inform Med Unlocked, V20, P100427, DOI 10.1016/j.imu.2020.100427
   Tammina S, 2019, Int. J. Sci. Res. Publ, V9, P143, DOI DOI 10.29322/IJSRP.9.10.2019.P9420
   Thompson EJ, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30836-0
   Wagner CS, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0261624
   Wang MY, 2020, FRONT CELL INFECT MI, V10, DOI 10.3389/fcimb.2020.587269
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Yadav PD, 2021, VIRUSES-BASEL, V13, DOI 10.3390/v13050925
   Yadav PD, 2021, J TRAVEL MED, V28, DOI 10.1093/jtm/taab009
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang YC, 2020, VIROL J, V17, DOI 10.1186/s12985-020-01369-z
   Younis A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147282
   Yuen KS, 2020, CELL BIOSCI, V10, DOI 10.1186/s13578-020-00404-4
   Zhang LY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61123-x
   Zhao WT, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93832-2
   Zhen LH, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/4176059
   Zoabi Y, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00372-6
NR 75
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-17086-y
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300005
DA 2024-07-18
ER

PT J
AU Esmaeili, M
   Kiani, K
AF Esmaeili, Masoumeh
   Kiani, Kourosh
TI Generating personalized facial emotions using emotional EEG signals and
   conditional generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion; Electroencephalogram (EEG); Common Spatial Pattern (CSP);
   Bidirectional Long Short-Term Memory (BiLSTM); Reconstruction;
   conditional Generative Adversarial Network (cGAN)
AB Facial expressions are one of the most effective and straightforward ways of conveying our emotions and intentions. Therefore, it is crucial to conduct research aimed at developing a Brain Computer Interface (BCI) that can assist individuals with facial motor disabilities in expressing their emotions. This paper proposes a hybrid GAN-based model that reconstructs a personalized facial expression based on their corresponding emotional ElectroEncephaloGram (EEG) signals, utilizing a conditional Generative Adversarial Network (cGAN). To recognize emotions using EEG signals, a novel method called CSP-BiLSTM is introduced, which combines the Common Spatial Pattern (CSP) and Bidirectional Long Short-Term Memory (BiLSTM) network to explore the spatial and temporal dependencies of the raw EEG signals. Finally, a Fully Connected (FC) layer with a Softmax activation function are applied to the extracted spatiotemporal features to recognize the label of the EEG signals. The predicted emotional label is then input into a cGAN, along with a neutral facial image, to emotionally reconstruct the input image. Experimental results on the SEED dataset demonstrate that our proposed CSP-BiLSTM model outperforms previous models in both subject-dependent and cross-subject scenarios, achieving 99.97% and 99.93% accuracy, respectively, for three classification tasks. A thorough evaluation of the images generated by cGAN is conducted using three challenging facial expression benchmarks: AffectNet, CK + , and CelebA. The results of applying FID, emotion classification using pre-trained Arcface model, and human evaluation indicated that samples synthesized using this model outperformed those generated by recent techniques.
C1 [Esmaeili, Masoumeh; Kiani, Kourosh] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Kiani, K (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM esmaeili_m98@semnan.ac.ir; kourosh.kiani@semnan.ac.ir
RI Kiani, Kourosh/T-7468-2019
OI Kiani, Kourosh/0000-0001-6582-8691
CR Abyaneh A, 2020, About us
   Baradaran F, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102232
   Bodur R, 2023, ICASSP 2023 2023 IEE, P1
   Brownlee J, 2019, Machine Learning Mastery, V652
   Chen Yan, 2023, Proceedings of SPIE, DOI 10.1117/12.2663756
   Cheng WX, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105349
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chowdary MK, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152387
   Cimtay Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072034
   Cui FC, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040582
   Deng JK, 2022, IEEE T PATTERN ANAL, V44, P5962, DOI 10.1109/TPAMI.2021.3087709
   Deng X, 2023, J NEUROSCI METH, V384, DOI 10.1016/j.jneumeth.2022.109747
   Dogan S, 2023, COGN NEURODYNAMICS, V17, P647, DOI 10.1007/s11571-022-09859-2
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Esmaeili M., 2015, Elixir Comp Engg, V82, P32134
   Fang S, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103464
   Fang Z, 2022, VISUAL COMPUT, V38, P1151, DOI 10.1007/s00371-021-02074-w
   Farhana I, 2023, IEEE ACCESS, V11, P44019, DOI 10.1109/ACCESS.2023.3270177
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo JY, 2022, PHYSICA A, V603, DOI 10.1016/j.physa.2022.127700
   Han BJ, 2023, SYMMETRY-BASEL, V15, DOI 10.3390/sym15040956
   Hou FZ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3240230
   Iyer A, 2023, MULTIMED TOOLS APPL, V82, P4883, DOI 10.1007/s11042-022-12310-7
   Jana GC, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020324
   Jin M., 2023, arXiv
   Jun Ling, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P37, DOI 10.1007/978-3-030-58604-1_3
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Khaleghi N, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11213637
   Kim S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186813
   Komolovaite D, 2022, LIFE-BASEL, V12, DOI 10.3390/life12030374
   Kumari N, 2023, MULTIMED TOOLS APPL, V82, P32259, DOI 10.1007/s11042-023-14769-4
   Lambiase PD, 2023, INT J SOC ROBOT, DOI 10.1007/s12369-023-00973-7
   Li ZJ, 2023, J NEURAL ENG, V20, DOI 10.1088/1741-2552/acb79e
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lucey Patrick, 2010, Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2010.5543262
   Maria MA, 2023, IEEE ACCESS, V11, P37809, DOI 10.1109/ACCESS.2023.3264845
   Mishra R, 2023, NEURAL COMPUT APPL, V35, P9181, DOI 10.1007/s00521-022-08178-1
   Mishra R, 2022, PROC SPIE, V12032, DOI 10.1117/12.2613297
   Mohammadzadeh Koumleh S., 2021, J. Chem. Lett, V2, P157, DOI [10.22034/jchemlett.2022.325476.1046, DOI 10.22034/JCHEMLETT.2022.325476.1046]
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Musha T., 1997, Artificial Life and Robotics, V1, P15, DOI 10.1007/BF02471106
   Padhmashree V, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107867
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rakhshan SA, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106817
   Roshdy A, 2023, ROBOTICS, V12, DOI 10.3390/robotics12040099
   Sajjad M, 2023, ALEX ENG J, V68, P817, DOI 10.1016/j.aej.2023.01.017
   She QS, 2023, COMPUT BIOL MED, V159, DOI 10.1016/j.compbiomed.2023.106860
   Singh P, 2023, ICASSP 2023 2023 IEE, P1, DOI [10.1109/ICASSP49357.2023.10096587, DOI 10.1109/ICASSP49357.2023.10096587]
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Tesei Gino L., 2019, Generating Realistic Facial Expressions through Conditional Cycle-Consistent Generative Adversarial Networks
   ul Haq QM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145158
   Wang F, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9456007
   Wang XH, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1126994
   Wu RL, 2020, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR42600.2020.00507
   Wu X, 2022, J NEURAL ENG, V19, DOI 10.1088/1741-2552/ac49a7
   Xu T, 2023, J NEURAL ENG, V20, DOI 10.1088/1741-2552/acae06
   Xu W., 2022, ACSS, V6, P31, DOI DOI 10.23977/ACSS.2022.060404
   Yang CY, 2022, LECT NOTES COMPUT SC, V13676, P737, DOI 10.1007/978-3-031-19787-1_42
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zhong MY, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104211
   Zhu J, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105815
NR 63
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-17018-w
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600011
DA 2024-07-18
ER

PT J
AU Madanan, M
   Muthukumaran, N
   Tiwari, S
   Vijay, A
   Saha, I
AF Madanan, Mukesh
   Muthukumaran, N.
   Tiwari, Shrikant
   Vijay, A.
   Saha, Indranil
TI RSA based improved YOLOv3 network for segmentation and detection of weed
   species
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Weed detection; Adaptive gamma correction; High boost filtering;
   Improved YOLOv3
AB Weeds are among the major risks impacting agricultural production and quality, it is still difficult to create reliable weed identification and detection systems because of the unstructured field circumstances and substantial biological heterogeneity of weeds. The proposed work develops a weed detection model for achieving higher crop yield. Crop and weed images are taken as an input for the proposed method. The collection of data consists of raw-data that cannot produce high accuracy. So, a certain pre-processing technique is used in the proposed method for achieving high accuracy. Adaptive median filter, adaptive gamma correction and high boost filtering techniques are used as pre-processing techniques for noise removal, contrast enhancement and edge sharpening. Then the pre-processed image is segmented and detected according to the features and properties of the pixels in the image. Improved YOLOv3-technique is used in the proposed approach for segmentation and detection of weed species. RSA-optimization is used to select the hyperparameters of YOLOv3-optimally. The proposed method is tested with several metrics which attain better performance like 96% accuracy, 96% precision, 95% recall, 4% error and 95% specificity value. Thus the designed model detects weed-species in an effective manner and it is useful for achieving higher crop production.
C1 [Madanan, Mukesh] Dhofar Univ, Dept Comp Sci, Salalah 211, Oman.
   [Muthukumaran, N.] Sri Eshwar Coll Engn, Ctr Computat Imaging & Machine Vis, Dept ECE, Coimbatore 641202, Tamil Nadu, India.
   [Tiwari, Shrikant] Galgotias Univ, Sch Comp Sci & Engn SCSE, Dept Comp Sci & Engn, Greater Noida 203201, Uttar Pradesh, India.
   [Vijay, A.] Sri Ramakrishna Engn Coll, Dept Elect & Commun Engn, Coimbatore 641022, Tamilnadu, India.
   [Saha, Indranil] GLA Univ, Dept Phys, Mathura 281406, Uttar Pradesh, India.
C3 Dhofar University; Galgotias University; Sri Ramakrishna Engineering
   College; GLA University
RP Muthukumaran, N (corresponding author), Sri Eshwar Coll Engn, Ctr Computat Imaging & Machine Vis, Dept ECE, Coimbatore 641202, Tamil Nadu, India.
EM mukesh@du.edu.om; kumaranece@gmail.com; shrikanttiwari15@gmail.com;
   vijaypgpece@gmail.com; indranil.saha@gla.ac.in
RI kumaran, Dr. N. Muthu/I-3259-2016; A, Vijay/AAZ-7723-2021
OI kumaran, Dr. N. Muthu/0000-0003-0592-6630; A, Vijay/0000-0001-9531-8983;
   SAHA, INDRANIL/0000-0002-2908-029X
CR Abualigah L, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116158
   Che'Ya NN, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11071435
   Dadashzadeh M, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9050559
   Espejo-Garcia B, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105306
   Fawakherji M, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P146, DOI 10.1109/IRC.2019.00029
   Gai JY, 2020, J FIELD ROBOT, V37, P35, DOI 10.1002/rob.21897
   Hasan ASMM, 2021, COMPUT ELECTRON AGR, V184, DOI 10.1016/j.compag.2021.106067
   Jin XJ, 2021, IEEE ACCESS, V9, P10940, DOI 10.1109/ACCESS.2021.3050296
   kaggle, US
   Karthick S., 2017, J ADV RES DYN CONTRO, V9, P2679
   Kiruthika K., 2015, Int J Appl Eng Res, V10, P19536
   Lu ZY, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM 2019), P827, DOI [10.1109/ICARM.2019.8833671, 10.1109/icarm.2019.8833671]
   Patil Sarika B., 2020, 2020 International Conference on Industry 4.0 Technology (I4Tech), P148, DOI 10.1109/I4Tech48345.2020.9102677
   Ponraj D.N., 2011, Journal of Emerging Trends in Computing and Information Sciences, V2, P656
   Rajasekhara Babu L., 2023, Int J Eng Trends Technol, V71, P359, DOI [10.14445/22315381/IJETT-V71I4P232, DOI 10.14445/22315381/IJETT-V71I4P232]
   Sabzi S, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03685
   Sahnoun M, 2020, SIGNAL IMAGE VIDEO P, V14, P377, DOI 10.1007/s11760-019-01561-x
   Sampathkumar S, 2022, IETE J RES, V68, P3786, DOI 10.1080/03772063.2020.1780163
   Subeesh A, 2022, ARTIF INTELL AGR, V6, P47, DOI 10.1016/j.aiia.2022.01.002
   Vaidhehi M, 2022, ACTA AGR SCAND B-S P, V72, P463, DOI 10.1080/09064710.2021.2011395
   Wang AC, 2020, IEEE ACCESS, V8, P81724, DOI 10.1109/ACCESS.2020.2991354
   Yan X, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P336, DOI [10.1109/ITOEC49072.2020.9141894, 10.1109/itoec49072.2020.9141894]
   You J, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105750
   Zhang SW, 2021, NEUROCOMPUTING, V452, P665, DOI 10.1016/j.neucom.2020.06.140
NR 24
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16739-2
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200006
DA 2024-07-18
ER

PT J
AU Malik, V
   Mittal, R
   Kaur, A
   Singla, G
   Mittal, A
   Singh, M
AF Malik, Varun
   Mittal, Ruchi
   Kaur, Amandeep
   Singla, Geetanjali
   Mittal, Amit
   Singh, Manjinder
TI Enhancement and analysis of hyperspectral satellite images for Soil
   Study and Behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SAVI; MSAVI; TVI; RVI; NDVI; DVI
AB Using soil maps at the proper scales can help with environmental and agricultural decision-making. In this way, soil properties have been investigated using remote sensing technologies, although, the assessment of their spatial information may be limited by the existence of objects other than soil. This problem has been addressed by soil researchers who have been analyzing the spatial patterns via hyperspectral satellite images in an effort to enhance the soil property maps. In this research, we introduced a four-step model named Enhancement and Analysis of Hyperspectral Satellite Images for Soil Study and Behavior (EAHSB) which includes the steps like preprocessing, segmentation, feature extraction, and classification. The work starts with the preprocessing of the input image via improved anisotropic filtering, which enhances the image to process further. Subsequently, the segmentation takes place by the improved spatial constraint kernel Fuzzy c-means (KFCM) to segment the Region of Interest (ROI) and non-Region of interest (ROI) regions. For the study of soil behavior classification, the vegetation indices-based features are extracted including Transformed Vegetation Index (TVI), Radar Vegetation index (RVI), soil adjusted vegetation index (SAVI), Difference Vegetation Index (DVI), Normalized Difference Vegetation Index (NDVI), modified soil adjusted vegetation index (MSAVI), and Modified Soil Ratio (MSR) as well. Finally, the soil behavior classification is carried out based on the extracted features via a hybrid model combining Deep Residual Network (DRN) and Improved Recurrent Neural Network (RNN) with new layer structure on attaining the classification outcomes like Soil Moister Index Forecast (SMI), Soil Vegetation Index (SVI), and pH, respectively.
C1 [Malik, Varun; Mittal, Ruchi; Kaur, Amandeep; Singla, Geetanjali] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, India.
   [Mittal, Amit; Singh, Manjinder] Chitkara Univ, Chitkara Business Sch, Rajpura, Punjab, India.
C3 Chitkara University, Punjab; Chitkara University, Punjab
RP Malik, V (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, India.
EM varunmalik7288@gmail.com
CR Al-Ameen Z, 2020, TRAIT SIGNAL, V37
   Anurogo W., 2018, J GEOSCI ENG ENV TEC, V3, P15, DOI [10.24273/jgeet.2018.3.01.1003, DOI 10.24273/JGEET.2018.3.01.1003]
   Asha CS, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100415
   Basso S, 2021, SCI TOTAL ENVIRON, V756, DOI 10.1016/j.scitotenv.2020.143469
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Celik MF, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14215584
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Choi H, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060938
   Das SK, 2020, B ENVIRON CONTAM TOX, V105, P261, DOI 10.1007/s00128-020-02936-4
   eartharchitecture, About us
   Fathololoumi S, 2021, GEODERMA, V385, DOI 10.1016/j.geoderma.2020.114901
   Ghadr S, 2022, CONSTR BUILD MATER, V331, DOI 10.1016/j.conbuildmat.2022.127263
   Ghazali Mochamad Firman, 2020, Information Processing in Agriculture, V7, P294, DOI 10.1016/j.inpa.2019.08.003
   Hariharan K, 2021, WIRELESS PERS COMMUN, V117, P2729, DOI 10.1007/s11277-020-07044-4
   Khanduri N, 2020, AMITY J COMPUT SCI A, V4
   Kukreja Vinay, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P97, DOI 10.1109/ICOSEC49089.2020.9215359
   Kumar VV., 2020, ALOCHANA CHAKRA J, VIX, P1570
   Le TTH, 2016, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-015-3011-9
   Li XF, 2022, J INTELL TRANSPORT S, V26, P557, DOI 10.1080/15472450.2021.1933471
   Markkandan S., 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-021-07700-4
   Mehravar S, 2021, ADV SPACE RES, V68, P4573, DOI 10.1016/j.asr.2021.08.041
   Demattê JAM, 2018, REMOTE SENS ENVIRON, V212, P161, DOI 10.1016/j.rse.2018.04.047
   Naik D, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00664-6
   Nibali A, 2017, INT J COMPUT ASS RAD, V12, P1799, DOI 10.1007/s11548-017-1605-6
   Padarian J, 2019, SOIL-GERMANY, V5, P79, DOI 10.5194/soil-5-79-2019
   Pandey A, 2021, 2021 IEEE INT GEOSC
   Riad S, 2022, P INT C 4 IND REV 20
   Salas EAL, 2014, REMOTE SENS-BASEL, V6, P20, DOI 10.3390/rs6010020
   Serwa A, 2021, EGYPT J REMOTE SENS, V24, P283, DOI 10.1016/j.ejrs.2020.12.006
   Shukla PK, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/7804540
   Silvero NEQ, 2021, GEODERMA, V397, DOI 10.1016/j.geoderma.2021.115089
   Singh S, 2020, IEEE SENS J, V20, P12459, DOI 10.1109/JSEN.2020.3002720
   Sojoudi M, 2023, J ROCK MECH GEOTECH, V15, P1535, DOI 10.1016/j.jrmge.2022.09.008
   Sothe C, 2022, GEODERMA, V405, DOI 10.1016/j.geoderma.2021.115402
   Thakur R., 2022, MEASUREMENT SENSORS, V24, P100437
   Wang LJ, 2022, SOILS FOUND, V62, DOI 10.1016/j.sandf.2022.101181
   Wang S, 2023, REMOTE SENS ENVIRON, V285, DOI 10.1016/j.rse.2022.113366
   Zhou Y, 2020, SOIL DYN EARTHQ ENG, V136, DOI 10.1016/j.soildyn.2020.106215
NR 38
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33879
EP 33902
DI 10.1007/s11042-023-16729-4
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001071641500005
DA 2024-07-18
ER

PT J
AU Li, XL
   Chen, HJ
   Li, YF
   Peng, YH
AF Li, Xiaoling
   Chen, Houjin
   Li, Yanfeng
   Peng, Yahui
TI Multi-focus image fusion via adaptive fractional differential and guided
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Defocused pixels; Adaptive fractional
   differential; Adaptive guided filtering
ID NEURAL-NETWORKS; PERSON REIDENTIFICATION
AB The goal of multi-focus image fusion is to make an image that is all-in-focus with a finite depth of field. Although multi-focus image fusion algorithms have advanced significantly, it is still difficult to avoid defocused pixels in fused results. To alleviate the problem, a multi-focus image fusion method via adaptive fractional differential and guided filtering is proposed in this paper. Specifically, by combining the guided filtering and the fractional differential, the base and detail layers can be obtained using the designed effective two-scale image decomposition approach. In addition, an image decomposition scheme based on the statistical characteristics concerning the source images is developed, which can retain more detailed information by adaptively adjusting parameters, thereby reducing defocused pixels. The fused all-in-focus images are obtained by merging features from different scales. Experiments demonstrate that compared with existing image fusion algorithms, the promising results on three public datasets are achieved by the proposed method in qualitative evaluation and quantitative measurement, especially in terms of AG, VIF, and SF. On the Lytro dataset, our method has 22%, 34%, and 14% improvement in AG, VIF, and SF compared to the sub-optimal method. On the MFFW dataset, compared with the sub-optimal method, the proposed method has 12%, 14%, and 19% improvement in AG, VIF, and SF, respectively. On the MFI-WHU dataset, the proposed method realizes a performance improvement of 22%, 4%, and 30% in AG, VIF, and SF, compared with the sub-optimal method.
C1 [Li, Xiaoling; Chen, Houjin; Li, Yanfeng; Peng, Yahui] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Chen, HJ (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM hjchen@bjtu.edu.cn
RI Li, Xiaoling/JVN-8800-2024; 李, 延风/JTV-4562-2023
OI Li, Xiaoling/0000-0002-1489-117X; 
FU the National Natural Science Foundation of China
FX The authors would like to thank the anonymous reviewers and editors for
   their invaluable suggestions. The work was supported in part by the
   Fundamental Research Funds for the Central Universities (No.
   2022YJS013), the National Natural Science Foundation of China (No.
   62172029), and the Fundamental Research Funds for the Central
   Universities (No. 2020JBM008).
CR Aymaz S, 2023, MULTIMED TOOLS APPL, V82, P1821, DOI 10.1007/s11042-022-13323-y
   Azarang A, 2018, REMOTE SENS LETT, V9, P91, DOI 10.1080/2150704X.2017.1395963
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Chen ZY, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1688, DOI 10.1109/IAEAC.2017.8054302
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Fu GP, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102760
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   He N, 2015, SIGNAL PROCESS, V112, P180, DOI 10.1016/j.sigpro.2014.08.025
   Hu ZH, 2021, APPL INTELL, V51, P4453, DOI 10.1007/s10489-020-02066-8
   Huang W, 2007, PATTERN RECOGN LETT, V28, P1123, DOI 10.1016/j.patrec.2007.01.013
   Jiang LB, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116068
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Lauriola I, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107194
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li H, 2021, PATTERN RECOGN LETT, V141, P45, DOI 10.1016/j.patrec.2020.11.014
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li XS, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108062
   Liu W, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107850
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Ma XL, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103328
   Mao QY, 2022, MULTIMED TOOLS APPL, V81, P12305, DOI 10.1007/s11042-021-11278-0
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Mishra Abhay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P887, DOI 10.1007/978-981-15-0751-9_81
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Pu YF, 2018, IEEE T IMAGE PROCESS, V27, P1214, DOI 10.1109/TIP.2017.2779601
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rao YJ, 1997, MEAS SCI TECHNOL, V8, P355, DOI 10.1088/0957-0233/8/4/002
   Sayevand K, 2012, APPL MATH MODEL, V36, P4356, DOI 10.1016/j.apm.2011.11.061
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Singh H, 2020, DIGIT SIGNAL PROCESS, V104, DOI 10.1016/j.dsp.2020.102793
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Song Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P401, DOI 10.1109/ROBIO.2006.340210
   Tan J, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116130
   Tang D, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116737
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Xu S, 2020, Arxiv, DOI arXiv:2002.04780
   Yang Y, 2019, IEEE T COMPUT IMAG, V5, P262, DOI 10.1109/TCI.2018.2889959
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang X, 2022, ISA Trans
   Zhang XC, 2022, IEEE T PATTERN ANAL, V44, P4819, DOI 10.1109/TPAMI.2021.3078906
   Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060
   Zhang YX, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116128
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   [左凯 Zuo Kai], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P3027
NR 62
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32923
EP 32943
DI 10.1007/s11042-023-16785-w
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400011
DA 2024-07-18
ER

PT J
AU Ahuja, P
   Sethi, P
   Chauhan, N
AF Ahuja, Pooja
   Sethi, Preeti
   Chauhan, Naresh
TI A comprehensive survey of security threats, detection, countermeasures,
   and future directions for physical and network layers in cognitive radio
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio; Data Link; Radio networks; Spectrum scarcity; Network
AB Cognitive radio is providing the solution to the challenges of spectrum scarcity. The central idea behind this technology is to use spectrum without interfering with the rights of primary users, allowing multiple users to use the spectrum at the same time. Thus, the goals are to avoid high-cost spectrum resetting and improving overall spectrum utilization. This technology brings the TCP/IP protocol stack's Physical, Data Link, and Network Layers up to date with reference to Cognitive radio technology. Furthermore, due to the dynamic nature of cognitive radio Networks, these can be easily physically or mentally hurt, influenced, or attacked: to a slew of new security flaws. We concentrated on various attacks that target the Physical, Medium Access Control, and Network layers in this paper. A comparison of current defenses against outside and inside attacks is also included, as is a discussion of the current detection mechanisms and their countermeasures. Moreover, the systematic review is conducted to look into various attack vectors or malicious activities that may degrade the performance of cognitive radio networks. In addition to this, various paper discusses various recent tools and techniques that can be used to diagnose potential threats on wireless ecosystem. This survey also highlights the fundamental security challenges for cognitive radio networks.
C1 [Ahuja, Pooja; Sethi, Preeti; Chauhan, Naresh] JC BOSE Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Ahuja, P (corresponding author), JC BOSE Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad, Haryana, India.
EM ahujap316@gmail.com
RI Chauhan, Naresh/AAG-5800-2021
OI Chauhan, Naresh/0000-0002-3132-7968
CR Abdelaziz AK, 2014, INT CONF MULTIMED, P752, DOI 10.1109/ICMCS.2014.6911193
   Ajayi OO., 2021, J Invent Eng Technol, V1, P64
   [Anonymous], 2008, 3 INT C COGN RAD OR
   [Anonymous], 2002, Rep. ET Docket no 02.135
   [Anonymous], 2013, P 8 ANN CYB SEC INF
   Atlasis A., 2012, BLACKHAT EUROPE, P14
   Bennaceur J, 2017, INT WIREL COMMUN, P2079, DOI 10.1109/IWCMC.2017.7986604
   Bouabdellah M, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION SYSTEMS AND INFORMATION SECURITY (ACOSIS), P175
   Chen CL, 2012, IEEE GLOB COMM CONF, P4856, DOI 10.1109/GLOCOM.2012.6503888
   Chen R, 2006, P IEEE WORKSH NWING
   Chen R, 2008, IEEE J SEL AREA COMM, V26, P25, DOI 10.1109/JSAC.2008.080104
   Chorti A, 2012, IEEE GLOB COMM CONF, P4868, DOI 10.1109/GLOCOM.2012.6503890
   Darwish M, 2013, Information society (i-Society)
   Das D., 2013, Int J Comput Network Wirel Commun, V3, P312
   El-Hajj W, 2011, J INTERNET TECHNOL, V12, P181
   Elderini T, 2017, IET COMMUN, V11, P1173, DOI 10.1049/iet-com.2016.0919
   Elghamrawy SM, 2020, FUTURE GENER COMP SY, V109, P479, DOI 10.1016/j.future.2018.08.022
   Gupta I, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P27, DOI 10.1109/ICCMC.2018.8487476
   Hanen I, 2014, P WORLD C ENG, V1, P1
   Haque MM, 2007, P INT COMP SOFTW APP, P49
   Hasnat M, 2019, IEEE INT C EL COMP C, P1
   Haykin S, 2005, IEEE J SEL AREA COMM, V23, P201, DOI 10.1109/JSAC.2004.839380
   Henze M., 2017, Security and Privacy in Cyber-Physical Systems: Foundations, Principles and Applications, P25
   Holcomb S, 2016, SE C, P1
   Tran H, 2016, 2016 IEEE SIXTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P457, DOI 10.1109/CCE.2016.7562679
   Idoudi H., 2014, P WORLD C ENG, V1, P2
   Jin Z, 2009, P IEEE INT C COMM, P1
   Karlof C, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL WORKSHOP ON SENSOR NETWORK PROTOCOLS AND APPLICATIONS, P113, DOI 10.1109/SNPA.2003.1203362
   Khalil I, 2005, I C DEPEND SYS NETWO, P612, DOI 10.1109/DSN.2005.58
   Khasawneh M, 2017, IEEE ACCESS, V5, P15597, DOI 10.1109/ACCESS.2017.2723322
   Kim M, 2011, COMPUT COMMUN, V34, P567, DOI 10.1016/j.comcom.2010.05.008
   Kundu C, 2015, IEEE T WIREL COMMUN, V14, P4614, DOI 10.1109/TWC.2015.2423290
   Lei HJ, 2017, IEEE T GREEN COMMUN, V1, P192, DOI 10.1109/TGCN.2017.2684827
   Ling MH, 2019, IEEE T COGN COMMUN, V5, P28, DOI 10.1109/TCCN.2018.2881135
   Liu S, 2012, IEEE GLOB COMM CONF, P603, DOI 10.1109/GLOCOM.2012.6503179
   Liu YB, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT UBIQUITOUS COMPUTING AND EDUCATION, P366, DOI 10.1109/IUCE.2009.127
   Manesh MR, 2017, INT J CRIT INFR PROT, V19, P16, DOI 10.1016/j.ijcip.2017.10.002
   Mitola J, 1999, IEEE PERS COMMUN, V6, P13, DOI 10.1109/98.788210
   Moalla S, 2015, SECUR COMMUN NETW, V8, P360, DOI 10.1002/sec.984
   Mouaatamid O.E., 2016, Electron. J. Inf. Technol, V9, P24
   Newsome J, 2004, P 3
   Padmadas M., 2015, Int J Adv Res Comput Commun Eng, V4, P170
   Parvin S., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P230, DOI 10.1109/BWCCA.2011.95
   Parvin S, 2013, Doctoral dissertation
   Parvin S, 2012, J NETW COMPUT APPL, V35, P1691, DOI 10.1016/j.jnca.2012.06.006
   Patel A., 2007, Fragmentation attack on wireless NW
   Pathan ASK., 2016, Security of self-organizing NWs: MANET, WSN, WMN, VANET
   Pei QQ, 2011, CHINESE J ELECTRON, V20, P138
   Quang DV, 2018, IEEE SENS J, V18, P2050, DOI 10.1109/JSEN.2018.2791563
   Do QV, 2019, INT J ELECTRON, V106, P1543, DOI 10.1080/00207217.2019.1600740
   Raisinghani VT, 2004, COMPUT COMMUN, V27, P720, DOI 10.1016/j.comcom.2003.10.011
   Rathee G., 2016, Int J Comput Sci Inf Secur, V14, P406
   Rawat AS, 2011, IEEE T SIGNAL PROCES, V59, P774, DOI 10.1109/TSP.2010.2091277
   Rawat AS, 2010, INT CONF ACOUST SPEE, P3098, DOI 10.1109/ICASSP.2010.5496102
   Rizvi S, 2015, PROCEDIA COMPUT SCI, V61, P206, DOI 10.1016/j.procs.2015.09.195
   Sajid A, 2020, FUTURE GENER COMP SY, V108, P816, DOI 10.1016/j.future.2020.03.020
   Salim S, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-102
   Sarkar S, 2012, ANNU IEEE IND CONF, P1084
   Selvapriya T., 2017, Int J Innov Res Electric Electron Instrum Control Eng, V5, P1
   Srinivasan S., 2018, Int J Appl Eng Res, V13, P52
   Thalor J., 2013, Int J Adv Res Comput Sci Softw Eng, V3, P137
   Tongjie Zhang, 2013, 2013 IEEE International Conference on Communications (ICC), P2601, DOI 10.1109/ICC.2013.6654927
   Nguyen VD, 2017, IEEE T COGN COMMUN, V3, P599, DOI 10.1109/TCCN.2017.2748132
   Vimal S, 2020, NEURAL COMPUT APPL, V32, P151, DOI 10.1007/s00521-018-3788-3
   Wang BB, 2011, IEEE J-STSP, V5, P5, DOI 10.1109/JSTSP.2010.2093210
   Wang WB, 2014, IEEE WCNC, P2510, DOI 10.1109/WCNC.2014.6952783
   Wang XY, 2016, IEEE T VEH TECHNOL, V65, P5611, DOI 10.1109/TVT.2015.2463686
   Wang Y., 2017, J Commun, V12, P1
   Wenkai W, 2009, IEEE GLOB TEL C, P1
   Xia H, 2013, AD HOC NETW, V11, P2096, DOI 10.1016/j.adhoc.2012.02.009
   Yilmaz MH, 2015, 2015 IEEE 40TH LOCAL COMPUTER NETWORKS CONFERENCE WORKSHOPS (LCN WORKSHOPS), P812, DOI 10.1109/LCNW.2015.7365932
   Yu R, 2016, IEEE NETWORK, V30, P62, DOI 10.1109/MNET.2016.1200149NM
   Yuan Z, 2013, IEEE T MOBILE COMPUT, V12, P1750, DOI 10.1109/TMC.2012.137
   Zakhary SR, 2010, WONS 2010: SEVENTH INTERNATIONAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES, P161, DOI 10.1109/WONS.2010.5437117
   Zhang N, 2012, IEEE ICC, P1763, DOI 10.1109/ICC.2012.6364434
   Zhang QH, 2005, 25TH IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P185
   Zhou X., 2013, Physical Layer Security in Wireless Communications
   Zou C, 2016, SECUR COMMUN NETW, V9, P4151, DOI 10.1002/sec.1595
   Zou YL, 2015, IEEE COMMUN MAG, V53, P48, DOI 10.1109/MCOM.2015.7263345
NR 79
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32715
EP 32738
DI 10.1007/s11042-023-16642-w
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069966300001
DA 2024-07-18
ER

PT J
AU Yashwanth, K
   Soni, B
AF Yashwanth, Kolli
   Soni, Badal
TI Encoder-Decoder Architectures based Video Summarization using Key-Shot
   Selection Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; CNN; LSTM; RNN; Key-Shot; Summarization
AB With the exponential growth of video data, video summarization has become a challenging task. In this article, we propose a deep learning framework for video summarization that utilizes a sequence learning cum encoder-decoder network architecture with a key-shot selection model. We develop two RNN-based deep models, Additive Attentive Summariser (AAS) and Multiplicative Attentive Summariser (MAS), as well as a CNN-based model named - Sequential CNN Summariser (SCS). Our SCS and MAS model displays state-of-the-art performance in semantic segmentation, which we leverage to achieve superior performance in video summarization. We evaluate our models on two well-known datasets, SumMe and TVSum, and show that our proposed MAS and SCS models outperform state-of-the-art models such as DR-DSN. The proposed MAS model achieved an average F1 score of 44.1% and 60.7% on SumMe and TVSum datasets, respectively. Further, our contributions include the development of novel RNN-based and CNN-based models for video summarization and comprehensive experimental evaluations on multiple datasets that demonstrate the effectiveness of our proposed models.
C1 [Yashwanth, Kolli; Soni, Badal] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Soni, B (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, India.
EM yashkolli01@gmail.com; badal@cse.nits.ac.in
CR [Anonymous], 2002, P 10 ACM INT C MULT
   Bhandari HN, 2022, MACH LEARN APPL, V9, DOI 10.1016/j.mlwa.2022.100320
   BoHe Jun, 2023, ARXIV
   Choudhury NA, 2023, IEEE T IND INFORM, V19, P10379, DOI 10.1109/TII.2022.3229522
   Choudhury NA, 2021, IEEE SENS J, V21, P16852, DOI 10.1109/JSEN.2021.3077563
   Feng KY, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103663
   Frizzo Stefenon Stefano, 2022, ELECTR POW SYST RES, V202
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hu W., 2023, MICROBIAL BIOPROCESS, P1
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   Kanafani H, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR '21), P466, DOI 10.1145/3460426.3463597
   Li X., 2022, PROC IEEECVF C COMPU, P18847
   Liang G., 2021, ARXIV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Meena P, 2023, ENG APPL ARTIF INTEL, V118, DOI 10.1016/j.engappai.2022.105667
   Moreno SR, 2020, ENERG CONVERS MANAGE, V213, DOI 10.1016/j.enconman.2020.112869
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Sabha Ambreen, 2023, MULTIMED TOOLS APPL, P1
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Srinivas M, 2016, PROCEDIA COMPUT SCI, V89, P812, DOI 10.1016/j.procs.2016.06.065
   Yadav AK, 2023, MULTIMED TOOLS APPL, V82, P29135, DOI 10.1007/s11042-023-14613-9
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Yoon UN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134562
   Yuan L, 2019, AAAI CONF ARTIF INTE, P9143
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang YJ, 2020, PATTERN RECOGN LETT, V130, P376, DOI 10.1016/j.patrec.2018.07.030
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhu WC, 2021, IEEE T IMAGE PROCESS, V30, P948, DOI 10.1109/TIP.2020.3039886
NR 30
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31395
EP 31415
DI 10.1007/s11042-023-16700-3
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500015
DA 2024-07-18
ER

PT J
AU Nie, TY
   Zhao, MZ
   Zhu, ZY
   Zhao, K
   Wang, ZH
AF Nie, Tingyuan
   Zhao, Mingzhi
   Zhu, Zuyuan
   Zhao, Kun
   Wang, Zhenhao
TI Estimating feature importance in circuit network using machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Complex network; Centrality; Physical design;
   Estimation
ID IDENTIFYING INFLUENTIAL SPREADERS; CENTRALITY
AB Identifying the feature of the circuit network is a crucial step to understanding the behavior of the Very Large Scale Integration (VLSI). Unfortunately, the growing complexity of the VLSI design makes enormous computations for estimating the property of the network. We propose a machine learning framework to overcome the intractable estimation of feature importance in the circuit network. We extract complex network features at the placement stage and compute circuit wire length at the routing stage, then study their correlation using machine learning and estimate the importance of complex network features by the learned correlation. The experimental result on TAU 2017 Benchmark shows the high efficiency of the framework that the prediction accuracy achieves an average of 96.722%. The estimated importance of complex network features is in order of the number of nodes, the average degree, the average edge weight, the average betweenness, the average strength, and the average weighted clustering coefficient. The result is convincing and consistent with the previous work, demonstrating the reliability of our method.
C1 [Nie, Tingyuan; Zhao, Mingzhi; Zhu, Zuyuan; Zhao, Kun; Wang, Zhenhao] Qingdao Univ Technol, Sch Informat & Control Engn, 777 Jialingjiang Rd, Qingdao 266520, Shandong, Peoples R China.
C3 Qingdao University of Technology
RP Nie, TY (corresponding author), Qingdao Univ Technol, Sch Informat & Control Engn, 777 Jialingjiang Rd, Qingdao 266520, Shandong, Peoples R China.
EM tynie@qut.edu.cn; zhao17662839186@163.com; zuyuanzhu@163.com;
   sterling1982@163.com; wangzhenghao@qut.edu.cn
FU NSFC [61572269]; Shandong Provincial Natural Science Foundation
   [ZR2021MF101]
FX Project 61572269 supported by NSFC. And project ZR2021MF101 supported by
   Shandong Provincial Natural Science Foundation.
CR Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Barthélemy M, 2004, EUR PHYS J B, V38, P163, DOI 10.1140/epjb/e2004-00111-4
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Berahmand K, 2018, CHAOS SOLITON FRACT, V110, P41, DOI 10.1016/j.chaos.2018.03.014
   Boguñá M, 2009, NAT PHYS, V5, P74, DOI [10.1038/nphys1130, 10.1038/NPHYS1130]
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cancho RFI, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.046119
   Chan T. R., 2006, Proceedings of ISPD'06. 2006 International Symposium on Physical Design, P212, DOI 10.1145/1123008.1123055
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P1228, DOI 10.1109/TCAD.2008.923063
   Cohen E., 2014, P 2 ACM C ONL SOC NE, P37, DOI [DOI 10.1145/2660460.2660465, 10.1145/2660460.2660465]
   D'Huys O, 2008, CHAOS, V18, DOI 10.1063/1.2953582
   Friedman J H, 1995, Stat Methods Med Res, V4, P197, DOI 10.1177/096228029500400303
   Grando F, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3237192
   Hu Jie, 2010, Proceedings of the 2010 International Conference of Information Science and Management Engineering, P35, DOI 10.1109/ISME.2010.191
   Hua Y, 2015, 2015 IEEE 23RD INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), P1, DOI 10.1109/IWQoS.2015.7404696
   Huang GY, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3451179
   Kapre N, 2015, ANN IEEE SYM FIELD P, P119, DOI 10.1109/FCCM.2015.36
   Khan HN, 2018, NAT ELECTRON, V1, P14, DOI 10.1038/s41928-017-0005-9
   Khatkhate A, 2004, P INT S PHYS DES, P84
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Mendonça MRF, 2021, IEEE T NETW SCI ENG, V8, P220, DOI 10.1109/TNSE.2020.3035352
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Nie TY, 2020, IEEE ACCESS, V8, P72683, DOI 10.1109/ACCESS.2020.2985736
   Nie TY, 2016, PHYSICA A, V453, P290, DOI 10.1016/j.physa.2016.02.009
   Onnela JP, 2005, PHYS REV E, V71, DOI 10.1103/PhysRevE.71.065103
   Pastor-Satorras R, 2001, PHYS REV LETT, V86, P3200, DOI 10.1103/PhysRevLett.86.3200
   Pretorius A, 2016, 2016 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH)
   Raman K, 2011, J R SOC INTERFACE, V8, P269, DOI 10.1098/rsif.2010.0212
   Rattigan M.J., 2006, KDD, P357
   Roy JA, 2006, IEEE T COMPUT AID D, V25, P1313, DOI 10.1109/TCAD.2005.855969
   Salavati C, 2019, NEUROCOMPUTING, V336, P36, DOI 10.1016/j.neucom.2018.04.086
   Samadi N, 2019, COMPUTING, V101, P1147, DOI 10.1007/s00607-018-0659-9
   Saxena A, 2020, ARXIV
   Shishavan ST, 2022, MULTIMED TOOLS APPL, V81, P25205, DOI 10.1007/s11042-022-12409-x
   Smith O, 2020, PHYS REV E, V101, DOI 10.1103/PhysRevE.101.020301
   Szentimrey H, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3373269
   Tang XW, 2014, IEEE ACM T COMPUT BI, V11, P407, DOI 10.1109/TCBB.2013.2295318
   Viswanathan N, 2007, ASIA S PACIF DES AUT, P135
   Wang David Eppstein Joseph, 2006, Graph Algorithms and Applications, V5, P39
   Xiaojian Yang, 2002, Proceedings of ISPD'02. 2002 International Symposium on Physical Design, P42, DOI 10.1145/505388.505400
NR 40
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31233
EP 31249
DI 10.1007/s11042-023-16814-8
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066762000011
DA 2024-07-18
ER

PT J
AU Saleh, S
   Cherradi, B
   El Gannour, O
   Hamida, S
   Bouattane, O
AF Saleh, Shawki
   Cherradi, Bouchaib
   El Gannour, Oussama
   Hamida, Soufiane
   Bouattane, Omar
TI Predicting patients with Parkinson's disease using Machine Learning and
   ensemble voting technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthcare; Parkinson's disease prediction; Hyperparameters;
   Cross-validation; Ensemble voting classifier; Disease diagnosis; Machine
   Learning
AB Parkinson's disease is the second most common neurological disorder that causes significant physical disabilities, decreases the quality of life, and does not have a cure. Because it is a nervous system disorder, it impacts people in different ways, affecting movement and speech and causing muscle stiffness. Approximately, 90% of people with Parkinson's disease have speech disorders. Machine Learning (ML) algorithms can mostly be employed for the early detection of diseases to enhance the lifespan and improve the lifestyle of people with chronic diseases such as Parkinson's disease. In this paper, we have employed an Artificial Neurons Network (ANN) and nineteen ML algorithms to predict people with Parkinson's disease using two different acoustic datasets. Contrary to the train-test split approach, this work aims to utilize the cross-validation technique to estimate the performance. The objective is to ensure that each sample in these small and unbalanced acoustic datasets contributes to both the training and testing processes to provide accurate estimations for the performance of the classifiers on unseen dataset, and to provide a clear insight into the effectiveness of ML algorithms in diagnosing Parkinson's disease via voice disorder. To enhance the performance of the prediction, we employed several techniques such as Optimal Hyperparameters Tuning and Cross-Validation to obtain the best performance and results, and we have provided a detailed explanation of these algorithms' performance and the Optimal Hyperparameters used for each of them. Based on the results and performance, the best classifiers have been selected to build two independent ensemble voting classifiers for the two different datasets. We calculated and represented the accuracy, sensitivity, specificity, precision and AUC. They reached 96.41% and 97.35% of accuracy, respectively.
C1 [Saleh, Shawki; Cherradi, Bouchaib; El Gannour, Oussama; Hamida, Soufiane; Bouattane, Omar] Hassan II Univ Casablanca, ENSET Mohammedia, EEIS Lab, Mohammadia, Morocco.
   [Cherradi, Bouchaib] Prov Sect El Jadida, STIE Team, CRMEF Casablanca Settat, El Jadida 24000, Morocco.
   [Hamida, Soufiane] SupMTI Rabat, GENIUS Lab, Rabat, Morocco.
C3 Hassan II University of Casablanca
RP Cherradi, B (corresponding author), Hassan II Univ Casablanca, ENSET Mohammedia, EEIS Lab, Mohammadia, Morocco.; Cherradi, B (corresponding author), Prov Sect El Jadida, STIE Team, CRMEF Casablanca Settat, El Jadida 24000, Morocco.
EM bouchaib.cherradi@gmail.com
RI EL GANNOUR, OUSSAMA/IAR-0349-2023; bouchaib, cherradi/J-2572-2016
OI EL GANNOUR, OUSSAMA/0000-0003-2536-9528; bouchaib,
   cherradi/0000-0002-2016-8682; saleh, shawki/0000-0002-8401-1959
CR Alexander Garrett E, 2004, Dialogues Clin Neurosci, V6, P259
   [Anonymous], Scikit-learn
   Aouraghe I, 2023, MULTIMED TOOLS APPL, V82, P11923, DOI 10.1007/s11042-022-13759-2
   archive, Parkinson's Disease dataset
   Arora P, 2022, MULTIMED TOOLS APPL, V81, P32215, DOI 10.1007/s11042-022-12960-7
   Asmae O, 2020, 2020 1st international conference on innovative research in applied science, engineering and technology (IRASET), DOI [10.1109/IRASET48871.2020.9092228, DOI 10.1109/IRASET48871.2020.9092228]
   Bentéjac C, 2021, ARTIF INTELL REV, V54, P1937, DOI 10.1007/s10462-020-09896-5
   Berrar D., 2019, Cross-Validation, P542, DOI DOI 10.1016/B978-0-12-809633-8.20349-X
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Bühlmann P, 2002, ANN STAT, V30, P927
   Chakraborty S, 2020, INT CONF ADV COMMUN, P298, DOI [10.23919/ICACT48636.2020.9061497, 10.23919/icact48636.2020.9061497]
   Chen HL, 2013, EXPERT SYST APPL, V40, P263, DOI 10.1016/j.eswa.2012.07.014
   Cherradi Bouchaib, 2021, 2021 International Congress of Advanced Technology and Engineering (ICOTEN), DOI 10.1109/ICOTEN52080.2021.9493524
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Cunningham P, 2008, COGN TECHNOL, P21, DOI 10.1007/978-3-540-75171-7_2
   Daanouni O, 2020, 3RD INTERNATIONAL CONFERENCE ON NETWORKING, INFORMATION SYSTEM & SECURITY (NISS'20), DOI 10.1145/3386723.3387887
   Daanouni O, 2019, 4TH INTERNATIONAL CONFERENCE ON SMART CITY APPLICATIONS (SCA' 19), DOI 10.1145/3368756.3369072
   Devarajan D, 2022, IEEE ACCESS, V10, P126957, DOI 10.1109/ACCESS.2022.3221451
   Du J, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012046
   El Gannour O., 2022, 2022 2nd international conference on innovative research in applied science, engineering and technology (IRASET), P1
   El Gannour O., 2020, 2020 IEEE 2nd international conference on electronics, control, optimization and computer science (ICECOCS), P1
   El Gannour O, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010103
   Eskidere Ö, 2012, EXPERT SYST APPL, V39, P5523, DOI 10.1016/j.eswa.2011.11.067
   Fekri-Ershad S, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13040686
   Fraiwan Luay, 2016, Journal of Medical Engineering & Technology, V40, P127, DOI 10.3109/03091902.2016.1148792
   Gannour OE, 2022, IJACSA, V13, DOI [10.14569/IJACSA.2022.0130668, DOI 10.14569/IJACSA.2022.0130668]
   García-Ordás MT, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14932-x
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Gupta I, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2203.11287, 10.48550/ARXIV.2203.11287]
   Hamida S., 2020, 2020 IEEE 2 INT C EL, P1
   Hamida S, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9437538
   Hasanin T, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12112844
   Jiji GW, 2023, MULTIMED TOOLS APPL, V82, P14915, DOI 10.1007/s11042-022-14042-0
   kaggle, Parkinson's Disease (PD) classification
   Khadidos AO, 2024, CURR BIOINFORM, V19, P281, DOI 10.2174/1574893618666230206121127
   Kour N, 2023, MULTIMED TOOLS APPL, V82, P10211, DOI 10.1007/s11042-022-13398-7
   Kumar A, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13298
   Kumari S., 2021, INT J COGN COMPUT EN, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Laghmati S., 2020, 3 INT C ADV COMMUNIC, P1, DOI [DOI 10.1109/COMMNET49926.2020.9199633, 10.1109/CommNet49926.2020.9199633]
   Lamrani D, 2022, INT J ADV COMPUT SC, V13, P452
   Leung PH, 2021, Artificial Intelligence and Big Data Analytics for Smart Healthcare, P197, DOI [10.1016/B978-0-12-822060-3.00014-0, DOI 10.1016/B978-0-12-822060-3.00014-0]
   Little MA, 2009, IEEE T BIO-MED ENG, V56, P1015, DOI 10.1109/TBME.2008.2005954
   Little MA, 2007, BIOMED ENG ONLINE, V6, DOI 10.1186/1475-925X-6-23
   Montemurro N, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19148799
   Morales-Alvarez P, 2018, IEEE T GEOSCI REMOTE, V56, P1103, DOI 10.1109/TGRS.2017.2758922
   Moujahid H., 2020, Adv. Sci. Technol. Eng. Syst. J., V5, P167
   Moujahid H., 2020, Smart applications and data analysis, P329, DOI [10.1007/978-3-030-45183-7_25, DOI 10.1007/978-3-030-45183-7_25]
   Moujahid H, 2022, INTELL AUTOM SOFT CO, V32, P723, DOI 10.32604/iasc.2022.022179
   Müller P, 2024, Arxiv, DOI [arXiv:2304.10151, 10.48550/ARXIV.2304.10151, DOI 10.48550/ARXIV.2304.10151]
   Nematzadeh S, 2022, COMPUT BIOL CHEM, V97, DOI 10.1016/j.compbiolchem.2021.107619
   Nilashi M, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/2793361
   Ouhmida A, 2021, 2021 international congress of advanced technology and engineering (ICOTEN), P1
   Ouhmida A., 2022, 2022 2 INT C INN RES, P1
   Parmar A, 2019, LECT NOTE DATA ENG, V26, P758, DOI 10.1007/978-3-030-03146-6_86
   Poewe W, 2006, J NEUROL, V253, P2, DOI 10.1007/s00415-006-7002-7
   Priya S, 2023, INTELL AUTOM SOFT CO, V35, P2673, DOI 10.32604/iasc.2023.028599
   Priyanka, 2020, International Journal of Information and Decision Sciences, V12, P246
   Rafalo M, 2022, ICT EXPRESS, V8, P183, DOI 10.1016/j.icte.2021.05.001
   Ross K. A., 2009, ENCY DATABASE SYSTEM, P532, DOI [DOI 10.1007/978-0-387-39940-9_565, 10.1007/978-0-387-39940-9_565]
   Saeed U, 2021, RELIAB ENG SYST SAFE, V205, DOI 10.1016/j.ress.2020.107284
   Sakar CO, 2019, APPL SOFT COMPUT, V74, P255, DOI 10.1016/j.asoc.2018.10.022
   Saleh S., 2023, 2023 3 INT C INN RES, P1
   Saleh S., 2023, Bulletin of Electrical Engineering and Informatics, V12, P1055
   Senthilkumar B, 2022, IFAC PAPERSONLINE, V55, P429, DOI 10.1016/j.ifacol.2022.04.071
   Shahhosseini M, 2022, MACH LEARN APPL, V7, DOI 10.1016/j.mlwa.2022.100251
   Shikha S., 2020, IJRASET, V8, P349, DOI [10.22214/ijraset.2020.7057, DOI 10.22214/IJRASET.2020.7057]
   Singh Rameshwer, 2023, Materials Today: Proceedings, P1006, DOI 10.1016/j.matpr.2021.04.356
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Sonawane B, 2021, MULTIMED TOOLS APPL, V80, P29437, DOI 10.1007/s11042-021-11061-1
   Suganya P., 2015, INDIAN J SCI TECHNOL, V8
   Supervised learning, scikit-learn
   Taleb C, 2023, EVOL INTELL, V16, P1813, DOI 10.1007/s12065-020-00470-0
   Taud H., 2018, Geomatic approaches for modeling land change scenarios, DOI [DOI 10.1007/978-3-319-60801-3_27, DOI 10.1007/978-3-319-60801-327]
   Tavana P, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119290
   Terrada O, 2020, 1 INT C INN RES APPL, P1, DOI [10.1109/IRASET48871.2020.9092082, DOI 10.1109/IRASET48871.2020.9092082]
   Terrada O., 2020, 2020 3 INT C ADV COM, P1
   Terrada O., 2020, Inform Med Unlocked, V21, P100483, DOI [10.1016/j.imu.2020.100483, DOI 10.1016/J.IMU.2020.100483]
   Terrada O., 2020, Adv Sci Technol Eng Syst, V5, P269, DOI [10.25046/aj050533, DOI 10.25046/AJ050533]
   Terrada O., 2018, 2018 4th international conference on optimization and applications (ICOA), P1
   UCI Machine Learning Repository, Parkinsons Data Set
   van Wieringen W, 2021, Arxiv, DOI arXiv:1509.09169
   Yang YZ, 2022, NAT MED, V28, P2207, DOI 10.1038/s41591-022-01932-x
   Zham P, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00435
   Zhang RL, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103883
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 85
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33207
EP 33234
DI 10.1007/s11042-023-16881-x
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066762000002
DA 2024-07-18
ER

PT J
AU Ajroud, C
   Hattay, J
   Machhout, M
AF Ajroud, Chokri
   Hattay, Jamel
   Machhout, Mohsen
TI A novel holographic technique for RFID localization in indoor
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RFID; Indoor localization; Holographic algorithm; Static tags
ID TAGS; LPM
AB The increasing use of communication technology, the Internet Of Things, and their applications and services has led to a growing demand for indoor localization. A Radio Frequency Identification (RFID)-based indoor localization system can provide a viable solution for these applications and services. However, the complexity of indoor environments and the resulting multipath interference are identified as major challenges in achieving high localization accuracy. In this paper, we propose an enhanced holographic RFID localization method for static tags in indoor environments. The proposed method involves using four RFID readers that move around an indoor area to enhance holographic RFID localization. By reducing the computational load and optimizing the number and placement of the readers, the proposed method achieves a localization error of only 2 cm within a 10 x 10 m(2) indoor environment. Overall, the proposed enhanced holographic RFID localization method presents a viable solution for achieving high localization accuracy in indoor environments, with potential applications in various domains such as logistics, healthcare, and security.
C1 [Ajroud, Chokri; Hattay, Jamel; Machhout, Mohsen] Lab Elect & Microelect LR99ES30, Monastir, Tunisia.
RP Ajroud, C (corresponding author), Lab Elect & Microelect LR99ES30, Monastir, Tunisia.
EM Chokri.ajroud@tunisietelecom.tn; jamel.hattay@tunisietelecom.tn;
   mohsen.machhout@fsm.rnu.tn
RI Ajroud, Chokri/JPX-2791-2023
OI Ajroud, Chokri/0000-0001-5270-9984
CR Alsalih W., 2014, INT J DISTRIB SENS N, V793982, P12, DOI [10.1155/2014/, DOI 10.1155/2014]
   Asaad SM, 2022, COMPUT NETW, V212, DOI 10.1016/j.comnet.2022.109041
   Bechteler TF, 2003, IEEE T MICROW THEORY, V51, P1584, DOI 10.1109/TMTT.2003.810142
   Bekkali A., 2007, Proceedings of IEEE Inter- national Conference on Wireless and Mobile Computing, Networking and Com- munications, P21, DOI DOI 10.1109/WIMOB.2007.4390815
   Bouet M, 2008, RFID TAGS POSITIONIN, P1, DOI [10.1109/WD.2008.4812905, DOI 10.1109/WD.2008.4812905]
   Eid A, 2021, IEEE INTERNET THINGS, V8, P14719, DOI 10.1109/JIOT.2021.3071693
   Frencken WGP, 2010, J SCI MED SPORT, V13, P641, DOI 10.1016/j.jsams.2010.04.003
   Gu YY, 2009, IEEE COMMUN SURV TUT, V11, P13, DOI 10.1109/SURV.2009.090103
   Habaebi Mohamed Hadi, 2020, International Journal of Interactive Mobile Technologies, V14, P4, DOI 10.3991/ijim.v14i05.13309
   Hightower J, 2000, P 2000 INT C MOB COM, P165
   Huang WQ, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON SYSTEMS AND INFORMATICS (ICSAI), P497, DOI 10.1109/ICSAI.2014.7009338
   Huang Y, 2020, WORLD NEUROSURG, V138
   Huang ZQ, 2015, INT CONF KNOWL SYS, P489, DOI 10.1109/ISKE.2015.16
   Kong HS, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4812057
   Lipka M, 2020, I M I C MICROW I M, DOI 10.1109/icmim48759.2020.9299062
   Liu HK, 2021, IEEE T VEH TECHNOL, V70, P1984, DOI 10.1109/TVT.2021.3053313
   Merhi ZM, 2009, IEEE T MOBILE COMPUT, V8, P1690, DOI 10.1109/TMC.2009.81
   Ni LM, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS (PERCOM 2003), P407, DOI 10.1109/PERCOM.2003.1192765
   Obeidat H, 2021, WIRELESS PERS COMMUN, V119, P289, DOI 10.1007/s11277-021-08209-5
   Resch A., 2012, P 2012 INT C LOC GNS, P1, DOI [10.1109/ICL-GNSS.2012.6253104, DOI 10.1109/ICL-GNSS.2012.6253104]
   Stelzer A, 2004, IEEE T MICROW THEORY, V52, P2664, DOI 10.1109/TMTT.2004.838281
   Stevens TGA, 2014, INT J SPORT PHYSIOL, V9, P446, DOI [10.1123/ijspp.2013-0340, 10.1123/IJSPP.2013-0340]
   V-C Ta, 2017, MACHINE LEARNING CS
   Viani F, 2011, RADIO SCI, V46, DOI 10.1029/2010RS004561
   Wang C, 2007, IEEE INFOCOM SER, P1235, DOI 10.1109/INFCOM.2007.147
   Xue F, 2020, PRECISE LOCALIZATION
   Yang J, 2008, ENCY GIS, DOI [10.1007/978-0-387-35973-1-627, DOI 10.1007/978-0-387-35973-1-627]
   Yang P, 2014, IEEE T IND ELECTRON, V61, P5641, DOI 10.1109/TIE.2014.2301737
   Yassin A, 2017, IEEE COMMUN SURV TUT, V19, P1327, DOI 10.1109/COMST.2016.2632427
   Yu JH, 2017, IEEE T MOBILE COMPUT, V16, P1371, DOI 10.1109/TMC.2016.2592902
   Zafari F, 2019, IEEE COMMUN SURV TUT, V21, P2568, DOI 10.1109/COMST.2019.2911558
   Zhao BB, 2019, COMPUT NETW, V162, DOI 10.1016/j.comnet.2019.106864
NR 32
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29827
EP 29840
DI 10.1007/s11042-023-16539-8
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900009
DA 2024-07-18
ER

PT J
AU Krishna, MV
   Swaroopa, K
   Swarnalatha, G
   Yasaswani, V
AF Krishna, M. Vamsi
   Swaroopa, K.
   Swarnalatha, G.
   Yasaswani, V.
TI Crop yield prediction in India based on mayfly optimization empowered
   attention-bi-directional long short-term memory (LSTM)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop yield prediction; Cultivation; Feature selection; Bidirectional
   long short-term memory
ID MODEL; CORN
AB Accurate crop yield prediction is extremely useful to global food production. On the basis of precise forecasts, timely import and export choices should be made. The model of crop yield prediction facilitates the farmers for making better decision regarding the suitable time for crop cultivation. In this study, the prediction of major crops in India is focused by using weather, soli and rainfall data.This study uses pre-processing, feature selection (FS) and prediction model. Initially, the dataset is normalized and the necessary features are selected by three FS models. The FS models are Lasso Based Feature Selection (LFS), Correlation Based Feature Selection (CFS) and Mutual Information Based Feature Selection (MIFS). Then deep learning (DL) based optimization (Attention with Bidirectional Long Short-Term Memory (A-BiLSTM)-MayFlyAlgorithm (MFA) is used for crop prediction. This optimization is used to minimize the loss function; thereby achieving better prediction. In India, the crops like Rice, sugarcane, wheat andmaize are the most cultivatable. Hence, in this work, these crops are considered for prediction. The performance of the BiLSTM- MFA is compared with certain DL models on the basis of error measures.
C1 [Krishna, M. Vamsi; Swaroopa, K.; Swarnalatha, G.; Yasaswani, V.] Aditya Engn Coll, Surampalem, India.
   [Krishna, M. Vamsi; Swaroopa, K.; Swarnalatha, G.; Yasaswani, V.] Jawaharlal Nehru Technol Univ Kakinada, Kakinada, Andhra Pradesh, India.
C3 Aditya Engineering College, Surampalem; Jawaharlal Nehru Technological
   University - Kakinada
RP Krishna, MV (corresponding author), Aditya Engn Coll, Surampalem, India.; Krishna, MV (corresponding author), Jawaharlal Nehru Technol Univ Kakinada, Kakinada, Andhra Pradesh, India.
EM vamsikrishna12phd@gmail.com; swaroopachalam@gmail.com;
   dasariswarnaprasad@gmail.com; yashu.vanapalli29@gmail.com
RI Mangalapalli, Vamsi Krishna/AFM-7203-2022
OI Mangalapalli, Vamsi Krishna/0000-0001-5285-9990; /0000-0002-7814-5045
CR Aghighi H, 2018, IEEE J-STARS, V11, P4563, DOI 10.1109/JSTARS.2018.2823361
   Agrawal A, EMERGING TECHNOLOGIE, P981
   Anbananthen KSM, 2021, F1000 RES, V10
   Brown JN, 2018, AGR FOREST METEOROL, V260, P247, DOI 10.1016/j.agrformet.2018.06.001
   Cao J, 2021, AGR FOREST METEOROL, V297, DOI 10.1016/j.agrformet.2020.108275
   Champaneri M, 2020, INT J SCI RES IJSR, V9
   Doshi Z, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   Elavarasan D, 2018, COMPUT ELECTRON AGR, V155, P257, DOI 10.1016/j.compag.2018.10.024
   Feng PY, 2020, AGR FOREST METEOROL, V285, DOI 10.1016/j.agrformet.2020.107922
   Folberth C, 2019, AGR FOREST METEOROL, V264, P1, DOI 10.1016/j.agrformet.2018.09.021
   Kalaiarasi E., 2021, INDIAN J SCI TECHNOL, V14, P131, DOI [10.17485/IJST/v14i2.2115, DOI 10.17485/IJST/v14i2.2115]
   Khaki S, 2020, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01750
   Li Y, 2019, FIELD CROP RES, V234, P55, DOI 10.1016/j.fcr.2019.02.005
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Ma YC, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106314
   Masare Y., 2020, INT J RES TECHNOL, VISSN, P2278
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104859
   Peng B, 2020, INT J APPL EARTH OBS, V90, DOI 10.1016/j.jag.2020.102126
   Qiao MJ, 2021, INT J APPL EARTH OBS, V102, DOI 10.1016/j.jag.2021.102436
   Sun J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204363
   Velmurugan P, 2021, MATER TODAY-PROC, V81, P112
   Wang XL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111744
   Wolanin A, 2020, ENVIRON RES LETT, V15, DOI 10.1088/1748-9326/ab68ac
NR 24
TC 1
Z9 1
U1 10
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29841
EP 29858
DI 10.1007/s11042-023-16807-7
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900004
DA 2024-07-18
ER

PT J
AU Anjali, T
   Masilamani, 
AF Anjali, T.
   Masilamani, V
TI Explainable masked face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mask occlusion; Cropping-based approach; Masked face recognition; Vision
   transformers
AB The COVID-19 epidemic has made us all to understand that using face masks is one of the best ways to save ourselves from infections. Face recognition techniques often focus on the essential facial landmarks such as nose, mouth and eyes. Removing masks in airports or other public places for authentication will raise the danger of virus infection, and this will pose a challenge to the existing face recognition systems. This paper presents a novel approach to recognize masked faces that combines cropping the unmasked half of the face (the upper part of a face) image using a vision transformer model. Various scenarios are investigated in this paper. The model is trained using the images of the upper half of the face and tested on the same, full-face images with a mask and full face images without a mask. The experiments on the standard datasets, namely RMFRD, MLFW and masked CASIA-WebFace show that the proposed approach improves masked face recognition significantly compared to the existing methods. The explainability of the proposed model is demonstrated using a class activation map.
C1 [Anjali, T.; Masilamani, V] Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Kancheepuram 600127, Tamil Nadu, India.
C3 Indian Institute of Information Technology, Design & Manufacturing,
   Kancheepuram
RP Anjali, T (corresponding author), Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Kancheepuram 600127, Tamil Nadu, India.
EM coe20d001@iiitdm.ac.in; masila@iiitdm.ac.in
CR Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Alzu'bi A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212666
   Anwar A., 2020, arXiv
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen HQ, 2022, IEEE ACCESS, V10, P75536, DOI 10.1109/ACCESS.2022.3191113
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2021, IEEE INT CONF COMP V, P1437, DOI 10.1109/ICCVW54120.2021.00165
   Ding FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2281, DOI 10.1145/3394171.3413731
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Du H, 2021, IEEE SIGNAL PROC LET, V28, P768, DOI 10.1109/LSP.2021.3071663
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Geng MY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2246, DOI 10.1145/3394171.3413723
   Golwalkar R, 2022, APPL INTELL, V52, P13268, DOI 10.1007/s10489-021-03150-3
   Hariri W, 2022, SIGNAL IMAGE VIDEO P, V16, P605, DOI 10.1007/s11760-021-02050-w
   Ku Hongchang., 2020, Frontiers in Signal Processing, V4, P37
   Kumar S, 2023, MECH BASED DES STRUC, V51, P6293, DOI 10.1080/15397734.2022.2040362
   Li YD, 2021, APPL INTELL, V51, P3012, DOI 10.1007/s10489-020-02100-9
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   pytorch, PYTORCH TORCHVISION
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Sun Y, 2014, ADV NEUR IN, V27
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Wu GL, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5591020
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yi Dong, 2014, ARXIV14117923
   Yin BJ, 2019, IEEE I CONF COMP VIS, P9347, DOI 10.1109/ICCV.2019.00944
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang YX, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108522
   Zhenbin Shuai, 2021, 2021 IEEE International Conference on Smart Internet of Things (SmartIoT), P82, DOI 10.1109/SmartIoT52359.2021.00022
   Zhong Y., 2021, ARXIV
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu Z., 2021, ARXIV
NR 38
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31123
EP 31138
DI 10.1007/s11042-023-16571-8
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063374600001
DA 2024-07-18
ER

PT J
AU Baraheem, SS
   Nguyen, TV
AF Baraheem, Samah S.
   Tam V. Nguyen
TI Sketch-to-image synthesis via semantic masks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch-to-image generation; Sketch-to-image synthesis; Computer vision;
   Generative adversarial networks; Instance and semantic segmentation;
   Machine learning
ID NETWORKS
AB Sketch-to-image is an important task to reduce the burden of creating a color image from scratch. Unlike previous sketch-to-image models, where the image is synthesized in an end-to-end manner, leading to an unnaturalistic image, we propose a method by decomposing the problem into subproblems to generate a more naturalistic and reasonable image. It first generates an intermediate output which is a semantic mask map from the input sketch through instance and semantic segmentation in two levels, background segmentation and foreground segmentation. Background segmentation is formed based on the context of the foreground objects. Then, the foreground segmentations are sequentially added to the created background segmentation. Finally, the generated mask map is fed into an image-to-image translation model to generate an image. Our proposed method works with 92 distinct classes. Compared to state-of-the-art sketch-to-image models, our proposed method outperforms the previous methods and generates better images.
C1 [Baraheem, Samah S.] Umm Al Qura Univ, Dept Comp Sci, Al Lith, Saudi Arabia.
   [Baraheem, Samah S.; Tam V. Nguyen] Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
C3 Umm Al Qura University; University System of Ohio; University of Dayton
RP Baraheem, SS (corresponding author), Umm Al Qura Univ, Dept Comp Sci, Al Lith, Saudi Arabia.; Baraheem, SS (corresponding author), Univ Dayton, Dept Comp Sci, Dayton, OH 45469 USA.
EM ssbaraheem@uqu.edu.sa
OI Baraheem, Samah/0000-0003-4742-6861
FU University of Dayton Office for Graduate Academic Affairs Affairs
   through the Graduate Student Summer Fellowship Program
FX The first author would like to thank Umm Al-Qura University, in Saudi
   Arabia, for the continuous support. The second author is supported by
   NSF grant # 2025234. This work has been supported in part by the
   University of Dayton Office for Graduate Academic Affairs through the
   Graduate Student Summer Fellowship Program.
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   Baraheem SS, 2020, PATTERN RECOGN LETT, V133, P25, DOI 10.1016/j.patrec.2020.02.013
   Baraheem SS, 2020B 54 ANN C INFOR, P1
   Beyeler M., 2015, OpenCV with Python Blueprints Design and Develop Advanced Computer Vision Projects using OpenCV with Python
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chalechale A, 2004, IEE P-VIS IMAGE SIGN, V151, P93, DOI 10.1049/ip-vis:20040332
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Chicco D, 2021, METHODS MOL BIOL, V2190, P73, DOI 10.1007/978-1-0716-0826-5_3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Dokmanic I, 2015, ADV NEURAL INF PROCE, V29
   Eitz M, 2011, IEEE COMPUT GRAPH, V31, P56, DOI 10.1109/MCG.2011.67
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Fan Q., 2019, PROC CVPR IEEE
   Fang YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6890, DOI 10.1109/ICCV48922.2021.00683
   Feng ZY, 2019, PROC CVPR IEEE, P10356, DOI 10.1109/CVPR.2019.01061
   Gao CY, 2020, PROC CVPR IEEE, P5173, DOI 10.1109/CVPR42600.2020.00522
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Güngör A, 2023, MED IMAGE ANAL, V88, DOI 10.1016/j.media.2023.102872
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hensel M, 2017, ADV NEUR IN, V30
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Ho J, 2022, J MACH LEARN RES, V23, P1
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Iyyer M, 2018, ARXIV
   Jolicoeur-Martineau A, 2020, ARXIV
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Krause A, 1998, CMU             0101
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kwon H, 2022, J SENSORS, V2022, DOI 10.1155/2022/4390413
   Li B, 2022, IEEE T MULTIMEDIA, V24, P4077, DOI 10.1109/TMM.2021.3113786
   Li ZY, 2021, IEEE T MULTIMEDIA, V23, P2694, DOI 10.1109/TMM.2020.3015015
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu B, 2020, P 15 AS C COMP VIS, P207
   Liu BC, 2021, AAAI CONF ARTIF INTE, V35, P2073
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Liu MC, 2021, ADV NEUR IN, V34
   Liu Yun, 2017, arXiv
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nichol A, 2021, PR MACH LEARN RES, V139
   Nichol Alex, 2021, arXiv
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Osahor U, 2020, IEEE COMPUT SOC CONF, P3575, DOI 10.1109/CVPRW50498.2020.00418
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ozbey M, 2022, IEEE T MED IMAGING
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Qi YG, 2022, INT J COMPUT VISION, V130, P2006, DOI 10.1007/s11263-022-01623-7
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Rajput GG, 2019, PROCEDIA COMPUT SCI, V165, P216, DOI 10.1016/j.procs.2020.01.089
   Ramesh A., 2022, arXiv
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Runtao Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P36, DOI 10.1007/978-3-030-58580-8_3
   Salimans T, 2016, ADV NEUR IN, V29
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sasaki H., 2021, arXiv
   Shen JL, 2021, INFORM SCIENCES, V569, P469, DOI 10.1016/j.ins.2020.11.026
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song Y., 2020, ADV NEURAL INFORM PR, V33, P12438, DOI DOI 10.48550/ARXIV.2006.09011
   Soo: S., 2014, Institute of Computer Science, University of Tartu, V2, P1
   Springenberg JT, 2014, INT C LEARNING REPRE
   Sun JY, 2022, NEURAL NETWORKS, V154, P179, DOI 10.1016/j.neunet.2022.07.013
   Szanto B., 2011, 2011 IEEE 9th International Symposium on Applied Machine Intelligence and Informatics (SAMI), P183, DOI 10.1109/SAMI.2011.5738872
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tian Q, 2022, ARXIV
   Tian Y, 2020, ARXIV
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4672, DOI 10.1109/ICCV48922.2021.00465
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang T., 2022, ARXIV
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   XU PENG, 2020, arXiv
   Yang B, 2023, APPL INTELL, V53, P2332, DOI 10.1007/s10489-022-03469-5
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhang RQ, 2022, NEUROCOMPUTING, V490, P413, DOI 10.1016/j.neucom.2021.12.015
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zihan Chen, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P155, DOI 10.1109/ICIVC50857.2020.9177494
   Zou CQ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356561
NR 87
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29047
EP 29066
DI 10.1007/s11042-023-16704-z
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001062311100002
DA 2024-07-18
ER

PT J
AU Kallimani, R
   Pai, KS
   Raghuwanshi, P
   Iyer, S
   López, OLA
AF Kallimani, Rakhee
   Pai, Krishna
   Raghuwanshi, Prasoon
   Iyer, Sridhar
   Lopez, Onel L. A.
TI TinyML: Tools, applications, challenges, and future research directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TinyML; Embedded AI; Edge computing; IoT
ID EDGE
AB In recent years, Artificial Intelligence (AI) and Machine learning (ML) have gained significant interest from both, industry and academia. Notably, conventional ML techniques require enormous amounts of power to meet the desired accuracy, which has limited their use mainly to high-capability devices such as network nodes. However, with many advancements in technologies such as the Internet of Things (IoT) and edge computing, it is desirable to incorporate ML techniques into resource-constrained embedded devices for distributed and ubiquitous intelligence. This has motivated the emergence of the TinyML paradigm which is an embedded ML technique that enables ML applications on multiple cheap, resource- and power-constrained devices. However, during this transition towards appropriate implementation of the TinyML technology, multiple challenges such as processing capacity optimisation, improved reliability, and maintenance of learning models' accuracy require timely solutions. In this article, various avenues available for TinyML implementation are reviewed. Firstly, a background of TinyML is provided, followed by detailed discussions on various tools supporting TinyML. Then, state-of-art applications of TinyML using advanced technologies are detailed. Lastly, detailed prospects are presented which include various research challenges and identification of future directions.
C1 [Kallimani, Rakhee] KLE Technol Univ, Dept Elect & Elect Engn, Dr MS Sheshgiri Campus, Belagavi 590008, Karnataka, India.
   [Raghuwanshi, Prasoon; Lopez, Onel L. A.] Univ Oulu, Fac Informat Technol & Elect Engn, Oulu 90014, Finland.
   [Iyer, Sridhar] KLE Technol Univ, Dept CSE AI, Dr MS Sheshgiri Campus, Belagavi 590008, Karnataka, India.
   [Pai, Krishna] KLE Technol Univ, Dept Elect & Commun Engn, Dr MS Sheshgiri Campus, Belagavi 590008, Karnataka, India.
C3 KLE Technological University; University of Oulu; KLE Technological
   University; KLE Technological University
RP Pai, KS (corresponding author), KLE Technol Univ, Dept Elect & Commun Engn, Dr MS Sheshgiri Campus, Belagavi 590008, Karnataka, India.
EM rakhee.kallimani@klescet.ac.in; krishnapai271999@gmail.com;
   Prasoon.Raghuwanshi@oulu.fi; sridhariyer1983@klescet.ac.in;
   onel.alcarazlopez@oulu.fi
RI PAI, KRISHNA/AFL-7466-2022; Lopez, Onel Luis Alcaraz/AAX-1853-2020;
   Iyer, Sridhar/AAE-6849-2020
OI PAI, KRISHNA/0000-0003-0972-3275; Lopez, Onel Luis
   Alcaraz/0000-0003-1838-5183; Iyer, Sridhar/0000-0002-8466-3316;
   Kallimani, Dr. Rakhee/0000-0003-0790-024X
CR Adi SE, 2021, IEEE ENG MED BIO, P7028, DOI 10.1109/EMBC46164.2021.9629549
   Agrawal A, 2020, ALGORITHMICA, V82, P1939, DOI 10.1007/s00453-020-00681-y
   Alajlan NN, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060851
   Alongi F, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P350, DOI 10.1109/SMARTCOMP50058.2020.00076
   Apache MXNet, FLEX EFF LIB DEEP LE
   Avola D, 2022, LECT NOTES COMPUT SC, V13231, P489, DOI 10.1007/978-3-031-06427-2_41
   Awad AI, 2023, ICT EXPRESS, V9, P473, DOI 10.1016/j.icte.2022.05.006
   Banbury C. R., 2020, arXiv
   Banbury C. R., 2021, Benchmarking TinyML systems: Challenges and direction
   Bao WGDL, 2021, CHINA COMMUN, V18, P39, DOI 10.23919/JCC.2021.06.004
   Benmeziane H., 2021, ARXIV
   Bharadwaj HK, 2021, IEEE ACCESS, V9, P38859, DOI 10.1109/ACCESS.2021.3059858
   Bringmann O, 2021, CODES ISSS 21
   Cai H, 2020, ARXIV
   Carrera-Rivera Angela, 2022, MethodsX, V9, P101895, DOI 10.1016/j.mex.2022.101895
   cartesiam, HOM NANOEDGETM STUD
   Coffen B., 2021, P IEEE INT C E HLTH, P1, DOI [10.1109/HEALTHCOM49281.2021.9399005, DOI 10.1109/HEALTHCOM49281.2021.9399005]
   Corepla, US
   Curnick DJ, 2022, REMOTE SENS ECOL CON, V8, P139, DOI 10.1002/rse2.239
   Dai XF, 2020, IEEE SOUTHEASTCON, DOI 10.1109/southeastcon44009.2020.9249652
   Day M, 2022, PROGRAMMABLE POWER M
   De Leon JD, 2022, INT CONF ACOUST SPEE, P3963, DOI 10.1109/ICASSP43922.2022.9746843
   de Prado M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041339
   Delnevo G, 2021, P 2021 IEEE GLOBECOM, P1
   Ding C, 2022, IEEE T NEUR NET LEAR, V33, P7210, DOI 10.1109/TNNLS.2021.3084467
   Dutta L, 2021, INTERNET THINGS-NETH, V16, DOI 10.1016/j.iot.2021.100461
   Edge Impulse, About us
   ericsson, TINYML SERV MACH LEA
   Eroma A, 2020, UNSUPERVISED COLLABO
   Fahim F, 2021, HLS4ML OPEN SOURCE C
   Fedorov I, 2020, ARXIV
   Fedorov I, 2020, INTERSPEECH, P4054, DOI 10.21437/Interspeech.2020-1864
   github, AUTOFLOW LEARN BETT
   github, EMB LEARN LIB EMB LE
   google, ML KIT FIR
   Goudarzi M., 2021, IEEE T MOBILE COMPUT, P1
   Gousev E, 2020, RECENT PROGR TINYML
   GULERIA C, 2021, INNOVATIONS ENERGY M, P1
   Hui Han, 2022, 2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P269, DOI 10.1109/ICAIIC54071.2022.9722636
   Immonen R, 2022, J SENSORS, V2022, DOI 10.1155/2022/7437023
   Introduction to STM32Cube, STMICROELECTRONICS
   Iyer S, 2023, WIRELESS PERS COMMUN, V129, P569, DOI 10.1007/s11277-022-10111-7
   Johnny F, 2021, CMSIS NN OPTIMIZATIO
   Khajooei A, 2023, INFORMATION, V14, DOI 10.3390/info14040235
   Kitchenham B., 2007, 2007001 EBSE
   Krippendorff K., 2018, CONTENT ANAL INTRO I
   Krstulovic S, 2020, DATA COLLECTION DESI
   Kwon J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112211073
   Li HH, 2023, IEEE T INF FOREN SEC, V18, P1410, DOI 10.1109/TIFS.2023.3240859
   Li J, 2021, ARXIV
   Liberis E, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569468
   Liu JL, 2022, IEEE INTERNET THINGS, V9, P10370, DOI 10.1109/JIOT.2021.3091599
   Lopez OA, 2023, ENERGY SUSTAINABLE I
   López OLA, 2021, IEEE INTERNET THINGS, V8, P8816, DOI 10.1109/JIOT.2021.3050612
   Lord M, 2021, THESIS CALIFORNIA ST
   Mahmood N. H., 2020, 6G Research Visions, V11
   Merk T, 2022, EXP NEUROL, V351, DOI 10.1016/j.expneurol.2022.113993
   microsoft, About us
   Mlcommons, 2023, US
   Mohan Puranjay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2021. Lecture Notes in Electrical Engineering (LNEE 756), P657, DOI 10.1007/978-981-16-0749-3_52
   Mooney P, 2022, KAGGLE MACHINE LEARN
   Muhammad G, 2021, IEEE INTERNET THINGS, V8, P16894, DOI 10.1109/JIOT.2021.3058587
   Muniswamaiah Manoj, 2021, 2021 8th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2021 7th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom), P139, DOI 10.1109/CSCloud-EdgeCom52276.2021.00034
   Nakhle F, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100323
   Njor E, 2022, IFIP ADV INF COMM TE, V647, P67, DOI 10.1007/978-3-031-08337-2_6
   Ogino T, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2021), P168, DOI 10.1109/ICICT52872.2021.00035
   Omar.unwrap, 2022, EST YOUR EMB IOT DEV
   Padhi PK, 2021, APPL SYST INNOV, V4, DOI 10.3390/asi4030066
   Pai K, 2023, SURVEY BRAIN COMPUTE, P210
   Paissan F, 2022, ACM T EMBED COMPUT S, V21, DOI 10.1145/3510832
   Patil SG, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P403, DOI 10.1145/3332165.3347881
   Paul Aditya Jyoti, 2020, 2020 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P147, DOI 10.1109/RAICS51191.2020.9332480
   Petticrew M., 2006, Syst. Rev. Soc. Sci.: A Pract. guide, DOI DOI 10.1002/9780470754887
   Prasanna R, 2022, IMPLEMENTATION TINY
   pytorch, HOM PYTORCH
   Quer J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00483
   Rajapakse V, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3583683
   RashidHA MA, 2020, TINY RESPNET SCALABL
   Ray PP, 2022, J KING SAUD UNIV-COM, V34, P1595, DOI 10.1016/j.jksuci.2021.11.019
   Raza W, 2021, DRONES-BASEL, V5, DOI 10.3390/drones5040127
   Reddi VJ, 2021, WIDENING ACCESS APPL
   Ren H, 2021, ARXIV
   Ren W, 2022, IEEE T NETW SCI ENG, V9, P416, DOI 10.1109/TNSE.2021.3120270
   Rosero-Montalvo Paul D., 2018, 2018 IEEE Third Ecuador Technical Chapters Meeting (ETCM), DOI 10.1109/ETCM.2018.8580268
   Roshan AN, 2021, 2021 SIXTH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P451, DOI [10.1109/WISPNET51692.2021.9419472, 10.1109/WiSPNET51692.2021.9419472]
   Sanchez-Iborra R, 2020, IEEE CIRC SYST MAG, V20, P4, DOI 10.1109/MCAS.2020.3005467
   Santosh Kumar B., 2022, 2022 Fourth International Conference on Emerging Research in Electronics, Computer Science and Technology (ICERECT), P1, DOI 10.1109/ICERECT56837.2022.10060135
   Schizas N, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14120363
   Shafique M, 2021, DES AUT CON, P1303, DOI 10.1109/DAC18074.2021.9586232
   Signoretti G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124153
   Singh J, 2021, IEEE INTERNET THINGS, V8, P5794, DOI 10.1109/JIOT.2020.3033265
   Situnayake D, 2020, MLOPS TINYML
   Staples M, 2007, J SYST SOFTWARE, V80, P1425, DOI 10.1016/j.jss.2006.09.046
   Sudharsan Bharath, 2021, 2021 IEEE 7th World Forum on Internet of Things (WF-IoT), P883, DOI 10.1109/WF-IoT51360.2021.9595024
   Sun DQ, 2021, PROC CVPR IEEE, P10088, DOI 10.1109/CVPR46437.2021.00996
   Tabanelli E, 2022, DNN IS NOT ALL YOU N
   Tajar AT, 2021, J REAL-TIME IMAGE PR, V18, P2389, DOI 10.1007/s11554-021-01131-w
   tensorflow, TENSORFLOW LIT INF
   tinyml, HOM
   tinyML Talks, AUTOFLOW OP SOURC FR
   Tsoukas V, 2021, 25TH PAN-HELLENIC CONFERENCE ON INFORMATICS WITH INTERNATIONAL PARTICIPATION (PCI2021), P69, DOI 10.1145/3503823.3503836
   Turnquist B, 2020, AMBER COMPLETE ML BA
   Vincent E, 2013, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2013.6637622
   Vuletic M., 2021, P 30 INT JOINT C ART, P19
   Vysogorets A, 2021, J MACH LEARN RES, V24
   Wang XY, 2020, IEEE INTERNET THINGS, V7, P4403, DOI 10.1109/JIOT.2020.2976702
   Warden Pete, TinyML: machine learning with TensorFlow Lite on Arduino and ultra-low-power microcontrollers
   Wenjing Li, 2021, 2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), P145, DOI 10.1109/ICBAIE52039.2021.9389919
   Wu D, 2021, IEEE T MOBILE COMPUT, V20, P1110, DOI 10.1109/TMC.2019.2954872
   XuEtaCompute, 2020, ENABLING NEURAL NETW
   Yeom S-K, 2022, COMPACT DEEP NEURAL
   Ying J, 2021, 2021 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (IEEE METROIND4.0 & IOT), P682, DOI [10.1109/METROIND4.0IOT51437.2021.9488441, 10.1109/MetroInd4.0IoT51437.2021.9488441]
   Zhang Y.-F., 2021, arXiv
   Zhang YK, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6024, DOI 10.1109/ICASSP39728.2021.9413854
NR 114
TC 4
Z9 4
U1 10
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29015
EP 29045
DI 10.1007/s11042-023-16740-9
EA SEP 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001062311100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kaur, P
   Kumar, N
AF Kaur, Prabhjot
   Kumar, Nitin
TI SIFTBCS: scale invariant feature transform based fuzzy vault scheme in
   biometric cryptosystem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BCS; SIFT; SIFTBCS; Ear biometric; Biometric key
ID FINGERPRINT
AB Biometric cryptosystem (BCS) is a challenging field of study where data is secured using biometrics features and cryptographic encryption. The necessity for retaining login credentials has been eliminated by the incorporation of biometrics in encrypted technology. The integration of biometrics into cryptographic systems eliminates the necessity of recalling passwords. This manuscript puts forward an innovative approach referred to as Scale Invariant Feature Transform (SIFT) based Biometric Cryptosystem (SIFTBCS) for the construction of cryptographic keys from the obtained features. The foundation of this technique rests upon the established Fuzzy Vault scheme utilized for safeguarding data. Themotive behind employing the SIFT scheme in biometric cryptosystems is that the extracted features remain unaltered by changes in orientation and scaling, thereby enhancing the accuracy and reliability of authentication. SIFTBCS method is comprised of three distinct stages, namely Key generation, Enrollment and Authentication. Comprehensive experiments were performed on five different ear databases, namely Mathematical Analysis of Images, Carreira-Perpinan, Indian Institute of Technology Delhi (version 1 & 2) and University of Science & Technology Beijing (version 2). Statistical and non-numeric data are used to draw meaningful conclusions from the study. The proposed technique achieves an accuracy of approximate to 94% on USTB-v2, IITD-v1 and CP databases. Our approach demonstrated superior performance using both kinds of performance evaluations.
C1 [Kaur, Prabhjot] Natl Inst Technol Uttarakhand, Dept Comp Sci & Engn, Garhwal 246174, Uttarakhand, India.
   [Kaur, Prabhjot] DIT Univ, Sch Comp, Dehra Dun, Uttarakhand, India.
   [Kumar, Nitin] Punjab Engn Coll Deemed Univ, Dept Comp Sci & Engn, Sect 12, Chandigarh 160012, Punjab, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; DIT University; Punjab Engineering College
   (Deemed University)
RP Kumar, N (corresponding author), Punjab Engn Coll Deemed Univ, Dept Comp Sci & Engn, Sect 12, Chandigarh 160012, Punjab, India.
EM prabhjotkaur.phd19@nituk.ac.in; nitink@pec.edu.in
CR Clancy T.C., 2003, P 2003 ACM SIGMM WOR, P45
   Daesung Moon, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P290, DOI 10.1109/ISCE.2009.5156914
   Elrefaei LA, 2022, J KING SAUD UNIV-COM, V34, P204, DOI 10.1016/j.jksuci.2019.10.011
   Gonzalez E., 2012, AMI EAR DATABASE
   Greg C, 2020, ISO IEC JTC 1 SC 37
   Hine GE, 2017, IEEE T INF FOREN SEC, V12, P1724, DOI 10.1109/TIFS.2017.2686005
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Kaur Prabhjot, 2022, MULTIMED TOOLS APPL, P1
   Kholmatov A, 2006, LECT NOTES COMPUT SC, V4263, P981
   Koetter R, 2003, IEEE T INFORM THEORY, V49, P2809, DOI 10.1109/TIT.2003.819332
   Krivokuca V, 2015, LECT NOTES COMPUT SC, V9443, P77, DOI 10.1007/978-3-319-25530-9_6
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Lee YJ, 2007, LECT NOTES COMPUT SC, V4642, P800
   Li HX, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P19, DOI 10.1109/IAS.2009.305
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manisha, 2020, ARTIF INTELL REV, V53, P3403, DOI 10.1007/s10462-019-09767-8
   Mathur A, 2013, THESIS U LIMERICK
   Mu Z, 2002, USTB EAR DATABASE
   Nagar A, 2008, INT C PATT RECOG, P822
   Ong ThianSong., 2008, IJ Network Security, V6, P127
   Panchal G, 2018, COMPUT ELECTR ENG, V69, P461, DOI 10.1016/j.compeleceng.2018.01.028
   Ponce-Hernandez W, 2020, IEEE ACCESS, V8, P11152, DOI 10.1109/ACCESS.2020.2965165
   Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223
   Rathgeb C, 2011, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2011-3
   Rathgeb C, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P511
   Sujitha V, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4513
   Sujitha V, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1220-x
   Uludag U, 2006, J PATTERN RECOGNITIO, P1
   Wang Y, 2007, IEEE I CONF COMP VIS, P2800
   Wu ZD, 2016, SOFT COMPUT, V20, P4907, DOI 10.1007/s00500-015-1778-2
   Zhang W., 2005, IEEE INT C IMAGE PRO, P781
NR 33
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28635
EP 28656
AR s11042-023-16643-9
DI 10.1007/s11042-023-16643-9
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900014
DA 2024-07-18
ER

PT J
AU Megahed, A
   Han, Q
   Fadl, S
AF Megahed, Amr
   Han, Qi
   Fadl, Sondos
TI Exposing deepfake using fusion of deep-learned and hand-crafted features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face forensics; Video manipulation detection; Convolution neural
   network; Facial manipulation detection; Frequency domain; Blurred images
ID IMAGES
AB With the milliards of images and videos, visual content has become a critical source of information. The spread of misinformation has become a significant problem through the availability of editing tools, requiring robust manipulation detection methods. Some of the manipulations, such as copy-move and splicing, are easy to detect, while other advanced facial manipulations, such as DeepFake are hard to detect. Facial manipulations can change human expressions by creating highly realistic faces. In this paper, we propose an efficient method to expose DeepFake in digital videos. A fusion of hand-crafted and deep-learned features is utilized to improve detection performance. The image quality measure (FM) is used besides the similarity measure of face and body skin color to generate the hand-crafted features. The experimental results show the efficiency of the proposed method for exposing DeepFake. We conducted the experiments on the three commonly and publicly available datasets Celeb-df, DFDC, and Faceforensics++.
C1 [Megahed, Amr; Han, Qi] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Fadl, Sondos] Menoufia Univ, Fac Comp & Informat, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM amr.m@hit.edu.cn; qi.han@hit.edu.cn; sondos.magdy@ci.menofia.edu.eg
FU This work was supported by the National Natural Science Foundation of
   China [grant numbers 61771168, 61471141, 61361166006, 61571018, and
   61531003]; Key Technology Program of Shenzhen, China, [grant number
   JSGG20160427185010977]; Basic Research Project of [61471141,
   61361166006, 61571018, 61531003, JSGG20160427185010977]; National
   Natural Science Foundation of China [JCYJ20150513151706561]; Key
   Technology Program of Shenzhen, China; Basic Research Project of
   Shenzhen, China;  [61771168]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61771168, 61471141, 61361166006, 61571018, and
   61531003]; Key Technology Program of Shenzhen, China, [grant number
   JSGG20160427185010977]; Basic Research Project of Shenzhen, China [grant
   number JCYJ20150513151706561].
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Boylan JF, 2018, NEW YORK TIMES
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   De K, 2013, PROCEDIA ENGINEER, V64, P149, DOI 10.1016/j.proeng.2013.09.086
   Dolhansky B, 2019, ARXIV
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Fadl SM, 2017, NEUROCOMPUTING, V265, P57, DOI 10.1016/j.neucom.2016.11.091
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fung Sheldon, 2021, ARXIV
   Fung Sheldon, 2021, 2021 INT JOINT C NEU, P1
   Gatys L. A., 2015, arXiv
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Juefei-Xu F, 2021, ARXIV
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Korshunov P., 2018, arXiv
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Kumar P, 2020, IEEE WINT CONF APPL, P2578, DOI [10.1109/WACV45572.2020.9093628, 10.1109/wacv45572.2020.9093628]
   Laws K.I., 1980, Textured Image Segmentation
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Li YZ, 2017, ADV NEUR IN, V30
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Megahed Amr, 2020, 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1260, DOI 10.1109/TrustCom50675.2020.00169
   Megahed A, 2022, MULTIMED TOOLS APPL, V81, P43441, DOI 10.1007/s11042-022-13102-9
   Megahed A, 2017, INT CONF SOFTW ENG, P141, DOI 10.1109/ICSESS.2017.8342883
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2018, arXiv
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Sitara K, 2018, FORENSIC SCI INT, V289, P186, DOI 10.1016/j.forsciint.2018.04.056
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Suganthi ST, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.881
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang G., 2020, ARXIV
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI [10.1109/icassp40776.2020.9053969, 10.1109/ICASSP40776.2020.9053969]
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 47
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26797
EP 26817
DI 10.1007/s11042-023-16329-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300012
DA 2024-07-18
ER

PT J
AU Cheng, SL
   Wu, ZQ
   Qian, M
   Huang, WT
AF Cheng, Shulin
   Wu, Zhongquan
   Qian, Meng
   Huang, Wentao
TI Point-of-interest recommendation based on bidirectional self-attention
   mechanism by fusing spatio-temporal preference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE POI recommendation; Attention mechanism; Spatio-temporal preference;
   Deep neural network; Location-based social networks
AB Point-of-Interest (POI) recommendation has emerged as a significant research area within Location-Based Social Networks (LBSNs). Many extant POI recommendation approaches utilize a unidirectional structure to encode users' historical check-in sequences, often neglecting to adequately consider the time interval between users' check-ins and the spatial distance between POIs. This omission potentially leads to lower recommendation accuracy. To counter these issues, we propose a model, BSA-ST-Rec (Point-of-Interest Recommendation based on Bidirectional Self-Attention Mechanism by Fusing Spatio-Temporal Preference). Initially, feature information such as check-in sequences, time intervals, and spatial distances are extracted from users' check-in time sequences. Following this, the feature information is transformed into sequential and spatio-temporal fusion embeddings through an embedding layer. These can be used as enhanced data sources and in conjunction with the bidirectional self-attention mechanism, to capture the dynamic interest preferences of users, thereby predicting users' next POIs and improving POI recommendation performance. We conducted experiments using two public datasets from Foursquare and Gowalla and compared our results with benchmark methods. The experimental findings demonstrate that our proposed method effectively improves the accuracy of POI recommendations.
C1 [Cheng, Shulin; Wu, Zhongquan; Qian, Meng; Huang, Wentao] Anqing Normal Univ, Sch Comp & Informat, Anqing 246000, Anhui, Peoples R China.
   [Cheng, Shulin; Qian, Meng] Univ Key Lab Intelligent Percept & Comp Anhui Pro, Anqing 246000, Anhui, Peoples R China.
C3 Anqing Normal University
RP Cheng, SL; Qian, M (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Anqing 246000, Anhui, Peoples R China.; Cheng, SL; Qian, M (corresponding author), Univ Key Lab Intelligent Percept & Comp Anhui Pro, Anqing 246000, Anhui, Peoples R China.
EM ChengshL@aqnu.edu.cn; wzqjet@gmail.com; qianmeng@aqun.edu.cn;
   1144947062@qq.com
RI Cheng, Shulin/HGU-7766-2022; Zhongquan, Wu/KLY-2562-2024
OI Cheng, Shulin/0000-0002-3744-6335; 
FU Nature Science Foundation of Anhui Province in China [2008085MF193];
   Outstanding Young Talents Program of Anhui Province in China; Major
   Science and Technology Project of Anhui Province [201903a06020006];
   Provincial Quality Project of the Anhui Province Education Department in
   China [2019jyxm0285]
FX The work was supported by grants from the Nature Science Foundation of
   Anhui Province in China, No.2008085MF193, the Outstanding Young Talents
   Program of Anhui Province in China, No.gxyqZD2018060, the Major Science
   and Technology Project of Anhui Province, No.201903a06020006, the
   Provincial Quality Project of the Anhui Province Education Department in
   China, No.2019jyxm0285. And we thank all the anonymous reviewers for
   their hard work and valuable comments.
CR Cai Z, 2022, NEUROCOMPUTING, V488, P107, DOI 10.1016/j.neucom.2022.02.070
   [柴瑞敏 Chai Ruimin], 2021, [智能系统学报, CAAI Transactions on Intelligent Systems], V16, P407
   Cheng C., 2013, 23 INT JOINT C ART I
   Cui Q, 2019, LECT NOTES ARTIF INT, V11441, P289, DOI 10.1007/978-3-030-16142-2_23
   Dai SJ, 2022, DATA SCI ENG, V7, P44, DOI 10.1007/s41019-022-00180-w
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Donkers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P152, DOI 10.1145/3109859.3109877
   Feng SS, 2017, AAAI CONF ARTIF INTE, P102
   Feng SS, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2069
   He J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1837
   Hendrycks D., 2016, ARXIV160608415
   Hidasi B., 2016, ARXIV
   Hidasi B, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P843, DOI 10.1145/3269206.3271761
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Li WM, 2019, IEEE ACCESS, V7, P45451, DOI 10.1109/ACCESS.2018.2885084
   Li WM, 2018, J PARALLEL DISTR COM, V118, P81, DOI 10.1016/j.jpdc.2017.10.003
   Li XT, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P433, DOI 10.1145/2766462.2767722
   Lian DF, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2009, DOI 10.1145/3394486.3403252
   Lian DF, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P831, DOI 10.1145/2623330.2623638
   Lin WM, 2021, IEEE T COMPUT SOC SY, V8, P227, DOI 10.1109/TCSS.2020.2965234
   Liu Q, 2016, AAAI CONF ARTIF INTE, P194
   Rendle S, 2009, BPR BAYESIAN PERSONA, V10
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Robusto C.C., 1957, Am. Math. Mon, V64, P38, DOI [DOI 10.2307/2309088, 10.2307/2309088]
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Tan Y. K., 2016, Proceedings of the 1st workshop on deep learning for recommender systems, P17
   Tao Y, 2023, NEURAL COMPUT APPL, V35, P13077, DOI 10.1007/s00521-021-05723-2
   Wu CY, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3018661.3018689
   Ye M, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P325
   Yuan FJ, 2016, PROC INT C TOOLS ART, P46, DOI [10.1109/ICTAI.2016.15, 10.1109/ICTAI.2016.0018]
   Yuan Q, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P363
   Zhang J.D., 2013, P 21 ACM SIGSPATIAL, P334, DOI DOI 10.1145/2525314.2525339
   Zhang J.-D., 2014, P 22 ACM SIGSPATIAL, P103, DOI [10.1145/2666310.2666400, DOI 10.1145/2666310.2666400]
   Zhang JD, 2015, IEEE T SERV COMPUT, V8, P701, DOI 10.1109/TSC.2014.2328341
NR 34
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26333
EP 26347
DI 10.1007/s11042-023-16542-z
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001086308500005
DA 2024-07-18
ER

PT J
AU Liu, S
   Liu, YN
   Zhu, XD
   Zhang, SQ
AF Liu, Shuai
   Liu, Yuanning
   Zhu, Xiaodong
   Zhang, Shaoqiang
TI Data-knowledge driven: a new learning strategy for iris recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris recognition; Data-knowledge driven; Iris category knowledge;
   Unlimited iris category recognition
ID FACE
AB This article focuses on the issues of poor interpretability and low universality of traditional iris recognition models in unsteady states. It proposes a new learning strategy for iris recognition: data-knowledge driven strategy, whose core idea is that the iris category knowledge is extracted from the clustering range of the iris feature data, and the knowledge is integrated into the recognition decision-making process to promote the recognition. The process of knowledge cluster analysis enables users to clearly understand the process of obtaining decision basis, and improves the interpretability of the process of recognition model design. The iris feature knowledge is set according to the consistent fact reflected in the data distribution of a large number of iris samples in various scenarios under the same process, which enhances the universality of the iris recognition model in the unsteady state. In addition, the data-knowledge-driven mode decreases the impact of the semantic gap between iris feature data and iris physiological form on the iris recognition model, thus effectively reducing the dependence of the iris recognition model training on data. An iris recognition model aiming at the process of feature expression and recognition is tested in different iris libraries. The experiment results show that the application of data-knowledge driven strategy to iris recognition is feasible and rationality, and it can make the recognition model complete the unlimited iris category recognition which can be expanded at any time.
C1 [Liu, Shuai; Liu, Yuanning; Zhu, Xiaodong; Zhang, Shaoqiang] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Liu, Shuai; Liu, Yuanning; Zhu, Xiaodong; Zhang, Shaoqiang] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Zhu, XD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhu, XD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM zhuxd@jlu.edu.cn
RI Liu, Shuai/G-8181-2018
OI Liu, Shuai/0000-0003-1337-6034; Zhu, Xiaodong/0000-0002-7200-7629
FU National Natural Science Foundation of China (NSFC) [61471181]; Natural
   Science Foundation of Jilin Province [YDZJ202101ZYTS144]; Jilin
   Provincial Key Laboratory of Biometrics New Technology
FX This research was funded by the National Natural Science Foundation of
   China (NSFC), grant number 61471181; Natural Science Foundation of Jilin
   Province, grant number YDZJ202101ZYTS144. Thanks to the Jilin Provincial
   Key Laboratory of Biometrics New Technology for supporting this project.
CR Ayoobi H, 2022, ROBOT AUTON SYST, V147, DOI 10.1016/j.robot.2021.103911
   Caiyong Wang, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P40, DOI 10.1109/TBIOM.2019.2962190
   cbsr, 2017, CASIA IRIS IMAGE DAT
   Chen Y, 2023, NEUROCOMPUTING, V517, P264, DOI 10.1016/j.neucom.2022.10.064
   Choudhary M, 2020, MULTIMED TOOLS APPL, V79, P32807, DOI 10.1007/s11042-020-09286-7
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   Ding HJ, 2020, NEUROCOMPUTING, V380, P150, DOI 10.1016/j.neucom.2019.10.097
   Dong Z., 2021, MATH PROBL ENG, V2021, P3412060
   Elangovan P, 2022, INT J IMAG SYST TECH, V32, P2034, DOI 10.1002/ima.22761
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   Guo H, 2022, IEEE ACCESS, V10, P32574, DOI 10.1109/ACCESS.2022.3157297
   Huang JL, 2019, IEEE ACCESS, V7, P43707, DOI 10.1109/ACCESS.2019.2904995
   Huo G, 2022, MULTIMED TOOLS APPL, V81, P41249, DOI 10.1007/s11042-022-13198-z
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   jlucomputer, 2018, JLU IRIS IMAGE DATAB
   Karanwal S, 2022, INT J COMPUT SCI ENG, V25, P198, DOI 10.1504/IJCSE.2022.122206
   Karn P, 2020, MULTIMED TOOLS APPL, V79, P31783, DOI 10.1007/s11042-020-09553-7
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Lan GW, 2017, ADV ENG SOFTW, V114, P372, DOI 10.1016/j.advengsoft.2017.08.003
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Liang W, 2018, COMPUT ELECTR ENG, V65, P310, DOI 10.1016/j.compeleceng.2017.05.001
   Lin CD, 2022, IEEE T CIRC SYST VID, V32, P6137, DOI 10.1109/TCSVT.2022.3158969
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Liu S, 2022, MULTIMED TOOLS APPL, V81, P907, DOI 10.1007/s11042-021-11377-y
   Liu S, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422500094
   Liu S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232319
   Mahmood Z, 2016, IET BIOMETRICS, V5, P111, DOI 10.1049/iet-bmt.2015.0008
   Meenakshi K, 2023, INTELL AUTOM SOFT CO, V35, P627, DOI 10.32604/iasc.2023.026961
   Song CY, 2022, IEEE T IND ELECTRON, V69, P1829, DOI 10.1109/TIE.2021.3062255
   Sukor ASA, 2019, J INTELL FUZZY SYST, V36, P4177, DOI 10.3233/JIFS-169976
   Suto J, 2020, NEURAL COMPUT APPL, V32, P15673, DOI 10.1007/s00521-018-3437-x
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang CY, 2020, IEEE T INF FOREN SEC, V15, P2944, DOI 10.1109/TIFS.2020.2980791
   Xu XY, 2017, WIRELESS PERS COMMUN, V97, P5983, DOI 10.1007/s11277-017-4823-x
   Yang ZY, 2017, KNOWL-BASED SYST, V130, P74, DOI 10.1016/j.knosys.2017.05.013
   Yu JF, 2021, INT J ANTENN PROPAG, V2021, DOI 10.1155/2021/2049646
   [余义斌 Yu Yibin], 2018, [工程数学学报, Chinese Journal of Engineering Mathematics], V35, P648
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
   Zhuang Y, 2020, INT CONF SYST ENG, P134, DOI 10.1109/ICSET51301.2020.9265389
NR 41
TC 1
Z9 1
U1 14
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27995
EP 28025
DI 10.1007/s11042-023-16567-4
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900006
DA 2024-07-18
ER

PT J
AU Ding, B
   Fan, ZF
   Zhao, ZJ
   Xia, SH
AF Ding, Bo
   Fan, Zhenfeng
   Zhao, Zejun
   Xia, Shihong
TI Mining collaborative spatio-temporal clues for face forgery detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face forgery detection; Spatial-temporal clue; Low-level feature;
   Collaborative learning; Multimodel attention
AB Face forgery detection has been a widespread issue recently due to the adverse effects of face forgery techniques on social media. The state-of-the-art deep learning based methods commonly employ low-level texture features for face forgery detection, since most face forgery methods have difficulty simulating low-level signals in natural images. However, most existing methods only visit the low-level features from the spatial or temporal perspective. In this work, we revisit the face forgery detection problem from a spatio-temporal perspective to cover both for better generalization performance. Specifically, we propose a Spatio-Temporal Difference Network (STDN) to mine low-level clues for face forgery detection. The network contains three different but complementary branches 1) high-frequency channel difference images, 2) inter-frame residual signals, and 3) raw RGB images. It is able to capture face forgery traces through a three-branch collaborative learning framework. Furthermore, we propose a multimodal attention fusion module to effectively fuse the complementary features from different branches. Through comprehensive experiments on several publicly available datasets, we demonstrate the superior performance of the proposed STDN. The effectiveness of low-level spatio-temporal clues in a collaborative learning framework could potentially guide future work in face forgery detection.
C1 [Ding, Bo; Fan, Zhenfeng; Zhao, Zejun; Xia, Shihong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Ding, Bo; Fan, Zhenfeng; Zhao, Zejun; Xia, Shihong] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Xia, SH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.; Xia, SH (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM dingbo21s@ict.ac.cn; fanzhenfeng@ict.ac.cn; zhaozejun21s@ict.ac.cn;
   xsh@ict.ac.cn
OI Ding, Bo/0000-0002-6630-829X
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Borujeni SE, 2009, MATH PROBL ENG, V2009, DOI 10.1155/2009/762652
   Brooks R, 2022, APSIPA TRANS SIGNAL, V11, DOI 10.1561/116.00000024
   Caldelli R, 2021, PATTERN RECOGN LETT, V146, P31, DOI 10.1016/j.patrec.2021.03.005
   Chen S, 2021, AAAI CONF ARTIF INTE, V35, P1081
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   Dascalescu AC, 2013, NONLINEAR DYNAM, V74, P307, DOI 10.1007/s11071-013-0969-6
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Durall R., 2020, P IEEE CVF C COMP VI, P7890, DOI DOI 10.1109/CVPR42600.2020.00791
   Dzanic T., 2020, Advances in neural information processing systems, V33, P3022
   Fei JW, 2022, PROC CVPR IEEE, P20238, DOI 10.1109/CVPR52688.2022.01963
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   github, 2018, FAC FAC GITH
   github, 2018, DEEPF DEEPF GITH
   Fernández EG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092804
   Gu ZH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3473, DOI 10.1145/3474085.3475508
   Guan J, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2207.02803
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Guo ZQ, 2021, MULTIMED TOOLS APPL, V80, P7687, DOI 10.1007/s11042-020-10098-y
   Haliassos A, 2021, PROC CVPR IEEE, P5037, DOI 10.1109/CVPR46437.2021.00500
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kingma D. P., 2014, arXiv
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839102
   Kohli A, 2022, MULTIMED TOOLS APPL, V81, P31391, DOI 10.1007/s11042-022-12778-3
   Kuang L, 2022, MULTIMED TOOLS APPL, V81, P42591, DOI 10.1007/s11042-021-11539-y
   Li JM, 2021, PROC CVPR IEEE, P6454, DOI 10.1109/CVPR46437.2021.00639
   Li LZ, 2020, PROC CVPR IEEE, P5073, DOI 10.1109/CVPR42600.2020.00512
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2018, IEEE INT WORKS INFOR
   Loukhaoukha K, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/173931
   Luo YC, 2021, PROC CVPR IEEE, P16312, DOI 10.1109/CVPR46437.2021.01605
   Megahed A, 2022, MULTIMED TOOLS APPL, V81, P43441, DOI 10.1007/s11042-022-13102-9
   Mnih V, 2014, ADV NEUR IN, V27
   Nick D, 2019, DEEPFAKE DETECTION D
   Nirkin Y, 2022, IEEE T PATTERN ANAL, V44, P6111, DOI 10.1109/TPAMI.2021.3093446
   Panda SK, 2023, MULTIMED TOOLS APPL, V82, P20101, DOI 10.1007/s11042-022-14307-8
   Qian Y., 2020, EUROPEAN C COMPUTER, V12357, P86, DOI 10.1007/978-3- 030-58610-2 6
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Rahmouni Nicolas, 2017, Information Forensics and Security (WIFS), 2017 IEEE Workshop on, P1
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Saikia P, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892905
   Shin HJ, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Sun ZK, 2021, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR46437.2021.00361
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Yu Y, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3499026
   Zhang BG, 2022, AAAI CONF ARTIF INTE, P3243
   Zhang D, 2022, MATER TODAY, V60, P17, DOI 10.1016/j.mattod.2022.09.001
   [张怡暄 Zhang Yixuan], 2020, [信息安全学报, Journal of Cyber Security], V5, P49
   Zhao TC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15003, DOI 10.1109/ICCV48922.2021.01475
   Zheng YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15024, DOI 10.1109/ICCV48922.2021.01477
NR 59
TC 0
Z9 0
U1 7
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27901
EP 27920
DI 10.1007/s11042-023-16173-4
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060295500002
DA 2024-07-18
ER

PT J
AU Pande, SD
   Ahammad, SKH
   Gurav, MN
   Faragallah, OS
   Eid, MMA
   Rashed, ANZ
AF Pande, Sandeep Dwarkanath
   Hasane Ahammad, S. K.
   Gurav, Madhuri Navnath
   Faragallah, Osama S.
   Eid, Mahmoud M. A.
   Rashed, Ahmed Nabih Zaki
TI Depression detection based on social networking sites using data mining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of words; Data Mining; Depression detection; Depression level; Naive
   Bayes; Social networking
AB Social networking is becoming increasingly prevalent in today's globe. Young folks, senior citizens, and the general public use social media. However, over usage of social network communication harms human existence. In recent years, many mental diseases, such as reliance on cybernetic interactions, information overload, and network restriction, have been noticed in social networks. Currently, the indications of those mental diseases can be seen, posing several dangers. Human emotions, such as despair, are interior feelings that reveal an individual's actual behavior. Monitoring and detecting these thoughts from individual's choices in virtual social interactions could be very beneficial in realizing their behavior. This research develops a system that uses social media posts to detect individuals' depression. Data mining techniques have been employed to analyze social media data to identify individuals at risk of depression. It provides an overview of the major contributions made in the field of depression detection based on social networking sites using several machine learning (ML), deep learning, and data mining. We discuss the use of sentiment analysis (SA), natural language processing (NLP), ML, user profiling, and early warning systems. The paper highlights the potential benefits of using social media data for depression detection, including the ability to provide early intervention to individuals at risk of depression. However, there are also ethical considerations to be addressed, such as ensuring data privacy and avoiding stigmatization. The bag of words (BoW) approach is effective in capturing the sentiment and emotional tone of social media posts, which is crucial for detecting depression. It employs Naive Bayes (NB) classifier which is is known for its accuracy in classifying text data for detecting the depression level. The implemented approach is compared with other SA methods concerning performance and results. In many evaluation parameters, the proposed method outperforms other SA systems. The approach provides runtime provision for adding new keywords and sentiments which adapts the approach to work fine for newest trends, wordings, and formats of posts. It suggests actions to be undertaken in case of detection of depressed users to control them drowning in further stress. Overall, this paper aims to provide a comprehensive understanding of the current state of research in depression detection based on social networking sites using data mining, and the potential implications for mental health care.
C1 [Pande, Sandeep Dwarkanath] MIT Acad Engn, Sch Comp Engn & Technol, Pune, Maharashtra, India.
   [Hasane Ahammad, S. K.] Koneru Lakshmaiah Educ Fdn, Dept ECE, Vaddeswaram 522302, Andhra Pradesh, India.
   [Gurav, Madhuri Navnath] Sydata Consulting India Pvt Ltd, Hyderabad, India.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, Taif 21944, Saudi Arabia.
   [Eid, Mahmoud M. A.] Taif Univ, Coll Engn, Dept Elect Engn, POB 11099, At Taif 21944, Saudi Arabia.
   [Rashed, Ahmed Nabih Zaki] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.
   [Rashed, Ahmed Nabih Zaki] SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tamilnadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Taif University; Taif University; Egyptian Knowledge Bank (EKB); Menofia
   University; Saveetha Institute of Medical & Technical Science; Saveetha
   School of Engineering
RP Rashed, ANZ (corresponding author), Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia 32951, Egypt.; Rashed, ANZ (corresponding author), SIMATS, Inst Elect & Commun Engn, Saveetha Sch Engn, Dept VLSI Microelect, Chennai 602105, Tamilnadu, India.
EM sandeep7887pande@gmail.com; ahammadklu@gmail.com;
   guravmadhuri93@gmail.com; o.salah@tu.edu.sa; m.elfateh@tu.edu.sa;
   ahmed_733@yahoo.com
RI Rashed, Ahmed nabih zaki/AFB-6046-2022; Pande, Sandeep/ABB-2210-2022;
   Faragallah, Osama S./AHB-8031-2022; Pande, Sandeep/AAR-6754-2021
OI Rashed, Ahmed nabih zaki/0000-0002-5338-1623; Faragallah, Osama
   S./0000-0003-1982-335X; Pande, Sandeep/0000-0001-6969-0423
CR Almeida H, 2017, WORKING NOTES CLEF 2, P1
   Babu Nirmal Varghese, 2022, SN Comput Sci, V3, P74, DOI 10.1007/s42979-021-00958-1
   Chancellor S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0233-7
   Choudhary MD, 2013, PREDICTING DEPRESSIO, P1
   Dong YF, 2020, IEEE ACCESS, V8, P37014, DOI 10.1109/ACCESS.2020.2973711
   Gatta S., 2020, INT J ADV TRENDS COM, V9, P1440, DOI [10.30534/ijatcse/2020/81922020, DOI 10.30534/IJATCSE/2020/81922020]
   Herdiansyah Haris, 2023, Procedia Computer Science, P691, DOI 10.1016/j.procs.2022.12.185
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Islam MR, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0046-0
   Karim F, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8627
   Katchapakirin K, 2018, INT JOINT CONF COMP, P227
   Kumar V, 2020, NATL CONF COMMUN, DOI 10.1109/ncc48643.2020.9056085
   Mulyawan, 2021, IOP Conference Series: Materials Science and Engineering, V1088, DOI 10.1088/1757-899X/1088/1/012035
   Pande S., 2018, J Adv Res Dynam Control Syst, V10, P2765
   Patel A., 2019, P 2 INT C ADV COMP S
   Prashanth KVTKN, 2022, J KING SAUD UNIV-COM, V34, P6663, DOI 10.1016/j.jksuci.2021.08.015
   Rodrigues AP, 2022, EVOL INTELL, V15, P877, DOI 10.1007/s12065-019-00236-3
   Stankevich M, 2019, CEUR WORKSHOP PROC, P279
   Steinsbekk S, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106528
   Syarif I, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND SECURITY (ICCCS), DOI 10.1109/cccs.2019.8888096
   Tyagi P., 2019, SSRN Electronic Journal, DOI [DOI 10.2139/SSRN.3349569, 10.2139/SSRN.3349569]
   Uddin AH, 2019, INT C COMP COMM CHEM
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Zerrouki Kadda, 2020, International Journal of Organizational and Collective Intelligence, V10, P35, DOI 10.4018/IJOCI.2020100103
NR 26
TC 0
Z9 0
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25951
EP 25967
DI 10.1007/s11042-023-16564-7
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060201500005
DA 2024-07-18
ER

PT J
AU Prasad, PRK
   Reddy, ES
   Sekharaiah, KC
AF Prasad, P. R. Krishna
   Reddy, Edara Sreenivasa
   Sekharaiah, K. Chandra
TI Deep U_ClusterNet: automatic deep clustering based segmentation and
   robust cell size determination in white blood cell
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE White blood cells; Automatic segmentation; Deep clustering; Cell size;
   U-Network; Contrast enhancement
ID CLASSIFICATION; ALGORITHM
AB White blood cells (WBCs) are cells of the immune system that protect the body from infectious diseases and invading bacteria and viruses. An accurate assessment of their quantity is considered of utmost importance in its initial stage for evaluating a probable disease. Because of the aberrant number of WBV, both abnormal increase and decline indicate infective disease seriousness. Several methods were devised for WBC segmentation; issues like over segmentation problems, poor contrast, and improper detection of seed points affect the performance. Therefore, this work aims to develop an automatic deep clustering based segmentation with cell size determination for accurate diagnosis as well as treatment planning. The steps followed for processing the image segmentation based on the deep clustering model are Image Pre-processing, Deep Clustering based Segmentation, Cell size Determination and Classification. Initially, pre-processing images is necessary to enhance the quality of the raw input images. Next, in WBCs (White Blood Cells), accurate segmentation remains a critical task due to variations in cell types, changes in staining techniques, colour, and shape. Here, an automated Deep U-Net with clustering based segmentation (Deep U_ClusterNet) is presented to achieve semantic multi-label segmentation using U-network along with deep clustering based on Spatial Reliable FCM (Fuzzy C-Means) Clustering model. The proposed Deep U_ClusterNet achieved better performance in terms of Accuracy, Recall, Specificity, Precision, and Dice similarity coefficient (DSC) and acquired the maximal values of 0.982, 0.998, 0.983, 0.957, and 0.951, respectively.
C1 [Prasad, P. R. Krishna] Jawaharlal Nehru Technol Univ, Vasireddy Venkatadri Inst Technol, Kakinada 533003, Andhra Pradesh, India.
   [Reddy, Edara Sreenivasa] Acharya Nagarjuna Univ, Univ Coll Engn, Guntur 522510, Andhra Pradesh, India.
   [Sekharaiah, K. Chandra] Jawaharlal Nehru Technol Univ Hyderabad, Univ Coll Engn, Hyderabad 500085, Telangana, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Acharya Nagarjuna
   University; Jawaharlal Nehru Technological University - Hyderabad
RP Prasad, PRK (corresponding author), Jawaharlal Nehru Technol Univ, Vasireddy Venkatadri Inst Technol, Kakinada 533003, Andhra Pradesh, India.
EM prkrishnaprasad@vvit.net
CR Ab Aziz MF, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115441
   Abdulhay E, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0912-y
   Abdulsahib AA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091295
   Abdulsahib AA, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00294-7
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Ananthi VP, 2022, FRONTIERS FRACTAL AN, P153
   [Anonymous], 2018, Microscopy science: last approaches on educational programs and applied research (Microscopy Book Series, 8)
   Banik PP, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113211
   Biswas S, 2018, OPTIK, V168, P931, DOI 10.1016/j.ijleo.2018.05.011
   Gupta D, 2019, MEASUREMENT, V143, P180, DOI 10.1016/j.measurement.2019.01.002
   Habibzadeh M, 2018, PROC SPIE, V10696, DOI 10.1117/12.2311282
   Khamael AD, 2019, 2019 IEEE AS PAC C C, P1, DOI DOI 10.1109/CSDE48274.2019.9162402(VERANST.),2019
   King W, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/6510842
   Ko BC, 2011, MICRON, V42, P695, DOI 10.1016/j.micron.2011.03.009
   Kumar CL, 2021, CMC-COMPUT MATER CON, V67, P1369, DOI 10.32604/cmc.2021.015116
   Kumar M, 2023, SOFT COMPUT, V27, P11661, DOI 10.1007/s00500-023-07844-3
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Kumar PR, 2020, 2021 INT C EL COMM C, P1, DOI DOI 10.1109/IC-ETITE47903.2020.ICETITE318
   Kutlu H, 2020, MED HYPOTHESES, V135, DOI 10.1016/j.mehy.2019.109472
   Lu Y, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107006
   Makem M, 2022, MULTIMED TOOLS APPL, V81, P17849, DOI 10.1007/s11042-022-12285-5
   Mijwil MM, 2022, MULTIMED TOOLS APPL, V81, P7011, DOI 10.1007/s11042-022-11939-8
   Mohammadpour E, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL WORKSHOP ON NETWORK CALCULUS AND APPLICATIONS (NETCAL2018), VOL 2, P1, DOI 10.1109/ITC30.2018.10053
   Nassar M, 2019, CYTOM PART A, V95A, P836, DOI 10.1002/cyto.a.23794
   Novoselnik F, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART SYSTEMS AND TECHNOLOGIES (SST), P163, DOI 10.1109/SST.2018.8564625
   Pan C, 2012, EXPERT SYST APPL, V39, P7479, DOI 10.1016/j.eswa.2012.01.114
   Rajinikanth Venkatesan, 2022, 2022 Third International Conference on Intelligent Computing Instrumentation and Control Technologies (ICICICT), P982, DOI 10.1109/ICICICT54557.2022.9917848
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy RM, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102385
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Sharma A, 2022, CMC-COMPUT MATER CON, V73, P3629, DOI 10.32604/cmc.2022.030879
   Tavakoli S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98599-0
   Theera-Umpon N, 2005, LECT NOTES ARTIF INT, V3614, P787
   Togaçar M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106810
   Umamaheswari Duraiswamy, 2021, International Journal of Cloud Computing, V10, P26, DOI 10.1504/IJCC.2021.113974
   Yan H, 2021, INT J COMPUT VISION, V129, P1837, DOI 10.1007/s11263-021-01449-9
   Yi FL, 2021, J BIOMED OPT, V26, DOI 10.1117/1.JBO.26.3.036001
   Zheng X, 2018, MICRON, V107, P55, DOI 10.1016/j.micron.2018.01.010
   Zheng X, 2014, MICRON, V56, P17, DOI 10.1016/j.micron.2013.09.006
   Zhong Y, 2021, INT C DAT MIN BIG D, P100
NR 41
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25923
EP 25949
DI 10.1007/s11042-023-16521-4
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060201500003
DA 2024-07-18
ER

PT J
AU Shaukat, Z
   Farooq, QA
   Xiao, CB
   Ali, S
   Akhtar, F
   Azeem, M
   Zulfiqar, AA
AF Shaukat, Zeeshan
   Farooq, Qurratul Ain
   Xiao, Chuangbai
   Ali, Saqib
   Akhtar, Faheem
   Azeem, Muhammad
   Zulfiqar, Abdul Ahad
TI Efficient scheme to perform semantic segmentation on 3-D brain tumor
   using 3-D u-net architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Brain tumor; 3-D U-net; Deep CNN
ID NEURAL-NETWORKS
AB Glioma is the most common type of brain tumor with varying level of malignancies and projection. Designing personalized therapy and to foresee response towards the therapy needs better understanding of tumor biology and diversification between tumors. Using different computational methods, accurate segmentation of tumors within the brain on MRI is the primary stride towards the understanding of tumor biology. The goal of current study is to draw an algorithm for MRI image segmentation of pre-treatment brain tumors and to evaluate its performance. In our research, we designed and implemented a novel 3D U-Net architecture for segmentation of sub-regions including edema, necrosis and enhancing tumor which are radiologically detectable. The group variance between tumor and non-tumorous spots is addressed by presenting weighted patch extraction scheme from tumor border regions. In its framework, context is captured using a contracting path and precise localization is performed by symmetric expanding path. In our study, the architecture based on Deep Convolutional Neural Network (DCNN) is trained on Brain Tumor Segmentation (BraTS) dataset of 750 patients among which 484 scans were labelled and 267 scans were used as training dataset. 3D patches were extracted from the dataset to train the system and results were assessed in terms of Specificity, Sensitivity and Dice Score. Our proposed system achieved Dice scores of 0.90 for whole tumor, 0.85 for tumor core, and 0.77 for enhancing tumor on dataset which shows potential of accurate intra-tumor segmentation of patch-based 3D U-Net architecture.
C1 [Shaukat, Zeeshan; Xiao, Chuangbai; Ali, Saqib] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   [Farooq, Qurratul Ain] Beijing Univ Technol, Fac Environm & Life Sci, Beijing, Peoples R China.
   [Akhtar, Faheem] Sukkur IBA Univ, Dept Comp Sci, Sukkur 65200, Pakistan.
   [Azeem, Muhammad] Univ Sialkot, Fac Comp & IT, Sialkot 51300, Pakistan.
   [Zulfiqar, Abdul Ahad] Beihang Univ, Dept Management Sci & Engn, Beijing, Peoples R China.
C3 Beijing University of Technology; Beijing University of Technology;
   Sukkur IBA University; Beihang University
RP Shaukat, Z; Xiao, CB (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
EM zee@emails.bjut.edu.cn; cbxiao@bjut.edu.cn
RI Shaukat, Zeeshan/AAH-5490-2019
OI Shaukat, Zeeshan/0000-0002-7901-6712
CR Ahmadvand P, 2017, MACHINE LEARNING DRI
   Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baid U, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00010
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817
   Cui SS, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/8619342
   Gharavi SMH, 2021, ARTIF INTELL, V17, P65
   Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jäkel S, 2017, FRONT CELL NEUROSCI, V11, DOI 10.3389/fncel.2017.00024
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kofler F, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00125
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li S., 2023, arXiv
   Li X., 2023, Int. J. Netw. Dyn. Intell, V2, P93, DOI [DOI 10.53941/IJNDI0201006, 10.53941/ijndi0201006]
   Li ZJ, 2021, IEEE T MED IMAGING, V40, P1065, DOI 10.1109/TMI.2020.3046692
   Li ZJ, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/9283480
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mo YJ, 2022, NEUROCOMPUTING, V493, P626, DOI 10.1016/j.neucom.2022.01.005
   Myronenko A, 2020, LECT NOTES COMPUT SC, V11993, P82, DOI 10.1007/978-3-030-46643-5_8
   Patel AP, 2019, LANCET NEUROL, V18, P376, DOI 10.1016/S1474-4422(18)30468-X
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schwartzbaum JA, 2006, NAT CLIN PRACT NEURO, V2, P494, DOI 10.1038/ncpneuro0289
   Su R, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.586197
   Van Meir EG, 2010, CA-CANCER J CLIN, V60, P166, DOI 10.3322/caac.20069
   Wang X, 2022, NEUROCOMPUTING, V486, P135, DOI 10.1016/j.neucom.2021.11.017
   Yeung M, 2022, COMPUT MED IMAG GRAP, V95, DOI 10.1016/j.compmedimag.2021.102026
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 32
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25121
EP 25134
DI 10.1007/s11042-023-16458-8
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800005
DA 2024-07-18
ER

PT J
AU Swetha, KR
   Ravikumar, GK
   Shashikala, SV
AF Swetha, K. R.
   Ravikumar, G. K. G.
   Shashikala, S. V. S.
TI Adaptive Spatial Filtering-based Component Exploration model for
   SSVEP-based Brain-Computer Interface for target identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steady-State Visually Evoked Potential (SSVEP); Brain-Computer
   Interaction (BCI) systems; Adaptive Spatial Filtering based Component
   Exploration (ASFCE) model; Electroencephalogram (EEG); Target detection
ID REHABILITATION
AB Non-invasive Brain-Computer Interface (BCI) systems have gained a massive boost from the advancement and developments in signal processing applications and BCI systems can be used, used in several applications like robotic arms. Implementation of BCI systems massively depends on the analysis of Steady-State Visually Evoked Potential (SSVEP) (SSVEP) components. The correct extraction of Steady-State Visually Evoked Potential (SSVEP) components, however, is crucial and difficult. As a result, by assessing SSVEP components from EEG data, an Adaptive Spatial Filtering approach is presented to successfully identify targets for the use of the SSVEP-based BCI system. Here, methods for identifying targets using EEG analysis are discussed. Here, the minimization of computational complexity and the optimization of the Eigenvalue problem are covered. The features provided in the reference signal are pre-developed and lacked precision in the earlier SSVEP detection algorithms. Therefore, the development of reference signals can address the inaccuracy of frequency detection. A MAMEM SSVEP dataset is used to analyze the performance results of the proposed Adaptive Spatial Filtering based Component Exploration (ASFCE) model. Results are presented in terms of detection accuracy and Information transfer rate (ITR) using the proposed ASFCE model and compared against varied SSVEP acquisition methods. The mean target detection accuracy and ITR results considering all 11 subjects are 93.48% and 308.23 bpm, respectively.
C1 [Swetha, K. R.; Ravikumar, G. K. G.; Shashikala, S. V. S.] Adichunchanagiri Univ, Dept CSE, BGSIT, Mandya, India.
   [Ravikumar, G. K. G.] BGSCET, Dept Comp Sci & Engn, Bengaluru, India.
   [Shashikala, S. V. S.] BGSIT, Dept Comp Sci & Engn, Mandya, India.
RP Swetha, KR (corresponding author), Adichunchanagiri Univ, Dept CSE, BGSIT, Mandya, India.
EM swethagowdha@gmail.com; ravikumargk@yahoo.com; shashisv7@gmail.com
CR Ang KK, 2015, CLIN EEG NEUROSCI, V46, P310, DOI 10.1177/1550059414522229
   Apicella A, 2022, IEEE SENS J, V22, P9087, DOI 10.1109/JSEN.2022.3161743
   Arvaneh M, 2017, NEURAL COMPUT APPL, V28, P3259, DOI 10.1007/s00521-016-2234-7
   Balasubramanian S, 2010, CURR OPIN NEUROL, V23, P661, DOI 10.1097/WCO.0b013e32833e99a4
   Bhatia M, 2022, MULTIMED TOOLS APPL, V81, P37519, DOI 10.1007/s11042-022-13505-8
   Cantillo-Negrete J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1624637
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125
   Chatzilari E, 2017, P 2 INT WORKSH MULT, P3, DOI [10.1145/3132635.3132636, DOI 10.1145/3132635.3132636]
   Chen XG, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065718500181
   Cheng N, 2020, IEEE T BIO-MED ENG, V67, P3339, DOI 10.1109/TBME.2020.2984003
   Cruz I, 2018, P INT C INT TECHN IN, V215, DOI [10.1007/978-3-319-73062-2_6, DOI 10.1007/978-3-319-73062-2_6]
   Fang Q, 2022, CAAI T INTELL TECHNO, V7, P167, DOI 10.1049/cit2.12043
   Gao SK, 2014, IEEE T BIO-MED ENG, V61, P1436, DOI 10.1109/TBME.2014.2300164
   Guney OB, 2022, IEEE T BIO-MED ENG, V69, P932, DOI 10.1109/TBME.2021.3110440
   Guo N, 2022, IEEE T NEUR SYS REH, V30, P1737, DOI 10.1109/TNSRE.2022.3185262
   Hatem SM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00442
   Huang JY, 2022, IEEE T NEUR SYS REH, V30, P851, DOI 10.1109/TNSRE.2022.3162029
   Kreilinger A, 2016, IEEE T BIO-MED ENG, V63, P519, DOI 10.1109/TBME.2015.2465866
   Lebedev MA, 2006, TRENDS NEUROSCI, V29, P536, DOI 10.1016/j.tins.2006.07.004
   Leon MSI, 2022, LECT NOTES DATA ENG, V95, DOI [10.1007/978-981-16-6636-0_45, DOI 10.1007/978-981-16-6636-0_45]
   Li Y, 2018, P ASME 2018 13 INT M, V3, DOI [10.1115/MSEC2018-6655, DOI 10.1115/MSEC2018-6655]
   Lin JJ, 2021, TSINGHUA SCI TECHNOL, V26, P505, DOI 10.26599/TST.2020.9010015
   Mallikarjuna SB, 2022, CAAI T INTELL TECHNO, V7, P156, DOI 10.1049/cit2.12088
   Nezamfar H, 2016, IEEE J-STSP, V10, P932, DOI 10.1109/JSTSP.2016.2552140
   Nouri A., 2020, Ali Nouri Frontiers in Biomedical Technologies, V7, P151
   Oikonomou V.P., 2016, ARXIV160200904
   Oikonomou VP, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1602.00904
   Peng NN, 2016, IEEE ENG MED BIO, P1556, DOI 10.1109/EMBC.2016.7591008
   Phipps MS, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.l6983
   Rashid M, 2020, INT J INTEGR ENG, V12, P165, DOI 10.30880/ijie.2020.12.06.019
   Thomas J, 2017, IEEE SYS MAN CYBERN, P234, DOI 10.1109/SMC.2017.8122608
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang K, 2022, IEEE T NEUR NET LEAR, V33, P2159, DOI 10.1109/TNNLS.2021.3135696
   Westerveld AJ, 2014, IEEE T BIO-MED ENG, V61, P2646, DOI 10.1109/TBME.2014.2325532
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Zerafa R, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aaca6e
   Zhang Y, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146950
   Zhao WW, 2019, J NEURORESTORATOLOGY, V7, P136, DOI 10.26599/JNR.2019.9040014
   Zhuang MM, 2020, J NEURORESTORATOLOGY, V8, P12, DOI 10.26599/JNR.2020.9040001
NR 39
TC 0
Z9 0
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25393
EP 25414
DI 10.1007/s11042-023-16468-6
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001054228300004
DA 2024-07-18
ER

PT J
AU Liu, YF
   Li, C
   Ning, KL
   Li, YL
AF Liu, Yanfei
   Li, Chao
   Ning, Kanglin
   Li, Yali
TI Path aggregation one-stage anchor free 3D object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D object detection; Path aggregation; Anchor free; Auxiliary
   segmentation network
AB In recent years, autonomous driving has entered a rapid development phase and put forward more challenging requirements for perception technology. Different from object detection methods for 2D images, 3D object detection, which uses Light Detection And Ranging (LiDAR) point cloud as input, can accurately provide the coordinates, physical size, and orientation of an object in 3D space. This paper constructs a deep learning neural network for 3D visual object recognition inspired by computational neuroscience. Considering that a part of the visual recognition pathway of the human brain tends to serve multiple visual recognition tasks, we set up an auxiliary task branch when training the proposed 3D object detector. Through this auxiliary branch task, the backbone of our 3D object detector can learn more generalizable features from the point cloud input. As the human brain needs to collect information from different visual areas, the proposed model designed a multi-stride residual 3D backbone network and a path aggregation 2D neck network to achieve similar functions. Extensive experiments have been conducted on the KITTI dataset and Waymo Open Dataset. The results show that our methods could achieve an outstanding balance between speed and accuracy.
C1 [Liu, Yanfei; Li, Chao; Ning, Kanglin; Li, Yali] Xian Res Inst Hitech, Dept Basic Courses, Xian 710025, Peoples R China.
C3 Rocket Force University of Engineering
RP Li, C (corresponding author), Xian Res Inst Hitech, Dept Basic Courses, Xian 710025, Peoples R China.
EM dalichaoxiao@163.com
RI Liu, Junjie/KHV-6949-2024; li, xiaomin/KCX-9845-2024; zhang,
   yuanyuan/KHV-4459-2024
OI Li, Chao/0000-0003-4244-4032
CR Agarap AF, 2018, arXiv, DOI 10.48550/arXiv.1803.08375
   Beltrán J, 2018, IEEE INT C INTELL TR, P3517, DOI 10.1109/ITSC.2018.8569311
   Bhattacharyya P, 2020, Arxiv, DOI arXiv:2008.08766
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cheng ZY, 2022, Arxiv, DOI arXiv:2207.04718
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Cui YM, 2021, Arxiv, DOI [arXiv:2108.05821, 10.48550/arXiv.2108.05821, DOI 10.48550/ARXIV.2108.05821]
   Deng JJ, 2021, Arxiv, DOI arXiv:2012.15712
   Ding X, 2022, ARXIV
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2018, ARXIV180601260, P5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YH, 2022, Arxiv, DOI arXiv:2112.09205
   Humphreys GW, 1999, PSYCHOL RES-PSYCH FO, V62, P118, DOI 10.1007/s004260050046
   Kingma D. P., 2014, arXiv
   Klambauer G, 2017, Arxiv, DOI [arXiv:1706.02515, DOI 10.48550/ARXIV.1706.02515, 10.48550/arXiv.1706.02515]
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Lei Ba J., 2016, arXiv
   Li ZY, 2021, Arxiv, DOI arXiv:2103.15396
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Mahmoud A, 2022, Arxiv, DOI arXiv:2203.00871
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Pant G, 2020, ALGAL RES, V48, DOI 10.1016/j.algal.2020.101932
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2020, Arxiv, DOI arXiv:1907.03670
   Shi SS, 2022, Arxiv, DOI arXiv:2102.00463
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang CY, 2021, Arxiv, DOI arXiv:2105.04206
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wang WG, 2022, Arxiv, DOI [arXiv:2210.00911, DOI 10.48550/ARXIV.2210.00911]
   WELLER RE, 1988, PROG BRAIN RES, V75, P293
   Wu XP, 2022, Arxiv, DOI arXiv:2203.09780
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhang GJ, 2019, IEEE T GEOSCI REMOTE, V57, P10015, DOI 10.1109/TGRS.2019.2930982
   Zhang R, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1156
   Zheng W, 2020, Arxiv, DOI [arXiv:2012.03015, DOI 10.1609/AAAI.V35I4.16470]
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 50
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16454-y
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600004
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Xie, SD
   Ji, LQ
AF Zhang, Qi
   Xie, Shaodong
   Ji, Liangqun
TI A lightweight CNN based information fusion for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-scale width information block; Information enhancement block;
   Lightweight model; Image denoising
ID CONVOLUTIONAL NEURAL-NETWORK; FRAMEWORK
AB Deep convolutional neural networks (CNNs) with strong learning abilities have obtained good results for image denoising. However, the CNNs for image denoising have increasingly heavy-weighted, which is not suitable for practical applications. In this paper, we present a lightweight width information fusion CNN(LWIFCNN) for image denoising to address this problem. The proposed model employs two key modules, i.e., multi-scale width information block (MWIB) and information enhancement block (IEB), to improve the model representing capability without heavy complexity. Specifically, in order to extract as much information as possible with low weights, MWIB utilizes a standard convolution and three lightweight residual attention blocks (RABs) to achieve multi-scale feature fusion. Each RAB utilizes two lightweight blocks (LWBs) and an enhanced channel attention mechanism (ECA) to extract width information and reduce computational complexity. IEB uses serial modules and ghost modules to combine width features and depth features to further enhance the representing capability of the model. Experimental results show that our method is better than many excellent methods in both quantitative and qualitative metrics.
C1 [Zhang, Qi; Ji, Liangqun] Harbin Univ Sci & Technol, Sch Econ & Management, Harbin 150006, Heilongjiang, Peoples R China.
   [Xie, Shaodong] Cent South Univ, Sch Comp Sci, Changsha 410083, Hunan, Peoples R China.
C3 Harbin University of Science & Technology; Central South University
RP Zhang, Q; Ji, LQ (corresponding author), Harbin Univ Sci & Technol, Sch Econ & Management, Harbin 150006, Heilongjiang, Peoples R China.
EM hit_zq910057@163.com; qlq@hrbust.edu.cn
FU Heilongjiang Postdoctoral Science Foundation [LBH-Z22194]; China
   Postdoctoral Science Foundation [2023M730886]
FX This work was supported in part by Heilongjiang Postdoctoral Science
   Foundation under Grant LBH-Z22194,~in part by China Postdoctoral Science
   Foundation under Grant 2023M730886.Data sharing not applicable to this
   article as no datasets were generated or analyzed during the current
   study.The authors declare that they have no conflict of interest.
CR ALLEN DM, 1971, TECHNOMETRICS, V13, P469, DOI 10.2307/1267161
   [Anonymous], 2018, KODAK LOSSLESS TRUE
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Bai J, 2020, IET IMAGE PROCESS, V14, P3471, DOI 10.1049/iet-ipr.2018.5499
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cruz C, 2018, Arxiv, DOI arXiv:1803.02112
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Godard C, 2018, LECT NOTES COMPUT SC, V11219, P560, DOI 10.1007/978-3-030-01267-0_33
   Gu SH, 2019, IEEE I CONF COMP VIS, P2511, DOI 10.1109/ICCV.2019.00260
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Gurrola-Ramos J, 2021, IEEE ACCESS, V9, P31742, DOI 10.1109/ACCESS.2021.3061062
   Han K, 2022, INT J COMPUT VISION, V130, P1050, DOI 10.1007/s11263-022-01575-y
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang J.-J., 2021, P EUROPEAN SIGNAL PR, P23, DOI DOI 10.23919/EUSIPCO54536.2021.9615931
   Huang JJ, 2022, IEEE T IMAGE PROCESS, V31, P4377, DOI 10.1109/TIP.2022.3184845
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Jo Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5067, DOI 10.1109/ICCV48922.2021.00504
   Kadkhodaie Z., 2020, PROC INT C LEARN REP
   Kim Y, 2019, IEEE ACCESS, V7, P63447, DOI 10.1109/ACCESS.2019.2917537
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Latif Ghazanfar, 2018, Int J Eng Technol, V7, P37, DOI DOI 10.1109/ASAR.2018.8480289
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Lei Ba J., 2016, arXiv
   Liang Liao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P683, DOI 10.1007/978-3-030-58583-9_41
   Liao L, 2021, PROC CVPR IEEE, P6535, DOI 10.1109/CVPR46437.2021.00647
   Liao L, 2021, IEEE J-STSP, V15, P310, DOI 10.1109/JSTSP.2020.3045627
   Liu WX, 2023, IEEE T IMAGE PROCESS, V32, P2719, DOI 10.1109/TIP.2023.3273459
   Lyu ZY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115727
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Pang TY, 2021, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR46437.2021.00208
   Ren C, 2021, PROC CVPR IEEE, P8592, DOI 10.1109/CVPR46437.2021.00849
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth S, 2005, PROC CVPR IEEE, P860
   Rubinstein R, 2012, INT CONF ACOUST SPEE, P5405, DOI 10.1109/ICASSP.2012.6289143
   Ruikar Sachin, 2010, 2010 2nd International Conference on Mechanical and Electrical Technology (ICMET), P509, DOI 10.1109/ICMET.2010.5598411
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Soh JW, 2021, INT C PATT RECOG, P747, DOI 10.1109/ICPR48806.2021.9412605
   Song JG, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050757
   Song JW, 2022, Arxiv, DOI arXiv:2004.10959
   Song YD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173809
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tao L, 2017, IEEE IMAGE PROC, P3215, DOI 10.1109/ICIP.2017.8296876
   Tian CW, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109050
   Tian CW, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.106949
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Y, 2021, IEEE SIGNAL PROC LET, V28, P424, DOI 10.1109/LSP.2021.3057544
   Xiao JY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031742
   Yahya AA, 2020, MULTIMED TOOLS APPL, V79, P20391, DOI 10.1007/s11042-020-08815-8
   Yang ZW, 2023, IEEE T IMAGE PROCESS, V32, P2985, DOI 10.1109/TIP.2023.3277389
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Q, 2023, CAAI T INTELL TECHNO, V8, P331, DOI 10.1049/cit2.12110
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YQ, 2020, NEURAL COMPUT APPL, V32, P12575, DOI 10.1007/s00521-020-04717-w
   Zhang YL, 2021, IEEE T IMAGE PROCESS, V30, P6255, DOI 10.1109/TIP.2021.3093396
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 65
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-16346-1
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600013
DA 2024-07-18
ER

PT J
AU Yawale, N
   Sahu, N
   Khalsa, N
AF Yawale, Nupoor
   Sahu, Neeraj
   Khalsa, Nikkoo
TI Design of a high-density bio-inspired feature analysis deep learning
   model for sub-classification of natural & synthetic imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Natural; Synthetic; LSTM; GRU; EHO; GAN
ID NETWORK; REGULARIZATION; CNN
AB Differentiation between Natural and Synthetic imagery is a specialized area of digital image processing that assists in identification of computer-generated entities. But due to advancements in computer graphic interfaces, it is difficult to identify synthetically generated images from their natural counterparts. A large number of deep learning models are proposed by researchers, that perform complex feature analysis in order to differentiate between these image sets. But these models are either highly complex, or do not process sub-components of the image, which results in reduced efficiency under large-scale scenarios. Moreover, these models showcase limited accuracy when used in categorical classification modes. To overcome these issues, this text proposes design of a novel high-density bio inspired feature analysis deep learning model for sub-classification of natural & synthetic image sets. The proposed model initially uses a YoLo model to identify different objects in the input image sets. These objects are individually processed via a hybrid LSTM (Long Short-Term Memory), and GRU (Gated Recurrent Unit) model, which assists in estimation of high-density feature sets. These feature sets are further extended using Wavelet, Cosine, Fourier & Convolutional features for multi-domain representation of input images. These feature sets are given to an Elephant Herding Optimization (EHO) Model, which assists in identification of feature sets with high inter-class variance levels. The selected features are classified via a customized 1D CNN model, and validated via an efficient GAN classifier, that assists in classification of these sub-entities into natural & synthetic objects. These classification results are combined in order to identify if the input image is purely natural, purely synthetic, of a mixture of both types. The model also evaluates a Natural Image Score (NIS), which assists in estimation of natural content in each of the input image sets. It was observed that the proposed model showcased 8.3% higher accuracy, 10.5% higher precision, 3.9% higher recall, and 8.5% higher AUC (Area Under the Curve) performance when compared with standard classification models under real-time scenarios.
C1 [Yawale, Nupoor; Sahu, Neeraj] GH Raisoni Univ, CSE Dept, Amravati, Maharashtra, India.
   [Khalsa, Nikkoo] PRMIT&R, EXTC Dept, Dean Training & Placement, Badnera Amravati, Maharashtra, India.
RP Yawale, N (corresponding author), GH Raisoni Univ, CSE Dept, Amravati, Maharashtra, India.
EM nupooryawale2021@gmail.com; neeraj.sahu@ghru.edu.in;
   nnkhalsa@mitra.ac.in
CR Bi H, 2021, IEEE J-STARS, V14, P6815, DOI 10.1109/JSTARS.2021.3093645
   Cao R, 2021, IEEE J-STARS, V14, P1985, DOI 10.1109/JSTARS.2021.3050108
   Cao YC, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3152854
   Chatterjee R, 2023, IEEE ACCESS, V11, P37515, DOI 10.1109/ACCESS.2023.3266514
   Chen QH, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3139103
   Gu J, 2020, IEEE T GEOSCI REMOTE, V58, P881, DOI 10.1109/TGRS.2019.2941288
   Gui R, 2021, IEEE T GEOSCI REMOTE, V59, P5449, DOI 10.1109/TGRS.2020.3028906
   Guo YW, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3128908
   Hou B, 2020, IEEE GEOSCI REMOTE S, V17, P1737, DOI 10.1109/LGRS.2019.2953203
   Hua WQ, 2022, IEEE J-STARS, V15, P2759, DOI 10.1109/JSTARS.2022.3162953
   Jansen RW, 2020, IEEE ACCESS, V8, P127440, DOI 10.1109/ACCESS.2020.3008350
   Li XF, 2020, IEEE ACCESS, V8, P146560, DOI 10.1109/ACCESS.2020.3004591
   Liang WK, 2020, IEEE T GEOSCI REMOTE, V58, P5317, DOI 10.1109/TGRS.2019.2963699
   Liu SJ, 2021, IEEE GEOSCI REMOTE S, V18, P1580, DOI 10.1109/LGRS.2020.3005076
   Liu XY, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3151353
   Ma SJ, 2023, ADV MULTIMED, V2023, DOI 10.1155/2023/8891239
   Nogueira FEA, 2020, IEEE GEOSCI REMOTE S, V17, P1287, DOI 10.1109/LGRS.2019.2941075
   Ou LS, 2023, ADV MULTIMED, V2023, DOI 10.1155/2023/7464628
   Qian PJ, 2020, IEEE T MED IMAGING, V39, P819, DOI 10.1109/TMI.2019.2935916
   Qian XX, 2021, IEEE T GEOSCI REMOTE, V59, P9290, DOI 10.1109/TGRS.2021.3051057
   Quan D, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3173476
   Ren ZL, 2020, IEEE T GEOSCI REMOTE, V58, P3864, DOI 10.1109/TGRS.2019.2959120
   Sujata D., 2020, DEEP LEARNING TECHNI
   Sushruta M., 2021, BIOINSPIRED NEUROCOM, P25, DOI [10.1007/978-981-15-5495-7_2, DOI 10.1007/978-981-15-5495-7_2]
   Swain D, 2022, ALGORITHMS, V15, DOI 10.3390/a15110403
   Wu Q, 2021, IEEE T GEOSCI REMOTE, V59, P4802, DOI 10.1109/TGRS.2020.3012276
   Wu ZT, 2021, IEEE T GEOSCI REMOTE, V59, P1200, DOI 10.1109/TGRS.2020.3004911
   Yang R, 2020, IEEE GEOSCI REMOTE S, V17, P431, DOI 10.1109/LGRS.2019.2923403
   Yibing L, 2023, WIREL COMMUN MOB COM, VComput, DOI [10.1155/2023/7724264, DOI 10.1155/2023/7724264]
   Yue ZY, 2020, IEEE J-STARS, V13, P4585, DOI 10.1109/JSTARS.2020.3016064
   Zhang YK, 2020, IEEE J-STARS, V13, P5730, DOI 10.1109/JSTARS.2020.3024002
   Zhu HL, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2020.3009179
   Zhu HL, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2020.2976836
   Zou B, 2020, IEEE J-STARS, V13, P609, DOI 10.1109/JSTARS.2020.2968966
NR 34
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 5
PY 2023
DI 10.1007/s11042-023-16296-8
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4EJ2
UT WOS:001043360000006
DA 2024-07-18
ER

PT J
AU Li, HJ
   Chen, JY
   Huang, XZ
   Zhang, YX
   Du, YL
   Chen, JJ
AF Li, Hongjun
   Chen, Jinyi
   Huang, Xiezhou
   Zhang, Yuxing
   Du, Yunlong
   Chen, Junjie
TI FOAD: a novel video anomaly detection focusing on objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Scene object; Autoencoder; Memory
AB With the popularity of surveillance video, people's increased security awareness and demand for risk warning, video anomaly detection is gradually gaining widespread attention. Since the amount of data in the background is larger than that of the foreground object, the background information of video frames is more easily noticed by the model, while the abnormal behaviors that cannot be easily detected mostly occur in the foreground. At the same time, if the background information is processed separately from the foreground information, it will inevitably increase the complexity of the model. In this paper, we propose a novel video anomaly detection based on scene object. In the training phase, we put foreground objects on the canvas for training and the memory module remembers various normal patterns of the foreground objects, so that the model can be more sensitive to the anomalies in the foreground objects during detection. Our method is able to achieve AUC 74.01% and 30 FPS on ShanghaiTech dataset. At the same time, several advanced video anomaly detection algorithms are compared, which all demonstrate the superiority of our method.
C1 [Li, Hongjun; Chen, Jinyi; Huang, Xiezhou; Zhang, Yuxing; Du, Yunlong; Chen, Junjie] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University; Nanjing University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 2010320025@stmail.ntu.edu.cn; 955971340@qq.com;
   zyx062127@163.com; a1002712404@163.com; cjjcy@ntu.edu.cn
OI li, hongjun/0000-0001-7500-4979; Du, yulong/0000-0001-6326-2102; Chen,
   Junjie/0000-0003-4219-6171
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Jiangsu Industry University Research Cooperation [BY2021349];
   Nantong Science and Technology Program [JC2021131]; Postgraduate
   Research and Practice Innovation Program of Jiangsu Province
   [KYCX21_3084, KYCX22_3340]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61871241, Grant 61971245 and Grant 61976120, in part
   by Jiangsu Industry University Research Cooperation Project BY2021349,
   in part by Nantong Science and Technology Program JC2021131 and in part
   by Postgraduate Research and Practice Innovation Program of Jiangsu
   Province KYCX21_3084 and KYCX22_3340.
CR Aslam N, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103598
   Bahrami M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103232
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   github, 2020, ULTR YOLOV5
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Lee S, 2021, PROC CVPR IEEE, P3053, DOI 10.1109/CVPR46437.2021.00307
   Li B, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103249
   Li B, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3955
   Li CB, 2023, APPL INTELL, V53, P542, DOI 10.1007/s10489-022-03488-2
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li Q, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109348
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhang Y, 2020, IEEE ACCESS, V8, P19033, DOI 10.1109/ACCESS.2020.2966827
   Zhong YH, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108336
NR 29
TC 0
Z9 0
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20637
EP 20651
DI 10.1007/s11042-023-16429-z
EA AUG 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200011
DA 2024-07-18
ER

PT J
AU Sanghavi, J
   Kurhekar, M
AF Sanghavi, Jignyasa
   Kurhekar, Manish
TI Ocular disease detection systems based on fundus images: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer Aided Diagnosis (CAD) systems; Ocular Diseases; Deep Learning;
   Transfer Learning; Artificial Intelligence
ID OPTIC-NERVE HEAD; MACULAR DEGENERATION; PATHOLOGICAL MYOPIA; LEARNING
   APPROACH; GLAUCOMA; CLASSIFICATION; DIAGNOSIS; SEGMENTATION; DATABASE
AB Ocular diseases are a leading cause of blindness and early detection is crucial for preventing permanent eye damage. Traditionally, instruments such as slit-lamps, tonometry, perimetry, gonioscopy, pachymetry, fundoscopy, and gyroscope have been employed for the detection and diagnosis of ocular diseases. However, recent advancements in machine learning (ML) and deep learning (DL) have enabled automated screenings and detection using retinal images. Computer-aided diagnosis (CAD) systems based on these algorithms have emerged as efficient tools for screening and diagnosis in telemedicine systems. This research paper focuses on studying ocular diseases, their symptoms, traditional diagnosis methods, and AI-based systems and explores algorithms for automatic screening and detection using retinal fundus images. Additionally, we review existing systems used for automatic diagnosis and provide a comprehensive comparison of various techniques employed in preprocessing, image enhancement, segmentation, feature extraction, and classification. These automated diagnosis systems serve as valuable second opinions and provide a rapid screening method.
C1 [Sanghavi, Jignyasa; Kurhekar, Manish] Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Sanghavi, J (corresponding author), Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
EM sjignyasa8588@gmail.com; manishkurhekar@cse.vnit.ac.in
RI Sanghavi Gandhi, Jignyasa/JXL-8447-2024
OI Sanghavi Gandhi, Dr. Jignyasa/0000-0002-7373-5628
CR Abbas Q, 2020, MULTIMED TOOLS APPL, V79, P31595, DOI 10.1007/s11042-020-09630-x
   Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Akbar S, 2018, COMPUT METH PROG BIO, V154, P123, DOI 10.1016/j.cmpb.2017.11.014
   Al-Diri B, 2008, IEEE ENG MED BIO, P2262, DOI 10.1109/IEMBS.2008.4649647
   Almazroa A, 2018, PROC SPIE, V10579, DOI 10.1117/12.2293584
   [Anonymous], 2021, SAMSUNG NEWSROOM
   Araci IE, 2014, NAT MED, V20, P1074, DOI 10.1038/nm.3621
   Baid U, 2019, TENCON IEEE REGION, P1345, DOI [10.1109/tencon.2019.8929252, 10.1109/TENCON.2019.8929252]
   Benghai Lee, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P2039, DOI 10.1109/ICIEA.2010.5515493
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Burlina PM, 2017, JAMA OPHTHALMOL, V135, P1170, DOI 10.1001/jamaophthalmol.2017.3782
   Butt M. M., 2019, Procedia Comput. Sci., V163, P283, DOI [10.1016/j.procs.2019.12.110, DOI 10.1016/J.PROCS.2019.12.110]
   Carmona EJ, 2008, ARTIF INTELL MED, V43, P243, DOI 10.1016/j.artmed.2008.04.005
   Chang L, 2016, DIGITALTRENDS   0911
   Chaudhary PK, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102237
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Devda J, 2019, PROCEDIA COMPUT SCI, V165, P239, DOI 10.1016/j.procs.2020.01.084
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Du R, 2021, OPHTHALMOL RETINA, V5, P1235, DOI 10.1016/j.oret.2021.02.006
   EyePACS database, 2015, DIABETIC RETINOPATHY
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Freire CR, 2020, AUTOMATIC LESION SEG
   Fu H., 2019, IEEE Dataport, DOI [10.21227/tz6--r977, DOI 10.21227/TZ6--R977]
   Fumero F, 2011, COMP MED SY
   Gao ZT, 2019, IEEE ACCESS, V7, P3360, DOI 10.1109/ACCESS.2018.2888639
   García-Floriano A, 2019, COMPUT ELECTR ENG, V75, P218, DOI 10.1016/j.compeleceng.2017.11.008
   Govindaiah A, 2018, I S BIOMED IMAGING, P1525, DOI 10.1109/ISBI.2018.8363863
   Grassmann F, 2018, OPHTHALMOLOGY, V125, P1410, DOI 10.1016/j.ophtha.2018.02.037
   Guo LY, 2015, COMPUT IND, V69, P72, DOI 10.1016/j.compind.2014.09.005
   Hemelings R, 2021, COMPUT METH PROG BIO, V199, DOI 10.1016/j.cmpb.2020.105920
   Hernandez-Matas C., 2017, Model. Artif. Intell. Ophthalmol., V1, P16, DOI DOI 10.35119/MAIO.V1I4.42
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Kar SS, 2018, IEEE T BIO-MED ENG, V65, P608, DOI 10.1109/TBME.2017.2707578
   Kauppi T, 2007, DIARETDB0 EVALUATION
   Keum D, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba3252
   Khanamiri HN, 2017, JOVE-J VIS EXP, DOI 10.3791/55958
   Khitran S., 2014, P 2014 4 INT C IM PR, P1, DOI [10.1109/IPTA.2014.7001984., DOI 10.1109/IPTA.2014.7001984]
   Klviinen RVJPH., 2007, Medical Image Understanding and Analysis, V2007, P61
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Liu J, 2010, J HEALTHC ENG, V1, P1, DOI 10.1260/2040-2295.1.1.1
   Long EP, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00319-x
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Ma YC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P433, DOI 10.1109/PERCOMW.2015.7134077
   Martins J, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105341
   Melo T, 2020, COMPUT BIOL MED, V126, DOI 10.1016/j.compbiomed.2020.103995
   Nakanishi M, 2017, JAMA OPHTHALMOL, V135, P550, DOI 10.1001/jamaophthalmol.2017.0738
   Narasimhan K, 2012, PROCEDIA ENGINEER, V38, P980, DOI 10.1016/j.proeng.2012.06.124
   National Eye Institute (NEI), 2006, AG REL EYE DIS STUD
   Niemeijer M, 2011, IEEE T MED IMAGING, V30, P1941, DOI 10.1109/TMI.2011.2159619
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   odir2019, PEK U INT COMP OC DI
   Ortega M, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/235746
   Panwar N, 2016, TELEMED E-HEALTH, V22, P198, DOI 10.1089/tmj.2015.0068
   Park H, 2018, MICROSYST NANOENG, V4, DOI 10.1038/s41378-018-0032-3
   Peng YF, 2019, OPHTHALMOLOGY, V126, P565, DOI 10.1016/j.ophtha.2018.11.015
   Pruthi J, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.102004
   Qi Yan, 2020, Nature Machine Intelligence, V2, P141, DOI 10.1038/s42256-020-0154-9
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Ran J, 2018, IEEE I C NETW INFRAS, P155, DOI 10.1109/ICNIDC.2018.8525852
   Registry of Research Data Repositories, 2021, ROTT OPHTH DAT REP
   Saleh E, 2018, ARTIF INTELL MED, V85, P50, DOI 10.1016/j.artmed.2017.09.006
   Sánchez CI, 2011, INVEST OPHTH VIS SCI, V52, P4866, DOI 10.1167/iovs.10-6633
   Savoy M, 2020, AM FAM PHYSICIAN, V101, P307
   Septiarini A, 2018, HEALTHC INFORM RES, V24, P53, DOI 10.4258/hir.2018.24.1.53
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Shoba SJG, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.101986
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Syahputra MF, 2017, INT CONF COMP APPL I, P70
   Tan JH, 2018, FUTURE GENER COMP SY, V87, P127, DOI 10.1016/j.future.2018.05.001
   Tan NM, 2009, IEEE ENG MED BIO, P3609, DOI 10.1109/IEMBS.2009.5333517
   Thomas SA, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101962
   Triwijoyo BK, 2017, J PHYS CONF SER, V801, DOI 10.1088/1742-6596/801/1/012039
   Triwijoyo BK, 2017, PROCEDIA COMPUT SCI, V116, P166, DOI 10.1016/j.procs.2017.10.066
   varpa, VICAVR DAT
   W. H. Organization, 2014, 10 FACTS BLINDN VIS
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Zhang LL, 2017, IEEE INT C NETW SENS, P60, DOI 10.1109/ICNSC.2017.8000068
   Zhang Z, 2013, C IND ELECT APPL, P228
   Zhang Z, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065736
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zhou Y, 2020, IEEE T MED IMAGING, V39, P436, DOI 10.1109/TMI.2019.2928229
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 85
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21471
EP 21496
DI 10.1007/s11042-023-16366-x
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200004
DA 2024-07-18
ER

PT J
AU Singla, V
   Bawa, S
   Singh, J
AF Singla, Venus
   Bawa, Seema
   Singh, Jasmeet
TI Improving accuracy using ML/DL in vision based techniques of ISLR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indian sign language; Machine learning; Deep learning; Hand gesture
   recognition
AB Sign language is an optical language where the formation of signs are done using hands or body gestures. Although, communication using signs are quite understandable among hearing-impaired persons, yet the translation for generic use by other persons remains to be a major challenge. Various techniques are available to convert Sign Languages to Readable text. This paper analyses specifically vision-based techniques for Indian Sign Language Recognition (ISLR). Machine Learning and Deep Learning based techniques for ISLR have been presented here to achieve better accuracy. An experimental setup has been created to analyze the performance of various ML and DL techniques on three different static ISL datasets: First, One-handed with uniform background, second, two-handed with complex background and third one is a mixture of one-handed and two-handed datasets with uniform background. These three datasets have been used to compare the accuracy. The highest accuracy achieved among ML techniques is with the SVM classifier i.e. 99.17%, 81.41% and 99.96% respectively on the three datasets. It is further suggested that by creating Ensemble ML Classifiers or vision based transformers accuracy can be further enhanced. Using DL techniques, highest accuracy achieved on Dataset-I is with ResNet50 model is 100%, on Dataset-II is with MobileNetV2 is 99.96% and on Dataset-III 100% accuracy is achieved by using ResNet50, MobileNetV2 and InceptionResNetV2.
C1 [Singla, Venus; Bawa, Seema; Singh, Jasmeet] Thapar Inst Engn & Technol, Dept Comp Sci, Adarsh Nagar, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singla, V (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci, Adarsh Nagar, Patiala 147004, Punjab, India.
EM vsingla_phd20@thapar.edu; seema@thapar.edu; jasmeet.singh@thapar.edu
OI , Venus/0000-0002-7745-7901
CR Abraham Tuhina Sheryl, 2022, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2318/1/012041
   Alaskar H., 2021, Proceedings of Integrated Intelligence Enable Networks and Computing, P143
   Amrutha K, 2021, 2021 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN INFORMATION TECHNOLOGY (ICITIIT), DOI 10.1109/ICITIIT51526.2021.9399594
   [Anonymous], 2012, INT J ENG ADV TECHNO
   Badhe PC, 2020, 2020 11 INT C COMP C, P1, DOI [10.1109/ICCCNT49239.2020.9225294, DOI 10.1109/ICCCNT49239.2020.9225294]
   Badiger RM, 2021, INT J FUTUR GEN COMM, V14, P832
   Bastanfard A, 2010, LECT NOTES COMPUT SC, V6298, P705, DOI 10.1007/978-3-642-15696-0_65
   Bhavsar H, 2021, Indian Journal of Computer Science and Engineering, V12, P1093, DOI 10.21817/indjcse/2021/v12i4/211204220
   Boesch G, 2022, VISION TRANSFORMERS
   Bousbai K., 2019, 2019 6 INT C IMAGE S, P1, DOI DOI 10.1109/ISPA48434.2019.8966918
   Brahmankar V, 2021, INT J ADV TRENDS COM, V10, P1576, DOI [10.30534/ijatcse/2021/131032021, DOI 10.30534/IJATCSE/2021/131032021]
   Chakraberty S, 2021, CHALLENGES BUILDING
   Daniel M., 2020, EUR J MOL CLIN MED, V7, P2628
   Das Chakladar D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083439
   Deaf History-Europe, 1880, MIL C
   Dhanjal AS, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.165279
   Dhiman R., 2021, J PHYS C SERIES, V1950, P1, DOI [10.1088/1742-6596/1950/1/012020, DOI 10.1088/1742-6596/1950/1/012020]
   Dhivyasri S, 2021, INT CO SIG PROC COMM, P130, DOI 10.1109/ICSPC51351.2021.9451692
   Divyashree KM., 2019, INT RES J ENG TECHNO, V6, P1697
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Dutta KK, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P333, DOI 10.1109/CTCEEC.2017.8454988
   Farooq U, 2021, NEURAL COMPUT APPL, V33, P14357, DOI 10.1007/s00521-021-06079-3
   Indian Sign Language Research and Training Center (ISLRTC), 2021, HIST
   ISI Language Solutions, 2021, INT FACTS AM SIGN LA
   Jain R, 2021, ADV J GRAD RES, V11, P1, DOI [10.21467/ajgr.11.1.1-9, DOI 10.21467/AJGR.11.1.1-9]
   Jaiswal M, 2020, INT CONF COMM SYST, P44, DOI 10.1109/CSNT.2020.09
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Jovita F, 2022, DIFFERENCES INCEPTIO
   Kerneler, 2022, ISL DAT DOUBL HAND
   Kothadiya DR, 2023, IEEE ACCESS, V11, P4730, DOI 10.1109/ACCESS.2022.3231130
   Krishna S, 2020, P 2020 4 INT C VIS I, P1, DOI [10.1145/3448823.3448830, DOI 10.1145/3448823.3448830]
   Mariappan HM, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI [10.1109/MLUI52769.2019.10075566, 10.1109/iccids.2019.8862125]
   Minoofam SAH, 2022, MULTIMED TOOLS APPL, V81, P6389, DOI 10.1007/s11042-021-11806-y
   Mishra GS, 2019, INT J INNOVATIVE TEC, V8, P460, DOI [10.35940/ijitee.j1084.08810-19, DOI 10.35940/IJITEE.J1084.08810-19]
   National Programme for the Prevention Control of Deafness (NPPCD), 2021, NAT HLTH MISS
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Patil V, 2022, INT J ENG TRENDS TEC, V17, P32, DOI [10.14445/22315381/IJETT-V70I6P204, DOI 10.14445/22315381/IJETT-V70I6P204]
   Pu Q., 2013, P 19 ANN INT C MOB C, P27, DOI DOI 10.1145/2500423.2500436
   Rafi A, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673423
   Rao GA, 2018, AIN SHAMS ENG J, V9, P1929, DOI 10.1016/j.asej.2016.10.013
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Rishabh G, 2022, INDIAN SIGN LANGUAGE
   Rokade Yogeshwar I, 2017, International Journal of Engineering and Technology, V9
   Sahoo AK, 2022, MACROMOL SYMP, V401, DOI 10.1002/masy.202100286
   Sahoo AK, 2021, MACROMOL SYMP, V397, DOI 10.1002/masy.202000241
   Salunke TP, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1151, DOI 10.1109/ICCMC.2017.8282654
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Sharma A, 2021, NEURAL COMPUT APPL, V33, P6685, DOI 10.1007/s00521-020-05448-8
   Sharma P., 2021, GRAPH VIS COMPUT, V5, P200032, DOI [10.1016/j.gvc.2021.200032, DOI 10.1016/J.GVC.2021.200032]
   Sharma RP, 2015, PROCEDIA COMPUT SCI, V54, P721, DOI 10.1016/j.procs.2015.06.085
   Singh DK, 2021, PROCEDIA COMPUT SCI, V189, P76, DOI 10.1016/j.procs.2021.05.071
   Sreenivas A., 2020, INT J ADV SCI TECHNO, V29, P11015
   Sridhar A, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1366, DOI 10.1145/3394171.3413528
   Stokoe, 1960, W STOK
   Stoll S, 2020, INT J COMPUT VISION, V128, P891, DOI 10.1007/s11263-019-01281-2
   Sugandhi, 2021, COMPUTER, V54, P37, DOI 10.1109/MC.2020.2992237
   Sugandhi, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3384202
   Suvetha S., 2020, INT J CREATIVE RES T, V8, P1679
   Tyagi Sandhya Bansal, 2021, INT J COMPUT DIGIT S, V11, P1217, DOI DOI 10.12785/IJCDS/110199
   Vaishnavi A, 2021, INDIAN SIGN LANGUAGE
   Varsha M, 2021, 2021 8TH INTERNATIONAL CONFERENCE ON SMART COMPUTING AND COMMUNICATIONS (ICSCC), P193, DOI 10.1109/ICSCC51209.2021.9528246
   Vasani Neel, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P1250, DOI 10.1109/ICISS49785.2020.9315979
   Vaswani A, 2017, ADV NEUR IN, V30
   Venugopalan A, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115601
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wanbo Li, 2021, 2021 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P919, DOI 10.1109/ICAICA52286.2021.9498024
   WHO, 2021, about us
   World Federation of the Deaf, 2021, LEG REC NAT SIGN LAN
   Yadav K., 2019, J NETWORK COMMUNICAT, V9, P1
   Zhang Q., 2017, P 2017 IEEECIC INT C, P1
   Zhou H, 2022, IEEE T MULTIMEDIA, V24, P768, DOI 10.1109/TMM.2021.3059098
NR 71
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20677
EP 20698
DI 10.1007/s11042-023-16299-5
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200002
DA 2024-07-18
ER

PT J
AU Nguyen, TN
   Le, TK
   Ninh, VT
   Caputo, A
   Healy, G
   Smyth, S
   Tran, MT
   Binh, NT
AF Nguyen, Thao-Nhu
   Le, Tu-Khiem
   Ninh, Van-Tu
   Caputo, Annalina
   Healy, Graham
   Smyth, Sinead
   Tran, Minh-Triet
   Binh, Nguyen Thanh
TI LifeSeeker: an interactive concept-based retrieval system for lifelog
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifelog; Interactive retrieval system; Lifelog search challenge
AB Lifelogging was introduced as the process of passively capturing personal daily events via wearable devices. It ultimately creates a visual diary encoding every aspect of one's life with the aim of future sharing or recollecting. In this paper, we present LifeSeeker, a lifelog image retrieval system participating in the Lifelog Search Challenge (LSC) for 3 years, since 2019. Our objective is to support users to seek specific life moments using a combination of textual descriptions, spatial relationships, location information, and image similarities. In addition to the LSC challenge results, a further experiment was conducted in order to evaluate the power retrieval of our system on both expert and novice users. This experiment informed us about the effectiveness of the user's interaction with the system when involving non-experts.
C1 [Nguyen, Thao-Nhu; Le, Tu-Khiem; Ninh, Van-Tu; Caputo, Annalina; Healy, Graham; Smyth, Sinead] Dublin City Univ, Dublin, Ireland.
   [Tran, Minh-Triet; Binh, Nguyen Thanh] Vietnam Natl Univ Ho Chi Minh city, Univ Sci, Ho Chi Minh, Vietnam.
C3 Dublin City University; Vietnam National University Hochiminh City
RP Nguyen, TN; Le, TK; Ninh, VT (corresponding author), Dublin City Univ, Dublin, Ireland.
EM thaonhu.nguyen24@mail.dcu.ie; tukhiem.le4@mail.dcu.ie;
   tu.ninhvan@adaptcentre.ie
RI Nguyen, Binh/W-3689-2018; Tran, Minh-Triet/HTO-6586-2023
OI Smyth, Sinead/0000-0002-8736-0505; Nguyen, Thao-Nhu/0000-0003-1356-9434
FU Insight SFI Research Centre for Data Analytics [SFI/13/RC/2106 P2]; IReL
   Consortium [SFI/12/RC/2289_P2]; IReL Consortium [GOIPG/2016/741]; Irish
   Research Council (IRC) [18/CRT/6223]; Science Foundation Ireland Centre
   for Research Training [SFI/12/RC/2289 P2]; Insight SFI Research Centre
   for Data Analytics; ADAPT -Centre for Digital Content Technology; Irish
   Research Council (IRC) [GOIPG/2016/741] Funding Source: Irish Research
   Council (IRC)
FX Open Access funding provided by the IReL ConsortiumThis publication has
   emanated from research supported in part by research grants from Irish
   Research Council (IRC) under grant number GOIPG/2016/741, Science
   Foundation Ireland Centre for Research Training under grant number
   18/CRT/6223, Insight SFI Research Centre for Data Analytics under grant
   number SFI/12/RC/2289 P2 and ADAPT -Centre for Digital Content
   Technology under grant number SFI/13/RC/2106 P2.
CR Alam N, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P53, DOI 10.1145/3463948.3469069
   Alateeq A, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P65, DOI 10.1145/3463948.3469071
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dang-Nguyen D-T, 2018, CLEF 2018 WORKING NO
   Dang-Nguyen Duc-Tien, 2019, CEUR WORKSHOP PROC, P17
   Gurrin Cathal, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P584, DOI 10.1145/3372278.3388043
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Gurrin C, 2021, INTRO 4 ANN LIFELOG, DOI [10.1145/3460426.3470945, DOI 10.1145/3460426.3470945]
   Gurrin C, 2019, ITE TRANS MEDIA TECH, V7, P46, DOI 10.3169/mta.7.46
   Gurrin C, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P705, DOI 10.1145/2911451.2914680
   Gurrin Cathal, 2019, OVERVIEW NTCIR 14 LI, P13
   Heller S, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P35, DOI 10.1145/3463948.3469062
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lokoc J, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P71, DOI 10.1145/3463948.3469074
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nguyen TN, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P41, DOI 10.1145/3463948.3469065
   Ninh V-T, 2020, OVERVIEW IMAGECLEF L
   Radford A, 2021, PR MACH LEARN RES, V139
   Rossetto L, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P7, DOI 10.1145/3463948.3469068
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sculley D., 2010, P INT C WORLD WID WE, V19, P1177, DOI [DOI 10.1145/1772690.1772862, 10.1145/1772690.1772862]
   Spiess F, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P17, DOI 10.1145/3463948.3469061
   Tran LD, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P11, DOI 10.1145/3463948.3469064
   Tu-Khiem Le, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P57, DOI 10.1145/3379172.3391724
   Le TK, 2019, LSC '19 - PROCEEDINGS OF THE ACM WORKSHOP ON LIFELONG SEARCH CHALLENGE, P37, DOI 10.1145/3326460.3329162
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 1
PY 2023
DI 10.1007/s11042-023-15317-w
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O0QU8
UT WOS:001040962400012
PM 37799146
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Koutsiou, DCC
   Savelonas, MA
   Iakovidis, DK
AF Koutsiou, Dimitra-Christina C.
   Savelonas, Michalis A.
   Iakovidis, Dimitris K.
TI SUShe: simple unsupervised shadow removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shadow removal; Color; Histogram matching; Electromagnetism-like
   optimization
ID ILLUMINATION; MASK
AB Shadow removal is an important problem in computer vision, since the presence of shadows complicates core computer vision tasks, including image segmentation and object recognition. Most state-of-the-art shadow removal methods are based on complex deep learning architectures, which require training on a large amount of data. In this paper a novel and efficient methodology is proposed aiming to provide a simple solution to shadow removal, both in terms of implementation and computational cost. The proposed methodology is fully unsupervised, based solely on color image features. Initially, the shadow region is automatically extracted by a segmentation algorithm based on Electromagnetic-Like Optimization. Superpixel-based segmentation is performed and pairs of shadowed and non-shadowed regions, which are nearest neighbors in terms of their color content, are identified as parts of the same object. The shadowed part of each pair is relighted by means of histogram matching, using the content of its non-shadowed counterpart. Quantitative and qualitative experiments on well-recognized publicly available benchmark datasets are conducted to evaluate the performance of proposed methodology in comparison to state-of-the-art methods. The results validate both its efficiency and effectiveness, making evident that solving the shadow removal problem does not necessarily require complex deep learning-based solutions.
C1 [Koutsiou, Dimitra-Christina C.; Savelonas, Michalis A.; Iakovidis, Dimitris K.] Univ Thessaly, Dept Comp Sci & Biomed Informat, Papasiopoulou 2-4, Lamia 35131, Greece.
RP Iakovidis, DK (corresponding author), Univ Thessaly, Dept Comp Sci & Biomed Informat, Papasiopoulou 2-4, Lamia 35131, Greece.
EM dkoutsiou@uth.gr; msavelonas@uth.gr; diakovidis@uth.gr
OI Iakovidis, Dimitris/0000-0002-5027-5323
FU HEAL-Link Greece
FX Open access funding provided by HEAL-Link Greece.
CR Abiko R, 2022, IEEE ACCESS, V10, P12322, DOI 10.1109/ACCESS.2022.3147063
   Achanta R, 2010, EEE T PATTERN ANAL M, V34, P2274, DOI [10.1109/TPAMI.2012.120, DOI 10.1109/TPAMI.2012.120]
   Alvarado-Robles G, 2021, IEEE ACCESS, V9, P34240, DOI 10.1109/ACCESS.2021.3061102
   Baba M., 2004, P ACM SIGGRAPH, P60
   Barrow Harry, 1978, Comput. Vis. Syst, V2, P2
   Benalia S, 2022, COMPUT MATH APPL, V107, P95, DOI 10.1016/j.camwa.2021.12.023
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Chen ZP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4723, DOI 10.1109/ICCV48922.2021.00470
   Cun XD, 2020, AAAI CONF ARTIF INTE, V34, P10680
   Dhingra G, 2021, MULTIMED TOOLS APPL, V80, P33763, DOI 10.1007/s11042-021-11427-5
   Dimas G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082385
   Ding B, 2019, IEEE I CONF COMP VIS, P10212, DOI 10.1109/ICCV.2019.01031
   Einy T, 2022, IEEE COMPUT SOC CONF, P3011, DOI 10.1109/CVPRW56347.2022.00340
   Fan XY, 2020, VISUAL COMPUT, V36, P2175, DOI 10.1007/s00371-020-01916-3
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823
   Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z
   Fu L, 2021, PROC CVPR IEEE, P10566, DOI 10.1109/CVPR46437.2021.01043
   Aviña-Cervantes JG, 2007, LECT NOTES ARTIF INT, V4827, P650
   Gong H, 2016, J OPT SOC AM A, V33, P1798, DOI 10.1364/JOSAA.33.001798
   Guo RQ, 2013, IEEE T PATTERN ANAL, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Guo RQ, 2011, PROC CVPR IEEE
   He SF, 2021, IEEE SIGNAL PROC LET, V28, P957, DOI 10.1109/LSP.2021.3074082
   Hiary H, 2018, COMPUT J, V61, P459, DOI 10.1093/comjnl/bxy004
   Hieu Le, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P264, DOI 10.1007/978-3-030-58621-8_16
   Hu XW, 2021, IEEE T IMAGE PROCESS, V30, P1925, DOI 10.1109/TIP.2021.3049331
   Hu XW, 2019, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2019.00256
   Hu XW, 2020, IEEE T PATTERN ANAL, V42, P2795, DOI 10.1109/TPAMI.2019.2919616
   Jarraya SK, 2016, MULTIMED TOOLS APPL, V75, P10949, DOI 10.1007/s11042-015-2818-8
   Jin YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5007, DOI 10.1109/ICCV48922.2021.00498
   Khare M, 2018, MULTIMED TOOLS APPL, V77, P2391, DOI 10.1007/s11042-017-4371-0
   Koutsiou DCC, 2021, EUR SIGNAL PR CONF, P635, DOI 10.23919/Eusipco47968.2020.9287686
   Le H, 2022, IEEE T PATTERN ANAL, V44, P9088, DOI 10.1109/TPAMI.2021.3124934
   Le H, 2019, IEEE I CONF COMP VIS, P8577, DOI 10.1109/ICCV.2019.00867
   Liu F, 2008, LECT NOTES COMPUT SC, V5305, P437
   Liu YH, 2022, J APPL STAT, V49, P1323, DOI 10.1080/02664763.2021.1913103
   Liu ZH, 2021, PROC CVPR IEEE, P4925, DOI 10.1109/CVPR46437.2021.00489
   Liu ZH, 2021, IEEE T IMAGE PROCESS, V30, P1853, DOI 10.1109/TIP.2020.3048677
   Maini R., 2010, J COMPUT, V2, DOI DOI 10.48550/ARXIV.1003.4053
   Murali S, 2022, VISUAL COMPUT, V38, P1527, DOI 10.1007/s00371-021-02086-6
   Murali S, 2019, MULTIMED TOOLS APPL, V78, P21167, DOI 10.1007/s11042-019-7435-5
   Nagae T, 2021, EUR SIGNAL PR CONF, P630, DOI 10.23919/Eusipco47968.2020.9287528
   Ntakolia C, 2022, UNIVERSAL ACCESS INF, V21, P249, DOI 10.1007/s10209-020-00764-1
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248
   Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x
   Sovatzidi G, 2020, 2020 15TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2020), P33, DOI 10.1109/smap49528.2020.9248455
   Ufuktepe DK, 2021, P IEEECVF INT C COMP, P3926
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Wan J, 2022, LECT NOTES COMPUT SC, V13679, P361, DOI 10.1007/978-3-031-19800-7_21
   Wang J. M., 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P649
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang J, 2021, REMOTE SENS ENVIRON, V264, DOI 10.1016/j.rse.2021.112604
   Wang QM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108540
   Wu W, 2022, VISUAL COMPUT, V38, P1677, DOI 10.1007/s00371-021-02096-4
   Xiao M, 2007, INT J AUTOM COMPUT, V4, P38, DOI 10.1007/s11633-007-0038-z
   Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976
   Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P6972, DOI 10.1109/TGRS.2014.2306233
   Zhang L, 2020, AAAI CONF ARTIF INTE, V34, P12829
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng LX, 2017, MULTIMED TOOLS APPL, V76, P18321, DOI 10.1007/s11042-016-3880-6
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YR, 2022, PROC CVPR IEEE, P5617, DOI 10.1109/CVPR52688.2022.00554
NR 65
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19517
EP 19539
DI 10.1007/s11042-023-16282-0
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800005
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, M
   Bhandari, AK
   Jha, M
AF Kumar, Manish
   Bhandari, Ashish Kumar
   Jha, Manvi
TI Unevenly illuminated image distortion correction using brightness
   perception and chromatic luminance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement; Chromatic luminance; Dark image; Image
   enhancement; Unevenly illuminated
ID ADAPTIVE GAMMA CORRECTION; CONTRAST ENHANCEMENT; COLOR IMAGES;
   HISTOGRAM; EQUALIZATION; RETINEX
AB Images are of paramount significance in the contemporary scientific era for various applications. However, the environmental and lighting conditions of the surroundings greatly influence the quality and visibility of the images. In low-illumination scenes, images tend to suffer from poor visibility, which deteriorates in the presence of uneven illumination. Several methods have been developed to address this issue; however, their results have proven to be unsatisfactory. The present work deals effectively with unevenly illuminated dark images by deploying a brightness transfer function based on the Weber-Fechner law. The proposed transfer function is adaptively controlled by the value and saturation components of the input image converted in HSV space. Additionally, an image fusion technique is employed to acquire a detailed enhanced image. Furthermore, a novel function based on the Helmholtz-Kohlrausch (H-K) effect is introduced for color contrast enhancement. Both qualitative and quantitative assessments validate that the proposed approach outperforms several existing methods.
C1 [Kumar, Manish; Bhandari, Ashish Kumar; Jha, Manvi] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM manishk.pg19.ec@nitp.ac.in; bhandari.iiitj@gmail.com;
   manvij.ug19.ec@nitp.ac.in
RI Bhandari, Ashish Kumar/AAA-9991-2019
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; Jha,
   Manvi/0000-0001-5613-7039
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Celik T, 2016, IEEE T IMAGE PROCESS, V25, P4719, DOI 10.1109/TIP.2016.2599103
   Chen JH, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P944, DOI 10.1109/IMCCC.2012.226
   Chuanmin Xiao, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P45, DOI 10.1109/ICIG.2013.15
   Corney D, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005091
   Donofrio RL, 2011, J SOC INF DISPLAY, V19, P658, DOI 10.1889/JSID19.10.658
   Gupta B, 2016, OPTIK, V127, P1671, DOI 10.1016/j.ijleo.2015.10.068
   Han JH, 2011, IEEE T IMAGE PROCESS, V20, P506, DOI 10.1109/TIP.2010.2068555
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jha M, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3165303
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kandhway P, 2019, MULTIDIM SYST SIGN P, V30, P1859, DOI 10.1007/s11045-019-00633-y
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lim S, 2021, IEEE T MULTIMEDIA, V23, P4272, DOI 10.1109/TMM.2020.3039361
   Ling ZG, 2015, IET IMAGE PROCESS, V9, P1012, DOI 10.1049/iet-ipr.2014.0580
   Liu ZT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3125055
   Lv F., 2018, P BMVC, V220, P4
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Singh K, 2016, J MOD OPTIC, V63, P1444, DOI 10.1080/09500340.2016.1154194
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Srinivas K, 2020, J FRANKLIN I, V357, P13941, DOI 10.1016/j.jfranklin.2020.10.013
   Wang QM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3108540
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2019, INFORM SCIENCES, V489, P50, DOI 10.1016/j.ins.2019.02.058
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 31
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17395
EP 17428
DI 10.1007/s11042-023-16207-x
EA JUL 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700017
DA 2024-07-18
ER

PT J
AU Gharehchopogh, FS
   Ibrikci, T
AF Gharehchopogh, Farhad Soleimanian
   Ibrikci, Turgay
TI An improved African vultures optimization algorithm using different
   fitness functions for multi-level thresholding image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE African Vultures Optimization Algorithm; Multi-level Thresholding; Image
   Segmentation; Optimization
ID PARTICLE SWARM OPTIMIZATION; CUCKOO SEARCH ALGORITHM; CROSS-ENTROPY;
   FUZZY ENTROPY; KAPURS
AB Image segmentation is one of the most significant and required procedures in pre-processing and analyzing images. Metaheuristic optimization algorithms are used to solve a wide range of different problems because they can solve problems with different dimensions in an acceptable time and with quality results. It can show different functions in solving various problems. So, a metaheuristic algorithm should be adapted to solve the target problem with different mechanisms to find the best performance. In this paper, we have used the improved African Vultures Optimization Algorithm (AVOA) that uses the three binary thresholds (Kapur's entropy, Tsallis entropy, and Ostu's entropy) in multi-threshold image segmentation. The Quantum Rotation Gate (QRG) mechanism has increased population diversity in optimization stages, and optimal local trap escapes to improve AVOA performance. The Association Strategy (AS) mechanism is used to obtain and faster search for optimal solutions. These two mechanisms increase the diversity of production solutions in all optimization stages because the AVOA algorithm focuses on the exploration phase almost in the first half of the iterations. So, in this approach, it is possible to guarantee a wide variety of solutions and avoid falling into the local optimum trap. Standard criteria and datasets were used to evaluate the performance of the proposed algorithm and then compared with other optimization algorithms. Eight images with large dimensions have been used to evaluate the proposed algorithm so that the ability of the proposed algorithm and other compared algorithms can be accurately checked. A better solution to large-scale problems requires good performance of the algorithm in both the exploitation and exploration phases, and a balance must be created between these two phases. According to the experimental results from the proposed algorithm, it is determined that it has a good and significant performance.
C1 [Gharehchopogh, Farhad Soleimanian] Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
   [Ibrikci, Turgay] Adana Alparslan Turkes Sci & Technol Univ, Dept Software Engn, Adana, Turkiye.
C3 Islamic Azad University; Adana Alparslan Turkes Science & Technology
   University
RP Gharehchopogh, FS (corresponding author), Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
EM bonab.farhad@gmail.com
RI Gharehchopogh, Farhad Soleimanian/AAX-9598-2020
OI Gharehchopogh, Farhad Soleimanian/0000-0003-1588-1659
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd Elaziz M, 2021, ENG APPL ARTIF INTEL, V98, DOI 10.1016/j.engappai.2020.104105
   Abd Elaziz M, 2020, IEEE ACCESS, V8, P125306, DOI 10.1109/ACCESS.2020.3007928
   Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P112, DOI 10.1016/j.eswa.2019.01.047
   Abdel-Basset M, 2022, ARTIF INTELL REV, V55, P6389, DOI 10.1007/s10462-022-10157-w
   Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Ahilan A, 2019, IEEE ACCESS, V7, P89570, DOI 10.1109/ACCESS.2019.2891632
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Al-Rahlawee ATH, 2021, MULTIMED TOOLS APPL, V80, P28217, DOI 10.1007/s11042-021-10860-w
   Alwerfali HSN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030328
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Bao XL, 2019, IEEE ACCESS, V7, P76529, DOI 10.1109/ACCESS.2019.2921545
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhunia AK, 2019, PATTERN RECOGN, V85, P172, DOI 10.1016/j.patcog.2018.07.034
   Bohani FA, 2019, INT J ELECTR COMPUT, V10, P45
   Chakraborty S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114142
   Chen Y, 2022, EXPERT SYST APPL, V194, DOI 10.1016/j.eswa.2022.116511
   Dhal KG, 2020, NEURAL COMPUT APPL, V32, P3059, DOI 10.1007/s00521-019-04585-z
   Díaz-Cortés MA, 2018, INFRARED PHYS TECHN, V93, P346, DOI 10.1016/j.infrared.2018.08.007
   Frongillo M, 2018, IEEE T ANTENN PROPAG, V66, P6646, DOI 10.1109/TAP.2018.2876602
   Ghafori S, 2022, ARCH COMPUT METHOD E, V29, P1569, DOI 10.1007/s11831-021-09624-4
   Gharehchopogh FS, 2022, ARCH COMPUT METHOD E, V29, P3281, DOI 10.1007/s11831-021-09698-0
   Gharehchopogh FS, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6310
   Gharehchopogh FS, 2020, ARTIF INTELL REV, V53, P2265, DOI 10.1007/s10462-019-09733-4
   Gharehchopogh FS, 2019, SWARM EVOL COMPUT, V48, P1, DOI 10.1016/j.swevo.2019.03.004
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Houssein EH, 2021, STUD COMPUT INTELL, V967, P239, DOI 10.1007/978-3-030-70542-8_11
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121421
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Katsuragawa K, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3181672
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Liang HN, 2019, IEEE ACCESS, V7, P11258, DOI 10.1109/ACCESS.2019.2891673
   Liang JH, 2018, MULTIMED TOOLS APPL, V77, P31787, DOI 10.1007/s11042-018-6119-x
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Nadimi-Shahraki MH, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116895
   Nadimi-Shahraki MH, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101636
   Nadimi-Shahraki MH, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10232975
   Nadimi-Shahraki MH, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121637
   Oliva D, 2018, MULTIMED TOOLS APPL, V77, P25761, DOI 10.1007/s11042-018-5815-x
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pare S, 2017, APPL SOFT COMPUT, V61, P570, DOI 10.1016/j.asoc.2017.08.039
   Pare S, 2016, APPL SOFT COMPUT, V47, P76, DOI 10.1016/j.asoc.2016.05.040
   Park SJ, 2018, PATTERN RECOGN LETT, V112, P249, DOI 10.1016/j.patrec.2018.07.032
   Rahnema N, 2020, MULTIMED TOOLS APPL, V79, P32169, DOI 10.1007/s11042-020-09639-2
   Raja N., 2018, INNOVATIONS ELECT CO, P229, DOI [10.1007/978-981-10-3812-9_24, DOI 10.1007/978-981-10-3812-9_24]
   Rapaka S, 2018, IET IMAGE PROCESS, V12, P1721, DOI 10.1049/iet-ipr.2016.0917
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Sadiq AS, 2022, EXPERT SYST APPL, V203, DOI 10.1016/j.eswa.2022.117395
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Shayanfar H, 2018, APPL SOFT COMPUT, V71, P728, DOI 10.1016/j.asoc.2018.07.033
   Sun Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115759
   Tang KZ, 2011, KNOWL-BASED SYST, V24, P1131, DOI 10.1016/j.knosys.2011.02.013
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   visibleearth.nasa, LANDSAT IMAGERY COUR
   Wang SK, 2020, MATH BIOSCI ENG, V17, P700, DOI 10.3934/mbe.2020036
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P12007, DOI 10.1007/s11042-019-08566-1
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P1137, DOI 10.1007/s11042-019-08229-1
   Xiong W, 2018, OPTIK, V164, P218, DOI 10.1016/j.ijleo.2018.02.072
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Zamani H, 2022, COMPUT METHOD APPL M, V392, DOI 10.1016/j.cma.2022.114616
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao D, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114122
   Zhu DL, 2023, MULTIMED TOOLS APPL, V82, P21825, DOI 10.1007/s11042-022-14024-2
NR 73
TC 34
Z9 34
U1 11
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16929
EP 16975
DI 10.1007/s11042-023-16300-1
EA JUL 2023
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500002
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Bhanuse, RS
   Mal, S
AF Bhanuse, Roshan Sureshrao
   Mal, Sandip
TI Optimal e-learning course recommendation with sentiment analysis using
   hybrid similarity framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE N-gram feature; Improved horse herd optimization; Sentiment
   classification; Hybrid similarity; Weight optimization; Online learning;
   Optimal course recommendation
AB Nowadays, online course recommendation frameworks are popular for suggesting courses to new learners. Various courses are available on the Internet, and it is very challenging to suggest optimal learning courses for learners. This work presented an effective online course recommendation with sentiment analysis using hybrid similarity based approaches. Initially, the input text online course data is pre-processed using tokenization, stop word removal, Stemming, noise filtering, and lemmatization processes. Then, effective features like Lexicon combined TF-IDF feature, Word2vector features, N-gram feature, and Glove feature are extracted from the pre-processed data. Subsequently, the improved horse herd Optimization (IHHO) algorithm is utilized to select features optimally. Afterwards, a hybrid Bidirectional long short term memory-convolutional neural network (Hybrid BLSTM-CNN) is presented to classify courses into positive, negative and neutral for the sentiment analysis of courses. Here, the adaptive salp swarm emperor penguin optimization (ASEP) approach is utilized to update the optimized weights of the hybrid classifiers. Finally, the hybrid content-collaborative similarity (Hybrid-CCS) approach is considered for an optimal course recommendation. The experimental results of the developed approach outperformed the compared existing schemes in terms of accuracy (99.79%), F1-score (99.648%), Kappa (99.061%), RMSE (0.2092), precision (99.69%), recall (99.698%), MAE (0.012), HR (0.9321) and ARHR (0.1621) and AUC (99.79%).
C1 [Bhanuse, Roshan Sureshrao; Mal, Sandip] VIT Bhopal Univ, SCSE, Bhopal, India.
   [Bhanuse, Roshan Sureshrao] Yeshwantrao Chavan Coll Engn, Nagpur, India.
C3 VIT Bhopal University; Yeshwantrao Chavan College of Engineering
RP Bhanuse, RS (corresponding author), VIT Bhopal Univ, SCSE, Bhopal, India.; Bhanuse, RS (corresponding author), Yeshwantrao Chavan Coll Engn, Nagpur, India.
EM roshan.bhanuse2018@vitbhopal.ac.in; sandip.mal@vitbhopal.ac.in
CR Aldowah H, 2020, J COMPUT HIGH EDUC, V32, P429, DOI 10.1007/s12528-019-09241-y
   Ali S, 2022, EGYPT INFORM J, V23, P33, DOI 10.1016/j.eij.2021.05.003
   Ali W., 2020, Higher Education Studies, V10, P16, DOI DOI 10.5539/HES.V10N3P16
   Aljawarneh SA, 2020, J COMPUT HIGH EDUC, V32, DOI 10.1007/s12528-019-09207-0
   Alqurashi E, 2019, DISTANCE EDUC, V40, P133, DOI 10.1080/01587919.2018.1553562
   Ayu M., 2020, The Journal of English Literacy and Education, V7, P47
   Campos R, 2020, REUSE INTELLIGENT SY, P116
   Hussain M, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6347186
   Jena KK, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010157
   Jiang WJ, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P36, DOI 10.1145/3303772.3303814
   Kassymova G., 2020, International Journal of Advanced Science and Technology, V29, P346
   Khalid A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245485
   Khamparia Aditya, 2020, International Journal of Intelligent Information and Database Systems, V13, P139, DOI 10.1504/IJIIDS.2020.109451
   Khanal SS, 2020, EDUC INF TECHNOL, V25, P2635, DOI 10.1007/s10639-019-10063-9
   Koffi DDASL, 2021, INT J COMPUT SCI NET, V21, P148, DOI 10.22937/IJCSNS.2021.21.2.17
   Lemay DJ, 2022, INTERACT LEARN ENVIR, V30, P1782, DOI 10.1080/10494820.2020.1746673
   Lin YG, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107085
   Madani Y, 2020, J AMB INTEL HUM COMP, V11, P3921, DOI 10.1007/s12652-019-01627-1
   Maldonado-Mahauad J, 2018, COMPUT HUM BEHAV, V80, P179, DOI 10.1016/j.chb.2017.11.011
   Muzaffar AW, 2021, IEEE ACCESS, V9, P32689, DOI 10.1109/ACCESS.2021.3060192
   Nafea SM, 2019, IEEE ACCESS, V7, P163034, DOI 10.1109/ACCESS.2019.2935417
   Oladipo ID, 2021, INT C APPL INF CHAM
   Pillutla VS, 2020, TECHNOL KNOWL LEARN, V25, P881, DOI 10.1007/s10758-020-09434-w
   Castro MP, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12104063
   Purwoningsih T, 2019, 2019 4 INT C INF COM, P1, DOI DOI 10.1109/ICIC47613.2019.8985918
   Rezaeimehr F, 2018, FUTURE GENER COMP SY, V78, P419, DOI 10.1016/j.future.2017.04.003
   Saleem F, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9172078
   Shahbazi Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111798
   Shi DQ, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105618
   Wang J., 2021, Comput. Educ. Artif. Intell, V2, DOI [10.1016/j.caeai.2021.100010, DOI 10.1016/J.CAEAI.2021.100010]
   Zhang T, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166420
   Zheng FX, 2022, J MATH-UK, V2022, DOI 10.1155/2022/1313711
NR 32
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16417
EP 16446
DI 10.1007/s11042-023-16138-7
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001029126000013
DA 2024-07-18
ER

PT J
AU Alaufi, R
   Kalkatawi, M
   Abukhodair, F
AF Alaufi, Rawan
   Kalkatawi, Manal
   Abukhodair, Felwa
TI Challenges of deep learning diagnosis for COVID-19 from chest imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CT; X-ray; CNN; CapsNet; COVID-19
ID SARS-COV-2; PNEUMONIA; NETWORK; CT
AB The COVID-19 pandemic has spread worldwide for over 2 years now. The pandemic raises a significant threat to global health due to its transmissibility and high pathogenicity. The current standard detection method for COVID-19, namely, reverse transcription-polymerase chain reaction (RT-PCR), is slow and inaccurate to help fight the pandemic. RT-PCR takes hours to days to report a single test result and has a high false-negative rate. As a result, an infected person with a negative test result may unknowingly continue to spread the virus. Thus, better detection methods are required to improve the control of COVID-19. With technology advancements in artificial intelligence and machine learning, deep-learning diagnostic studies to detect COVID-19 infection using medical chest imaging have emerged. In this paper, we review these studies by analyzing their approaches and highlighting their major challenges. These challenges include dataset cleanness, public dataset availability, capability to differentiate COVID-19 from unrelated viral pneumonia, and the difficulty in dealing with images from multiple points of view. Finally, we discuss various ideas and solutions to address the highlighted challenges in the reviewed papers.
C1 [Alaufi, Rawan; Kalkatawi, Manal; Abukhodair, Felwa] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP Alaufi, R (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
EM rradialaufi@stu.kau.edu.sa; mkalkatawi@kau.edu.sa;
   fabukhodair@kau.edu.sa
RI Kalkatawi, Manal/H-2887-2018
OI Kalkatawi, Manal/0000-0002-9820-4129; alaufi, rawan/0000-0002-7006-6772
CR Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Ahamed KU, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.105014
   Ahmed A, 2021, INT J ADV COMPUT SC, V12, P200
   Ahuja S, 2021, APPL INTELL, V51, P571, DOI 10.1007/s10489-020-01826-w
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   [Anonymous], 2020, COR ONLINE
   [Anonymous], 2016, How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?
   Ayyar MP, 2021, IEEE INT CONF COMP V, P519, DOI 10.1109/ICCVW54120.2021.00064
   Bali R, 2018, Hands-On Transfer Learning with Python: Implement advanced deep learning and neural network models using TensorFlow and Keras
   Brunese L, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105608
   Chen Y-W., 2020, DEEP LEARNING HEALTH
   Chlap P, 2021, J MED IMAG RADIAT ON, V65, P545, DOI 10.1111/1754-9485.13261
   Chowdhury MEH, 2020, COVID 19 RADIOGRAPHY
   Cohen J.P., 2020, arXiv
   Ding Q, 2020, J MED VIROL, V92, P1549, DOI 10.1002/jmv.25781
   Eslambolchi A, 2020, WORLD J RADIOL, V12, P289, DOI 10.4329/wjr.v12.i12.289
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Franquet T, 2011, RADIOLOGY, V260, P18, DOI 10.1148/radiol.11092149
   Fu Hang, 2020, MEDRXIV
   Gunraj H, 2021, ARXIV
   Harris G, 2010, STUDY FINDS
   Heo Lim, 2020, bioRxiv, DOI 10.1101/2020.03.25.008904
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Jimenez-Sanchez A, 2018, CVII STENT LABELS MI
   kaggle, 2020, COVID 19 XRAYS
   Karakanis S, 2021, COMPUT BIOL MED, V130, DOI 10.1016/j.compbiomed.2020.104181
   Kassania SH, 2021, BIOCYBERN BIOMED ENG, V41
   Kim H, 2020, RADIOLOGY, V296, pE145, DOI 10.1148/radiol.2020201343
   Kim YY, 2016, DIAGNOSTIC INTERVENT, V22
   Li DS, 2020, KOREAN J RADIOL, V21, P505
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li YF, 2020, J MED VIROL, V92, P903, DOI 10.1002/jmv.25786
   Lin T., 2016, arXiv
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Ma J., 2020, COVID-19 CT Lung and Infection Segmentation Dataset
   MedSeg H, 2021, MEDSEG COVID DATASET
   Perumal V, 2021, APPL INTELL, V51, P341, DOI 10.1007/s10489-020-01831-z
   Pucci R, 2020, MULTIMED TOOLS APPL, V79, P32243, DOI 10.1007/s11042-020-09455-8
   Quan H, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104399
   Rahimzadeh M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102588
   Ravi V, 2022, MULTIMEDIA SYST, V28, P1401, DOI 10.1007/s00530-021-00826-1
   Rodriguezsalas R, 2021, THESES
   Sabour S, 2017, ARXIV
   Salehi S, 2020, EUR RADIOL, V30, P4930, DOI 10.1007/s00330-020-06863-0
   Shi Heshui, 2020, Lancet Infect Dis, V20, P425, DOI 10.1016/S1473-3099(20)30086-4
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   The World Health Organization, 2020, Use of chest imaging in COVID-19: a rapid advice guide
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang H, 2020, EUR RADIOL, V30, P4910, DOI 10.1007/s00330-020-06880-z
   Wang L., 2020, ACTUALMED COVID 19 C
   Wang L., 2020, FIGURE 1 COVID 19 CH
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang W., 2020, Deep Learning in Healthcare: Paradigms and Applications, P33
   Wang YS, 2020, J MED VIROL, V92, P538, DOI 10.1002/jmv.25721
   Wang Z, 2020, PATTERN RECOGNITION, V110
   Wang Z, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107613
   World Health Organization, 2020, LAB TEST COR VIR DIS
   WorldHealth Organization, 2020, US CHEST IM COVID 19
   Xie SD, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20200243
   Xu XW, 2020, BMJ-BRIT MED J, V368, DOI [10.1136/bmj.m606, 10.1136/bmj.m792]
   Yan T, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110153
   Zhang J, 2020, LANCET RESPIRATORY M, V8
   Zhang JN, 2020, LANCET RESP MED, V8, pE11, DOI 10.1016/S2213-2600(20)30071-0
   Zhang K, 2020, CONSORTIUM CHEST CT
   Zhang K, 2020, CELL, V182, P1360, DOI 10.1016/j.cell.2020.08.029
   Zhang K, 2020, CELL, V181, P1423, DOI 10.1016/j.cell.2020.04.045
NR 69
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14337
EP 14361
DI 10.1007/s11042-023-16017-1
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700007
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, R
   Sharma, NVK
   Chaurasiya, VK
AF Kumar, Ritesh
   Sharma, Nistala Venkata Kameshwer
   Chaurasiya, Vijay K.
TI Adaptive traffic light control using deep reinforcement learning
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Reinforcement Learning; Traffic Control Interface(TraCI);
   Simulation in Urban MObility(SUMO); Dedicated-Short-Range-Communication
   (DSRC)
ID SIGNAL CONTROL
AB Smart city growth needs information and communication technology to increase urban sustainability but faces critical traffic congestion and vehicle classification issues. It is crucial to dynamically change the traffic light on the road network to reduce the delay of vehicles and avoid congestion in the smart city. Modifying the traffic light should be adaptive, considering the number of vehicles on the road and the options available to route the vehicles toward their destination. Our scheme is the first proposed model based on deep learning to solve the problem of traffic congestion in the urban environment. This model classifies the vehicle's type on the road and assigns different vehicle weights. We assign 0.0 for no vehicles, and 1.0, 2.0, 3.0 for light-weight, moderate-weight, and heavy-weight vehicles respectively. The proposed work has trained using experience replay and target network based on a deep double-Q learning mechanism. Our resultant model applies in a real-time traffic network that uses Dedicated-Short-Range-Communication (DSRC) protocol for wireless communication. The simulation of this work uses SUMO (Simulation in Urban MObility) with the data generated on SUMO using a random function. The results show that the traffic light of a certain traffic intersection becomes adaptive, aligning with the goals mentioned above. The proposed model efficiently reduces the average waiting time up to 91.7% at the intersection points of the road which is shown in the graph in the result section.
C1 [Kumar, Ritesh; Sharma, Nistala Venkata Kameshwer; Chaurasiya, Vijay K.] Indian Inst Informat Technol, Allahabad, India.
C3 Indian Institute of Information Technology Allahabad
RP Kumar, R (corresponding author), Indian Inst Informat Technol, Allahabad, India.
EM pwc2016002@iiita.ac.in; vijayk@iiita.ac.in
OI KUMAR, RITESH/0000-0001-7934-2369
CR BELLMAN R, 1957, P NATL ACAD SCI USA, V43, P749, DOI 10.1073/pnas.43.8.749
   Casas N., 2017, ARXIV
   Christopher, 1992, Q LEARN MACH LEARN, V8, P279
   Coskun M, 2018, INT CONF DAT MIN WOR, P564, DOI 10.1109/ICDMW.2018.00088
   Farazi NP, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2010.06187
   Gao J., 2017, arXiv
   Garg D, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P214, DOI 10.1109/ICITE.2018.8492537
   Genders W, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1611.01142
   Gong YB, 2019, TRANSP RES INTERDISC, V1, DOI 10.1016/j.trip.2019.100020
   Hu X, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2009.14627
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Kumar N, 2020, IEEE T INTELLTRANSP
   Li CH, 2020, IEEE INT CON AUTO SC, P652, DOI [10.1109/case48305.2020.9216899, 10.1109/CASE48305.2020.9216899]
   Li L, 2016, IEEE-CAA J AUTOMATIC, V3, P247, DOI 10.1109/JAS.2016.7508798
   Liang X, 2019, THESIS NEW JERSEY I
   Liang X, 2018, ARXIV
   Liang XY, 2019, IEEE T VEH TECHNOL, V68, P1243, DOI 10.1109/TVT.2018.2890726
   Liang XY, 2018, IEEE INTERNET THINGS, V5, P1924, DOI 10.1109/JIOT.2018.2817459
   Ma D., 2021, IEEE Transactions on Intelligent Transportation Systems, P1
   Ma Z, 2021, J ADV TRANSP, V2021
   Maadi S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197501
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mousavi SS, 2017, IET INTELL TRANSP SY, V11, P417, DOI 10.1049/iet-its.2017.0153
   Navarro-Espinoza A, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10010005
   Pang HL, 2019, CHIN CONT DECIS CONF, P5861, DOI [10.1109/ccdc.2019.8832406, 10.1109/CCDC.2019.8832406]
   Prosper HB, 2017, EPJ WEB CONF, V137, DOI 10.1051/epjconf/201713711007
   Raeisi M, 2021, 2021 26 INT COMP C C, P1
   Rasheed F, 2020, FUTURE GENER COMP SY, V109, P431, DOI 10.1016/j.future.2020.03.065
   Sahu Satya Prakash, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P697, DOI 10.1109/ICAIS50930.2021.9395880
   Saleem M, 2022, EGYPT INFORM J, V23, P417, DOI 10.1016/j.eij.2022.03.003
   Schneider C, 2020, INTELLIGENT SIGNALIZ
   Sutton RS, 1998, Introduction to reinforcement learning, V135
   Tan KL, 2019, DYNAMIC SYSTEMS CONT, V59162
   Tong W, 2019, IEEE ACCESS, V7, P10823, DOI 10.1109/ACCESS.2019.2891073
   van der Pol E., 2016, Deep reinforcement learning for coordination in traffic light control
   Wei H, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2496, DOI 10.1145/3219819.3220096
   Wu T, 2020, IEEE T VEH TECHNOL, V69, P8243, DOI 10.1109/TVT.2020.2997896
   Yu BQ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3345, DOI 10.1145/3340531.3417450
   Yuan X, 2021, J PHYS C SOLID STATE, VSer1748
   Zeinaly Z, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15021329
   Zhang RS, 2021, IEEE T INTELL TRANSP, V22, P404, DOI 10.1109/TITS.2019.2958859
NR 41
TC 2
Z9 2
U1 6
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13851
EP 13872
DI 10.1007/s11042-023-16112-3
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022149800002
DA 2024-07-18
ER

PT J
AU Prandi, C
   Valva, A
   Salomoni, P
   Roccetti, M
   Mirri, S
AF Prandi, Catia
   Valva, Antonella
   Salomoni, Paola
   Roccetti, Marco
   Mirri, Silvia
TI Incidental language and culture learning through mobile technologies: a
   multi-case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incidental learning; Mobile application; User-centered design; Mobile
   assisted language learning
ID STRATEGIES; CLASSROOM; LEARNERS; SKILLS
AB Incidental learning is a human learning paradigm that takes its form as a response to unplanned initiatives, potentially occurring at any time and at any place. It is emerging as very promising in the case of learning a second language, as it multiplies the occurrence of unexpected and unintentional learning situations. Still open, and subject of debate, is the issue of which is the right methodology to be applied when mobile computer-based technologies are exploited to provide support to such kind of a learning paradigm. Drawing on the results of an international Project (ILOCALAPP), in this paper we provide our reflections on a specific incidental learning methodology we have adopted, based on the use of a mobile application (the UniOn! App) that was developed at the University of Bologna to support mobility students in their daily activities. Our main goal was to understand if such an approach was effective to let individuals incidentally learn the Italian language and culture driven by our mobile application, while conducting informal and daily activities. Specifically, we aimed to measure how much students have learned Italian, by means of self-evaluation and self-assessment tools and statistical analysis, involving 95 students who incidentally improve their Italian language skills, supported by the app. In particular, we adopted a quasi-experimental design, and we focused our investigation on four different dimensions: target users, users' language background, duration and frequency of use, context of use. The 95 participants were grouped into 5 case studies, based on the four different dimensions. After having used the app, the participants were asked to answer a survey. The obtained results confirm the viability of our approach, showing that incidental learning is enhanced if certain conditions (i.e., integrated guidance) are met, where more than 55% of the participants reported to be more confident about their acquired skills.
C1 [Prandi, Catia; Salomoni, Paola; Mirri, Silvia] Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, Bologna, Italy.
   [Valva, Antonella; Roccetti, Marco] Univ Bologna, Dept Modern Languages Literatures & Cultures, Bologna, Italy.
C3 University of Bologna; University of Bologna
RP Mirri, S (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, Bologna, Italy.
EM silvia.mirri@unibo.it
RI Prandi, Catia/KIB-1268-2024; Mirri, Silvia/I-7983-2016
OI Prandi, Catia/0000-0002-5566-2269; Mirri, Silvia/0000-0002-5385-4734
FU Alma Mater Studiorum -Universita di Bologna; Erasmus+ Programme, Grant
   [20151-IT02-KA20301545120151-IT02-KA203015451]
FX Open access funding provided by Alma Mater Studiorum -Universita di
   Bologna within the CRUI-CARE Agreement. This work was supported by
   Erasmus+ Programme, Grant 2015-1-IT02-KA203-015451.
CR Aghajani M, 2018, INT J INSTR, V11, P433, DOI 10.12973/iji.2018.11330a
   Arslan RS, 2010, COMPUT ASSIST LANG L, V23, P183, DOI 10.1080/09588221.2010.486575
   Awada G, 2016, COGENT EDUC, V3, DOI 10.1080/2331186X.2016.1264173
   Bachore MM, 2015, J ED PRACT, V6
   Banks J.A., 2007, Learning in and out of school in diverse environments: Life-long, lifewide, life-deep
   Banks J.A., 2007, Educating citizens in a multicultural society, V2nd
   Botero GG, 2019, COMPUT ASSIST LANG L, V32, P71, DOI 10.1080/09588221.2018.1485707
   Brown H.D., 2002, Methodology in language teaching: An anthology of current practice, P9
   Burston J, 2014, COMPUT ASSIST LANG L, V27, P344, DOI 10.1080/09588221.2014.914539
   Cahoon BB, 1996, COMPUTER SKILL LEARN
   Castañeda DA, 2016, COMPUT ASSIST LANG L, V29, P1195, DOI 10.1080/09588221.2016.1197950
   Castillo S, 2012, METHODS AND INNOVATIONS FOR MULTIMEDIA DATABASE CONTENT MANAGEMENT, P240, DOI 10.4018/978-1-4666-1791-9.ch014
   CASTILLO SergioLuis., 2012, Encyclopedia of the sciences of learning, P2293, DOI DOI 10.1007/978-1-4419-1428-6_54
   Ceccherelli A, 2016, FUTURE ED C P, P270
   Cenoz J., 2008, IRAL-INT REV APPL LI, V46, P267, DOI 10.1515/IRAL.2008.012
   Cervini, 2018, ESPERIENZE E LEARNIN
   Cervini, 2019, LINGUE MINORITARIE T
   Cervini C, 2016, CALL COMMUNITIES CUL, P81
   Chen BY, 2012, INT REV RES OPEN DIS, V13, P87, DOI 10.19173/irrodl.v13i1.1027
   Choi J., 2010, Social Studies, V101, P174, DOI [10.1080/00377990903284153, DOI 10.1080/00377990903284153]
   Darginaviciene I, 2017, SABIED INTEGR IZGL, P601, DOI 10.17770/sie2017vol3.2354
   Dewey J., 1938, EXPERIENCE ED
   Diaz-Oreiro I., 2019, MULTIDISCIPLINARY DI, V31, P14, DOI DOI 10.3390/PROCEEDINGS2019031014
   DURANTI A, 1992, AM ANTHROPOL, V94, P657, DOI 10.1525/aa.1992.94.3.02a00070
   Gaved M., 2013, QScience Proceedings, 12th World Conference on Mobile and Contextual Learning (mLearn 2013), V13. 10.5339/qproc.2013.mlearn.13
   Gikas J, 2013, INTERNET HIGH EDUC, V19, P18, DOI 10.1016/j.iheduc.2013.06.002
   Habók A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01388
   Hulstijn JH, 2011, INCIDENTAL LEARNING
   Hung HT, 2015, COMPUT ASSIST LANG L, V28, P81, DOI 10.1080/09588221.2014.967701
   ilocalapp, 2015, ILOCALAPP PROJECT
   Jones A., 2006, USING MOBILE DEVICES
   Kacetl J, 2019, EDUC SCI, V9, DOI 10.3390/educsci9030179
   Kerka S., 2000, Trends and Issues Alert No. 18
   Kim Y, 2011, LANG LEARN, V61, P100, DOI 10.1111/j.1467-9922.2011.00644.x
   Kolb AY, 2005, ACAD MANAG LEARN EDU, V4, P193, DOI 10.5465/AMLE.2005.17268566
   Kolb D.A., 2000, EXPERIENTIAL LEARNIN
   Kramsch C., 2009, Interkulturelle Kompetenz Und Fremdsprachliches Lernen: Modelle, Empirie, Evaluation = Intercultural Competence and Foreign Language Learning: Models, Empiricism, Assessment, P107
   Kukulska-Hulme A., 2015, Ubiquitous Learning: An International Journal, V7, P9
   Kukulska-Hulme A, 2012, DESIGNING INCLUSION
   Kukulska-Hulme A., 2017, HDB TECHNOLOGY 2 LAN, P217, DOI DOI 10.1002/9781118914069.CH15
   Kukulska-Hulme A, 2012, INNOV LEAD ENGL LANG, V6, P3, DOI 10.1108/S2041-272X(2012)0000006004
   Landry R, 1997, J LANG SOC PSYCHOL, V16, P23, DOI 10.1177/0261927X970161002
   Laufer B, 2001, APPL LINGUIST, V22, P1, DOI 10.1093/applin/22.1.1
   Lewin K, 1999, The complete social scientist: A Kurt Lewin reader, V17, P333
   Lewin K., 1951, FIELD THEORY SOCIAL, P155, DOI 10.1086/638467
   Li J, 2015, COMPUT ASSIST LANG L, V28, P450, DOI 10.1080/09588221.2014.881387
   Low SM, 2009, SEMIOTICA, V175, P21, DOI 10.1515/semi.2009.041
   Martin F, 2013, COMPUT EDUC, V68, P76, DOI 10.1016/j.compedu.2013.04.021
   Merriam S.B., 2020, LEARNING ADULTHOOD C
   Mirri S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0129-6
   Mirri S, 2017, IEEE SYMP COMP COMMU, P111, DOI 10.1109/ISCC.2017.8024514
   Newton J, 2013, LANG TEACH RES, V17, P164, DOI 10.1177/1362168812460814
   O'Dowd R., 2006, TELECOLLABORATION DE
   Oz E., 2018, Educational Policy Analysis and Strategic Research, V13, P108, DOI DOI 10.29329/EPASR.2018.178.6
   Paulhus D.L., 2007, Handbook of Research Methods in Personality Psychology, P224, DOI DOI 10.1002/0470013435.CH6
   Risager K., 2007, LANGUAGE CULTURE PED, DOI DOI 10.21832/9781853599613
   Robson RL, 2012, J MICROBIOL BIOL EDU, V13, P28, DOI 10.1128/jmbe.v13i1.360
   Rosell-Aguilar F, 2018, COMPUT ASSIST LANG L, V31, P854, DOI 10.1080/09588221.2018.1456465
   Rosell-Aguilar Fernando., 2016, The International Handbook of Mobile-Assisted Language Learning, P545
   Scanlon Eileen, 2014, Proceedings of the 10th International Conference on Mobile Learning 2014, P238
   Scanlon E., 2014, Increasing Access through Mobile Learning. Perspectives on Open and Distance Learning, P85
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Schugurensky D., 2000, The forms of information learning: towards a conceptualization of the field
   Schwartz CE, 1997, PSYCHOSOM MED, V59, P362, DOI 10.1097/00006842-199707000-00005
   Seker M, 2016, LANG TEACH RES, V20, P600, DOI 10.1177/1362168815578550
   Sharples M., 2007, SAGE HDB E LEARNING, P221
   Shih YC, 2015, COMPUT ASSIST LANG L, V28, P407, DOI 10.1080/09588221.2013.851703
   Silva P., 2007, EPISTEMOLOGY INCIDEN
   STIGLER SM, 1992, AM J EDUC, V101, P60, DOI 10.1086/444032
   Straka G.A., 2003, Shaping flexibility in vocational education and training, P149
   Taleb Z, 2012, PROCD SOC BEHV, V69, P1102, DOI 10.1016/j.sbspro.2012.12.038
   Teng LS, 2016, MOD LANG J, V100, DOI 10.1111/modl.12339
   Trinder K., 2008, LEARNING DIGITAL NAT
   UniOn, 2018, MOB APP
   Valva A, 2018, 12 INT MULT SOC CYB
   Valva A, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P294, DOI 10.1145/3284869.3284872
   Vavoula G, 2005, LECT NOTES COMPUT SC, V3746, P534
   Vavoula GK, 2004, THESIS U BIRMINGHAM
   Walinski J, 2017, FOREIGN LANGUAGE ED, V107
   Werquin P., 2010, RECOGNITION NONFORMA
   Wu MH, 2021, COMPUT ASSIST LANG L, V34, P778, DOI 10.1080/09588221.2019.1642211
NR 82
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 46039
EP 46063
DI 10.1007/s11042-023-16095-1
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001024891800003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Xie, CJ
   Song, HZ
   Zhu, H
   Mi, KT
   Li, ZH
   Zhang, Y
   Cheng, JW
   Zhou, HL
   Li, RJ
   Cai, HF
AF Xie, Changjiang
   Song, Huazhu
   Zhu, Hao
   Mi, Kaituo
   Li, Zhouhan
   Zhang, Yi
   Cheng, Jiawen
   Zhou, Honglin
   Li, Renjie
   Cai, Haofeng
TI Music genre classification based on res-gated CNN and attention
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genre classification; CNN; Transformer
AB The amount of digital music available on the internet has grown significantly with the rapid development of digital multimedia technology. Managing these massive music resources is a thorny problem that powerful music media platforms need to face where music genre classification plays an important role, and a good music genre classifier is indispensable for the research and application of music resources in the related aspects, such as efficient organization, retrieval, recommendation, etc. Due to convolutional networks' powerful feature extraction capability, more and more researchers are devoting their efforts to music genre classification models based on convolutional neural networks (CNNs). However, many models do not combine the musical signal features for effective design of the convolutional structure, which cause a simpler convolutional network part of the model and weaker local feature extraction ability. To solve the above problem, our group proposes a model using a 1D res-gated CNN to extract local information of audio sequences rather than the traditional CNN architecture. Meanwhile, to aggregate the global information of audio feature sequences, our group applies the Transformer to the music genre classification model and modifies the decoder structure of the Transformer according to the task. The experiments utilize the benchmark datasets, including GTZAN and Extended Ballroom. Our group conducted contrastive experiments to verify our model, and experimental results demonstrated that our model outperforms most of the previous approaches and can improve the performance of music genre classification.
C1 [Xie, Changjiang; Song, Huazhu; Zhu, Hao; Li, Zhouhan; Zhang, Yi; Cheng, Jiawen; Zhou, Honglin; Li, Renjie; Cai, Haofeng] Wuhan Univ Technol, Wuhan, Peoples R China.
   [Song, Huazhu; Mi, Kaituo] Anngeen Technol Co Ltd, Wuhan, Peoples R China.
C3 Wuhan University of Technology
RP Song, HZ (corresponding author), Wuhan Univ Technol, Wuhan, Peoples R China.; Song, HZ (corresponding author), Anngeen Technol Co Ltd, Wuhan, Peoples R China.
EM 715480238@qq.com; 756862517@qq.com; 1276004625@qq.com;
   kaituo.mi@analyses.cn; 765975094@qq.com; 1581554849@qq.com;
   1264825375@qq.com; 3485997412@qq.com; 1143936357@qq.com;
   862378176@qq.com
RI zhang, jiayue/JUF-0129-2023; li, song/JVO-5938-2024; Zhang,
   Zhipeng/KHY-2239-2024; Wang, Zejun/KBB-8454-2024; Zhang,
   Wenkai/JWO-2030-2024; zhao, weiwei/JUU-6585-2023; yu,
   xiao/KFT-1725-2024; Sun, Jia/JXM-0311-2024; Wang, Zhiquan/HHS-6768-2022;
   Liu, Shaobo/JUU-5767-2023; zhao, wei/JZD-4475-2024; PENG,
   CHENG/KCL-2506-2024; CHEN, WENJIE/JQW-1608-2023; Zhang,
   Xiaofeng/JMC-6060-2023; zhou, yuwei/KHD-4127-2024; Wang,
   Jiacheng/ABE-5948-2020
OI Zhang, Xiaofeng/0000-0003-2738-3286; Wang, Jiacheng/0000-0003-4327-1508;
   Song, Huazhu/0000-0003-3174-6203
CR Abdoli S, 2019, EXPERT SYST APPL, V136, P252, DOI 10.1016/j.eswa.2019.06.040
   Andén J, 2014, IEEE T SIGNAL PROCES, V62, P4114, DOI 10.1109/TSP.2014.2326991
   [Anonymous], 2014, ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing-Proceedings
   [Anonymous], 2015, NAACL HLT 2015
   Ba J., 2015, P ICLR, P1, DOI DOI 10.1016/J.JCYT.2014.02.008
   Cano P., 2006, ISMIR 2004 Audio Description Contest
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen X, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5904, DOI 10.1109/ICASSP39728.2021.9413535
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Ciresan DC, 2012, IEEE IJCNN
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dai JY, 2016, IEEE ICC, P808, DOI 10.1109/ICC.2016.7510791
   Dai YM, 2021, IEEE T GEOSCI REMOTE, V59, P9813, DOI 10.1109/TGRS.2020.3044958
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Freitag M, 2018, J MACH LEARN RES, V18
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermann Karl Moritz, 2015, Advances in Neural Information Processing Systems, P1693
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Kereliuk C, 2015, IEEE WORK APPL SIG
   Kim T, 2019, IEEE J-STSP, V13, P285, DOI 10.1109/JSTSP.2019.2909479
   Koerich KM, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207309
   Kumar DP, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING, VLSI, ELECTRICAL CIRCUITS AND ROBOTICS (DISCOVER), P190, DOI 10.1109/DISCOVER.2016.7806258
   Li TLH, 2010, LECT NOTES ENG COMP, P546
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Malhotra P., 2015, ESANN, V89, P89
   Marchand U., 2016, EXTENDED BALLROOM DA
   Meng F, 2015, ARXIV
   Mnih V, 2014, ADV NEUR IN, V27
   Nanni L, 2017, PATTERN RECOGN LETT, V88, P49, DOI 10.1016/j.patrec.2017.01.013
   Ngai H, 2021, ARXIV
   Pons J, 2017, EUR SIGNAL PR CONF, P2744, DOI 10.23919/EUSIPCO.2017.8081710
   Rush Alexander M., 2015, P 2015 C EMPIRICAL M, P379, DOI [10.48550/arXiv.1509.00685, DOI 10.18653/V1/D15-1044]
   Shi YY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6783, DOI 10.1109/ICASSP39728.2021.9414560
   Silla CN, 2007, IEEE SYS MAN CYBERN, P3336
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F., 2016, ARXIV
   Wang Z, 2021, INT J HUM RESOUR MAN, V32, P2264, DOI [10.1080/09585192.2019.1579254, 10.1109/CVPRW.2019.00007]
   Xu C, 2003, 2003 IEEE INT C AC S, V5, pV, DOI DOI 10.1109/ICASSP.2003.1199998
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu WJ, 2021, T ASSOC COMPUT LING, V9, P311
   Yang CHH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6523, DOI 10.1109/ICASSP39728.2021.9413453
   Yang HS, 2019, INTERSPEECH, P3382, DOI 10.21437/Interspeech.2019-1298
   Yang R, 2020, IEEE ACCESS, V8, P19629, DOI 10.1109/ACCESS.2020.2968170
   Zhang PJ, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P379, DOI 10.1145/2671188.2749367
   Zhang T, 2022, IEEE T CYBERNETICS, V52, P6232, DOI 10.1109/TCYB.2021.3050508
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
NR 53
TC 1
Z9 1
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13527
EP 13542
DI 10.1007/s11042-023-15277-1
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001024891800002
DA 2024-07-18
ER

PT J
AU Misra, P
   Panigrahi, N
   Patro, SGK
   Salau, AO
   Aravinth, SS
AF Misra, Priyavrat
   Panigrahi, Niranjan
   Patro, S. Gopal Krishna
   Salau, Ayodeji Olalekan
   Aravinth, Sinnappampatty S.
TI PETLFC: Parallel ensemble transfer learning based framework for COVID-19
   differentiation and prediction using deep convolutional neural network
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Convolutional neural network; Chest X-rays; Transfer learning;
   Data parallel model; All-to-one reduction; Inter-process communication
ID CHEST-X-RAY
AB Despite a worldwide research involvement in the global COVID-19 pandemic, the research community is still struggling to develop reliable and faster prediction mechanisms for this infectious disease which is distinct from other respiratory diseases. The commonly used clinical RT-PCR test is not widely available in areas with limited testing facilities, and it performs and responds slowly. Using digital chest X-Ray images and CT scan images, recently a number of works are proposed using deep transfer learning and ensemble of these deep models as base classifiers. Though ensemble approaches exhibit better accuracy, they are computational intensive and have slower prediction time. Therefore, to handle computational-intensiveness and to accelerate prediction time without compromising accuracy, a Parallel Ensemble Transfer Learning based Framework for COVID (PETLFC) is proposed for the underlying multi-class classification problem. Three pre-trained convolutional neural network models (VGG16, ResNet18, and DenseNet121) were fine tuned to act as base models for the proposed parallelized bagging-based ensemble to predict COVID-19. The data parallel model is implemented on PARAM SHAVAK HPC system using MPI programming and a dataset of 21,165 chest X-Ray images (10,192 normal, 1345 pneumonia, 3616 COVID-19, and 6012 lung opacity). The results are compared with some state-of-the-art sequential ensemble approaches where the proposed PETLFC was observed to exhibit superior performance.
C1 [Misra, Priyavrat; Panigrahi, Niranjan] Parala Maharaja Engn Coll, Berhampur 761003, Odisha, India.
   [Patro, S. Gopal Krishna] GLA Univ, Inst Engn & Technol, Dept Comp Engn & Applicat, Mathura, India.
   [Aravinth, Sinnappampatty S.] KoneruLakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andhra Pradesh, India.
   [Salau, Ayodeji Olalekan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Olalekan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
C3 GLA University; Koneru Lakshmaiah Education Foundation (K L Deemed to be
   University); Saveetha Institute of Medical & Technical Science; Saveetha
   School of Engineering
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
EM cse.pm@protonmail.com; niranjan.cse@pmec.ac.in; sgkpatro2008@gmail.com;
   ayodejisalau98@gmail.com; aravinthkrithick@gmail.com
RI Patro, Dr. S Gopal Krishna/CAF-9606-2022; salau, ayodeji
   Olalekan/C-1016-2018; Seshadri, Dr. S.Aravinth/AAP-3448-2021
OI Patro, Dr. S Gopal Krishna/0000-0003-3130-339X; salau, ayodeji
   Olalekan/0000-0002-6264-9783; Seshadri, Dr.
   S.Aravinth/0000-0002-0175-7115
CR Aleem S, 2023, ARXIV
   Alghamdi HS, 2021, IEEE ACCESS, V9, P20235, DOI 10.1109/ACCESS.2021.3054484
   Ayalew AM, 2023, MULTIMED TOOLS APPL, V82, P44507, DOI 10.1007/s11042-023-15389-8
   Ayalew AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103530
   Azemin MZC, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8828855
   Baik SM, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05321-0
   Biswas S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157004
   Bressem KK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70479-z
   Chakraborty D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31737-y
   Chan SH, 2014, IEEE T IMAGE PROCESS, V23, P3711, DOI 10.1109/TIP.2014.2327813
   Deriba F.G., 2023, J of Pharm Negative Results, V14, P1250
   Diederik P. K., 2014, ARXIV
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432
   Frimpong S.A., 2022, Math Model Eng Probl 9, V9, P1557, DOI [10.18280/mmep.090615, DOI 10.18280/MMEP.090615]
   Grama A, 2012, INTRO PARALLEL COMPU, P856
   Guo K, 2022, IEEE T MULTIMEDIA, DOI [10.1109/TMM.3168146, DOI 10.1109/TMM.3168146]
   Guo Kehua, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3185395
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Indumathi N, 2022, PREDICTION COVID 19, DOI [10.1007/978-981-16-6542-4_10, DOI 10.1007/978-981-16-6542-4_10]
   Jain R, 2021, APPL INTELL, V51, P1690, DOI 10.1007/s10489-020-01902-1
   kaggle, 2020, KAGGLE ONLINE DATA R
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Li X, 2020, IEEE INT C BIOINFORM, P1063, DOI 10.1109/BIBM49941.2020.9313217
   Meng LW, 2020, IEEE J BIOMED HEALTH, V24, P3576, DOI 10.1109/JBHI.2020.3034296
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rajaraman S, 2020, IEEE ACCESS, V8, P115041, DOI [10.1109/ACCESS.2020.3003810, 10.1109/access.2020.3003810]
   Roy PK, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108018
   Salau AO, 2021, 2021 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATION (DASA), DOI 10.1109/DASA53625.2021.9682267
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh PD, 2021, INFORM SYST FRONT, V23, P1385, DOI 10.1007/s10796-021-10132-w
   Win KY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210528
   World Health Organization, 2020, MUN SEC C
   Wubineh B.Z., 2023, J of Pharm Negative Results, V14, P1242
   Zazzaro G, 2021, J CLIN MED, V10, DOI 10.3390/jcm10245982
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
NR 38
TC 2
Z9 2
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14211
EP 14233
DI 10.1007/s11042-023-16084-4
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023700800002
DA 2024-07-18
ER

PT J
AU Yang, CY
   Lin, YN
   Wang, SK
   Shen, VRL
   Tung, YC
   Lin, JF
AF Yang, Cheng-Ying
   Lin, Yi-Nan
   Wang, Sheng-Kuan
   Shen, Victor R. L.
   Tung, Yi-Chih
   Lin, Jia-Fu
TI An Edge Computing System for Fast Image Recognition Based on
   Convolutional Neural Network and Petri Net Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Edge computing system; Object detection; Petri net; YOLO
AB As a computer system can precisely detect some target objects, many application scenarios will be developed. In this study, the customized object recognition model was trained by using a software tool, You Only Look Once (YOLO), and burned into one hardware component, Maix Bit, for an image edge computing system, so as to fast recognize humans or objects in the images. In the beginning of system development, a Petri net (PN) model was established to detect all possible abnormal processes and to verify the feasibility and completeness of an edge computing system by using Petri net software tool, Workflow Petri net Designer (WoPeD). Compared with many other development boards, Maix Bit is smaller, more flexible, more economical, and more adaptable to those needs of the edge side scenarios. When equipped with an Artificial Intelligence (AI) chip, Kendryte K210, it is suitable for object recognition due to its superior power consumption, film frames, and processors. YOLO, mainly characterized by its fast speed in using the convolutional neural network (CNN) to recognize objects, can be used to predict the positions and types of multiple objects concurrently. Also, CNN can be used to detect and recognize targets from end to end promptly, when configured to train an image recognition model. Finally, the experimental results have shown that the promising mean Average Precision (mAP), 78.6%, was obtained, which outperforms other existing systems.
C1 [Yang, Cheng-Ying] Univ Taipei, Dept Comp Sci, 1 Ai Kao W Rd, Taipei 100, Taiwan.
   [Lin, Yi-Nan; Tung, Yi-Chih; Lin, Jia-Fu] Ming Chi Univ Technol, Dept Elect Engn, 84 Gongzhuan Rd, New Taipei City 243, Taiwan.
   [Wang, Sheng-Kuan] Ming Chi Univ Technol, Dept Elect Engn, 84 Gongzhuan Rd, New Taipei City 243, Taiwan.
   [Shen, Victor R. L.] Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei City 237, Taiwan.
   [Shen, Victor R. L.] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 University of Taipei; Ming Chi University of Technology; Ming Chi
   University of Technology; National Taipei University; Chaoyang
   University of Technology
RP Shen, VRL (corresponding author), Natl Taipei Univ, Dept Comp Sci & Informat Engn, 151 Univ Rd, New Taipei City 237, Taiwan.; Shen, VRL (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM cyang@utaipei.edu.tw; jnlin@mail.mcut.edu.tw; skwang@mail.mcut.edu.tw;
   rlshen@mail.ntpu.edu.tw; iggy@mail.mcut.edu.tw;
   M07158004@mail2.mcut.edu.tw
OI Shen, Victor R. L./0000-0001-8194-3446
FU Ministry of Science and Technology, Taiwan [MOST 107-2221-E-845-001-MY3,
   MOST 110-2221-E-845-002-]
FX AcknowledgmentsThe authors are grateful to the anonymous reviewers for
   their constructive comments which have improved the quality of this
   paper. During the second revision period, Mr. Frank H.C. Shen is highly
   appreciated for his great efforts in editing. Also, this work was
   supported by the Ministry of Science and Technology, Taiwan, under
   grants MOST 107-2221-E-845-001-MY3 and MOST 110-2221-E-845-002-.
CR Abed R, 2021, MULTIMED TOOLS APPL, V80, P23157, DOI 10.1007/s11042-020-09385-5
   AlphaGo, 2020, US
   [Anonymous], 2020, SIPEED MAIX BIT
   [Anonymous], 2020, DFROBOT M1 M1W AI IO
   [Anonymous], 2020, WEBDUINO SMART INTRO
   [Anonymous], 2020, ARCHITECTURE INTERNE
   [Anonymous], 2020, UNDERSTANDING WEBDUI
   [Anonymous], 2020, COMPUTER VISION OBJE
   [Anonymous], 2020, MAIX BIT K210 PINOUT
   [Anonymous], 2020, Workflow Petri Net Designer
   Chung YH, 2020, THESIS NAT YUNLIN U
   Fang J, 2021, COMPUT ELECTR ENG, V96, DOI 10.1016/j.compeleceng.2021.107539
   FDDB, 2020, US
   github, 2020, GITHUB TZUTALIN LABE
   github, 2020, GITHUB THTRIEU DARKF
   github, 2020, About us
   github, 2020, GITHUB TFREYTAG WOPE
   github, 2020, GITHUB KENDRYTE KFLA
   github, 2020, GITHUB SIPEED MAIX T
   GitHub AlexeyAB/darknet, 2020, US
   Hor N., 2019, INT J COMPUTER SCI E, V8, P246
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   maixpy.sipeed, 2020, INTRO MAIXPY DOC
   Mean Average Precision (mAP), IND EV QUAL OBJ DET
   Petri net, 2020, WIKIPEDIA
   Singh RD, 2019, MULTIMED TOOLS APPL, V78, P15951, DOI 10.1007/s11042-018-6912-6
   Singh VK, 2022, MULTIMED TOOLS APPL, V81, P3, DOI 10.1007/s11042-021-11158-7
   trendforce, 2021, DISTRIBUTION FOUNDRY
   twblogs, CONVERT WEIGHTS FILE
   WoPeD (Workflow Petri net Designer), 2020, US
   wordpress, 2020, BUILD YOUR OWN YOLO
   Yin HG, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106983
   YOLO, 2020, REAL TIME OBJECT DET
NR 33
TC 0
Z9 0
U1 7
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12849
EP 12873
DI 10.1007/s11042-023-15388-9
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001020157200007
DA 2024-07-18
ER

PT J
AU Saravanarajan, VS
   Chen, RC
   Dewi, C
   Chen, LS
   Ganesan, L
AF Saravanarajan, Vani Suthamathi
   Chen, Rung-Ching
   Dewi, Christine
   Chen, Long-Sheng
   Ganesan, Lata
TI Car crash detection using ensemble deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Car crash recognition; Object detection; Deep learning; Convolutional
   neural networks; VGG16; MobileNetV2; InceptionResNetV2; Resnet50
ID CLASSIFICATION
AB With the recent advancements in Autonomous Vehicles (AVs), two important factors that play a vital role to avoid accidents and collisions are obstacles and track detection. AVs must implement an accident detection model to detect accident vehicles and avoid running into rollover vehicles. At present many trajectories-based and sensor-based multiple-vehicle accident prediction models exist. In Taiwan, the AV Tesla sedan's failure to detect overturned vehicles shows that an efficient deep learning model is still required to detect a single-car crash by taking appropriate actions like slowing down, tracking changes, and informing the concerned authorities. This paper proposes a novel car crash detection system for various car crashes using three deep learning models, namely VGG16(feature extractor using transfer learning), RPN (region proposal network), and CNN8L (region-based detector). The CNN8L is a novel lightweight sequential convolutional neural network for region-based classification and detection. The model is trained using a customized dataset, evaluated using different metrics and compared with various state-of-the-art models. The experimental results show that the VGG16 combined with the CNN8L model performed much better when compared to other models. The proposed system accurately recognizes car accidents with an Accident Detection Rate (ADR) of 86.25% and False Alarm Rate (FAR) of 33.00%.
C1 [Saravanarajan, Vani Suthamathi; Chen, Rung-Ching; Dewi, Christine; Chen, Long-Sheng] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Dewi, Christine] Satya Wacana Christian Univ, Fac Informat Technol, Kota Salatiga, Central Java, Indonesia.
   [Ganesan, Lata] 441 Vanderveer Rd, Raritan, NJ 08869 USA.
C3 Chaoyang University of Technology; Universitas Kristen Satya Wacana
RP Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM s10814909@gm.cyut.edu.tw; crching@cyut.edu.tw;
   christine.dewi13@gmail.com; lschen@cyut.edu.tw; lataganesan@gmail.com
RI Dewi, Christine/AAL-9605-2021
OI Dewi, Christine/0000-0002-1284-234X
FU Ministry of Science and Technology, Taiwan [MOST 111-2221-E-324 -020]
FX AcknowledgementsThis paper is supported by the Ministry of Science and
   Technology, Taiwan. The Nos is MOST 111-2221-E-324 -020, Taiwan.
CR Abdulhafedh A., 2017, J TRANSPORTATION TEC, V7, P190, DOI [10.4236/jtts.2017.72014, DOI 10.4236/JTTS.2017.72014]
   Adewopo V, 2022, Arxiv, DOI [arXiv:2208.09588, 10.48550/arXiv.2208.09588, DOI 10.48550/ARXIV.2208.09588]
   [Anonymous], 2018, Critical Reasons for Crashes Investigated in the National Motor Vehicle Crash Causation Survey
   Bakheet S, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e11397
   Bera A, 2016, IEEE INT CONF ROBOT, P5528, DOI 10.1109/ICRA.2016.7487768
   Chan FH, 2017, LECT NOTES COMPUT SC, V10114, P136, DOI 10.1007/978-3-319-54190-7_9
   Chand D, 2020, 2020 IEEE 17 INDIA C, DOI [10.1109/INDICON49873.2020.9342226, DOI 10.1109/INDICON49873.2020.9342226]
   Chang WJ, 2019, IEEE ACCESS, V7, P148163, DOI 10.1109/ACCESS.2019.2946468
   Chen RC, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147191
   Chen RC, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00327-4
   Chen W, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103177
   Choi JG, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115400
   Dewi C, 2022, MULTIMED TOOLS APPL, V81, P37821, DOI 10.1007/s11042-022-12962-5
   Dewi C, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.943
   Dewi C, 2022, CYBERN INF TECHNOL, V22, P104, DOI 10.2478/cait-2022-0007
   Ekundayo Oluwatobi, 2022, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys). Lecture Notes in Networks and Systems (296), P405, DOI 10.1007/978-3-030-82199-9_26
   Ferguson M., 2017, Automatic Localization of Casting Defects with Convolutional Neural Networks, P1726
   Ferguson M, 2018, SMART SUSTAIN MANUF, V2, P137, DOI 10.1520/SSMS20180033
   Gavai NR, 2018, 2017 INT C BIG DAT I, DOI [10.1109/BID.2017.8336590, DOI 10.1109/BID.2017.8336590]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Ijjina EP, 2019, INT CONF COMPUT
   iStock, ISTOCK PHOT
   Jiang KY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031166
   Khairi MHH, 2021, IEEE ACCESS, V9, P76024, DOI 10.1109/ACCESS.2021.3081629
   Komol MMR, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255828
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu ZB, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/8848874
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Nienaber M. J., 2015, P 34 SO AFR TRANSP C, P153
   Nienaber S, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P419, DOI 10.1109/SSCI.2015.69
   Pashaei A, 2020, J REAL-TIME IMAGE PR, V17, P1051, DOI 10.1007/s11554-019-00852-3
   Pathik N, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14137701
   Pillai MS, 2021, SOFT COMPUT, V25, P11929, DOI 10.1007/s00500-021-05576-w
   Pour HH, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103634
   Rabano SL, 2018, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM.2018.8666300
   Rahim MA, 2021, ACCIDENT ANAL PREV, V154, DOI 10.1016/j.aap.2021.106090
   Sahrawat D, 2019, IMPROVING ROAD SAFET
   Saravanarajan VS, 2020, THE 7 MULTIDISCIPLIN, P1
   Saravanarajan VS, 2022, GEOMETRIC FEATURE LE
   Saravanarajan VS., 2020, INT J APPL SCI ENG, V18, P1
   Saravanarajan VS, 2021, IN2021 4 INT C ELECT, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, ARXIV PREPRINT ARXIV, P1, DOI [10.1109/ICCV.2011.6126456, DOI 10.1109/ICCV.2011.6126456]
   Tai SK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196997
   Thinh NH, 2020, VNU J SCI COMPUT SCI, V36, DOI [10.25073/2588-1086/vnucsce.217, DOI 10.25073/2588-1086/VNUCSCE.217]
   Tian DX, 2019, IEEE ACCESS, V7, P127453, DOI 10.1109/ACCESS.2019.2939532
   Unsplash, CAR CRASH
   Wu JJ, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108214
   Yang EH, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23070881
   Zhou ZL, 2022, IEEE T INTELL TRANSP, V23, P19772, DOI 10.1109/TITS.2022.3147826
NR 52
TC 5
Z9 5
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 30
PY 2023
DI 10.1007/s11042-023-15906-9
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L3CX6
UT WOS:001022083300005
DA 2024-07-18
ER

PT J
AU Barman, D
   Sarkar, R
   Chowdhury, N
AF Barman, Debaditya
   Sarkar, Ritam
   Chowdhury, Nirmalya
TI A cooperative co-evolutionary genetic algorithm for query recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query Recommendation; Genetic Algorithm; Multi-objective optimisation;
   Cooperative co-evolutionary genetic algorithm
ID OPTIMIZATION; LOGS; SYSTEM
AB Search engines often recommend a few queries related to the users' original query to help them find the content they are searching. Since extracting the user's intent from the query is a very challenging task due to its short length and ambiguity, it is tough to build a good Query Recommendation system. In this work, we have proposed a Query Recommendation system using a Multi-objective Cooperative Co-evolutionary Genetic Algorithm (QRMOCCGA) to address the problem. First, we have decomposed the entire problem into two sub-problems. These sub-problems optimise two objective functions, created using users' search behaviours and various string-based similarity methods. QRMOCCGA uses separate sub-populations to solve the sub-problems simultaneously. It finds complete Pareto-optimal solutions by assembling the relevant members from the two sub-populations which have been collaboratively co-evolved. QRMOCCGA also maintains diversity in the population. We perform extensive experiments to benchmark our proposed algorithm against several popular algorithms on a large-scale search log extracted from a commercial search engine.
C1 [Barman, Debaditya] Visva Bharati, Dept Comp & Syst Sci, Santini Ketan 731235, West Bengal, India.
   [Sarkar, Ritam] Indian Inst Technol Patna, Dept Comp Sci & Engn, Bihta 801106, Bihar, India.
   [Chowdhury, Nirmalya] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, West Bengal, India.
C3 Visva Bharati University; Indian Institute of Technology (IIT) - Patna;
   Jadavpur University
RP Chowdhury, N (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, West Bengal, India.
EM debadityabarman@gmail.com; ritamsrkr.cse@gmail.com; nirmalya63@gmail.com
OI Sarkar, Ritam/0000-0002-7826-1812
CR Ahmedi L, 2017, WEBIST: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, P370, DOI 10.5220/0006363803700375
   Anagnostopoulos Aris., 2010, Proceedings of the Third International Conference on Web Search and Web Data Mining, WSDM 2010, New York, NY, USA, February 4-6, 2010, P161
   Anagnostopoulos I, 2015, NEUROCOMPUTING, V163, P137, DOI 10.1016/j.neucom.2014.12.090
   Baeza-Yates R, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P76
   BaezaYates R, 2004, LECT NOTES COMPUT SC, V3268, P588
   Barman D, 2020, J INTERDISCIP MATH, V23, P523, DOI 10.1080/09720502.2020.1731964
   Binshtok M., 2007, PROC NATL CONF ARTIF, V22, P1231
   Bonchi F, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P345, DOI 10.1145/2348283.2348332
   Cai XJ, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113648
   Câmara A, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P511, DOI 10.1145/3298689.3346994
   Chai ZY, 2019, IEEE ACCESS, V7, P6060, DOI 10.1109/ACCESS.2018.2842257
   Cheng H, 2007, IEEE DATA MINING, P457, DOI 10.1109/ICDM.2007.8
   Cheng R, 2016, IEEE T EVOLUT COMPUT, V20, P773, DOI 10.1109/TEVC.2016.2519378
   Cohoon J. P., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P148
   Colson B, 2005, OPTIM METHOD SOFTW, V20, P493, DOI 10.1080/10556780500140227
   Cui LZ, 2017, J PARALLEL DISTR COM, V103, P53, DOI 10.1016/j.jpdc.2016.10.014
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Deepak G, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER APPLICATIONS (ICACA), P44, DOI 10.1109/ICACA.2016.7887921
   Duan JY, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR 2018), P86, DOI 10.1145/3268866.3268873
   El Ghali B, 2017, KNOWL INF SYST, V50, P751, DOI 10.1007/s10115-016-0952-x
   El-Hady GF, 2011, INT J INF RETR RES, V1, P45, DOI 10.4018/ijirr.2011010104
   Fernández-Tobías I, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P35, DOI 10.1145/2983323.2983823
   Fonseca BM, 2003, FIRST LATIN AMERICAN WEB CONGRESS, PROCEEDINGS, P66, DOI 10.1109/LAWEB.2003.1250284
   Geng BR, 2019, INFORM SCIENCES, V475, P161, DOI 10.1016/j.ins.2018.09.068
   Guo JF, 2017, INFORM RETRIEVAL J, V20, P4, DOI 10.1007/s10791-016-9287-1
   Hanauer DA, 2017, J BIOMED INFORM, V67, P1, DOI 10.1016/j.jbi.2017.01.013
   He Q, 2009, PROC INT CONF DATA, P1443, DOI 10.1109/ICDE.2009.71
   Huang ZP, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3233186
   Jansen B. J., 1998, SIGIR Forum, V32, P5, DOI 10.1145/281250.281253
   Jeh G., 2002, P 8 ACM SIGKDD INT C, P538, DOI DOI 10.1145/775047.775126
   Karabadji NE, 2018, EXPERT SYST APPL, V98, P153, DOI 10.1016/j.eswa.2018.01.015
   Li HY, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P107
   Li MQ, 2014, IEEE T EVOLUT COMPUT, V18, P348, DOI 10.1109/TEVC.2013.2262178
   Li RR, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2978, DOI 10.1145/3308558.3313412
   Liu YQ, 2011, EXPERT SYST APPL, V38, P13847, DOI 10.1016/j.eswa.2011.04.188
   Ma C, 2018, IEEE T KNOWL DATA EN, V30, P2024, DOI 10.1109/TKDE.2018.2815544
   Ma H, 2012, IEEE T KNOWL DATA EN, V24, P1051, DOI 10.1109/TKDE.2011.18
   Ma XL, 2019, IEEE T EVOLUT COMPUT, V23, P421, DOI 10.1109/TEVC.2018.2868770
   Meunier H, 2000, IEEE C EVOL COMPUTAT, P317, DOI 10.1109/CEC.2000.870312
   Ombuki B, 2006, APPL INTELL, V24, P17, DOI 10.1007/s10489-006-6926-z
   Padhye N, 2011, RAPID PROTOTYPING J, V17, P458, DOI 10.1108/13552541111184198
   Paredis Jan, 1996, Artificial Life, V2, P355, DOI 10.1162/artl.1995.2.4.355
   Pass Greg, 2006, INFOSCALE 06
   Pizzuti C, 2012, IEEE T EVOLUT COMPUT, V16, P418, DOI 10.1109/TEVC.2011.2161090
   Ponnambalam SG, 2001, PROD PLAN CONTROL, V12, P764, DOI 10.1080/09537280110040424
   Potter MA, 1994, LECT NOTES COMPUT SC, V866, P249
   Qian C, 2015, ADV NEURAL INFORM PR, P1765
   Qiao DD, 2017, INFORM MANAGE-AMSTER, V54, P531, DOI 10.1016/j.im.2016.11.003
   Sanchez-Gomez JM, 2019, KNOWL-BASED SYST, V174, P123, DOI 10.1016/j.knosys.2019.03.002
   Senthilkumar NC, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1350-1
   Shi XD, 2007, J AM SOC INF SCI TEC, V58, P1871, DOI 10.1002/asi.20632
   Shinde PP, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Silverstein C., 1999, SIGIR Forum, V33, P6, DOI 10.1145/331403.331405
   Song W, 2014, EXPERT SYST APPL, V41, P366, DOI 10.1016/j.eswa.2013.07.052
   Swamy MK, 2017, LECT NOTES COMPUT SC, V10439, P340, DOI 10.1007/978-3-319-64471-4_27
   Tekli J, 2019, KNOWL-BASED SYST, V164, P378, DOI 10.1016/j.knosys.2018.11.010
   Tekli J, 2018, DATA KNOWL ENG, V117, P133, DOI 10.1016/j.datak.2018.07.007
   Vahabi Hossein., 2013, P 7 ACM C RECOMMENDE, P33
   Wang JG, 2015, NEUROCOMPUTING, V167, P195, DOI 10.1016/j.neucom.2015.04.076
   Wang SF, 2016, KNOWL-BASED SYST, V104, P145, DOI 10.1016/j.knosys.2016.04.018
   WELCH WJ, 1982, J STAT COMPUT SIM, V15, P17, DOI 10.1080/00949658208810560
   Wen J.-R., 2001, Proceedings of the 10th International Conference on World Wide Web, WWW '01, P162, DOI DOI 10.1145/371920.371974
   Whitley D., 1990, Journal of Experimental and Theoretical Artificial Intelligence, V2, P189, DOI 10.1080/09528139008953723
   Wood A, 2016, P 18 INT C INF INT W, P298, DOI DOI 10.1145/3011141.3011220
   Yang SX, 2013, IEEE T EVOLUT COMPUT, V17, P721, DOI 10.1109/TEVC.2012.2227145
   Yang ZY, 2008, INFORM SCIENCES, V178, P2985, DOI 10.1016/j.ins.2008.02.017
   Zaiane O. R., 2002, Advances in Object-Oriented Information Systems. OOIS 2002 Workshops. Proceedings (Lecture Notes in Computer Science Vol.2426), P207
   Zhang Zhiyong., 2006, P 15 INT C WORLD WID, P1039
   Zhao Z, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4084
   Zitzler E., 2001, TIK-Report, V103, P1
   Zuo Y, 2015, IEEE COMPUT INTELL M, V10, P52, DOI 10.1109/MCI.2014.2369894
NR 72
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11461
EP 11491
DI 10.1007/s11042-023-15585-6
EA JUN 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100003
DA 2024-07-18
ER

PT J
AU Wei, Z
   Wang, TT
AF Wei, Zhao
   Wang, Tingting
TI Joint attention mechanism with dynamic kernel for yolov5 mobile wireless
   charging coil surface defect identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Carafe; Condconv; Defect detection; Feature fusion; Triplet; Transformer
AB The yolov5-CTD (you only look once version five-carafe triplet double attention vision transformer) coil defect detection algorithm is proposed to address the problems associated with the manufacturing process of wireless charging coils, which are the core component of wireless chargers and can produce multiple types of defects. To address the problem of small area defects, a large amount of detail semantic information is lost in the process of down-sampling in the backbone network. DA-ViT (Double Attention Vision transformer) is incorporated into the enhanced feature extraction network to supplement the detail semantic information and enhance the ability of the network to build up the extraction of long-distance information. The Triplet attention mechanism module is introduced to be embedded in the lateral hop connection of the multiscale feature extraction network to enhance the neck network's ability for local information extraction by rotating the dimension for multidimensional feature capture and improve the effect of multiscale feature fusion. For the large number of extreme aspect ratio defects in the coil, Carafe up sampling is used to aggregate contextual information to improve the perceptual field, while optimising the jaggedness and mosaic phenomenon of the defect edges of the feature map caused by nearest neighbor interpolation up sampling. To enable the backbone feature extraction network to learn better feature information, the convolution part of yolov5 is optimised to dynamic conditional convolution. Experiments have shown that yolov5-CTD can detect surface defects on mobile phone wireless charging coils with the accuracy of Map@0.5 reaches 80.9% which is 4.8% higher than the original network, and the detection speed is 41.15FPS, which can meet the industrial production line requirements in terms of speed and accuracy.
C1 [Wei, Zhao; Wang, Tingting] Hohai Univ, Sch Mech & Elect Engn, Changzhou 213022, Peoples R China.
C3 Hohai University
RP Wang, TT (corresponding author), Hohai Univ, Sch Mech & Elect Engn, Changzhou 213022, Peoples R China.
EM 1660328756@qq.com; 20121894@hhu.edu.cn
CR Bochovskiy A, 2020, ARXIV
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Dosovitskiy Alexey, 2021, ICLR
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Lin HR., 2017, RES ROTOR WINDING DE
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mehta S., 2021, ARXIV
   Misra D., 2020, ARXIV
   Ni LY., 2020, RES STATOR COIL DEFE
   Qi JT, 2022, COMPUT ELECTRON AGR, V194, DOI 10.1016/j.compag.2022.106780
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi CP, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14030608
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Ullah Z, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-27266-9
   Wang JQ, 2019, IEEE I CONF COMP VIS, P3007, DOI 10.1109/ICCV.2019.00310
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan S., 2020, RES ROTOR WINDING QU
NR 26
TC 0
Z9 0
U1 7
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12403
EP 12424
DI 10.1007/s11042-023-16061-x
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100006
DA 2024-07-18
ER

PT J
AU Haque, E
   Ul Hoque, S
   Paul, M
   Sarker, MR
   Al Suman, A
   Ul Huque, T
AF Haque, Ershadul
   Ul Hoque, Sami
   Paul, Manoranjan
   Sarker, Mahidur R.
   Al Suman, Abdullah
   Ul Huque, Tanvir
TI Impact analysis of recovery cases due to COVID-19 outbreak using deep
   learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SARS-CoV2 (Severe acute respiratory syndrome coronavirus 2); LSTM;
   Covid-19; Impact analysis; Recovery cases; Prediction of recovery cases
ID PREDICTION
AB The present world is badly affected by novel coronavirus (COVID-19). Using medical kits to identify the coronavirus affected persons are very slow. What happens in the next, nobody knows. The world is facing erratic problem and don't know what will happen in near future. This paper is trying to make prognosis of the coronavirus recovery cases using LSTM(Long Short Term Memory). This work exploited data of 258 regions, their latitude and longitude and the number of death of 403 days ranging from 22-01-2020 to 27-02-2021. Specifically, advanced deep learning-based algorithms known as the LSTM, play a great effect on extracting highly essential features for time series data (TSD) analysis.There are lots of methods which already use to analyze propagation prediction. The main task of this paper culminates in analyzing the spreading of Coronavirus across worldwide recovery cases using LSTM deep learning-based architectures.
C1 [Haque, Ershadul; Paul, Manoranjan] Charles Sturt Univ, Sch Comp Math & Engn, Bathurst, Australia.
   [Haque, Ershadul; Ul Hoque, Sami] Feni Univ, Dept EEE, Feni 3900, Bangladesh.
   [Sarker, Mahidur R.] Univ Kebangsaan Malaysia, Inst IR 4 0, Ukm Bnagi 43600, Selangor, Malaysia.
   [Al Suman, Abdullah] Macquarie Univ, Dept Clin Med, Sydney, Australia.
   [Ul Huque, Tanvir] Queensland Univ Technol, Sch Comp Sci, Brisbane, Australia.
C3 Charles Sturt University; Universiti Kebangsaan Malaysia; Macquarie
   University; Queensland University of Technology (QUT)
RP Ul Hoque, S (corresponding author), Feni Univ, Dept EEE, Feni 3900, Bangladesh.
EM samiul0906@gmail.com
RI Sarker, Mahidur/AET-9061-2022
OI Sarker, Mahidur/0000-0002-5363-6219; Paul,
   Manoranjan/0000-0001-6870-5056
CR Acosta-Quiroz Johana, 2020, Rev Neuropsiquiatr, V83, P212, DOI 10.20453/rnp.v83i3.3784
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI DOI 10.1007/978-3-030-67187-7_30
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Fouladi S, 2021, COMPUT COMMUN, V176, P234, DOI 10.1016/j.comcom.2021.06.011
   Geron A, 2017, HANDS ON MACHINE LEA
   Gupta V, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110708
   Hao Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239960
   Hassan SA, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.7355
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang XG, 2020, CMC-COMPUT MATER CON, V63, P537, DOI 10.32604/cmc.2020.010691
   Khan AA, 2022, ALEX ENG J, V61, P5083, DOI 10.1016/j.aej.2021.10.008
   Khan AA, 2022, EUR PHYS J PLUS, V137, DOI 10.1140/epjp/s13360-022-02365-8
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Kuniya T, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030789
   Mahmoudi MR, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110230
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A., 2021, Data Science and Its Applications, P63
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Pal R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186448
   Petropoulos F, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231236
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Rath S, 2020, DIABETES METAB SYND, V14, P1467, DOI 10.1016/j.dsx.2020.07.045
   Ray EL, 2020, medRxiv, P2020, DOI [10.1101/2020.08.19.20177493, DOI 10.1101/2020.08.19.20177493]
   Salehi AW, 2020, MATER TODAY-PROC, V33, P3896, DOI 10.1016/j.matpr.2020.06.245
   Shah K, 2020, ALEX ENG J, V59, P3221, DOI 10.1016/j.aej.2020.08.028
   Singhal T, 2020, INDIAN J PEDIATR, V87, P281, DOI 10.1007/s12098-020-03263-6
   Tiwari S, 2020, DISASTER MED PUBLIC, V14, pE33, DOI 10.1017/dmp.2020.115
   Waibler Z, 2007, J VIROL, V81, P12102, DOI 10.1128/JVI.01190-07
   Wan H, 2020, MEDRXIV
   Xu Q, 2014, MATH PROBL ENG, V2014
   Xu Q, 2013, MATH PROBL ENG, V2013
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yuan Xiaoling, 2020, Explor Res Hypothesis Med, V5, P1, DOI 10.14218/ERHM.2020.00023
   Zamir M, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2020.103784
   Zhang NN, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322188
   Zhou T, 2020, J EVID-BASED MED, V13, P3, DOI 10.1111/jebm.12376
NR 44
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11169
EP 11185
DI 10.1007/s11042-023-14837-9
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900003
DA 2024-07-18
ER

PT J
AU Reeja, JJ
   Arun, CH
AF Reeja, J. Jackulin
   Arun, C. H.
TI Acute ischemic stroke identification using mean and reorder resample,
   synthetic minority oversampling technique and linear discriminant
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NifTi image; SPM12 brain atlas; Magnetic Resonance Imaging; Acute
   Ischemic Stroke; Linear Discriminant Analysis; SMOTE; Machine learning
ID COMPUTER-AIDED DETECTION; SEGMENTATION; SMOTE
AB Blood arteries that transport blood to the brain become blocked, leading to an acute ischemic stroke (AIS). Although physical lesion identification techniques are still the gold standard for diagnosing strokes, they necessitate anatomical expertise. However, automated diagnostic methods utilising machine learning algorithms help clinicians identify strokes more quickly and accurately. The lesion's size, shape, and location contribute to the complexity of an automated diagnosis of AIS on an MRI. In order to identify the AIS lesion from the image, this paper suggests a method for extracting features using linear discriminant analysis (LDA) from resampled images by computing the mean of the MR image first. The image is then reordered and classified using machine learning algorithms. The Anatomical Tracings of Lesions After Stroke dataset is used to achieve this while correcting for class imbalance and challenges associated with the medical dataset using the synthetic minority oversampling technique. The tests on mean image and reorder image revealed that the accuracy of using mean image is the highest. The Support Vector Machine with the kernel Radial Basis Function shows the best accuracy of 90% on the ATLAS dataset. The proposed method helped generate a valuable feature set for machine learning models to accurately identify the lesions.
C1 [Reeja, J. Jackulin; Arun, C. H.] Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.
RP Reeja, JJ (corresponding author), Nesamony Mem Christian Coll, Dept Comp Sci, Marthandam, India.
EM reejajackulin@gmail.com; dass.arun@gmail.com
CR Alexopoulos E, 1999, Machine Learning and Applications: Machine Learning in Medical Applications, P20
   Ali L, 2019, IEEE J TRANSL ENG HE, V7, DOI 10.1109/JTEHM.2019.2940900
   Arslan AK, 2016, COMPUT METH PROG BIO, V130, P87, DOI 10.1016/j.cmpb.2016.03.022
   Badriyah T, 2020, INT C EL COMM COMP E, P1
   Brett M, 2001, NEUROIMAGE, V13, pS85
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chlap P, 2021, J MED IMAG RADIAT ON, V65, P545, DOI 10.1111/1754-9485.13261
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Cuingnet R, 2010, ADV NEURAL INFORM PR, V23
   Eaton-Rosen Z., 2018, INT C MED IM DEEP LE
   Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224
   Heo J, 2019, STROKE, V50, P1263, DOI 10.1161/STROKEAHA.118.024293
   Jeatrakul P, 2010, LECT NOTES COMPUT SC, V6444, P152, DOI 10.1007/978-3-642-17534-3_19
   Kassubek J, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00061
   Khagi B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136175
   Larobina M, 2014, J DIGIT IMAGING, V27, P200, DOI 10.1007/s10278-013-9657-9
   Li XR, 2016, J NEUROSCI METH, V264, P47, DOI 10.1016/j.jneumeth.2016.03.001
   Liew SL, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.11
   Lo CM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081668
   Lucas C, 2018, I S BIOMED IMAGING, P1118, DOI 10.1109/ISBI.2018.8363767
   Maier O., 2014, SPIE, V9035, P21
   Melingi SB, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0230-6
   Moghimi P, 2021, ARXIV
   Nazir M, 2015, J INTELL FUZZY SYST, V28, P1127, DOI 10.3233/IFS-141396
   Noor NSM., 2019, INT J ELECTR COMPUT, V9, P1832
   Nowinski WL, 2006, ACAD RADIOL, V13, P1025, DOI 10.1016/j.acra.2006.05.009
   Pérez-García F, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106236
   Rajini NH, 2013, MEASUREMENT, V46, P1865, DOI 10.1016/j.measurement.2013.01.010
   Sajedi H, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1401-7
   Sharique MD, 2019, BIORXIV
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sivakumar P, 2017, INT J IMAG SYST TECH, V27, P265, DOI 10.1002/ima.22231
   Surisetty VVAK, 2018, INT J REMOTE SENS, V39, P7463, DOI 10.1080/01431161.2018.1471538
   Takahashi N, 2008, ACTA RADIOL, V49, P816, DOI 10.1080/02841850802126570
   Tang FH, 2011, COMPUT BIOL MED, V41, P529, DOI 10.1016/j.compbiomed.2011.05.001
   Tazin T, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7633381
   Van Essen DC, 2001, VISION RES, V41, P1359, DOI 10.1016/S0042-6989(01)00045-1
   Xing XX, 2011, MAGN RESON IMAGING, V29, P731, DOI 10.1016/j.mri.2011.02.007
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11785
EP 11803
DI 10.1007/s11042-023-16009-1
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000011
DA 2024-07-18
ER

PT J
AU Arshad, B
   Ehatisham-ul-Haq, M
   Hussain, Z
   Asghar, A
AF Arshad, Bilal
   Ehatisham-ul-Haq, Muhammad
   Hussain, Zamir
   Asghar, Awais
TI A novel approach for designing secure substitution boxes based on
   Catalan number and elliptic curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Substitution box (S-box); Catalan number; Elliptic curve cryptography
   (ECC); Image encryption
ID AVERAGING FUSION STRATEGY; S-BOXES; SCHEME; CONSTRUCTION
AB While using the internet, sending confidential emails, or dealing with financial information that affects many aspects of our everyday life, security is one of the most important considerations. We can prevent illegal access to our data with the aid of security. Cryptography is one of the methods used for encryption and decryption in this context to safeguard data. The S-box is the most important and the sole nonlinear component of any cryptographic algorithm that adds uncertainty to the data. Based on the combination of the Catalan number and the elliptic curve, the proposed method constitutes a unique algorithm. The strength of S-boxes is then assessed using nonlinearity, strict avalanche criterion, bit independence criterion, linear and differential approximation probabilities. Performance studies show that the proposed S-boxes have exceptional functionality and can give cryptosystems a significant amount of nonlinearity. Furthermore, the comparison shows that the newly proposed S-boxes offer enhanced security features in contrast to other S-boxes that are already in use literature.
C1 [Arshad, Bilal] Dept Elementary & Secondary Educ, Khyber Pakhtunkhwa, Pakistan.
   [Arshad, Bilal] Univ Engn & Technol, Dept Basic Sci, Taxila, Pakistan.
   [Ehatisham-ul-Haq, Muhammad] Air Univ, Dept Creat Technol, Islamabad, Pakistan.
   [Hussain, Zamir] Univ Wah, Dept Math, Wah Cantt, Pakistan.
   [Asghar, Awais] Pak Austria Fachhochschule Inst Appl Sci & Technol, Haripur, Pakistan.
C3 University of Engineering & Technology Taxila; Air University Islamabad
RP Arshad, B (corresponding author), Dept Elementary & Secondary Educ, Khyber Pakhtunkhwa, Pakistan.; Arshad, B (corresponding author), Univ Engn & Technol, Dept Basic Sci, Taxila, Pakistan.
EM bilalarshad689@gmail.com; ehatishamuet@gmail.com;
   zamir.hussain@uow.edu.pk; awais.asghar154@gmail.com
CR Abd-El-Atty B, 2023, COMPLEX INTELL SYST, V9, P4817, DOI 10.1007/s40747-023-00988-7
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ali A, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.940
   Altaleb A, 2017, AIP ADV, V7, DOI 10.1063/1.4978264
   Amounas F, 2013, INT J INFORM NETWORK, V2
   Anees A, 2019, NEURAL COMPUT APPL
   Anees A, 2015, WIRELESS PERS COMMUN, V82, P1497, DOI 10.1007/s11277-015-2295-4
   Arshad B, 2020, INT J COMP SC INFO S, V18, P09
   Arshad B, 2022, WIRELESS PERS COMMUN, V124, P3527, DOI 10.1007/s11277-022-09524-1
   Arshad Nasim, 2013, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V16, P1156, DOI 10.9717/kmms.2013.16.10.1156
   Aslam M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.892
   Attaullah, 2018, WIRELESS PERS COMMUN, V99, P213, DOI 10.1007/s11277-017-5054-x
   Azam NA, 2019, FRONT INFORM TECH EL, V20, P1378, DOI 10.1631/FITEE.1800434
   Azam NA, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/3421725
   Cassal-Quiroga BB, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2702653
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   Detombe J., 1993, Advances in Cryptology - AUSCRYPT '92. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P165
   Gao W, 2020, IEEE ACCESS
   Hayat U, 2021, ARAB J SCI ENG, V46, P8887, DOI 10.1007/s13369-021-05666-9
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hayat U, 2018, WIRELESS PERS COMMUN, V101, P439, DOI 10.1007/s11277-018-5698-1
   Hussain I, 2011, WORLD APPL SCI J, V13, P2389
   Hussain I., 2011, WORLD APPL SCI J, V14, P1779
   Hussain I., 2011, World Appl. Sci. J, V13, P2385
   Ibrahim S, 2021, INFORM SCIENCES, V558, P246, DOI 10.1016/j.ins.2021.01.014
   Irfan M, 2022, IEEE ACCESS
   Jamal SS, 2019, IEEE ACCESS, V7, P173273, DOI 10.1109/ACCESS.2019.2956385
   Joan D., 2013, The design of Rijndael: AES-the advanced encryption standard
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan MAM, 2023, J KING SAUD UNIV-COM, V35, P219, DOI 10.1016/j.jksuci.2022.11.012
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu JM, 2005, 19th International Conference on Advanced Information Networking and Applications, Vol 1, Proceedings, P724
   Magdy M, 2022, MULTIMED TOOLS APPL, V81, P25101, DOI 10.1007/s11042-022-11956-7
   Malik MSM, 2020, IEEE ACCESS, P1
   Miller V. S., 1985, ADV CRYPTOLOGY CRYPT, P417, DOI DOI 10.1007/3-540-39799-X_31
   Naseer Y, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010006
   Özkaynak F, 2020, PHYSICA A, V550, DOI 10.1016/j.physa.2019.124072
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   PUNDDANGE S, 2017, INDIAN J SCI TECHNOL, V10
   Razaq A, 2020, IEEE ACCESS, V8, P75473, DOI 10.1109/ACCESS.2020.2989676
   Razaq A, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4987021
   Razaq A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5101934
   Sani RH, 2021, MULTIDIM SYST SIGN P
   Sarfraz M., 2016, INT J COMPUT SCI INF, V14, P187
   Shahzad I., 2019, SEC COMM NETWORKS, V1-13, P2019
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Siddiqui N, DIGITAL OBJECT IDENT, DOI [10.1109/ACCESS.2020, DOI 10.1109/ACCESS.2020]
   Siddiqui N, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241890
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   Theresa XB., 2018, INT J APPL ENG RES, V13, P8831
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   Ullah I, 2021, J INF SECUR APPL, V56, DOI 10.1016/j.jisa.2020.102619
   Vinay DR., 2021, TURK J COMPUT MATH E, V12, P2031, DOI [10.17762/turcomat.v12i6.4808, DOI 10.17762/TURCOMAT.V12I6.4808]
   Zahid AH, 2020, IEEE ACCESS, V8, P150326, DOI 10.1109/ACCESS.2020.3016401
   Zhang YQ, 2020, IEEE ACCESS, V8, P54175, DOI 10.1109/ACCESS.2020.2979827
NR 61
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10409
EP 10425
DI 10.1007/s11042-023-15971-0
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200006
DA 2024-07-18
ER

PT J
AU Chen, JH
   Niu, YZ
AF Chen, Junhao
   Niu, Yuzhen
TI Two-stream network with viewport selection for blind omnidirectional
   video quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Omnidirectional video; Video quality assessment; Viewport selection;
   Two-stream convolutional neural network
ID PERCEPTION
AB In omnidirectional images or videos, the viewer receives an interactive and immersive experience from the viewport by changing the viewing angle. Due to the wide application of omnidirectional videos, the visual quality assessment for omnidirectional videos is becoming an urgent issue. Due to the large resolution of an omnidirectional video, regions with object motions usually catch the viewers' attention, so the motion regions have great influences on the visual quality perception. Since the number of potential viewports is huge and the viewer spends varying amounts of time for different viewports, viewport selection is a critical yet not resolved problem for omnidirectional video quality assessment (VQA). In this paper, we propose a two-stream network with viewport selection for blind omnidirectional VQA to incorporate the influences of motion regions and viewport selection. Firstly, we propose a two-stream multi-task convolutional neural network (TSMT) for VQA at any viewport, which uses video frame sequences and motion sequences as inputs. The motion sequences are represented as horizontal and vertical optical flows. Based on the observation that the low latitude regions, the front view, and the moving objects have higher possibilities that appearing in the viewport, we propose a viewport selection method based on a fusion-based saliency map that considers those regions. Experimental results on two datasets demonstrated that the proposed model outperforms state-of-the-art omnidirectional VQA methods.
C1 [Chen, Junhao; Niu, Yuzhen] Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informat, Fuzhou 350108, Peoples R China.
C3 Fuzhou University
RP Niu, YZ (corresponding author), Fuzhou Univ, Fujian Key Lab Network Comp & Intelligent Informat, Fuzhou 350108, Peoples R China.
EM fz.junhao.chen@gmail.com; yuzhenniu@gmail.com
FU National Natural Science Foundation of China [61972097]; Natural Science
   Foundation of Fujian Province [2020J01494]
FX AcknowledgementsThis work is supported by the National Natural Science
   Foundation of China (No.61972097) and the Natural Science Foundation of
   Fujian Province (No.2020J01494).
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Boyce J, 2018, JVETE1030
   Chai XL, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165887
   Chen SC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240847
   Chi L, 2019, IEEE INT CONF COMP V, P4511, DOI 10.1109/ICCVW.2019.00552
   Choi B., 2017, ISO/IEC, P23090
   der Auwera GV, 2016, 0071 JVET
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kim HG, 2020, IEEE T CIRC SYST VID, V30, P917, DOI 10.1109/TCSVT.2019.2898732
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim J, 2017, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2017.213
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14
   Kingma D. P., 2014, arXiv
   Li C, 2019, PROC CVPR IEEE, P10169, DOI 10.1109/CVPR.2019.01042
   Li C, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P932, DOI 10.1145/3240508.3240581
   Lim HT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6737, DOI 10.1109/ICASSP.2018.8461317
   Mahmood S, 2019, 2019 4TH MEC INTERNATIONAL CONFERENCE ON BIG DATA AND SMART CITY (ICBDSC), P146, DOI 10.1109/icbdsc.2019.8645598
   Mangiante S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P30, DOI 10.1145/3097895.3097901
   Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun W, 2020, IEEE J-STSP, V14, P64, DOI 10.1109/JSTSP.2019.2955024
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Xu JH, 2021, IEEE T CIRC SYST VID, V31, P1724, DOI 10.1109/TCSVT.2020.3015186
   Xu JP, 2019, INT CONF WIRE COMMUN, DOI 10.1109/wcsp.2019.8927989
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Yang S, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhou YF, 2018, INT CONF SIGN PROCES, P54, DOI 10.1109/ICSP.2018.8652269
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12139
EP 12157
DI 10.1007/s11042-023-15739-6
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200002
DA 2024-07-18
ER

PT J
AU Lin, K
   Ru, YM
   Huang, JZ
   Yu, SS
   Chen, YH
AF Lin, Kai
   Ru, Yiming
   Huang, Jingzeng
   Yu, Songsen
   Chen, Yihua
TI SRPSGAN: Super-resolution with pose and expression robust spatial-aware
   generative adversarial network for makeup transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Makeup transfer; Makeup recommendation; Generative
   adversarial network
AB In this paper, we address special scenario makeup-transfer tasks designed to transfer makeup features from a low-resolution (LR) reference image to a LR source image and generate high-resolution (HR) results. Existing methods are not suitable when limited by storage space, especially when HR images are unavailable. To overcome this problem, we propose the super-resolution (SR) pose-and-expression robust spatial-aware (PS) generative adversarial network (GAN), which makes full use of the prior information while preserving the original network properties (i.e., robustness of pose and expression during makeup transfer). Specifically, it feeds the results of the PSGAN (Jiang et al. 20) into the prior estimation network (PEnet) to estimate facial landmarks and parsing maps. Then, a feature map containing makeup information extracted from the PSGAN is used as additional prior information. Both the feature map and the PEnet results are sent to the SR network to generate HR makeup-transfer images. Moreover, we propose a novel makeup recommender that integrates three evaluation metrics to provide superior decision support. Our extensive experiments show that the SRPSGAN achieves excellent results in SR makeup-transfer tasks.
C1 [Lin, Kai; Ru, Yiming; Huang, Jingzeng; Yu, Songsen; Chen, Yihua] South China Normal Univ, Sch Software, Taoyuan West Rd, Foshan 528000, Guangdong, Peoples R China.
C3 South China Normal University
RP Chen, YH (corresponding author), South China Normal Univ, Sch Software, Taoyuan West Rd, Foshan 528000, Guangdong, Peoples R China.
EM YihuaChen1314@163.com
RI lin, kai/KJL-3762-2024
OI Chen, Yihua/0000-0002-2673-6214
FU Guangdong Basic and Applied Basic Research Fund Regional Joint Fund
   Project [2020B1515120089]; Guangdong Colleges and Universities Special
   Project Foundation in Key Areas of Artificial Intelligence
   [2019KZDZX1033]; Science and Technology Innovation Project of Foshan
   City, Guangdong [2016AG100472]
FX This work was partially supported by the Guangdong Basic and Applied
   Basic Research Fund Regional Joint Fund Project (2020B1515120089), the
   Guangdong Colleges and Universities Special Project Foundation in Key
   Areas of Artificial Intelligence (2019KZDZX1033), and the Science and
   Technology Innovation Project of Foshan City, Guangdong (2016AG100472).
CR Alashkar T, 2017, AAAI CONF ARTIF INTE, P941
   Alashkar T, 2017, IEEE INT CONF AUTOMA, P325, DOI 10.1109/FG.2017.47
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Center XCR, 2014, CHIN IM LAW TUT WOM
   Chan KCK, 2021, PROC CVPR IEEE, P14240, DOI 10.1109/CVPR46437.2021.01402
   Chang HW, 2018, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.2018.00012
   Chen CF, 2021, PROC CVPR IEEE, P11891, DOI 10.1109/CVPR46437.2021.01172
   Chen HJ, 2019, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR.2019.01028
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Chen YH, 2017, AIP CONF PROC, V1812, DOI [10.1063/1.4975898, 10.1109/ICCV.2017.137]
   Deng H, 2021, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR46437.2021.00648
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Gan JY, 2014, NEUROCOMPUTING, V144, P295, DOI 10.1016/j.neucom.2014.05.028
   Goodfellow I. J., 2014, ARXIV
   Gowda, 2019, ARXIV
   Gu Q, 2019, IEEE I CONF COMP VIS, P10480, DOI 10.1109/ICCV.2019.01058
   Gulati K, 2021, ARXIV
   Hensel M, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang J., 2021, arXiv
   Jiang J., 2018, ARXIV
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalarot R, 2020, IEEE WINT CONF APPL, P359, DOI [10.1109/wacv45572.2020.9093399, 10.1109/WACV45572.2020.9093399]
   Kips Robin, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P280, DOI 10.1007/978-3-030-67070-2_17
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liao J., 2017, ARXIV
   Liu LQ, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2659234
   Liu S., 2016, ARXIV
   Lyu YM, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3601, DOI 10.1145/3474085.3475531
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Majdabadi MM, 2020, MULTIMED TOOLS APPL, V79, P31205, DOI 10.1007/s11042-020-09489-y
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nguyen TV, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1253, DOI 10.1145/3123266.3127926
   Organisciak D, 2021, INT C PATT RECOG, P6011, DOI 10.1109/ICPR48806.2021.9412604
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Ren Y., 2019, AUST J INTELL INF PR, V16, P59
   Scherbaum K, 2011, COMPUT GRAPH FORUM, V30, P485, DOI 10.1111/j.1467-8659.2011.01874.x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2020, MULTIMED TOOLS APPL, V79, P1641, DOI 10.1007/s11042-019-08254-0
   Song Y., 2017, ARXIV
   Sun ZY, 2022, AAAI CONF ARTIF INTE, P2325
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Nguyen T, 2021, PROC CVPR IEEE, P13300, DOI 10.1109/CVPR46437.2021.01310
   Wan ZY, 2022, IEEE WINT CONF APPL, P3113, DOI 10.1109/WACV51458.2022.00317
   Wang CY, 2020, INT CONF ACOUST SPEE, P2518, DOI [10.1109/icassp40776.2020.9053398, 10.1109/ICASSP40776.2020.9053398]
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xiaoyuan Yu, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P214, DOI 10.1109/TBIOM.2021.3051268
   Yang C.-A., 2022, ARXIV
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yang T, 2021, PROC CVPR IEEE, P672, DOI 10.1109/CVPR46437.2021.00073
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 61
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10147
EP 10165
DI 10.1007/s11042-023-15440-8
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400004
DA 2024-07-18
ER

PT J
AU Mangalampalli, S
   Karri, GR
   Kumar, M
   Khalaf, OI
   Romero, CAT
   Sahib, GA
AF Mangalampalli, Sudheer
   Karri, Ganesh Reddy
   Kumar, Mohit
   Khalaf, Osama Ibrahim
   Romero, Carlos Andres Tavera
   Sahib, GhaidaMuttashar Abdul
TI DRLBTSA: Deep reinforcement learning based task-scheduling algorithm in
   cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud Computing; Task Scheduling; Machine Learning; Deep Q- Learning;
   Makespan; Energy consumption; SLA violation
AB Task scheduling in cloud paradigm brought attention of all researchers as it is a challenging issue due to uncertainty, heterogeneity, and dynamic nature as they are varied in size, processing capacity and number of tasks to be scheduled. Therefore, ineffective scheduling technique may lead to increase of energy consumption SLA violations and makespan. Many of authors proposed heuristic approaches to solve task scheduling problem in cloud paradigm but it is fall behind to achieve goal effectively and need improvement especially while scheduling multimedia tasks as they consists of more heterogeneity, processing capacity. Therefore, to handle this dynamic nature of tasks in cloud paradigm, a scheduling mechanism, which automatically takes the decision based on the upcoming tasks onto cloud console and already running tasks in the underlying virtual resources. In this paper, we have used a Deep Q-learning network model to addressed the mentioned scheduling problem that search the optimal resource for the tasks. The entire extensive simulationsare performed usingCloudsim toolkit. It was carried out in two phases. Initially random generated workload is used for simulation. After that, HPC2N and NASA workload are used to measure performance of proposed algorithm. DRLBTSA is compared over baseline algorithms such as FCFS, RR, Earliest Deadline first approaches. From simulation results it is evident that our proposed scheduler DRLBTSA minimizes makespan over RR,FCFS, EDF, RATS-HM, MOABCQ by 29.76%, 41.03%, 27.4%, 33.97%, 33.57% respectively. SLA violation percentage for DRLBTSA minimized overRR,FCFS, EDF, RATS-HM, MOABCQ by48.12%, 41.57%, 37.57%, 36.36%, 30.59% respectively and energy consumption for DRLBTSA over RR,FCFS, EDF, RATS-HM, MOABCQ by36.58%,43.2%, 38.22%, 38.52%, 33.82%existing approaches.
C1 [Mangalampalli, Sudheer; Karri, Ganesh Reddy] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, AP, India.
   [Kumar, Mohit] NIT Jalandhar, Dept Informat Technol, Jalandhar, India.
   [Khalaf, Osama Ibrahim] Al Nahrin Univ, Al NahrinNanorenewable Energy Res Ctr, Bhagdad, Iraq.
   [Romero, Carlos Andres Tavera] Univ Santiago Cali, Cali, Colombia.
   [Sahib, GhaidaMuttashar Abdul] Univ Technol, Dept Comp Engn, Bhagdad, Iraq.
C3 VIT-AP University; National Institute of Technology (NIT System); Dr B R
   Ambedkar National Institute of Technology Jalandhar; Universidad
   Santiago de Cali; University of Technology- Iraq
RP Mangalampalli, S (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati, AP, India.
EM sudheerkietmtech@gmail.com
RI Reddy, Ganesh/IVU-9915-2023; Manglampalli, Sudheer/AAR-2779-2020; KUMAR,
   MOHIT/GNP-6004-2022; Khalaf, Osamah Ibrahim/AAK-3630-2021
OI Reddy, Ganesh/0000-0002-5177-8125; Manglampalli,
   Sudheer/0000-0002-1485-8783; KUMAR, MOHIT/0000-0003-1600-6872; Khalaf,
   Osamah Ibrahim/0000-0002-4750-8384
CR Abualigah L, 2022, J SUPERCOMPUT, V78, P740, DOI 10.1007/s11227-021-03915-0
   Adhikari M, 2022, SOFTWARE PRACT EXPER, V52, P1004, DOI 10.1002/spe.3025
   Agrawal K, 2022, J INFORM OPTIM SCI, V43, P607, DOI 10.1080/02522667.2022.2042097
   Amer DA, 2022, J SUPERCOMPUT, V78, P2793, DOI 10.1007/s11227-021-03977-0
   Bal PK, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031242
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Cheng F, 2022, CLUSTER COMPUT, V25, P619, DOI 10.1007/s10586-021-03436-8
   Ding D, 2020, FUTURE GENER COMP SY, V108, P361, DOI 10.1016/j.future.2020.02.018
   Dong TT, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5654
   Gazori P, 2020, FUTURE GENER COMP SY, V110, P1098, DOI 10.1016/j.future.2019.09.060
   Ghafari R, 2022, CLUSTER COMPUT, V25, P1035, DOI 10.1007/s10586-021-03512-z
   HPC2N, 2016, HPC2N HPC2N SETH LOG
   Huang YF, 2022, IEEE SYST J, V16, P4232, DOI 10.1109/JSYST.2021.3122126
   Karthiban K, 2020, SOFT COMPUT, V24, P14933, DOI 10.1007/s00500-020-04846-3
   Kruekaew B, 2022, IEEE ACCESS, V10, P17803, DOI 10.1109/ACCESS.2022.3149955
   Kumar R., 2022, ARTIF INTELL, P129, DOI [10.1007/978-981-16-1220-6_12, DOI 10.1007/978-981-16-1220-6_12]
   Lahande P, 2022, ITM WEB C, V50
   Li FC, 2019, ICBDC 2019: PROCEEDINGS OF 2019 4TH INTERNATIONAL CONFERENCE ON BIG DATA AND COMPUTING, P48, DOI 10.1145/3335484.3335513
   Madni SHH, 2019, CLUSTER COMPUT, V22, P301, DOI 10.1007/s10586-018-2856-x
   Mohanapriya N, 2018, J INTELL FUZZY SYST, V34, P1561, DOI 10.3233/JIFS-169451
   Nabi S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030920
   nasa, US
   Nayak SC, 2022, J KING SAUD UNIV-COM, V34, P282, DOI 10.1016/j.jksuci.2018.10.009
   Rjoub G, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5919
   Rjoub G, 2020, FUTURE GENER COMP SY, V110, P1079, DOI 10.1016/j.future.2019.11.019
   Sharma M, 2020, SUSTAIN COMPUT-INFOR, V26, DOI 10.1016/j.suscom.2020.100373
   Sheng SR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051666
   Siddesha K, 2022, CLUSTER COMPUT, V25, P4171, DOI 10.1007/s10586-022-03630-2
   Spanò S, 2019, IEEE ACCESS, V7, P186340, DOI 10.1109/ACCESS.2019.2961174
   Staddon JER, 2020, J EXP ANAL BEHAV, V113, P485, DOI 10.1002/jeab.587
   Swarup S, 2021, PROCEDIA COMPUT SCI, V184, P42, DOI 10.1016/j.procs.2021.03.016
   Tong Z, 2020, NEURAL COMPUT APPL, V32, P5553, DOI 10.1007/s00521-019-04118-8
   Tong Z, 2020, INFORM SCIENCES, V512, P1170, DOI 10.1016/j.ins.2019.10.035
   Wang YD, 2019, IEEE ACCESS, V7, P39974, DOI 10.1109/ACCESS.2019.2902846
   Wei Y, 2018, IEEE ACCESS, V6, P55112, DOI 10.1109/ACCESS.2018.2872674
   Yan JC, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107688
   Zhang XQ, 2019, J SYST SOFTWARE, V147, P147, DOI 10.1016/j.jss.2018.09.084
   Zhou G., 2021, ARXIV
NR 38
TC 8
Z9 8
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8359
EP 8387
DI 10.1007/s11042-023-16008-2
EA JUN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700006
DA 2024-07-18
ER

PT J
AU Ghosh, J
   Talukdar, AK
   Sarma, KK
AF Ghosh, Jyoti
   Talukdar, Anjan Kumar
   Sarma, Kandarpa Kumar
TI A light-weight natural scene text detection and recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text detection; Scene text recognition; Deep learning;
   Light-weight; MobileNetV2
AB Scene text recognition is an application of Computer Vision that analyses the scene image and recognizes the text present on it. This task has many applications and will gain more importance if it can be used in handheld devices. The problem with existing methods is that if the model has a huge number of parameters and complex architectures, then the model will have a huge file size which will be problematic to deploy the application on mobile devices. Therefore, the aim of this paper is to propose a light-weight model that is a model with less number of parameters, small file size and less complexity that can be used in platforms with limited resources while achieving a comparable accuracy with those of the heavy weight models. The proposed models rely on deep learning to handle most of the steps automatically, consume less time and give precise results after facing many challenges. The proposed scene text recognition model is in the form of a Convolutional-Recurrent Neural network where the Convolution network extracts the features from the cropped images of scene text and the Recurrent network processes the sequential data of varying length present in the cropped images. After training, the scene text recognition model generates a weight file of 12 MB with 1 M parameters. To reduce number of parameters, weight of files and to show trade-off between efficiency and accuracy, MobileNetV2 is used in place of Convolution network that generates weight file of 6 MB with 0.5 M parameters. The performance on ICDAR 2013, IIIT 5K and Total-Text datasets shows that the proposed work performs well in detecting and recognizing texts from natural scene images.
C1 [Ghosh, Jyoti; Talukdar, Anjan Kumar; Sarma, Kandarpa Kumar] Gauhati Univ, Dept Elect & Commun Engn, Gauhati 781014, Assam, India.
C3 Gauhati University
RP Ghosh, J (corresponding author), Gauhati Univ, Dept Elect & Commun Engn, Gauhati 781014, Assam, India.
EM jyotighosh02@gmail.com; anjantalukdar@gauhati.ac.in;
   kandarpaks@gauhati.ac.in
RI Sarma, Kandarpa Kumar/AAA-2036-2019; Sarma, Kandarpa Kumar/C-3675-2012
OI Sarma, Kandarpa Kumar/0000-0002-6236-0461; Sarma, Kandarpa
   Kumar/0000-0002-6236-0461
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Baek J, 2019, IEEE I CONF COMP VIS, P4714, DOI 10.1109/ICCV.2019.00481
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bagi R, 2020, IEEE ACCESS, V8, P111433, DOI 10.1109/ACCESS.2020.3002808
   Bisong E., 2019, BUILDING MACHINE LEA, DOI [DOI 10.1007/978-1-4842-4470-8_7, DOI 10.1007/978-1-4842-4470-87, 10.1007/978-1-4842-4470-8]
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Bradski G, 2000, DR DOBBS J, V25, P120
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Chollet F, 2015, KERAS
   Deli Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12110, DOI 10.1109/CVPR42600.2020.01213
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Fu KW, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1560, DOI [10.1109/ICMA.2019.8816384, 10.1109/icma.2019.8816384]
   Ghosh J, 2021, 2021 5 INT C COMP CO, P21, DOI [10.1109/ICCCSP52374.2021.9465515, DOI 10.1109/ICCCSP52374.2021.9465515]
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   He Y., 2021, arXiv
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jaderberg M., 2014, ARXIV
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Li B, 2020, ARXIV
   Li HZ, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107392
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Ling OY, 2018, 2018 8TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2018), P170, DOI 10.1109/ICCSCE.2018.8685019
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lu N, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107980
   Lundh Fredrik., 2001, Python standard library
   Munjal RS, 2021, ARXIV
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Umesh P, 2012, CSI Communications, V23
   Van Rossum G., 2009, Python 3 Reference Manual
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Zihao Liu, 2018, 2018 IEEE International Conference on Information Communication and Signal Processing (ICICSP). Proceedings, P59, DOI 10.1109/ICICSP.2018.8549799
NR 42
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6651
EP 6683
DI 10.1007/s11042-023-15696-0
EA JUN 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400007
DA 2024-07-18
ER

PT J
AU Tiwari, A
   Awasthi, D
   Srivastava, VK
AF Tiwari, Anurag
   Awasthi, Divyanshu
   Srivastava, Vinay Kumar
TI Image security enhancement to medical images by RDWT-DCT-Schur
   decomposition-based watermarking and its authentication using BRISK
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Zigzag scanning; Henon map; Schur decomposition; Discrete cosine
   transform; Redundant discrete wavelet transform; BRISK feature
ID SVD-BASED WATERMARKING; BLIND WATERMARKING; DWT; ROBUST; OPTIMIZATION;
   SCHEME
AB The growing use of the internet results in significant difficulties for the copyright protection of images. To resolve the copyright problem, a scheme is proposed that utilizes the advantages of Zigzag scanning (ZS), Schur decomposition (SD), Discrete cosine transform (DCT) and Redundant discrete wavelet transform (RDWT). In the proposed scheme, Henon map is applied on the watermarked image for its secure transfer and further enhancement of the security. Medical image security assurance is the need of the hour. Therefore, ultrasound images of the liver of six different patients are taken for experimental result analysis. The use of Singular value decomposition (SVD) is avoided here due to its false positive problem. RDWT is used to split the input ultrasound liver image into different sub-bands. Then DCT is applied on the suitable sub-band to improve the robustness of the presented work. The ZS is used to avoid artifacts which may occur at higher value of the gain factor. SD and RDWT are applied to the watermark logo (MNNIT logo) and selective pixel adding is used to embed the watermark logo into the host image. The authentication process is done by using binary robust invariant scalable keypoints (BRISK) features. The presented scheme perform satisfactorily against various attacks such as Histogram equalization, Region of interest (ROI) filtering, Cropping, Scaling, Rotation, Average and Median filtering attacks, Salt and Pepper, Gaussian noise attack, Flipping, etc. The proposed scheme shows better performance as compared to existing schemes in terms of various performance parameters such as Peak signal-to-noise ratio (PSNR), Structural similarity index measurement (SSIM) and Normalized correlation coefficient (NCC).
C1 [Tiwari, Anurag; Awasthi, Divyanshu; Srivastava, Vinay Kumar] Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Tiwari, A (corresponding author), Motilal Nehru Natl Inst Technol, Elect & Commun Engn Dept, Prayagraj 211004, Uttar Pradesh, India.
EM anuragt@mnnit.ac.in; divyanshuawasthi83@gmail.com; vinay@mnnit.ac.in
RI Tiwari, Anurag/IXX-1942-2023; Tiwari, Anurag/IUM-5006-2023; Srivastava,
   Vinay Kumar/AAL-2501-2021; awasthi, divyanshu/ABX-1965-2022
OI Tiwari, Anurag/0000-0001-6873-6450; Srivastava, Vinay
   Kumar/0000-0002-7993-0993; awasthi, divyanshu/0000-0002-1764-772X
CR Anand A, 2022, IEEE T DEPEND SECURE
   Anand A, 2022, IEEE T COMPUT SOC SY, V9, P1594, DOI 10.1109/TCSS.2021.3126628
   Awasthi D, 2023, SYST SIGNAL PROC, P1
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P35685, DOI 10.1007/s11042-023-14723-4
   Awasthi D, 2023, MULTIMED TOOLS APPL, V82, P16555, DOI 10.1007/s11042-022-14002-8
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Furqan A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P638, DOI 10.1109/CICT.2015.74
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Kamble S., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P224, DOI 10.1109/MSPCT.2011.6150480
   Kamble S, 2012, COMPUTER SCI INFORM
   Kamble S., 2012, INT J INF TECHNOLO K, V5, P101
   Khare P., 2014, 2014 STUDENTS C ENG, P1, DOI [10.1109/SCES.2014.6880072, DOI 10.1109/SCES.2014.6880072]
   Khare P, 2021, MULTIDIM SYST SIGN P, V32, P131, DOI 10.1007/s11045-020-00732-1
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Khare P, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P88, DOI 10.1109/SPIN.2018.8474125
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Mohammed AA, 2020, MULTIMED TOOLS APPL, V79, P32095, DOI 10.1007/s11042-020-09694-9
   Mohan B.Chandra., 2010, INT J COMPUTER ELECT, V2, P1793
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Rao VSV., 2012, IEEE STUD C EL EL CO, P1, DOI DOI 10.1109/SCEECS.2012.6184795
   Rathore V, 2021, MULTIMED TOOLS APPL, V80, P22275, DOI 10.1007/s11042-021-10719-0
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Sejpal S, 2019, 2019 5 INT C COMPUT, P1
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Singh KN, 2022, COGN COMPUT, DOI 10.1007/s12559-022-10040-4
   STEINBERG BZ, 1993, IEEE T ANTENN PROPAG, V41, P610, DOI 10.1109/8.222280
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P27593, DOI 10.1007/s11042-021-11064-y
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Tiwari A, 2023, J SUPERCOMPUT, V79, P13142, DOI 10.1007/s11227-023-05167-6
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Vaidya SP, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P251, DOI 10.1109/ICICCT.2018.8473345
   Yuan ZH, 2020, MULTIMED TOOLS APPL, V79, P30557, DOI 10.1007/s11042-020-09499-w
   Zear A, 2018, J INTELL SYST, V27, P5, DOI 10.1515/jisys-2016-0036
NR 40
TC 5
Z9 5
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 7
PY 2023
DI 10.1007/s11042-023-15878-w
EA JUN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I6WB4
UT WOS:001004157400011
DA 2024-07-18
ER

PT J
AU Mohsen, S
   Ali, AM
   Emam, A
AF Mohsen, Saeed
   Ali, Anas M.
   Emam, Ahmed
TI Automatic modulation recognition using CNN deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modulation techniques; Deep learning; Modulation recognition;
   Convolutional neural network (CNN)
ID CONVOLUTIONAL NEURAL-NETWORK; ENTERTAINMENT CENTERS; CLASSIFICATION
AB Modulation techniques are widely required in communication applications, especially in wireless communication systems. Thus, it is necessary to classify and recognize types of modulation. Deep learning (DL) models can help precisely recognize the modulation techniques, provided that well-designed and trained DL models for high-performance recognition are developed. In this paper, two different convolutional neural network (CNN) models are proposed for recognition of modulation techniques. These models are applied to two different datasets: the first dataset consists of mathematical vectors, namely RadioML2016.10a and the second dataset contains 24,460 images. The RadioML2016.10a has eleven classes of modulation techniques, namely 8PSK, AM-DSB, AM-SSB, BPSK, CPFSK, GFSK, PAM4, QAM16, QAM64, QPSK, and WBFM, while the images dataset has eight classes of digital modulation techniques, namely 16PSK, 16QAM, 2PSK, 32QAM, 64QAM, 8PSK, 8QAM, and QPSK. The two CNN models are trained and the models' parameters are precisely tuned of for high-accuracy achievement. Experimentally, classification reports of modulation techniques and receiver operating characteristic (ROC) curves are used to analyze the performance of the proposed models. The CNN models provide high performance, with a testing accuracy of 53.65% and 94.39%. The results show that the area under the micro-average ROC curves for the CNNs is 92% and 97%.
C1 [Mohsen, Saeed] Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.
   [Mohsen, Saeed; Emam, Ahmed] King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, South Sinai, Egypt.
   [Ali, Anas M.] Prince Sultan Univ, Robot & Internet Things Lab, Riyadh 12435, Saudi Arabia.
   [Ali, Anas M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
   [Emam, Ahmed] Menoufia Univ, Fac Sci, Comp Sci & Math Dept, Menoufia, Egypt.
C3 King Salman International University; Prince Sultan University; Egyptian
   Knowledge Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB);
   Menofia University
RP Mohsen, S (corresponding author), Al Madinah Higher Inst Engn & Technol, Dept Elect & Commun Engn, Giza 12947, Egypt.; Mohsen, S (corresponding author), King Salman Int Univ KSIU, Fac Comp Sci & Engn, Dept Artificial Intelligence Engn, El Tor 46511, South Sinai, Egypt.
EM g17082131@eng.asu.edu.eg
RI Mohsen, Saeed/GQH-2016-2022; Ali, Anas/AFI-5616-2022
OI Mohsen, Saeed/0000-0003-2863-0074; 
CR Abdel Hafiz El Rube I, 2010, INT C WIR OPT COMM, P1
   Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   Ali A, 2017, IEEE COMMUN SURV TUT, V19, P1277, DOI 10.1109/COMST.2016.2631080
   Aslam MW, 2012, IEEE T WIREL COMMUN, V11, P2742, DOI 10.1109/TWC.2012.060412.110460
   Bhagwat R, 2021, INT J ENG TECHNOL IN, V11, P216, DOI 10.46604/ijeti.2021.7346
   Dobre OA, 2007, IET COMMUN, V1, P137, DOI 10.1049/iet-com:20050176
   Gamble Justin A, 2020, 2020 IEEE INT SYST C, P1
   Hong JH, 2016, IEEE T HUM-MACH SYST, V46, P101, DOI 10.1109/THMS.2015.2489688
   Igual R, 2015, MED ENG PHYS, V37, P870, DOI 10.1016/j.medengphy.2015.06.009
   Jdid B, 2021, IEEE ACCESS, V9, P57851, DOI 10.1109/ACCESS.2021.3071801
   Jian-Xin Xu, 2010, 2010 IEEE Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P1, DOI 10.1109/ICCIS.2010.5518591
   Jiang KY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031166
   kaggle, 2016, RADIOML2016A MODULAT
   kaggle, US
   Klosowski P, 2018, SIG P ALGO ARCH ARR, P223, DOI 10.23919/SPA.2018.8563389
   Lattanzi E, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103812
   Lee D, 2020, INT J ENG TECHNOL IN, V10, P75
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Marfia G, 2010, IEEE T CONSUM ELECTR, V56, P2233, DOI 10.1109/TCE.2010.5681095
   Meng F, 2018, IEEE T VEH TECHNOL, V67, P10760, DOI 10.1109/TVT.2018.2868698
   Min Zhou, 2011, Proceedings of the 2011 International Conference on Intelligence Science and Information Engineering (ISIE 2011), P21, DOI 10.1109/ISIE.2011.8
   Mohsen S, 2022, SMART INNOV SYST TEC, V262, P304, DOI 10.1007/978-981-16-6128-0_29
   Mohsen S, 2021, IEEE ACCESS, V9, P150508, DOI 10.1109/ACCESS.2021.3125733
   Mossad OS, 2019, INT WIREL COMMUN, P1644, DOI 10.1109/iwcmc.2019.8766665
   O'Shea TJ, 2018, IEEE J-STSP, V12, P168, DOI 10.1109/JSTSP.2018.2797022
   Palazzi CE, 2006, IEEE T CONSUM ELECTR, V52, P1280, DOI 10.1109/TCE.2006.273146
   Ojeda JMP, 2021, INT J ENG TECHNOL IN, V11, P204, DOI 10.46604/ijeti.2021.7479
   Peng SL, 2019, IEEE T NEUR NET LEAR, V30, P718, DOI 10.1109/TNNLS.2018.2850703
   Prakasam P., 2009, INT J SIGNAL PROCESS, V5, P74
   Rana S, 2017, INT J ENG TECHNOL IN, V7, P11
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Shoaib M, 2015, SENSORS-BASEL, V15, P2059, DOI 10.3390/s150102059
   Su W, 2010, P 2 INT C COMP ENG T, V7, pV7
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang B, 2018, IEEE ACCESS, V6, P15713, DOI 10.1109/ACCESS.2018.2815741
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang Y, 2019, IEEE T VEH TECHNOL, V68, P4074, DOI 10.1109/TVT.2019.2900460
   West NE, 2017, 2017 IEEE INT S DYNA, P6
   Wu P, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2678310
   Yashashwi K, 2019, IEEE WIREL COMMUN LE, V8, P77, DOI 10.1109/LWC.2018.2855749
   Ye H, 2018, IEEE WIREL COMMUN LE, V7, P114, DOI 10.1109/LWC.2017.2757490
   Yilin S, 2022, IET COMMUN, P1
   Zeng Y, 2019, IEEE WIREL COMMUN LE, V8, P929, DOI 10.1109/LWC.2019.2900247
   Zhu Z, 2015, AUTOMATIC MODULATION CLASSIFICATION: PRINCIPLES, ALGORITHMS AND APPLICATIONS, P1
NR 45
TC 3
Z9 3
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7035
EP 7056
DI 10.1007/s11042-023-15814-y
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700004
DA 2024-07-18
ER

PT J
AU Bouzid, SM
   Zribi, CB
AF Bouzid, Saoussen Mathlouthi
   Zribi, Chiraz Ben Othmane
TI Semi-supervised self-training approach for identification of
   non-referential pronouns and ellipsis in arabic texts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Non-referential pronoun; Ellipsis position; Morphologic-syntactic
   features; Semi-supervised learning; Self-training SVM; Arabic
AB The identification of non-referential pronouns and ellipsis position is crucial for the Anaphora and Ellipsis Resolution task which is necessary for many NLP applications. Our paper proposes a joint approach for the classification of non-referential pronouns and elliptical positions in Arabic texts. It presents a novel semi-supervised self-training SVM approach that uses extended linguistic-based and pattern-based features as classification attributes. The self-training approach handles few labeled data and a larger number of unlabeled data. It trains an SVM classifier to predict labels for unlabeled data and selects the most accurate and the most informative ones to extend the small labeled database. Our goal is twofold. Firstly, we propose a generic approach for the identification of both non-referential pronouns and ellipsis, and secondly, we overcome the big problem of the lack of labeled data with pronouns and ellipses links and we extend the labeled dataset. The experiments show that the tenfold cross-validation precision of the proposed approach can reach 99.23% for pronouns and 94.33% for ellipsis.
C1 [Bouzid, Saoussen Mathlouthi; Zribi, Chiraz Ben Othmane] Univ Manouba, Natl Sch Comp Sci RIADI Lab, Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Bouzid, SM (corresponding author), Univ Manouba, Natl Sch Comp Sci RIADI Lab, Manouba 2010, Tunisia.
EM saoussen.mathlouthi@ensi-uma.tn; chiraz.zribi@ensi-uma.tn
CR Abdul-Mageed M., 2011, ACM T ASIAN LANGUAGE, V10, P535, DOI DOI 10.1145/1929908.1929913
   Ben Othmane C., 1998, THESIS ORSAY U PARIS
   Bergsma S, 2008, P ACL 08, P10
   Boyd A., 2005, Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in Natural Language Processing, P40
   Chapelle O., 2006, SEMISUPERVISED LEARN, V2
   Chaumartin F-R, 2007, ACT JOURN RES AN TRA
   Chen C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P320
   Danlos L, 2005, ACTES 12 C TRAIT AUT
   Denber M., 1998, Automatic resolution of anaphora in english
   Eitrich T, 2006, J COMPUT APPL MATH, V196, P425, DOI 10.1016/j.cam.2005.09.009
   Elghamry K, 2007, P 7 C LANGUAGE ENG C
   Evans R., 2001, Literary & Linguistic Computing, V16, P45, DOI 10.1093/llc/16.1.45
   Haddar K., 1999, P VEXTAL SAN SERVOLO, P159
   Hammami SM, 2010, 2010 7 INT C INF SYS, P1
   Hardt D, 1997, COMPUT LINGUIST, V23, P525
   Hasni E., 2009, P 3 INT C ARABIC LAN, P83
   Jaziri R., 2016, RESOLUTION ELLIPSES
   Kobele G, 2012, WIRES COGN SCI, V3, P411, DOI 10.1002/wcs.1168
   Lappin S., 1994, Computational Linguistics, V20, P535
   Lappin S, 1996, P COLING, V96, P351
   Litran J. C. C., 2004, P INT JOINT WORKSHOP, P61
   Maeireizo B, 2004, P ACL INT POST DEM S, P202
   Paice C. D., 1987, Computer Speech and Language, V2, P109, DOI 10.1016/0885-2308(87)90003-9
   Rello L, 2010, THESIS BARCELONA
   Weissenbacher D, 2007, DISCOURSE ANAPHORA A, P145
   Yarowsky D., 1995, 33 ANN M ASS COMPUTA, P189, DOI DOI 10.3115/981658.981684
   Zellama SA, 2017, THESIS U SORBONNE PA
   Zhu X., 2008, COMPUTER SCI T, V1530
NR 28
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15689-z
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300012
DA 2024-07-18
ER

PT J
AU Rao, KV
   Reddy, BVR
AF Rao, K. Venkateswara
   Reddy, B. Venkata Ramana
TI OFML-SMF: Optimal feature selection with hybrid machine learning
   classifier for stock market price forecasting using social media and
   secondary data sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stock investment; Stock price forecasting; Optimal feature selection;
   Movement prediction
ID PREDICTION; INFORMATION
AB Investing in stock market is considered a high-risk monetary motion where investor may not take into version the factor of stock charge fluctuations or destroy their profits without gaining professional knowledge and investment experience. In addition, when working with stock information, people increase the importance of available and self-correcting information, a habit that runs counter to objective and reasonable investment decisions. In recent years, various methods of stock market forecasting have been proposed to enhance the quality and profitability of investor decision making. Recent machine learning models have been able to reduce the risk of stock market forecasting. However, diversity remains a major challenge in developing better learning models and in identifying intellectually valuable traits to further improve diagnosis. In this paper, we propose an optimal characteristic selection with hybrid machine learning classifier for stock market price forecasting (OFML-SMF) using social media and secondary data sources. First, we introduce a multi-objective earthworm optimization (MOEO) algorithm for optimal feature selection among multiple features i.e. called feature optimization which reduces the data dimensionality problem. Second, we develop a hybrid Quantile regression learning based deep belief neural network (HQR-DBNN) to classify the stock market price movement prediction which enhances the statistical metrics. Finally, to appraise the presentation of planned OFML-SMF model through the influential international stock market indices and the performance can be compare with the existing state-of-art models in conditions of accuracy, precision, recall and F-measure.
C1 [Rao, K. Venkateswara] JNTUA, Dept CSE, Ananthapuramu 515002, Andhra Pradesh, India.
   [Reddy, B. Venkata Ramana] Joginpally BR Engn Coll, Dept CSE, Hyderabad 500075, Telangana, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Rao, KV (corresponding author), JNTUA, Dept CSE, Ananthapuramu 515002, Andhra Pradesh, India.
EM vrkatevarapu@gmail.com; busireddy100@gmail.com
CR Aloraini A, 2015, EVOL SYST-GER, V6, P93, DOI 10.1007/s12530-014-9124-y
   Anish CM, 2016, J KOREAN STAT SOC, V45, P64, DOI 10.1016/j.jkss.2015.07.002
   Ao SI, 2011, SOFT COMPUT, V15, P1041, DOI 10.1007/s00500-010-0580-4
   Bahrammirzaee A, 2010, NEURAL COMPUT APPL, V19, P1165, DOI 10.1007/s00521-010-0362-z
   Bitvai Z, 2015, MACH LEARN, V101, P187, DOI 10.1007/s10994-014-5480-x
   Bouktif S, 2020, IEEE ACCESS, V8, P40269, DOI 10.1109/ACCESS.2020.2976725
   Chen MY, 2013, NEURAL COMPUT APPL, V23, pS369, DOI 10.1007/s00521-013-1461-4
   Chen WQ, 2016, SOFT COMPUT, V20, P4575, DOI 10.1007/s00500-015-1764-8
   Chou JS, 2018, IEEE T IND INFORM, V14, P3132, DOI 10.1109/TII.2018.2794389
   Ding YS, 2015, IEEE T NEUR NET LEAR, V26, P2521, DOI 10.1109/TNNLS.2015.2426182
   Dong W., 2003, WUHAN UNIV J NAT SCI, V8, P1126, DOI DOI 10.1007/BF02903685
   El-Alfy ESM, 2015, ARAB J SCI ENG, V40, P303, DOI 10.1007/s13369-014-1438-3
   Galindo J., 2000, Computational Economics, V15, P107, DOI 10.1023/A:1008699112516
   Gavrishchaka VV, 2006, COMPUT MANAG SCI, V3, P147, DOI 10.1007/s10287-005-0005-5
   Hu HP, 2020, IEEE ACCESS, V8, P65891, DOI 10.1109/ACCESS.2020.2985596
   Kim S, 2020, IEEE ACCESS, V8, P111660, DOI 10.1109/ACCESS.2020.3002174
   Li XD, 2016, NEURAL COMPUT APPL, V27, P67, DOI 10.1007/s00521-014-1550-z
   Maragoudakis M, 2016, COMPUT ECON, V47, P589, DOI 10.1007/s10614-015-9492-9
   Minh DL, 2018, IEEE ACCESS, V6, P55392, DOI 10.1109/ACCESS.2018.2868970
   Nabipour M, 2020, IEEE ACCESS, V8, P150199, DOI 10.1109/ACCESS.2020.3015966
   Nousi P, 2019, IEEE ACCESS, V7, P64722, DOI 10.1109/ACCESS.2019.2916793
   Nti IK, 2020, J BIG DATA-GER, V7, DOI [10.1186/s43067-020-00021-8, 10.1186/s40537-020-00299-5]
   Qian B, 2007, APPL INTELL, V26, P25, DOI 10.1007/s10489-006-0001-7
   Qiao Qifeng, 2016, Environment Systems & Decisions, V36, P109, DOI 10.1007/s10669-016-9601-x
   Shangkun Deng, 2015, Computational Economics, V45, P49, DOI 10.1007/s10614-013-9407-6
   Shen JY, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00333-6
   Shi L, 2019, IEEE T KNOWL DATA EN, V31, P1094, DOI 10.1109/TKDE.2018.2854193
   Tan A, 2008, APPL INTELL, V29, P116, DOI 10.1007/s10489-007-0055-1
   Thenmozhi M, 2016, NEURAL COMPUT APPL, V27, P805, DOI 10.1007/s00521-015-1897-9
   Wang L, 2010, ANN OPER RES, V174, P103, DOI 10.1007/s10479-008-0357-7
   Wen M, 2019, IEEE ACCESS, V7, P28299, DOI 10.1109/ACCESS.2019.2901842
   Yang C, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2746845
   Yuan XH, 2020, IEEE ACCESS, V8, P22672, DOI 10.1109/ACCESS.2020.2969293
NR 33
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15461-3
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000003
DA 2024-07-18
ER

PT J
AU Yang, YG
   Wang, ZJ
   Wang, BP
   Zhou, YH
   Shi, WM
   Liao, X
AF Yang, Yu-Guang
   Wang, Zi-Jia
   Wang, Bao-Pu
   Zhou, Yi-Hua
   Shi, Wei-Min
   Liao, Xin
TI A new visually meaningful double-image encryption algorithm combining 2D
   compressive sensing with fractional-order chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image encryption; Double-image encryption; Compressive sensing;
   Kronecker product; Fractional-order chaotic system
ID SPARSE DECOMPOSITION; SIGNAL RECOVERY; STEGANOGRAPHY; SECRET
AB A visually meaningful double-image image encryption algorithm is proposed based on a fractional-order chaotic system combined with 2D compressive sensing (CS). Specifically, in the pre-encryption phase, a 2D discrete wavelet transform (DWT) is performed on two grayscale images followed by a measurement using 2D CS. The measurement matrices are generated by using the fractional-chaotic system and Kronecker product (KP). Then, a Zigzag confusion operation is performed on the two generated measurement matrices after quantization to obtain two secret images. A new measurement matrix optimization algorithm is presented to optimize the high-dimensional measurement matrix. In the embedding phase, a new repairable embedding algorithm is designed which combines matrix encoding and 2(K) correction algorithm. The loss of the carrier image quality is effectively reduced while the robustness of the cipher image is enhanced. It is more suitable for practical applications. Numerical simulation and performance analyses show that the average PSNR value of visually meaningful cipher images is 41.7 dB, and the PSNR value of the reconstructed image is 1 similar to 3 dB higher than those in other studies. In addition, the proposed algorithm is also superior to some recently proposed algorithms in efficiency, security, and robustness.
C1 [Yang, Yu-Guang; Wang, Zi-Jia; Wang, Bao-Pu; Zhou, Yi-Hua; Shi, Wei-Min] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Yang, Yu-Guang] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Beijing University of Technology; Hunan University
RP Yang, YG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.; Yang, YG (corresponding author), Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
EM yangyang7357@bjut.edu.cn
OI Yang, Yuguang/0000-0002-4040-2448
FU National Natural Science Foundation of China [62071015, 62171264,
   61972142]
FX AcknowledgmentsThis work was supported by the National Natural Science
   Foundation of China (Grant Nos. 62071015, 62171264, 61972142).
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Armijo-Correa JO, 2020, OPT LASER TECHNOL, V127, DOI 10.1016/j.optlastec.2020.106165
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen E, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500468
   Chen G, 2014, SIGNAL PROCESS, V104, P15, DOI 10.1016/j.sigpro.2014.03.039
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Crandall R., 1998, SOME NOTES STEGANOGR
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eshaghi S, 2020, MATH COMPUT SIMULAT, V172, P321, DOI 10.1016/j.matcom.2019.11.009
   Fang Y, 2012, SCI CHINA INFORM SCI, V55, P889, DOI 10.1007/s11432-012-4551-5
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Ghaffari A, 2009, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.2009.4960294
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hu WW, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-2579-9
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   Lin W.J., 2011, J NEW IND, V1, P78
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Musanna F, 2020, MULTIMED TOOLS APPL, V79, P25115, DOI 10.1007/s11042-020-09034-x
   [彭玉楼 Peng Yulou], 2012, [仪器仪表学报, Chinese Journal of Scientific Instrument], V33, P2655
   Ping P, 2019, IEEE ACCESS, V7, P170168, DOI 10.1109/ACCESS.2019.2955570
   Rong Huang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P105, DOI 10.1109/IIHMSP.2011.53
   Tian Xiangling, 2015, Electronic Science and Technology, V28, P102, DOI 10.16180/j.cnki.issn1007-7820.2015.08.030
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Van Loan CF, 2000, J COMPUT APPL MATH, V123, P85, DOI 10.1016/S0377-0427(00)00393-9
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang XY, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107316
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wang YT, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164685
   Wei JJ, 2021, INT CONF SOFTW ENG, P72, DOI 10.1109/ICSESS52187.2021.9522343
   Wen WY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107580
   Xiao D, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107077
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P10835, DOI 10.1007/s11042-022-13689-z
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P22033, DOI 10.1007/s11042-021-11656-8
   Yang YG, 2021, INFORM SCIENCES, V580, P174, DOI 10.1016/j.ins.2021.08.073
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P9055, DOI 10.1007/s11042-020-10149-4
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yu JG, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P563, DOI 10.1109/ITNG.2008.101
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang HT, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413300140
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
NR 59
TC 1
Z9 1
U1 11
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15662-w
EA MAY 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5VQ1
UT WOS:000989835300003
DA 2024-07-18
ER

PT J
AU Wang, LZ
   Li, ZH
   Liu, FG
AF Wang, Luzi
   Li, Zhuanghui
   Liu, Fengge
TI Objective detection of shear distortion of low-light-level image
   intensifier based on global scanning and image patch edge feature
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light-level image intensifier; Optical instrument measurement; Image
   processing; Feature detection
AB Shear distortion is the defect brought in the manufacturing stage of optical fiber panel of low-light-level (LLL) image intensifier. The traditional detection method of such defects is purely based on visual observation, so the recording measure is rough and the amount of manual intervention is large. According to the above facts, an objective detection method of shear distortion of LLL image intensifier based on global scanning and image patch edge feature analysis is proposed. Firstly, the inclination of parallel lines is calculated to realize the normalized rotation of the target image; Then, the effective area is scanned globally by means of spatial kernel for local defect detection. The image in the kernel is processed to retain only the edge features, and then the proposed shear distortion detection strategy is applied to each edge in the processed image. Finally, the distortion points in the local image are restored to the target image through the image patch spatial coordinates. To substantiate the performance of the proposed method, a series of image tubes with diverse degrees of shear distortion are put into experiments, and the relevant detection technologies are used as the comparison. It yields the conclusion that the proposed method is robust to the background noise, illumination change and image defects to some extent, and is superior to the relevant detection technology in overall performance. Compared with the traditional visual inspection method, this method not only standardizes the recording measure of test results, but also has better time stability.
C1 [Wang, Luzi; Li, Zhuanghui] Nanyang Inst Technol, Sch Informat Engn, Nanyang 473004, Henan, Peoples R China.
   [Liu, Fengge] North Night Vis Technol Co Ltd, Kunming 650114, Yunnan, Peoples R China.
C3 Nanyang Institute of Technology
RP Wang, LZ (corresponding author), Nanyang Inst Technol, Sch Informat Engn, Nanyang 473004, Henan, Peoples R China.
EM 921065900@qq.com
CR [Anonymous], 2018, IEEE ACCESS
   [Anonymous], 1994, GEN SPEC IM INT ASS
   [Anonymous], 1992, WJ
   Bosch LA, 2000, IMAGE INTENSIFIER TU
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Gonzalez RC., 2010, DIGITAL IMAGE PROCES
   He B., 2004, VISUAL C DIGITAL IMA
   Ke-Cong A.I., 2006, J APPL OPT, V27, P303
   Luzi W, 2021, APPL OPTICS, V60, P6888, DOI 10.1364/AO.427353
   Mirzu M, 1998, PROC SPIE, V3405, P926, DOI 10.1117/12.312690
   Oppenheim A. V., 1997, SIGNALS SYSTEMS
   Palm W J., 2008, CONCISE INTRO MATLAB
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Xiang SM, 1999, PRINCIPLE PHOTOELECT, P368
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 15
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15269-1
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100010
DA 2024-07-18
ER

PT J
AU Li, M
   Zeng, LL
   Zhao, L
   Wang, YW
   Liu, GQ
AF Li, Ming
   Zeng, Leilei
   Zhao, Le
   Wang, Yuwen
   Liu, Guoqi
TI Multiparty watermarking protocol based on blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital watermark; Watermark protocol; Cloud platform; Blockchain;
   Copyright protection
AB With the development of multimedia and the Internet, the problem of multimedia copyright infringement has become more and more serious. The combination of digital watermark and security protocol plays a vital role in copyright protection of multimedia in the up-to-date open network environment. Most of the existing schemes involve trusted third parties and arbitration institutions, but they are not usually credible. This paper proposes a new watermarking protocol with multiple parties based on the blockchain. The protocol involves the buyer, the seller, the cloud platform and the blockchain. In the protocol, the certificateless secret key negotiation between the buyer and the seller is utilized to avoid "Man-in-the-middle Attack", and the cloud platform is used to perform homomorphic calculations and watermark embedding operation. By using the characteristics of the blockchain such as non-tamperability and traceability, the security and fairness of the protocol can be ensured.
C1 [Li, Ming; Wang, Yuwen; Liu, Guoqi] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Peoples R China.
   [Li, Ming; Liu, Guoqi] Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan, Peoples R China.
   [Zeng, Leilei; Zhao, Le] Software Engn Inst Guangzhou, Dept Network Technol, Guangzhou 510990, Peoples R China.
C3 Henan Normal University
RP Li, M (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Peoples R China.; Li, M (corresponding author), Engn Lab Intelligence Business & Internet Things, Xinxiang, Henan, Peoples R China.
EM liming@htu.edu.cn; 86926491@qq.com; 1369905402@qq.com; 609373620@qq.com;
   liuguoqi080408@163.com
RI Li, Ming/Q-6532-2016
FU Science and Technology Research Project of Henan Province [212102210413,
   222102210029]; Key Program of Higher Education Institutions of Henan
   Province [23A520009]; Curriculum Reform Research Project of Teacher
   Education of Henan Province [2022-JSJYYB-003]; National Natural Science
   Foundation of China [61901160]; Special Project of Smart Teaching for
   Ordinary Undergraduate Colleges and Universities in Henan Province
FX This work was supported by the Science and Technology Research Project
   of Henan Province (Grant No. 212102210413, 222102210029), the Key
   Program of Higher Education Institutions of Henan Province (23A520009),
   the Special Project of Smart Teaching for Ordinary Undergraduate
   Colleges and Universities in Henan Province, the Curriculum Reform
   Research Project of Teacher Education of Henan Province
   (2022-JSJYYB-003), and the National Natural Science Foundation of China
   (Grant No. 61901160).
CR [Anonymous], 2012, INT J NETW SECUR
   Chang CC, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1779
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Fan CI, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1035
   Ferdous MS, 2021, J NETW COMPUT APPL, V182, DOI 10.1016/j.jnca.2021.103035
   Frattolillo F, 2007, IEEE T INF FOREN SEC, V2, P350, DOI 10.1109/TIFS.2007.903849
   Frattolillo F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217746
   Frattolillo F, 2019, J INF SECUR APPL, V47, P246, DOI 10.1016/j.jisa.2019.05.011
   Frattolillo F, 2018, INT J INF SECUR, V17, P587, DOI 10.1007/s10207-017-0386-9
   Frattolillo F, 2016, ACM T WEB, V10, DOI 10.1145/2856036
   Hu DF, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P105, DOI 10.1109/MINES.2009.132
   Jelly_lzy, 2019, 2 KEY NEGOTIATION EX
   Kamel I, 2009, COMPUT SECUR, V28, P395, DOI 10.1016/j.cose.2009.01.007
   Khan A, 2016, J NETW COMPUT APPL, V75, P317, DOI 10.1016/j.jnca.2016.08.026
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Vecchiola C., 2009, High speed and large scale scientific computing p, P267, DOI DOI 10.3233/978-1-60750-073-5-267
   Xiang YX, 2021, J NETW COMPUT APPL, V176, DOI 10.1016/j.jnca.2020.102953
   Zhang J., 2006, IEE Proceedings-Information Security, V153, P15, DOI 10.1049/ip-ifs:20055069
NR 19
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15691-5
EA MAY 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100001
DA 2024-07-18
ER

PT J
AU Sime, DM
   Wang, GT
   Zeng, Z
   Peng, B
AF Sime, Dejene M.
   Wang, Guotai
   Zeng, Zhi
   Peng, Bei
TI Deep learning-based automated steel surface defect segmentation: a
   comparative experimental study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine vision; Automated inspection; Deep learning; Defect segmentation
ID CLASSIFICATION
AB The use of machine vision and deep learning for intelligent industrial inspection has become increasingly important in automating the production processes. Despite the fact that machine vision approaches are used for industrial inspection, deep learning-based defect segmentation has not been widely studied. While state-of-the-art segmentation methods are often tuned for a specific purpose, extending them to unknown sets or other datasets, such as defect segmentation datasets, require further analysis. In addition, recent contributions and improvements in image segmentation methods have not been extensively investigated for defect segmentation. To address these problems, we conducted a comparative experimental study on several recent state-of-the-art deep learning-based segmentation methods for steel surface defect segmentation and evaluated them on the basis of segmentation performance, processing time, and computational complexity using two public datasets, NEU-Seg and Severstal Steel Defect Detection (SSDD). In addition we proposed and trained a hybrid transformer-based encoder with CNN-based decoder head and achieved state-of-the-art results, a Dice score of 95.22% (NEU-Seg) and 95.55% (SSDD).
C1 [Sime, Dejene M.; Wang, Guotai; Zeng, Zhi; Peng, Bei] Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Peng, B (corresponding author), Univ Elect Sci & Technol China, Sch Mech & Elect Engn, Chengdu 611731, Sichuan, Peoples R China.
EM djene.mengistu@std.uestc.edu.cn; guotai.wang@uestc.edu.cn;
   zhizeng@uestc.edu.cn; beipeng@uestc.edu.cn
RI Sime, Dejene Mengistu/KBA-6656-2024
OI Sime, Dejene Mengistu/0000-0002-7265-5765
FU Natural Science Foundation of China [51975107, 52175292]; Science and
   Technology Project of Sichuan Province [2020ZDZX0015]
FX AcknowledgmentsThis work was supported by Natural Science Foundation of
   China (No. 51975107, No.52175292), Science and Technology Project of
   Sichuan Province (No. 2020ZDZX0015).
CR Abdou MA, 2022, NEURAL COMPUT APPL, V34, P5791, DOI 10.1007/s00521-022-06960-9
   Abu M, 2021, J PHYS C SERIES
   Ahmed KR, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010544
   Badrinarayanan V, 2016, Arxiv, DOI [arXiv:1511.00561, DOI 10.48550/ARXIV.1511.00561]
   Bozkurt F, 2023, MULTIMED TOOLS APPL, V82, P18985, DOI 10.1007/s11042-022-14095-1
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Damacharla P., 2021, 2021 INT C APPL ARTI, DOI DOI 10.1109/ICAPAI49758.2021.9462060
   Demir K, 2023, NEURAL COMPUT APPL, V35, P8389, DOI 10.1007/s00521-022-08112-5
   Dong HW, 2020, IEEE T IND INFORM, V16, P7448, DOI 10.1109/TII.2019.2958826
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elizar E, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22197384
   Fu GZ, 2019, OPT LASER ENG, V121, P397, DOI 10.1016/j.optlaseng.2019.05.005
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao YP, 2020, ROBOT CIM-INT MANUF, V61, DOI 10.1016/j.rcim.2019.101825
   Hao RY, 2021, J INTELL MANUF, V32, P1833, DOI 10.1007/s10845-020-01670-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404
   Huang YB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071974
   Huang Z, 2021, MATER LETT, V301, DOI 10.1016/j.matlet.2021.130271
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Liu Z, 2022, ARAB J SCI ENG, P1
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, IEEE T INSTRUM MEAS, V69, P9681, DOI 10.1109/TIM.2020.3001695
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo QW, 2020, IEEE T INSTRUM MEAS, V69, P9329, DOI 10.1109/TIM.2020.3030167
   Luo QW, 2019, IEEE ACCESS, V7, P23488, DOI 10.1109/ACCESS.2019.2898215
   Ma JX, 2018, IEEE IMAGE PROC, P1508, DOI 10.1109/ICIP.2018.8451351
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Prappacher N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093290
   Qian K, 2019, ICVIP 2019: PROCEEDINGS OF 2019 3RD INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING, P42, DOI 10.1145/3376067.3376113
   Ren ZH, 2022, INT J PR ENG MAN-GT, V9, P661
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Severstal, 2019, SEV STEEL DEF DET KA
   Sime DM, 2023, IEEE T IND INFORM, V19, P9535, DOI 10.1109/TII.2022.3230785
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suvdaa B., 2012, Int. J. Softw. Eng. Its Appl, V6, P161
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang B, 2022, IET IMAGE P
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JQ, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac6fb2
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   WANIN M, 1993, J PHYS IV, V3, P1101, DOI 10.1051/jp4:19937172
   Wu HK, 2019, Arxiv, DOI [arXiv:1903.11816, 10.48550/arXiv.1903.11816]
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xie E, 2021, 35 C NEUR INF PROC S, P14
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu R, 2022, ADV ENG INFORM, V52, DOI 10.1016/j.aei.2022.101566
   Yan HT, 2023, Arxiv, DOI arXiv:2201.01615
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuan YH, 2021, INT J COMPUT VISION, V129, P2375, DOI 10.1007/s11263-021-01465-9
   Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang QL, 2021, ADV NEUR IN, V34
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zheng XQ, 2021, INT J ADV MANUF TECH, V113, P35, DOI 10.1007/s00170-021-06592-8
NR 68
TC 3
Z9 3
U1 17
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15307-y
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700010
DA 2024-07-18
ER

PT J
AU Wang, HT
   Zhou, SB
   Xu, XZ
   Zhang, GP
AF Wang, Haotian
   Zhou, Shibin
   Xu, Xinzheng
   Zhang, Guopeng
TI TPN: Triple parts network for few-shot instance segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Object detection; Instance segmentation
AB Few-shot instance segmentation aims to segment unseen objects in a so-called query image, given only one close-up illustration named support image. Recently, many few-shot instance segmentation methods are based on Mask R-CNN, and do not take advantage of the information embedding in support images. In this work, we propose Triple Parts Network (TPN) based on Mask R-CNN for few-shot instance segmentation consisting of three key modules, i.e., Attention Fusion Module (AFM), Cosine Similarity based Classifier with Circle Loss (CSC), and Cross-Local Module (CLM). AFM generates proposals targeting at the object in the support image. CSC uses cosine similarity with circle loss to classify objects. CLM is applied to the mask branch to establish a full relation between support feature maps and query feature maps. The experiments are conducted on the Microsoft COCO and PASCAL VOC benchmarks, and the results show that our TPN has better performance than other state-of-the-art methods.
C1 [Wang, Haotian; Zhou, Shibin; Xu, Xinzheng; Zhang, Guopeng] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Peoples R China.
C3 China University of Mining & Technology
RP Zhou, SB (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Peoples R China.
EM whtyl@cumt.edu.cn; zhoushibin@cumt.edu.cn; xxzheng@cumt.edu.cn;
   gpzhang@cumt.edu.cn
FU National Natural Science Foundation of China [61971421, 61976217]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant nos. 61971421 and 61976217).
CR Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305
   Bolya D, 2022, IEEE T PATTERN ANAL, V44, P1108, DOI 10.1109/TPAMI.2020.3014297
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Chen H, 2018, AAAI CONF ARTIF INTE, P2836
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Choi D, 2022, INT C LEARN REPR
   De Brabandere Bert, 2017, Semantic Instance Segmentation with a Discriminative Loss Function
   Doersch C., 2020, NEURIPS, V33, P21981
   Dong N., 2018, BMVC, V4, P4
   Dong XY, 2019, IEEE T PATTERN ANAL, V41, P1641, DOI 10.1109/TPAMI.2018.2844853
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Fan Z., 2020, P IEEE CVF C COMP VI, P9172, DOI [10.1109/cvpr42600.2020.00919, DOI 10.1109/CVPR42600.2020.00919]
   Finn C, 2017, PR MACH LEARN RES, V70
   Ganea DA, 2021, PROC CVPR IEEE, P1185, DOI 10.1109/CVPR46437.2021.00124
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2020, IEEE T INSTRUM MEAS, V69, P660, DOI 10.1109/TIM.2019.2905904
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kang BY, 2019, IEEE I CONF COMP VIS, P8419, DOI 10.1109/ICCV.2019.00851
   Karlinsky L, 2019, PROC CVPR IEEE, P5192, DOI 10.1109/CVPR.2019.00534
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Michaelis C., 2018, ARXIV
   Nguyen K, 2021, PROC CVPR IEEE, P11094, DOI 10.1109/CVPR46437.2021.01095
   Rakelly K., 2018, P ICLR WORKSH
   Ravi S., 2016, INT C LEARNING REPRE
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santoro A., 2016, INT C MACH LEARN, P1842, DOI DOI 10.5555/3045390.3045585
   Satorras V.G., 2018, P INT C LEARN REPR V
   Shaban A, 2017, ARXIV PREPRINT ARXIV, DOI 10.5244/C.31.167
   Snell J, 2017, ADV NEUR IN, V30
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang X., 2020, Advances in Neural information processing systems, V33, P17721, DOI DOI 10.48550/ARXIV.2003.10152
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Yan XP, 2019, IEEE I CONF COMP VIS, P9576, DOI 10.1109/ICCV.2019.00967
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
NR 49
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46439
EP 46455
DI 10.1007/s11042-023-15624-2
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986346600012
DA 2024-07-18
ER

PT J
AU Wu, DY
   Zhang, BH
   Lu, XQ
   Li, YX
   Gu, Y
   Li, JJ
   Ren, GY
AF Wu, Dongyang
   Zhang, Baohua
   Lu, Xiaoqi
   Li, Yongxiang
   Gu, Yu
   Li, Jianjun
   Ren, Guoyin
TI A domain generalization pedestrian re-identification algorithm based on
   meta-graph aware
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person re-identification; Domain generalization; Meta-Learning; Graph
   Aware; Inter-domain differences
AB Domain generalization is a key problem to solve the difference between the source domain and the target domain. This paper proposes a person re-identification algorithm based on meta-graph aware (Meta-GA) under the framework of meta-learning, which includes two stages: meta-global aware (M-GA) and meta-graph relationship sampling (M-GRS). In order to reduce inter-domain differences, a meta-global aware mechanism is proposed to construct an interaction model (paired relationship) in the meta training domain by stacking affinity models and dividing saliency features between the pedestrians. Then a learning interaction model is used to construct a global knowledge map to classify and weighted the structural information. In order to accurately learn the discriminative features, a meta-graph relationship sampling model is proposed. The similarity of the pedestrian cross-domain features between the domains is used to construct a feature relationship map between the adjacent classes. To enhance domain invariant features and improve the model generalization, positive samples are sampled cyclically and negative samples are sampled randomly. On this basis, the gradient norm is trimmed to prevent the model overfitting. The experimental results show that the robustness and accuracy of the proposed algorithm have been significantly improved. In the Market-1501 to DukeMTMC-ReID experiment, Rank-1 and mAP increased by 5.25% and 3.73%, respectively. In the DukeMTMC-ReID to Market-1501 experiment, Rank-1 and mAP increased by 1.73% and 0.93%, respectively, which are significantly superior to those of the recent representative algorithms.
C1 [Wu, Dongyang; Zhang, Baohua; Gu, Yu; Li, Jianjun; Ren, Guoyin] Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.
   [Lu, Xiaoqi] Mongolia Ind Univ, Sch Informat Engn, Hohhot 010051, Inner Mongolia, Peoples R China.
   [Li, Yongxiang; Li, Jianjun] Inner Mongolia Agr Univ, Coll Energy & Transportat Engn, Hohhot 010051, Inner Mongolia, Peoples R China.
C3 Inner Mongolia University of Science & Technology; Inner Mongolia
   Agricultural University
RP Wu, DY; Zhang, BH (corresponding author), Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Inner Mongolia, Peoples R China.
EM wdy_99@sina.cn; zbh_wj2004@imust.edu.cn; lvxiaoqi1881@imust.edu.cn;
   zoutaoyun221@yeah.net; Guyu20100232@imust.edu.cn; xidianjj@163.com;
   renguoyin@imust.cn
RI lu, xiaoqi/G-3472-2013; li, yongxiang/GPW-6930-2022
FU National Natural Science Foundation of China [61962046, 62262048,
   62001255, 62066036, 61841204]; Inner Mongolia Science and Technology
   Plan Project [2020GG0315, 2021GG0082]; Inner Mongolia Natural Science
   Foundation [2022MS06017, 2019MS06003, 2018MS06018]; Central Government
   Guides Local Science and Technology Development Fund Project of China
   [2021ZY0004]; Inner Mongolia College Science and Technology Research
   Project [NJZY145]; Chunhui Program of the Ministry of Education of the
   People's Republic of China [1383]; Program for Young Talents of Science
   and Technology in Universities of Inner Mongolia Autonomous Region
   [NJYT23057]; Fundamental Research Funds for Inner Mongolia University of
   Science Technology [019, 042]
FX The authors thank the anonymous reviewers and editors for the very
   constructive comments. This work was supported by the National Natural
   Science Foundation of China (61962046, 62262048, 62001255, 62066036,
   61841204); Inner Mongolia Science and Technology Plan Project
   (2020GG0315, 2021GG0082); Inner Mongolia Natural Science Foundation
   (2022MS06017, 2019MS06003, 2018MS06018); The Central Government Guides
   Local Science and Technology Development Fund Project of China (grant
   number: 2021ZY0004); Inner Mongolia College Science and Technology
   Research Project (grant numbers: NJZY145); Chunhui Program of the
   Ministry of Education of the People's Republic of China (1383). Program
   for Young Talents of Science and Technology in Universities of Inner
   Mongolia Autonomous Region (grant number: NJYT23057); Fundamental
   Research Funds for Inner Mongolia University of Science & Technology
   (grant number: 019, 042).
CR [Anonymous], 2019, PR MACH LEARN RES
   Bai ZC, 2021, PROC CVPR IEEE, P12909, DOI 10.1109/CVPR46437.2021.01272
   Chen KY, 2022, NEUROCOMPUTING, V467, P418, DOI 10.1016/j.neucom.2021.09.046
   Choi S, 2021, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR46437.2021.00343
   Dai YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11844, DOI 10.1109/ICCV48922.2021.01165
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang W, 2022, MULTIMED TOOLS APPL, V81, P36551, DOI 10.1007/s11042-022-13526-3
   Gong X, 2022, IEEE T MULTIMEDIA, V24, P217, DOI 10.1109/TMM.2021.3050082
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Guo YC, 2022, Arxiv, DOI arXiv:2210.10409
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Li YY, 2022, IEEE T MULTIMEDIA, V24, P415, DOI 10.1109/TMM.2021.3052354
   [梁文琦 Liang Wenqi], 2022, [自动化学报, Acta Automatica Sinica], V48, P103
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Pandey P, 2021, PROC CVPR IEEE, P12919, DOI 10.1109/CVPR46437.2021.01273
   Peng D, 2022, CVPR, P2594
   Qi L, 2022, IEEE T MULTIMEDIA
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Shengcai Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P456, DOI 10.1007/978-3-030-58621-8_27
   Wan Q, 2022, COMPLEX INTELL SYST, V8, P5377, DOI 10.1007/s40747-022-00762-1
   Wang HQ, 2023, ARTIF INTELL-AMST, V317, DOI 10.1016/j.artint.2023.103875
   Wang H, 2020, IEEE ACCESS, V8, P5339, DOI 10.1109/ACCESS.2019.2962581
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   Wang WJ, 2022, PROC CVPR IEEE, P7055, DOI 10.1109/CVPR52688.2022.00693
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YF, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2595, DOI 10.1145/3474085.3475434
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xu J, 2022, WORLD WIDE WEB, P1
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yu J., 2022, P IEEECVF C COMPUTER, p17 834
   Zhang J, 2022, LECT NOTES COMPUT SC, V13687, P161, DOI 10.1007/978-3-031-19812-0_10
   Zhang S, 2022, MULTIMED TOOLS APPL, V81, P39981, DOI 10.1007/s11042-022-13090-w
   Zhang TY, 2021, PROC CVPR IEEE, P11501, DOI 10.1109/CVPR46437.2021.01134
   Zhang Y., 2022, P IEEE CVF C COMP VI, P8035
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
   Zhou Chuanbo, 2022, ICIGP 2022: 2022 the 5th International Conference on Image and Graphics Processing (ICIGP), P132, DOI 10.1145/3512388.3512450
NR 43
TC 0
Z9 0
U1 10
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 12
PY 2023
DI 10.1007/s11042-023-15765-4
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G0SA7
UT WOS:000986346600003
DA 2024-07-18
ER

PT J
AU Bhola, G
   Vishwakarma, DK
AF Bhola, Geetanjali
   Vishwakarma, Dinesh Kumar
TI A review of vision-based indoor HAR: state-of-the-art, challenges, and
   future prospects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Human activity recognition; Assistive technology; Assisted living;
   Elderly care; Indoor activity; Patient care; Real-time HAR
ID HUMAN ACTIVITY RECOGNITION; HUMAN MOTION ANALYSIS; FALL DETECTION;
   VIDEO; MODEL; SYSTEM; IMAGE; POSE; REDUCTION; SEQUENCES
AB With the advent of technology, we are getting more comfortable with the use of gadgets, cameras, etc., and find Artificial Intelligence as an integral part of most of the tasks we perform throughout the day. In such a scenario, the use of cameras and vision-based sensors comes as an escape from many real-time problems and challenges. One major application of these vision-based systems is Indoor Human Activity Recognition (HAR) which serves in a variety of scenarios ranging from smart homes, elderly care, assisted living, and human behavior pattern analysis for identifying any abnormal behavior to abnormal activity recognition like falling, slipping, domestic violence, etc. The effect of HAR in real time has made the area of indoor activity recognition a more explored zone by the industrial segment to attract users with their products in multiple domains. Hence, considering these aspects of HAR, this work proposes a detailed survey on indoor HAR. Through this work, we have highlighted the recent methodologies and their performance in the field of indoor activity recognition. We have also discussed- the challenges, detailed study of approaches with real-world applications of indoor-HAR, datasets available for indoor activity, and their technical details in this work. We have proposed a taxonomy for indoor HAR and highlighted the state-of-the-art and future prospects by mentioning the research gaps and the shortcomings of recent surveys with respect to our work.
C1 [Bhola, Geetanjali; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 11042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 11042, India.
EM dvishwakarma@gmail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018; Arjmandmanesh,
   Saba/AGA-7907-2022; Bhola, Geetanjali/KRQ-7812-2024
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047; 
CR Abdel-Basset M, 2021, ANN OPER RES, DOI 10.1007/s10479-021-04164-3
   Abdelgawwad A, 2021, IEEE ACCESS, V9, P103393, DOI 10.1109/ACCESS.2021.3098951
   Abdul Lateef Haroon PS., 2021, J. Robot. Control (JRC), V2, P395, DOI 10.18196/JRC.25113
   Agarwal P, 2020, PROCEDIA COMPUT SCI, V167, P2364, DOI 10.1016/j.procs.2020.03.289
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Almaslukh B, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113726
   Amirbandi EJ, 2016, 2016 1ST CONFERENCE ON SWARM INTELLIGENCE AND EVOLUTIONARY COMPUTATION (CSIEC 2016), P160, DOI 10.1109/CSIEC.2016.7482122
   [Anonymous], REAL TIME DETECTION
   [Anonymous], P INT C INF TECHN CO, V2, DOI [10.5555/977403.978309, DOI 10.5555/977403.978309]
   [Anonymous], HUMAN ACTIVITY RECOG
   [Anonymous], CHILD MALTREATMENT
   [Anonymous], WHO Global Report on Falls Prevention in Older Age
   [Anonymous], ?About us"
   Antipov G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1263, DOI 10.1145/2733373.2806332
   Arifoglu D, 2019, ARTIF INTELL MED, V94, P88, DOI 10.1016/j.artmed.2019.01.005
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF COMP V, P3179, DOI 10.1109/ICCVW.2017.376
   Ashraf I, 2021, INT J MACH LEARN CYB, V12, P3203, DOI 10.1007/s13042-021-01279-8
   Babiker Mohanad., 2017, 2017 IEEE 4 INT C SM, P1, DOI DOI 10.1109/ICSIMA.2017.8312024
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Basly Hend, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P271, DOI 10.1007/978-3-030-51935-3_29
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Bhat O, 2022, EVOL SYST-GER, V13, P159, DOI 10.1007/s12530-021-09373-6
   Bhola G, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1101, DOI [10.1109/ICICCS48265.2020.9121061, 10.1109/iciccs48265.2020.9121061]
   Bibbo L, INTEGRATED SYSTEM IN
   Blank M, ACTIONS SPACE TIME S
   Bo L., 2013, Unsupervised Feature Learning for RGB-D Based Object Recognition, P387, DOI 10.1007/978-3-319- 00065-7_27
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bocus MJ, 2021, Arxiv, DOI arXiv:2110.04239
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Bux A, 2017, ADV INTELL SYST COMP, V513, P341, DOI 10.1007/978-3-319-46562-3_23
   Buzzelli M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010374
   Capela NA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124414
   Cardone G, 2014, IEEE SENS J, V14, DOI 10.1109/JSEN.2014.2344023
   Casale P, 2011, LECT NOTES COMPUT SC, V6669, P289
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen YL, 2016, NEUROCOMPUTING, V210, P294, DOI 10.1016/j.neucom.2015.11.126
   Chen YF, 2017, IEEE ACCESS, V5, P3095, DOI 10.1109/ACCESS.2017.2676168
   Chen ZH, 2020, IEEE T INSTRUM MEAS, V69, P3992, DOI 10.1109/TIM.2019.2945467
   Chen ZH, 2018, IEEE T IND INFORM, V14, P4334, DOI 10.1109/TII.2018.2789925
   Cheng GC, 2015, Arxiv, DOI arXiv:1501.05964
   Cheng XL, 2017, INT CONF ORANGE TECH, P7, DOI 10.1109/ICOT.2017.8336075
   Chua CS, 2002, IMAGE VISION COMPUT, V20, P191, DOI 10.1016/S0262-8856(01)00094-4
   Chung You-shin, 2021, [Journal of Advanced Navigation Technology, 한국항행학회논문지], V25, P299
   Dai R, 2023, IEEE T PATTERN ANAL, V45, P2533, DOI 10.1109/TPAMI.2022.3169976
   Damasevicius R, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/4073584
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Dang XC, 2018, EURASIP J WIREL COMM, DOI 10.1186/03638-018-1230-2
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Dash SCB, 2021, SOFT COMPUT, V25, P13079, DOI 10.1007/s00500-021-06149-7
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Dollar P., 2005, Behavior recognition via sparse spatiotemporal feature
   Du YT, 2007, IEEE SIGNAL PROC LET, V14, P952, DOI 10.1109/LSP.2007.908035
   Duan H, TRB NOVEL TRIPLET RE
   Duong TV, HUMAN BEHAV RECOGNIT
   Duong TV, 2005, ACTIVITY RECOGNITION
   Edwards M, 2016, COMPUT VIS IMAGE UND, V144, P73, DOI 10.1016/j.cviu.2015.10.010
   El Moudden I., 2016, Contemporary Engineering Sciences, V9, P1031, DOI 10.12988/ces.2016.67119
   Espinosa R, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103520
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Foroughi Homa, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1499, DOI 10.1109/ICOSP.2008.4697417
   Foroughi H, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P413, DOI 10.1109/ICVGIP.2008.49
   Foroughi H, 2008, INT C INTELL COMP CO, P83, DOI 10.1109/ICCP.2008.4648358
   Franco A, 2020, PATTERN RECOGN LETT, V131, P293, DOI 10.1016/j.patrec.2020.01.010
   Fu BY, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020024
   Gao J, 2004, INT C PATT RECOG, P915, DOI 10.1109/ICPR.2004.1334408
   Ghali A, 2003, P SOC PHOTO-OPT INS, V5150, P980, DOI 10.1117/12.503470
   Ghazal S, 2019, IET IMAGE PROCESS, V13, P2572, DOI 10.1049/iet-ipr.2019.0030
   Ghorbani S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253157
   Goffredo M, 2009, IEEE T INF TECHNOL B, V13, P207, DOI 10.1109/TITB.2008.2007960
   Gu FQ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3472290
   Gu Y, 2016, IEEE INTERNET THINGS, V3, P796, DOI 10.1109/JIOT.2015.2511805
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Gupta Jay Prakash, 2013, International Journal of Computer Vision and Image Processing, V3, P31, DOI 10.4018/ijcvip.2013070103
   Harrou F, 2017, IEEE INSTRU MEAS MAG, V20, P49, DOI 10.1109/MIM.2017.8121952
   Hu G, 2012, IEEE INT C INT ROBOT, P1714, DOI 10.1109/IROS.2012.6386103
   Huo FF, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P13, DOI 10.1109/WIAMIS.2009.5031420
   Ihianle IK, 2020, IEEE ACCESS, V8, P179028, DOI 10.1109/ACCESS.2020.3027979
   Incel OD, 2018, PROCEDIA COMPUT SCI, V130, P1019, DOI 10.1016/j.procs.2018.04.142
   Islam MM, 2020, IEEE INT C INT ROBOT, P10285, DOI 10.1109/IROS45743.2020.9340987
   Jalal A, 2007, THIRD INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES 2007, PROCEEDINGS, P74
   Jalal Ahmad, 2012, Impact Analysis of Solutions for Chronic Disease Prevention and Management. Proceedings 10th International Conference on Smart Homes and Health Telematics (ICOST 2012), P246, DOI 10.1007/978-3-642-30779-9_36
   Jalal A, 2016, J COMPUT NETW COMMUN, V2016, DOI 10.1155/2016/8087545
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jalal A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P119, DOI 10.1109/AVSS.2014.6918654
   Jalal A, 2014, SENSORS-BASEL, V14, P11735, DOI 10.3390/s140711735
   Jaouedi N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174944
   Kang S., 2016, CoRR
   Kareem I, 2020, P 2020 23 IEEE INT M, DOI [10.1109/INMIC50486.2020.9318061, DOI 10.1109/INMIC50486.2020.9318061]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke Y, 2007, PROC CVPR IEEE, P3835
   Khan ZA, 2011, IEEE T CONSUM ELECTR, V57, P1843, DOI 10.1109/TCE.2011.6131162
   Kotsiantis S, 2007, DATA PREPROCESSING S
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari S., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P239, DOI 10.1109/NCVPRIPG.2011.58
   Kuo YM, 2010, IEEE T INF TECHNOL B, V14, P255, DOI 10.1109/TITB.2009.2036168
   Lahiri D., 2018, 2017 C INF COMMUN TE, V2018-April, P1, DOI DOI 10.1109/INFOCOMTECH.2017.8340622
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee TK, 2012, IEEE INT C INT ROBOT, P1727, DOI 10.1109/IROS.2012.6385909
   Leu A., 2011, 2011 6th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI), P415, DOI 10.1109/SACI.2011.5873039
   Li CY, 2018, ARAB J SCI ENG, V43, P7777, DOI 10.1007/s13369-018-3189-z
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li X, 2018, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-96029-6_2
   Lin CH, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/453064
   Lin L, 2015, Arxiv, DOI arXiv:1512.01642
   Lin WY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77264-y
   Liu C-D, 2007, UNDERSTANDING HUMAN
   Liu CH, 2017, Arxiv, DOI arXiv:1703.07475
   Liu L, Learning Discriminative Representations from RGB-D Video Data
   Luhr S, EXPLICIT STATE DURAT
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001
   Lygouras E, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163542
   Manjarrés J, 2022, IEEE INTERNET THINGS, V9, P7545, DOI 10.1109/JIOT.2021.3093245
   Marinho LB, 2017, ADV INTELL SYST, V557, P529, DOI 10.1007/978-3-319-53480-0_52
   Mekruksavanich S, 2021, INT JOINT CONF COMP, DOI 10.1109/JCSSE53117.2021.9493807
   Meng B, 2018, MULTIMED TOOLS APPL, V77, P26901, DOI 10.1007/s11042-018-5893-9
   Menicatti R, 2017, INT CONF UBIQ ROBOT, P32
   Kang SM, 2016, Arxiv, DOI arXiv:1610.06906
   Hashim BAM, 2021, J AMB INTEL HUM COMP, V12, P2365, DOI 10.1007/s12652-020-02351-x
   Mukherjee S, 2020, MULTIMED TOOLS APPL, V79, P19787, DOI 10.1007/s11042-020-08747-3
   Natarajan P, 2008, IEEE WORKSH MOT VIDE, DOI [10.1109/WMVC.2008.4544064, DOI 10.1109/WMVC.2008.4544064]
   Ni T, 2021, UBICOMP/ISWC '21 ADJUNCT: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2021 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P666, DOI 10.1145/3460418.3480399
   Niu W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P719, DOI 10.1109/ICME.2004.1394293
   Noori FM, 2019, LECT NOTES COMPUT SC, V11482, P299, DOI 10.1007/978-3-030-20205-7_25
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Okeyo G, 2013, J UNIVERS COMPUT SCI, V19, P2577
   Paoletti G., 2022, arXiv
   Perez-Sala X, 2012, FRONT ARTIF INTEL AP, V248, P101, DOI 10.3233/978-1-61499-139-7-101
   Perry S, 2018, ADV COMPUT VIS PATT, P207, DOI 10.1007/978-3-319-96029-6_8
   Petscharnig S, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095737
   Pham HH, 2019, SENSORS SWITZERLAND, V20
   Rahman Maruf, 2021, Communication and Intelligent Systems. Proceedings of ICCIS 2020. Lecture Notes in Networks and Systems (LNNS 204), P813, DOI 10.1007/978-981-16-1089-9_63
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Ray S, 2021, INFORMATION, V12, DOI 10.3390/info12010006
   Ryuichi A, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P182, DOI 10.1109/HEALTH.2008.4600133
   Sani S, 2017, LECT NOTES ARTIF INT, V10339, P330, DOI 10.1007/978-3-319-61030-6_23
   Schrader L, 2020, J POPUL AGEING, V13, P139, DOI 10.1007/s12062-020-09260-z
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Sempena Samsu., 2011, P INT C EL ENG INF, P1, DOI DOI 10.1109/ICEEI.2011.6021605
   Seshan A, ENABLING HIGH ACCURA
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh T, 2021, MULTIMED TOOLS APPL, V80, P33505, DOI 10.1007/s11042-021-11415-9
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Subetha T, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Sumiya T, 2015, PROCEDIA COMPUT SCI, V60, P870, DOI 10.1016/j.procs.2015.08.250
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Sutton MA, 2009, IMAGE CORRELATION FOR SHAPE, MOTION AND DEFORMATION MEASUREMENTS: BASIC CONCEPTS, THEORY AND APPLICATIONS, P1, DOI 10.1007/978-0-387-78747-3_1
   Tao DP, 2015, INFORM SCIENCES, V320, P383, DOI 10.1016/j.ins.2015.03.031
   Tao DP, 2013, IEEE T CYBERNETICS, V43, P1406, DOI 10.1109/TCYB.2013.2264285
   Tiwari G, 2021, IEEE INTERNET THINGS, DOI [10.36227/TECHRXIV.16574588.V1, DOI 10.36227/TECHRXIV.16574588.V1]
   Tsung-Yen Liao, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P254, DOI 10.1109/ICSPS.2010.5555656
   Uddin MA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071599
   Vallathan G, 2021, J SUPERCOMPUT, V77, P3242, DOI 10.1007/s11227-020-03387-8
   Vandersmissen B, 2020, NEURAL COMPUT APPL, V32, P12295, DOI 10.1007/s00521-019-04408-1
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LL, 2017, PATTERN RECOGN LETT, V92, P33, DOI 10.1016/j.patrec.2017.04.004
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang P, TEMPORAL PYRAMID POO
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Wu CX, 2018, IEEE T PATTERN ANAL, V40, P467, DOI 10.1109/TPAMI.2017.2679054
   Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122
   Xiao YH, 2019, IEEE ACCESS, V7, P42210, DOI 10.1109/ACCESS.2019.2904620
   Xu FL, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P115, DOI 10.1109/AVSS.2003.1217910
   Yadav SK, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.106970
   Yang L, 2016, DIGIT COMMUN NETW, V2, P24, DOI 10.1016/j.dcan.2015.12.001
   Yang WJ, 2013, IEEE INT CONF TRUST, P1784, DOI 10.1109/TrustCom.2013.247
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yoshikawa Y, 2018, Arxiv, DOI arXiv:1804.04326
   Yu M., 2017, P 19 ACM INT C MULT, P416
   Yu-Ren Li, 2011, 2011 International Conference on Multimedia Technology, P2841
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zehra N, 2021, 2021 55TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS50987.2021.9400290
   Zhan K, 2015, PERVASIVE MOB COMPUT, V16, P251, DOI 10.1016/j.pmcj.2014.11.004
   Zhang CY, 2012, LECT NOTES COMPUT SC, V7382, P625, DOI 10.1007/978-3-642-31522-0_95
   Zhang LG, 2019, Arxiv, DOI arXiv:1906.11367
   Zhang Z, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769540
   Zhao H, 2019, IEEE I CONF COMP VIS, P8667, DOI 10.1109/ICCV.2019.00876
   Zhu DL, 2017, IEEE IJCNN, P1766, DOI 10.1109/IJCNN.2017.7966064
   Zhu S, 2021, MULTIPLE TARGET TRAC
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 197
TC 2
Z9 2
U1 14
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15443-5
EA MAY 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800012
PM 37362688
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Li, HY
   Yu, WQ
   Dai, XB
AF Li, Huiying
   Yu, Wenqi
   Dai, Xinbang
TI Joint linking of entity and relation for question answering over
   knowledge graph
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entity linking; Knowledge graph; Question answering; Relation linking
AB Entity linking and relation linking are two crucial components in many question answering systems over knowledge graphs, which aim to identify the relevant entity or relation mentions in a question and link them to the target entity or relation in the knowledge graph. Previous studies mostly solve these two tasks independently or as sequential tasks, which usually leads to poor performance since the short texts in most questions lack the context information needed for disambiguation. In this paper, we propose an approach to jointly perform entity linking and relation linking. The idea is to exploit both the independent and joint features of the candidates for disambiguation, which captures different characteristics when the knowledge graph information and the semantics of the question are both considered. We evaluated our approach on the QALD-7 and LC-QuAD datasets and the experimental results shows that our approach significantly outperforms the existing entity and relation linking approaches.
C1 [Li, Huiying; Yu, Wenqi; Dai, Xinbang] Southeast Univ, Sch Comp Sci & Engn, Southeast Univ Rd 2, Nanjing 211189, Peoples R China.
C3 Southeast University - China
RP Li, HY (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Southeast Univ Rd 2, Nanjing 211189, Peoples R China.
EM huiyingli@seu.edu.cn; 220181721@seu.edu.cn; magerical@163.com
OI Li, Huiying/0000-0002-6425-7193
FU National Natural Science Foundation of China [61502095]
FX AcknowledgementsThe work is supported by the National Natural Science
   Foundation of China under grant No. 61502095.
CR Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Barrena A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1903
   Bouarroudj W, 2022, KNOWL INF SYST, V64, P325, DOI 10.1007/s10115-021-01642-9
   Christen P, 2006, ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS, P290
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dubey M, 2018, LECT NOTES COMPUT SC, V11136, P108, DOI 10.1007/978-3-030-00671-6_7
   Ferragina P, 2010, INT C INF KNOWL MAN, P1625, DOI [10.1145/1871437 .1871689. (Ver, DOI 10.1145/1871437.1871689.(VER, DOI 10.1145/1871437.1871689]
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Joshi M, 2020, ARXIV
   Klie Jan Christoph., 2020, P 58 ANN M ASS COMPU, P6982, DOI 10.18653/v1/2020.acl-main.624
   Koncel-Kedziorski R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2284
   Lafferty John, 2001, INT C MACH LEARN ICM
   Liu Yinhan, 2019, ARXIV190711692
   Mendes Pablo N, 2011, P 7 INT C SEM SYST, P1, DOI [DOI 10.1145/2063518.2063519, 10.1145/2063518.2063519]
   Mulang Isaiah Onando, 2017, P 13 INT C SEMANTIC, P89, DOI 10.1145/3132218.3132229
   Nakashole Ndapandula, 2012, EMNLP, P1135, DOI DOI 10.1080/17517575.2015.1080301
   Pan JZ, 2019, LECT NOTES COMPUT SC, V11778, P523, DOI 10.1007/978-3-030-30793-6_30
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ran CW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1135, DOI 10.1145/3178876.3186012
   Sakor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2336
   Singh Kuldeep, 2017, P KNOWL CAPT C DEC 2, P1
   Tan Chuanqi, 2017, P 2017 C EMP METH NA, P68
   Tjong KSE, 2003, P 7 C NAT LANG LEARN, P142, DOI DOI 10.3115/1119176.1119195
   Trivedi P, 2017, LECT NOTES COMPUT SC, V10588, P210, DOI 10.1007/978-3-319-68204-4_22
   Usbeck R., 2017, P 4 SEMWEBEVAL CHALL, V769, P59, DOI [10.1007/978, 10.1007/978-3-319-69146-6_6, DOI 10.1007/978-3-319-69146-6_6]
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wu P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6130
   Yang Y, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P504
   Yih WT, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1321
   Yu M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P571, DOI 10.18653/v1/P17-1053
   Zafar H, 2020, FRONT ARTIF INTEL AP, V325, P2290, DOI 10.3233/FAIA200357
NR 31
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44801
EP 44818
DI 10.1007/s11042-023-15646-w
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000983013200009
DA 2024-07-18
ER

PT J
AU Li, WG
   Fang, AQ
   Wu, JS
   Li, Y
AF Li, Weigang
   Fang, Aiqing
   Wu, Junsheng
   Li, Ying
TI Quality and content-aware fusion optimization mechanism of infrared and
   visible images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Quality-aware mechanism; Content-aware mechanism; Deep
   learning
ID NETWORK; NEST
AB Infrared and visible image fusion aims to generate a single fused image that contains abundant texture details and thermal radiance information. For this purpose, many unsupervised deep learning image fusion methods have been proposed, ignoring image content and quality awareness. To address these challenges, this paper presents a quality and content-aware image fusion network, termed QCANet, capable of solving the similarity fusion optimization problems, e.g., the dependence of fusion results on source images and the weighted average fusion effect. Specifically, the QCANet is composed of three modules, i.e., Image Fusion Network (IFNet), Quality-Aware Network (QANet), and Content-Aware Network (CANet). The latter two modules, a.k.a., QANet and CANet, aim to improve the content semantic awareness and quality awareness of IFNet. In addition, a new quality-aware image fusion loss is introduced to avoid the weighted average effect caused by the traditional similarity metric optimization mechanism. Therefore, the stumbling blocks of deep learning in image fusion, i.e., similarity fusion optimization problems, are significantly mitigated. Extensive experiments demonstrate that the quality and content-aware image fusion method outperforms most state-of-the-art methods.
C1 [Li, Weigang; Wu, Junsheng] Northwestern Polytech Univ, Sch Software, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
   [Fang, Aiqing; Li, Ying] Northwestern Polytech Univ, Sch Comp Sci & Engn, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Fang, AQ (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, 1 Dongxiang Rd, Xian 710129, Shaanxi, Peoples R China.
EM liweigang@nwpu.edu.cn; aiqingf@mail.nwpu.edu.cn; wujunsheng@nwpu.edu.cn;
   liying_npu@mail.nwpu.edu.cn
RI Wu, Junsheng/AAE-4911-2019; Fang, aiqing/JGE-2871-2023
OI Wu, Junsheng/0000-0003-2942-5830; Fang, Aiqing/0000-0002-0425-7626
FU National Science and technology projects of China [D5120190078]; Key R
   amp; D projects of Shaanxi Province [D5140190006]
FX AcknowledgmentsThis work has been supported by these following projects:
   (1) Grant No. D5120190078, National Science and technology projects of
   China. (2) Grant No. D5140190006, Key R & D projects of Shaanxi
   Province.
CR Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fang AQ, 2020, NEUROCOMPUTING, V414, P333, DOI 10.1016/j.neucom.2020.07.014
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   Hou RC, 2019, MULTIMED TOOLS APPL, V78, P28609, DOI 10.1007/s11042-018-6099-x
   Kailai Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P787, DOI 10.1007/978-3-030-58523-5_46
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li H, 2021, INFORM FUSION, V73, P72, DOI 10.1016/j.inffus.2021.02.023
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038013
   Ma JY, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103016
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma JY, 2020, INFORM FUSION, V54, P85, DOI 10.1016/j.inffus.2019.07.005
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2021.3075747, DOI 10.1109/TIM.2021.3075747]
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Peng CL, 2021, NEURAL NETWORKS, V137, P188, DOI 10.1016/j.neunet.2021.01.021
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Shah P, 2013, SIGNAL IMAGE VIDEO P, V7, P95, DOI 10.1007/s11760-011-0219-7
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Tang LF, 2022, INFORM FUSION, V83, P79, DOI 10.1016/j.inffus.2022.03.007
   Tang LF, 2022, INFORM FUSION, V82, P28, DOI 10.1016/j.inffus.2021.12.004
   [王鸿南 Wang Hongnan], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P828
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu H, 2021, IEEE T COMPUT IMAG, V7, P824, DOI 10.1109/TCI.2021.3100986
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhai G., 2017, IEEE T IMAGE PROCESS, VPP, P1
   Zhang H, 2021, INFORM FUSION, V76, P323, DOI 10.1016/j.inffus.2021.06.008
   Zhang XC, 2020, IEEE COMPUT SOC CONF, P468, DOI 10.1109/CVPRW50498.2020.00060
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang ZS, 2018, IEEE T VEH TECHNOL, V67, P10378, DOI [10.1109/TIE.2018.2835378, 10.1109/TVT.2018.2866828]
   Zhou HB, 2023, IEEE T MULTIMEDIA, V25, P635, DOI 10.1109/TMM.2021.3129609
NR 39
TC 0
Z9 0
U1 12
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47695
EP 47717
DI 10.1007/s11042-023-15237-9
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000008
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Yan, LJ
AF Zhang, Yanhu
   Yan, Lijuan
TI Research on the optimization of energy consumption for multi-priority
   tasks in mobile computing offloading
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; Computation offloading; Multiple priority tasks;
   Simulated annealing algorithm; Evaluation value; Energy consumption
   model; Energy efficient
ID RESOURCE-ALLOCATION; STRATEGY
AB To solve the problem of insufficient energy consumption for multi-priority tasks in the computing and unloading environments of mobile devices, we designed evaluation methods to improve the traditional simulated annealing algorithm and obtain the optimal allocation scheme for these tasks under multiple computing resources. Firstly, we proposed the task model and discussed the classification and definition of task priority as well as the procedure of task processing in detail. Secondly, a calculation model for the energy consumption of mobile devices is provided. Thirdly, an evaluation mechanism is designed to evaluate the unloading distribution scheme of mobile devices effectively. Finally, the improved traditional simulated annealing algorithm was applied to find the optimal distribution scheme for this computing environment. All allocation schemes obtained in this study were compared and analyzed via simulation. The results showed that the proposed algorithm can reduce the energy consumption of mobile devices more significantly, shorten the system response time, and complete high-priority tasks based on time constraints.
C1 [Zhang, Yanhu; Yan, Lijuan] Guangdong Songshan Polytech, Shaoguan 512126, Guangdong, Peoples R China.
   [Zhang, Yanhu] Jose Rizal Univ, Mandaluyong 1550, Metro Manila, Philippines.
C3 Jose Rizal University
RP Yan, LJ (corresponding author), Guangdong Songshan Polytech, Shaoguan 512126, Guangdong, Peoples R China.
EM forzyh@163.com; juanjanny@qq.com
FU Characteristic Innovation Research Fund for Universities of Guangdong
   Province [2019GKTSCX041]; Science and Technology Program of Shaoguan
   [210722094530279]
FX This work was supported by the Characteristic Innovation Research Fund
   for Universities of Guangdong Province (No.2019GKTSCX041) and the
   Science and Technology Program of Shaoguan (No. 210722094530279).
CR Chen X, 2016, IEEE ACM T NETWORK, V24, P2827, DOI 10.1109/TNET.2015.2487344
   Cisco Visual Networking Index, GLOB MOB DAT TRAFF F
   Ding Y, 2020, IEEE T IND INFORM, V16, P4800, DOI 10.1109/TII.2019.2951206
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   He XM, 2020, IEEE WIREL COMMUN, V27, P111, DOI 10.1109/MWC.001.1900406
   Jiena L., 2020, J CHIN COMPUT SYST, V41, P1866
   Kim Y, 2015, 2015 13TH INTERNATIONAL SYMPOSIUM ON MODELING AND OPTIMIZATION IN MOBILE, AD HOC, AND WIRELESS NETWORKS (WIOPT), P443, DOI 10.1109/WIOPT.2015.7151104
   Li B, 2020, J ELECTRON INF TECHN, V42, P2664, DOI 10.11999/JEIT190483
   [刘亮 Liu Liang], 2019, [重庆邮电大学学报. 自然科学版, Journal of Chongqing University of Posts and Telecommunications. Natural Science Edition], V31, P158
   [孟浩 Meng Hao], 2019, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V42, P25
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Sivanandam S., 2007, International Journal of Computer Science Applications, V4, P95
   Steinbrunn M., 1997, VLDB Journal, V6, P191, DOI 10.1007/s007780050040
   Tong Z, 2020, INFORM SCIENCES, V537, P116, DOI 10.1016/j.ins.2020.05.057
   Xu J, 2019, ENERGY EFFICIENT MUL
   Xu Jia, 2019, Computer Integrated Manufacturing Systems, V25, P954, DOI 10.13196/j.cims.2019.04.018
   Yang LC, 2018, IEEE T VEH TECHNOL, V67, P6398, DOI 10.1109/TVT.2018.2799620
   Yiyi Z., 2020, J COMPUT APPL SOFTW, V37, P135
   You CS, 2017, IEEE T WIREL COMMUN, V16, P1397, DOI 10.1109/TWC.2016.2633522
   [于博文 Yu Bowen], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P537
   Zhang HL, 2017, IEEE CONF COMPUT, P115, DOI 10.1109/INFCOMW.2017.8116362
   Zhang J, 2018, IEEE INTERNET THINGS, V5, P2633, DOI 10.1109/JIOT.2017.2786343
   Zhang YH, 2022, MULTIMED TOOLS APPL, V81, P26015, DOI 10.1007/s11042-022-12804-4
   Zhao X, 2020, J ELECTRON INF TECHN, V42, P704, DOI 10.11999/JEIT190170
   Zhou SC, 2021, COMPUTING, V103, P2839, DOI 10.1007/s00607-021-00931-z
   Zhu Y, 2020, RES MULTIPRIORITY TA
NR 29
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45453
EP 45469
DI 10.1007/s11042-023-15490-y
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:001033146000002
OA hybrid
DA 2024-07-18
ER

PT J
AU Murshed, BAH
   Suresha
   Abawajy, J
   Saif, MAN
   Abdulwahab, HM
   Ghanem, FA
AF Murshed, Belal Abdullah Hezam
   Suresha
   Abawajy, Jemal
   Saif, Mufeed Ahmed Naji
   Abdulwahab, Hudhaifa Mohammed A.
   Ghanem, Fahd A.
TI FAEO-ECNN: cyberbullying detection in social media platforms using topic
   modelling and deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Media; Cyberbullying Detection; Fuzzy Adaptive Equilibrium
   Optimization; Short Text Topic Modelling; Deep Learning; CNN
AB The widespread use of Social Media Platforms (SMP) such as Twitter, Instagram, Facebook, etc. by individuals has recently led to a remarkable increase in Cyberbullying (CB). It is a challenging task to prevent CB in such platforms since bullies use sarcasm or passive-aggressiveness strategies. This article proposes a new CB detection model named FAEO-ECNN for detecting and classifying cyberbullying on social media platforms. The proposed approach integrates Fuzzy Adaptive Equilibrium Optimization (FAEO) clustering-based topic modelling and Extended Convolutional Neural Network (ECNN) to enhance the accuracy of CB detection process. Initially, pre-processing is performed in order to cleanse the dataset. Next, the features are extracted using multiple models. The unsupervised Fuzzy Adaptive Equilibrium Optimization (FAEO) is utilized for discovering the latent topics from the pre-processed input data, which automatically examines the text data and creates clusters of words. Finally, the cyberbullying classification makes use of the ECNN and Rain Optimization (RO) algorithm to detect CB from posts/texts. We evaluated the proposed FAEO-ECNN thoroughly with two short text datasets: Real-world CB Twitter (RW-CB-Twitter) and Cyberbullying Menedely (CB-MNDLY) datasets in comparison to State of The Art (SoTA) models like Long Short Term Memory (LSTM), Bi-directional LSTM (BLSTM), RNN, and CNN-LSTM. The proposed FAEO-ECNN model outperformed the SoTA models in detecting Cyberbullying on SMP. It has obtained 92.91% of accuracy, 92.28% of recall, 92.53% of precision, and 92.40% of F-Measure over CB-MNDLY dataset. Moreover, it has achieved 91.89% of accuracy, 91.32% of recall, 91.81% of precision, and 91.56% of F-Measure on RW-CB-Twitter dataset.
C1 [Murshed, Belal Abdullah Hezam] Univ Amran, Coll Engn & Informat Technol, Dept Comp Sci, Amran, Yemen.
   [Murshed, Belal Abdullah Hezam; Suresha] Univ Mysore, Dept Studies Comp Sci, Mysore 570006, Karnataka, India.
   [Abawajy, Jemal] Deakin Univ, Fac Sci Engn & Built Environm, Sch Informat Technol, Geelong, Vic 3220, Australia.
   [Saif, Mufeed Ahmed Naji] Sri Jayachamarajendra Coll Engn, Dept Comp Applicat, VTU, Mysore 570006, Karnataka, India.
   [Abdulwahab, Hudhaifa Mohammed A.] Ramaiah Inst Technol, Dept Comp Applicat, VTU, Bangalore 560054, India.
   [Ghanem, Fahd A.] Mysore Univ, PES Coll Engn, Dept Comp Sci & Engn, Mandya 571401, India.
C3 University of Mysore; Deakin University; Sri Jayachamarajendra College
   of Engineering; Ramaiah Institute of Technology; University of Mysore
RP Murshed, BAH (corresponding author), Univ Amran, Coll Engn & Informat Technol, Dept Comp Sci, Amran, Yemen.; Murshed, BAH (corresponding author), Univ Mysore, Dept Studies Comp Sci, Mysore 570006, Karnataka, India.
EM belal.a.hezam@gmail.com
RI Mohammed, Hudhaifa/JXY-6332-2024
OI Mohammed, Hudhaifa/0000-0001-6631-051X
CR Abdulwahab HM, 2022, APPL INTELL, V52, P13568, DOI 10.1007/s10489-021-03118-3
   Agarwal A., 2020, Proceedings of the 27th International Conference on Neural Information Processing (ICONIP), Bangkok, Thailand, P113
   Agrawal S, 2018, LECT NOTES COMPUT SC, V10772, P141, DOI 10.1007/978-3-319-76941-7_11
   Aind AT, 2020, P 2020 INT C EM TECH, P1, DOI [10.1109/INCET49848.2020.9154092, DOI 10.1109/INCET49848.2020.9154092]
   Akhter MP, 2022, MULTIMEDIA SYST, V28, P1925, DOI 10.1007/s00530-021-00784-8
   Al-Ajlan MA, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Al-Hassan A, 2022, MULTIMEDIA SYST, V28, P1963, DOI 10.1007/s00530-020-00742-w
   Alam Kazi Saeed, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P710, DOI 10.1109/ICICV50876.2021.9388499
   Alduailaj AM, 2023, MACH LEARN KNOW EXTR, V5, P29, DOI 10.3390/make5010003
   [Anonymous], 2013, P 23 INT JOINT C ART
   [Anonymous], 2014, P 3 INT WORKSHOP SOC, DOI [10.1145/2661126.2661133, DOI 10.1145/2661126.2661133]
   Balakrishnan V, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101710
   Balakrishnan V, 2019, PERS INDIV DIFFER, V141, P252, DOI 10.1016/j.paid.2019.01.024
   Banerjee V, 2019, INT CONF ADVAN COMPU, P604, DOI [10.1109/icaccs.2019.8728378, 10.1109/ICACCS.2019.8728378]
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Brochier R, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2587, DOI 10.1145/3308558.3313595
   Chen H, 2020, ARXIV
   Chen JY, 2020, NEURAL COMPUT APPL, V32, P10809, DOI 10.1007/s00521-018-3442-0
   Chen Xiao, 2014, Reluctance torque evaluation for interior permanent magnet machines using frozen permeability, DOI 10.1049/iet-tv.50.19173
   Cheng L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5829
   Chia ZL, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102600
   Cortis K, 2015, P 15 INT C KNOWLEDGE, V21-22-Octo, P1, DOI DOI 10.1145/2809563.2809605
   Dadvar Maral, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P693, DOI 10.1007/978-3-642-36973-5_62
   Dadvar M., 2018, ARXIV
   Dalvi RR, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P297, DOI [10.1109/ICICCS48265.2020.9120893, 10.1109/iciccs48265.2020.9120893]
   Edo-Osagie O, 2019, LECT NOTES COMPUT SC, V11506, P895, DOI 10.1007/978-3-030-20521-8_73
   Eronen J, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102616
   Fang Y, 2021, INFORMATION, V12, DOI 10.3390/info12040171
   Galán-García P, 2016, LOG J IGPL, V24, P42, DOI 10.1093/jigpal/jzv048
   Gamback B., 2017, P 1 WORKSH AB LANG O, P85, DOI [DOI 10.18653/V1/W17-3013, 10.18653/v1/W17-3013]
   Gao ZM, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P343, DOI 10.1109/ICCCS49078.2020.9118477
   Huang Q., 2018, P 1 WORKSH TROLL AGG, P42
   Iwendi C, 2023, MULTIMEDIA SYST, V29, P1839, DOI 10.1007/s00530-020-00701-5
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Khodabakhsh M, 2020, J INTELL INF SYST, V54, P101, DOI 10.1007/s10844-018-0519-2
   Kumar A, 2022, WORLD WIDE WEB, V25, P1537, DOI 10.1007/s11280-021-00920-4
   Kumar A, 2021, TOP ORGANOMETAL CHEM, V68, P1, DOI 10.1007/3418_2020_67
   Kumari K, 2021, SOFT COMPUT, DOI 10.1007/s00500-021-05817-y
   Kumari K, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3907
   Kumari K, 2020, SOFT COMPUT, V24, P11059, DOI 10.1007/s00500-019-04550-x
   Liang WX, 2018, IEEE ACCESS, V6, P43612, DOI 10.1109/ACCESS.2018.2863260
   Liu Z, 2020, IEEE ACCESS, V8, P99141, DOI 10.1109/ACCESS.2020.2997973
   Lu NJ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5627
   Mishna F, 2012, CHILD YOUTH SERV REV, V34, P63, DOI 10.1016/j.childyouth.2011.08.032
   Moazzeni AR, 2020, J PETROL SCI ENG, V195, DOI 10.1016/j.petrol.2020.107512
   Muneer A, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12110187
   Murshed BAH, 2021, STUDIES SYSTEMS DECI, V348, DOI [10.1007/978-3-030-67716-9_7, DOI 10.1007/978-3-030-67716-9_7]
   Murshed BAH, 2022, IEEE ACCESS, V10, P105328, DOI 10.1109/ACCESS.2022.3211396
   Murshed BAH, 2023, ARTIF INTELL REV, V56, P5133, DOI 10.1007/s10462-022-10254-w
   Murshed BAH, 2022, IEEE ACCESS, V10, P25857, DOI 10.1109/ACCESS.2022.3153675
   Murshed BAH, 2020, COMPUT SYST SCI ENG, V35, P495
   Nand P, 2016, PROC 26 INT C COMPUT, P695
   Paul S, 2022, MULTIMEDIA SYST, V28, P1897, DOI 10.1007/s00530-020-00710-4
   Paul S, 2022, MULTIMED TOOLS APPL, V81, P26989, DOI 10.1007/s11042-020-09631-w
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pericherla S, 2024, INT J INTELL UNMANNE, V12, P154, DOI 10.1108/IJIUS-02-2021-0011
   Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y
   Purnamasari N M. G. D., 2020, Indonesian Journal of Electrical Engineering and Computer Science, V18, P1494, DOI 10.11591/ijeecs.v18.i3.pp1494-1500
   Rosa H, 2018, IEEE IJCNN, P323
   Roy PK, 2022, COMPLEX INTELL SYST, V8, P5449, DOI 10.1007/s40747-022-00772-z
   Singh J, 2021, ANN MATH ARTIF INTEL, V89, P371, DOI 10.1007/s10472-020-09709-z
   Squicciarini A, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P280, DOI 10.1145/2808797.2809398
   Srinath AS, 2021, IEEE T COMPUT SOC SY, V8, P332, DOI 10.1109/TCSS.2021.3049232
   Talpur BA, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7040052
   Tripathy JK, 2022, MULTIMEDIA SYST, V28, P1941, DOI 10.1007/s00530-020-00690-5
   Van Hee C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203794
   Vivolo-Kantor AM, 2014, AGGRESS VIOLENT BEH, V19, P423, DOI 10.1016/j.avb.2014.06.008
   Wang KG, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206663
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Yan F, 2020, PATTERN RECOGN LETT, V130, P299, DOI 10.1016/j.patrec.2019.01.016
   Yuvaraj N, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6644652
   Yuvaraj N, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107186
   Zhang X, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P740, DOI [10.1109/ICMLA.2016.0132, 10.1109/ICMLA.2016.71]
   Zhang Y, 2018, PR INT CONF DATA SC, P504, DOI 10.1109/DSAA.2018.00065
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhao R, 2017, IEEE T AFFECT COMPUT, V8, P328, DOI 10.1109/TAFFC.2016.2531682
   Zhao Y, 2001, Criterion functions for document clustering: Experiments and analysis
   Zhou Chunting, 2015, ARXIV
   Zhou KL, 2020, PATTERN ANAL APPL, V23, P455, DOI 10.1007/s10044-019-00783-6
   Zuo Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2105, DOI 10.1145/2939672.2939880
NR 81
TC 3
Z9 3
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46611
EP 46650
DI 10.1007/s11042-023-15372-3
EA MAY 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000002
DA 2024-07-18
ER

PT J
AU Gupta, V
   Kanungo, A
   Kumar, P
   Kumar, N
   Choubey, C
AF Gupta, Varun
   Kanungo, Abhas
   Kumar, Pankaj
   Kumar, Neeraj
   Choubey, Chandan
TI A design of bat-based optimized deep learning model for EEG signal
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG signal; Normal patient; Depressed patient data; Time and frequency
   range; Band power; Convolutional layer; Depression rate
ID CLASSIFICATION
AB Depression is a mental illness that negatively affects a person's thinking, action, and feeling. Thus the rate of depression is identified by analysing Electroencephalogram (EEG) signals. Because of noise, the problem of classifying depression rate has some issues, such as low accuracy and required high training time. In this research work, a novel Bat-based U-NET Signal Analysis (BUSA) architecture is developed to estimate the patient's depression rate with an EEG dataset. This technique involves pre-processing, feature selection, feature extraction, and classification. After the data training, the pre-processing function was activated to neglect the noise in the brain signal. Hereafter, the noiseless Signal is used for the further process. Here, the bat algorithm mimics the behaviour of the bat's frequency and loudness, increasing the accuracy of prediction and classification. This fitness function is upgraded in the U-NET classification phase. Moreover, the brain signal's feature selection and depression rate were classified using the bat fitness that has helped to gain the desired output. Finally, the performance metrics of the proposed BUSA technique are compared with other existing methods regarding the accuracy, AUC, precision, recall, and power. The proposed BUSA framework attained a high accuracy rate of about 99.64%, a maximum precision level of approximately 99.98%, a high recall rate of approximately 99.95%, and a high AUC of approximately 99.2%. The developed framework has attained better results in classifying depression rates.
C1 [Gupta, Varun] KIET Grp Inst, Dept Elect & Elect Engn, Delhi NCR, Ghaziabad 201206, Uttar Pradesh, India.
   [Kanungo, Abhas] KIET Grp Inst, Dept Elect & Commun Engn, Delhi NCR, Ghaziabad 201206, Uttar Pradesh, India.
   [Kumar, Pankaj] CCS Univ Meerut Uttar Pradesh, SCRIET, Dept Elect & Commun Engn, Meerut 250003, India.
   [Kumar, Neeraj; Choubey, Chandan] Greater Noida Inst Technol, Dept Elect & Commun Engn, Greater Noida, India.
   [Choubey, Chandan] IMS Engn Coll, Dept Elect & Commun Engn, Ghaziabad, India.
C3 KIET Group of Institutions; KIET Group of Institutions; Greater Noida
   Institute of Technology
RP Gupta, V (corresponding author), KIET Grp Inst, Dept Elect & Elect Engn, Delhi NCR, Ghaziabad 201206, Uttar Pradesh, India.
EM vargup2@gmail.com; abhas.kanungo@kiet.edu; nadarpankaj.miet@gmail.com;
   iet_neeraj@yahoo.com; er.choubey.chandan@gmail.com
CR Aayesha, 2021, MULTIMED TOOLS APPL, V80, P17849, DOI 10.1007/s11042-021-10597-6
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Akbari H, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-021-00139-7
   Algan G, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106771
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Azad HK, 2022, PATTERN RECOGN LETT, V158, P148, DOI 10.1016/j.patrec.2022.04.013
   Azad HK, 2022, J INTELL INF SYST, V59, P71, DOI 10.1007/s10844-021-00687-0
   Barata C, 2019, IEEE J BIOMED HEALTH, V23, P1096, DOI 10.1109/JBHI.2018.2845939
   Büyüksahin ÜÇ, 2019, NEUROCOMPUTING, V361, P151, DOI 10.1016/j.neucom.2019.05.099
   Cai HS, 2020, INFORM FUSION, V59, P127, DOI 10.1016/j.inffus.2020.01.008
   Dose H, 2018, EXPERT SYST APPL, V114, P532, DOI 10.1016/j.eswa.2018.08.031
   Geng XZ, 2022, ALEX ENG J, V61, P4807, DOI 10.1016/j.aej.2021.10.034
   Gu XQ, 2022, MULTIMED TOOLS APPL, V81, P41733, DOI 10.1007/s11042-021-11244-w
   Gu XT, 2021, IEEE ACM T COMPUT BI, V18, P1645, DOI 10.1109/TCBB.2021.3052811
   Gupta V, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102124
   Hag A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248370
   Hasanzadeh F, 2019, J AFFECT DISORDERS, V256, P132, DOI 10.1016/j.jad.2019.05.070
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Kaur C, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102337
   Khare SK, 2022, IRBM, V43, P13, DOI 10.1016/j.irbm.2020.07.005
   Khare SK, 2021, IEEE T NEUR NET LEAR, V32, P2901, DOI 10.1109/TNNLS.2020.3008938
   Kim C, 2018, MED BIOL ENG COMPUT, V56, P1645, DOI 10.1007/s11517-017-1761-4
   Kundu S, 2020, IRBM, V41, P31, DOI 10.1016/j.irbm.2019.08.001
   Larabi-Marie-Sainte S, 2022, CMC-COMPUT MATER CON, V72, P4589, DOI 10.32604/cmc.2022.027922
   Liu L, 2019, IEEE ACCESS, V7, P47794, DOI 10.1109/ACCESS.2019.2910191
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30261, DOI 10.1007/s11042-020-09135-7
   Mehmood RM, 2022, MEASUREMENT, V202, DOI 10.1016/j.measurement.2022.111738
   Ogunseye E.O., 2022, ParadigmPlus, V3, P11, DOI [10.55969/paradigmplus.v3n2a2, DOI 10.55969/PARADIGMPLUS.V3N2A2]
   Omidvar M, 2021, J AMB INTEL HUM COMP, V12, P10395, DOI 10.1007/s12652-020-02837-8
   Ouyang CS, 2020, CLIN NEUROPHYSIOL, V131, P1902, DOI 10.1016/j.clinph.2020.04.172
   Polat K, 2020, IRBM, V41, P331, DOI 10.1016/j.irbm.2020.06.008
   Rajasekar P, 2020, SOFT COMPUT, V24, P14545, DOI 10.1007/s00500-020-04804-z
   Rudas Akos, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P1454, DOI 10.1109/ICMLA.2019.00238
   Rus ID, 2017, INT C INTELL COMP CO, P391, DOI 10.1109/ICCP.2017.8117036
   Scapicchio C, 2021, RADIOL MED, V126, P1296, DOI 10.1007/s11547-021-01389-x
   Seshadri NPG, 2022, COGN NEURODYNAMICS, V16, P1013, DOI 10.1007/s11571-021-09769-9
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Subasi A, 2019, MEASUREMENT, V146, P846, DOI 10.1016/j.measurement.2019.07.026
   Swati S, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102845
   Zazzaro G, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2019.03.002
   Zhang DL, 2019, IEEE SIGNAL PROC LET, V26, P715, DOI 10.1109/LSP.2019.2906824
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
   Zhao XY, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85138-0
NR 43
TC 4
Z9 4
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45367
EP 45387
DI 10.1007/s11042-023-15462-2
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978477000003
DA 2024-07-18
ER

PT J
AU Panda, SK
   Jena, AK
   Panda, MR
   Panda, S
AF Panda, Sandeep Kumar
   Jena, Ajay Kumar
   Panda, Mohit Ranjan
   Panda, Susmita
TI Speech emotion recognition using multimodal feature fusion with machine
   learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature fusion (FF); Speech emotion recognition (SER); Mel frequency
   cepstral coefficients; Zero Crossing Rate; Support vector machine;
   XGBoost
AB Speech-based emotional state recognition must have a significant impact on artificial intelligence as machine learning advances. When it comes to emotion recognition, proper feature selection is critical. As a result, feature fusion technology is offered in this work as a means of achieving high prediction accuracy by emphasizing the extraction of sole features. Mel Frequency Cepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Mel Spectrogram, Short-time Fourier transform (STFT) and Root Mean Square (RMS) are extracted, and four different feature fusion techniques are used on five standard machine learning classifiers: XGBoost, Support Vector Machine (SVM), Random Forest, Decision-Tree (D-Tree), and K Nearest Neighbor (KNN). The successful use of feature fusion techniques on our suggested classifier yields a satisfactory recognition rate of 99.64% on the female only dataset (TESS), 91% on SAVEE (male only dataset) and 86% on CREMA-D (both male and female) dataset. The proposed model shows that effective feature fusion improves the accuracy and applicability of emotion detection systems.
C1 [Panda, Sandeep Kumar] ICFAI Fdn Higher Educ Deemed Univ, Fac Sci & Technol IcfaiTech, Dept Data Sci & Artificial Intelligence, Hyderabad, Telangana, India.
   [Jena, Ajay Kumar; Panda, Mohit Ranjan] KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar, Odisha, India.
   [Panda, Susmita] SOA Deemed Univ, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
C3 The ICFAI Foundation for Higher Education (IFHE); Kalinga Institute of
   Industrial Technology (KIIT); Siksha 'O' Anusandhan University
RP Panda, SK (corresponding author), ICFAI Fdn Higher Educ Deemed Univ, Fac Sci & Technol IcfaiTech, Dept Data Sci & Artificial Intelligence, Hyderabad, Telangana, India.
EM skpanda00007@gmail.com; ajay.bbs.in@gmail.com;
   mohit.pandafcs@kiit.ac.in; susmitapanda@soa.ac.in
RI Panda, Sandeep Kumar/AAU-1903-2021
OI Panda, Sandeep Kumar/0000-0002-0752-4267
CR [Anonymous], 2012, INT J COMPUT SCI INF
   Anwer S, 2020, P 18 INT C ADV MOB C
   Basu S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P109, DOI 10.1109/ICICCT.2017.7975169
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Choudhury AR, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P257, DOI 10.1109/ASPCON.2018.8748626
   Dhar P, 2021, INT J MOL SCI, V7, P26, DOI [10.5815/ijmsc.2021.01.04, DOI 10.5815/IJMSC.2021.01.04]
   Esmaileyan Z, 2014, INT J ENG-IRAN, V27, P79, DOI 10.5829/idosi.ije.2014.27.01a.11
   Ghaleb E, 2020, IEEE MULTIMEDIA, V27, P37, DOI 10.1109/MMUL.2019.2960219
   Ingale Ashish B, 2012, International Journal of Soft Computing and Engineering (IJSCE), V2, P235
   Kanwal S, 2021, IEEE ACCESS, V9, P125830, DOI 10.1109/ACCESS.2021.3111659
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   Kumbhar HS, 2019, 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA), DOI 10.1109/iccubea47591.2019.9129067
   Liu ZT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082297
   Ho NH, 2020, IEEE ACCESS, V8, P61672, DOI 10.1109/ACCESS.2020.2984368
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Palo HK., 2018, INT J ENG TECHNOL, V7, P111
   Pan Yixiong, 2012, International Journal of Smart Home, V6, P101, DOI DOI 10.5120/431-636
   Pappagari R, 2020, INT CONF ACOUST SPEE, P7169, DOI [10.1109/icassp40776.2020.9054317, 10.1109/ICASSP40776.2020.9054317]
   Shah RD, 2016, INT J INNOV RES COMP, V4
   Shambhavi S., 2015, INT J ENG RES TECHNO, V4, P1067, DOI DOI 10.17577/IJERTV4IS060932
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
   Yixiong P, 2012, SPEECH EMOTION RECOG
NR 27
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42763
EP 42781
DI 10.1007/s11042-023-15275-3
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000973357400001
DA 2024-07-18
ER

PT J
AU Mahajan, HB
   Junnarkar, AA
AF Mahajan, Hemant B. B.
   Junnarkar, Aparna A. A.
TI Smart healthcare system using integrated and lightweight ECC with
   private blockchain for multimedia medical data processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical image procesing; Blockchain; Elliptical curve cryptography;
   Healthcare 4; 0; Internet of things; Multimedia data; Security
AB Cloud-based Healthcare 4.0 systems have research challenges with secure medical data processing, especially biomedical image processing with privacy protection. Medical records are generally text/numerical or multimedia. Multimedia data includes X-ray scans, Computed Tomography (CT) scans, Magnetic Resonance Imaging (MRI) scans, etc. Transferring biomedical multimedia data to medical authorities raises various security concerns. This paper proposes a one-of-a-kind blockchain-based secure biomedical image processing system that maintains anonymity. The integrated Healthcare 4.0 assisted multimedia image processing architecture includes an edge layer, fog computing layer, cloud storage layer, and blockchain layer. The edge layer collects and sends periodic medical information from the patient to the higher layer. The multimedia data from the edge layer is securely preserved in blockchain-assisted cloud storage through fog nodes using lightweight cryptography. Medical users then safely search such data for medical treatment or monitoring. Lightweight cryptographic procedures are proposed by employing Elliptic Curve Cryptography (ECC) with Elliptic Curve Diffie-Hellman (ECDH) and Elliptic Curve Digital Signature (ECDS) algorithm to secure biomedical image processing while maintaining privacy (ECDSA). The proposed technique is experimented with using publically available chest X-ray and CT images. The experimental results revealed that the proposed model shows higher computational efficiency (encryption and decryption time), Peak to Signal Noise Ratio (PSNR), and Meas Square Error (MSE).
C1 [Mahajan, Hemant B. B.] Godwit Technol, Pune, India.
   [Junnarkar, Aparna A. A.] PES Modern Coll Engn, Pune, India.
RP Mahajan, HB (corresponding author), Godwit Technol, Pune, India.
EM aparna.junnarkar@gmail.com
RI Mahajan, Hemant B./AAP-2042-2020; Junnarkar, Aparna Atul/JVN-9700-2024
OI Mahajan, Hemant B./0000-0001-6703-7711; Junnarkar, Aparna
   Atul/0000-0002-3187-9228
CR Alghazo J., 2020, ACM T MULTIM COMPUT, DOI DOI 10.1145/3396852
   Alhayani B, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02152-4
   Andrychowicz M, 2016, COMMUN ACM, V59, P76, DOI 10.1145/2896386
   Andrychowicz M, 2014, LECT NOTES COMPUT SC, V8438, P105, DOI 10.1007/978-3-662-44774-1_8
   Arumugam S., 2021, Med. Imag Health Informat, V11, P1533
   Bentov I, 2014, LECT NOTES COMPUT SC, V8617, P421, DOI 10.1007/978-3-662-44381-1_24
   Chenthara S, 2019, IEEE ACCESS, V7, P74361, DOI 10.1109/ACCESS.2019.2919982
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Essa YM, 2018, HEALTH TECHNOL-GER, V8, P271, DOI 10.1007/s12553-018-0219-5
   Ferdous MS, 2017, INT CON DISTR COMP S, P2632, DOI 10.1109/ICDCS.2017.178
   Gao YL, 2018, IEEE ACCESS, V6, P27205, DOI 10.1109/ACCESS.2018.2827203
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Hardjono T., 2016, Proceedings of the 2nd ACM International Workshop on IoT Privacy, Trust, and Security, P29
   Hassan MM, 2017, FUTURE GENER COMP SY, V66, P48, DOI 10.1016/j.future.2015.12.016
   Huang L, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8859961
   Jaeger S, 2014, IEEE T MED IMAGING, V33, P233, DOI 10.1109/TMI.2013.2284099
   Jemal H, 2015, LECT NOTES ARTIF INT, V9330, P408, DOI 10.1007/978-3-319-24306-1_40
   Kaur M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8829829
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Koul S, 2022, MULTIMED TOOLS APPL, V81, P11259, DOI 10.1007/s11042-022-11974-5
   Kruse CS, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1075-6
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kumar N, 2022, ENG TECHNOL APPL SCI, V12, P7993, DOI 10.48084/etasr.4613
   Kumar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9983652
   Li H., 2017, ARXIV
   Liu XG, 2019, IEEE ACCESS, V7, P118943, DOI 10.1109/ACCESS.2019.2937685
   Madhu B, 2019, RECENT TRENDS IMAGE, P332, DOI [10.1007/978-981-13-9184-2_30, DOI 10.1007/978-981-13-9184-2_30]
   Mahajan HB., 2018, INT J ADV SCI TECHNO, V2018, P37
   Mahajan HB., 2019, J ADV RES DYNAMICAL, V11, P1276, DOI [10.5373/JARDCS/V11I9/20193162, DOI 10.5373/JARDCS/V11I9/20193162]
   Mahajan HB., 2020, INT J ADV SCI TECHNO, V29, P214
   Mahajan HB, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02164-0
   Mahajan HB, 2021, WIRELESS PERS COMMUN, V121, P3125, DOI 10.1007/s11277-021-08866-6
   Mahajan HB, 2021, J AMB INTEL HUM COMP, V12, P7777, DOI 10.1007/s12652-020-02502-0
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Mubarakali A, 2020, MOBILE NETW APPL, V25, P1330, DOI 10.1007/s11036-020-01551-1
   Oyenuga SO, 2021, LECT NOTES NETWORKS, V175, DOI [10.1007/978-3-030-67187-7_24, DOI 10.1007/978-3-030-67187-7_24]
   Pai MMM, 2021, HEALTH SERV OUTCOME, V21, P339, DOI 10.1007/s10742-020-00238-0
   Pournaghi SM, 2020, J AMB INTEL HUM COMP, V11, P4613, DOI 10.1007/s12652-020-01710-y
   Rajendran Sujarani, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012106
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Reyad O, 2021, ARAB J SCI ENG, V46, P3581, DOI 10.1007/s13369-020-05196-w
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Srinivasan K, 2022, MULTIMED TOOLS APPL, V81, P9079, DOI 10.1007/s11042-021-11481-z
   Sundareswaran S, 2012, IEEE T DEPEND SECURE, V9, P556, DOI 10.1109/TDSC.2012.26
   Uke N., 2021, TURKISH J COMPUTER M, DOI [10.17762/turcomat.v12i11.5858, DOI 10.17762/TURCOMAT.V12I11.5858]
   Weiner M, 2019, J GEN INTERN MED, V34, P2299, DOI 10.1007/s11606-019-05281-3
   Xia Q, 2017, IEEE ACCESS, V5, P14757, DOI 10.1109/ACCESS.2017.2730843
   Xia Q, 2017, INFORMATION, V8, DOI 10.3390/info8020044
   Yepdia LMH, 2021, SENS IMAGING, V22, DOI 10.1007/s11220-021-00340-8
   Zhang CF, 2019, IEEE ACCESS, V7, P136223, DOI 10.1109/ACCESS.2019.2939158
   Zhang YH, 2018, IEEE ACCESS, V6, P31077, DOI 10.1109/ACCESS.2018.2844400
   Zyskind G, 2015, ARXIV
NR 53
TC 6
Z9 6
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44335
EP 44358
DI 10.1007/s11042-023-15204-4
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000970495100007
PM 37362704
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Jain, R
   Rai, RS
   Jain, S
   Ahluwalia, R
   Gupta, J
AF Jain, Rishit
   Rai, Revant Singh
   Jain, Sajal
   Ahluwalia, Ruchir
   Gupta, Jyoti
TI Real time sentiment analysis of natural language using multimedia input
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Chatbot; Audio; Video and text analysis; Machine
   learning; Natural language processing
AB Semantics and Sentiments are parts of our daily speech and expressions that helps to convey the message in the tone intended. The accurate interpretation of emotions and actions is prudent as it expresses the true meaning of the message. This interpretation has been studied extensively in the past two decades, where professionals from various disciplines have pondered this question. Every action and expression-whether it's in a speech, in a video or through some written material-helps the recipient understand the intent behind the message. The primary motive in these studies has been to automate the analysis of these sentiments by teaching the computers to do so, using the audio, video and text-based data that has been collected so far. Machine Learning (ML) and Deep Learning (DL) is the discipline that can help us tackle such a problem which requires analysis and recognition of copious amounts of data. Classification based on these multi-media inputs has seen the application of several common and uncommon ML techniques such as Support Vector Machines (SVMs), Bayesian Networks (BNs), Decision Trees (DTs), Convolutional Neural Networks (CNNs) and K-Means Clustering. These techniques, to a certain level of accuracy, can classify a certain part of a message into a different emotion. Through this research, firstly, a comparison is represented between the previously conducted studies and secondly, a system is developed of our own that enables Real Time Sentiment Analysis and helps a user assess his/her day-to-day attitude and get appropriate recommendations for the same.
C1 [Jain, Rishit; Rai, Revant Singh; Jain, Sajal; Ahluwalia, Ruchir; Gupta, Jyoti] Bharati Vidyapeeths Coll Engn, Dept Elect & Commun Engn, New Delhi 110063, India.
RP Gupta, J (corresponding author), Bharati Vidyapeeths Coll Engn, Dept Elect & Commun Engn, New Delhi 110063, India.
EM rishitjainn@gmail.com; revantrai@gmail.com; sjain30sept@gmail.com;
   ruchirwalia1@gmail.com; jyoti.gupta@bharatividyapeeth.edu
OI Jain, Rishit/0000-0002-1925-6730
CR Agarwal Ayush, 2019, 2019 4th International Conference on Big Data, Cloud Computing, Data Science & Engineering (BCD), P19, DOI 10.1109/BCD.2019.8885108
   Ahmad M., 2017, Int. J. Multidiscip. Sci. Eng, V8, P27
   Al-Azani S, 2020, IEEE ACCESS, V8, P136843, DOI 10.1109/ACCESS.2020.3011977
   Bhuiyan H, 2017, IEEE I C SIGNAL IMAG, P474, DOI 10.1109/ICSIPA.2017.8120658
   Chu E, 2017, IEEE DATA MINING, P829, DOI 10.1109/ICDM.2017.100
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ezzat S., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P105, DOI 10.1109/SOCPAR.2010.5686000
   Gaikwad, 2016, INT C INVEN COMPUT T, V2, P1
   Gautam J, 2021, TWITTER DATA SENTIME, DOI [10.1007/978-981-33-6919-1_10, DOI 10.1007/978-981-33-6919-1_10]
   Ghofrani A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P817, DOI [10.1109/kbei.2019.8734924, 10.1109/KBEI.2019.8734924]
   Kaur H, 2021, INFORM SYST FRONT, V23, P1417, DOI 10.1007/s10796-021-10135-7
   Kaushik L, 2013, 2013 IEEE INT C AC S
   LI C, 2018, NEWS TEXT CLASSIFICA, DOI DOI 10.1109/ITME.2018.00199
   Luo Z., 2019, AFFCON AAAI
   Maulik PK, 2017, PSYCHOL MED, V47, P565, DOI [10.1017/S0033291716002804, 10.1017/s0033291716002804]
   Mechili EA, 2021, J PSYCHIATR MENT HLT, V28, P317, DOI 10.1111/jpm.12672
   Parveen H, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P416, DOI 10.1109/ICATCCT.2016.7912034
   Pereira MHR, 2016, P INT AAAI C WEB SOC, P659
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Rao A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P24, DOI 10.1109/ICCCIS51004.2021.9397147
   Raza H, 2019, INT J ADV COMPUT SC, V10, P157
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Samji H, 2022, CHILD ADOL MENT H-UK, V27, P173, DOI 10.1111/camh.12501
   Schmidt Thomas, 2019, P DIG HUM NORD COUNT, P405
   Singh J, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0116-3
   Stappen L, 2021, IEEE INTELL SYST, V36, P88, DOI 10.1109/MIS.2021.3062200
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
NR 29
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41021
EP 41036
DI 10.1007/s11042-023-15213-3
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000968990200004
PM 37362666
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Pal, S
AF Pal, Saurabh
TI Prediction for chronic kidney disease by categorical and non_categorical
   attributes using different machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chronic kidney disease; Support Vector Machine; Random Forest;
   Artificial Neural Network; Voting
AB Chronic kidney disease (CKD) is a common disease as it is difficult to diagnose early due to its lack of symptoms. The main goal is to first diagnose kidney failure, which is a requirement for dialysis or a kidney transplant. This model teaches patients how to live a healthy life, helps doctors identify the risk and severity of disease, and how plan future treatments. Machine learning algorithms are often used in health care to predict and manage the disease. The purpose of this study is to develop a model for the early detection of CKD, which has three parts: (a) applying baseline classifiers on categorical attributes, (b) applying baseline classifiers on non_categorical attributes, (c) applying baseline classifiers on both categorical and non_categorical attributes, and (d) improving the results of the proposed model by combing the results of above three classifiers based on a majority vote. The proposed model based on baseline classifiers and the majority voting method shows a 3% increase in accuracy over the other existing models. The results provide support for increased accuracy in the current classification of chronic kidney disease.
C1 [Pal, Saurabh] VBS Purvanchal Univ, Dept Comp Applicat, Jaunpur, India.
RP Pal, S (corresponding author), VBS Purvanchal Univ, Dept Comp Applicat, Jaunpur, India.
EM drsaurabhpal@yahoo.co.in
RI Pal, Prof. Saurabh/C-7618-2013
OI Pal, Prof. Saurabh/0000-0001-9545-7481
FU Veer Bahadur Singh Purvanchal University, Jaunpur
FX The author thanks Veer Bahadur Singh Purvanchal University, Jaunpur for
   providing the support for conducting this research work as a part of the
   minor project "Analysis of Hidden Pattern and Discover Real Fact of
   Medical Diseases using Integrated Machine Learning Techniques".
CR Al-Hyari AY, 2014, INT J INF TECHNOL WE, V9, P1, DOI 10.4018/ijitwe.2014100101
   Aljaaf AJ, 2018, IEEE C EVOL COMPUTAT, P251, DOI 10.1109/CEC.2018.8477876
   [Anonymous], 2014, International Journal of Advances in Engineering and Technology
   Aqlan F, 2017, P 67 ANN C EXP I IND
   Bojja GR, 2019, ANN RES S, V24
   Borisagar N, 2017, ADV INTELL SYST, V508, P295, DOI 10.1007/978-981-10-2750-5_31
   Chaurasia V, 2014, REV RES, V3, P1
   Chaurasia V., 2020, SN Comput. Sci, V1, P1, DOI [10.1007/s42979-020-00296-8, DOI 10.1007/S42979-020-00296-8]
   Dong ZY, 2022, J TRANSL MED, V20, DOI 10.1186/s12967-022-03339-1
   Han X, 2019, ANN TRANSL MED, V7, P1, DOI [10.21037/atm.2018.12, DOI 10.21037/ATM.2018.12]
   Hu RY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102782
   Ifraz GM, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6141470
   Ilyas H, 2021, BMC NEPHROL, V22, DOI 10.1186/s12882-021-02474-z
   Krishnamurthy S, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9050546
   Nishanth Anandanadarajah, 2018, IEEE Rev Biomed Eng, V11, P208, DOI 10.1109/RBME.2017.2787480
   Ogunleye A, 2020, IEEE ACM T COMPUT BI, V17, P2131, DOI 10.1109/TCBB.2019.2911071
   Rady El-Houssainy A., 2019, Informatics in Medicine Unlocked, V15, P203, DOI 10.1016/j.imu.2019.100178
   Ramya S., 2016, International Journal of Innovative Research in Computer and Communication Engineering, V4, P812, DOI 10.15680/IJIRCCE.2016
   Rehman ZU, 2020, MED HYPOTHESES, V141, DOI 10.1016/j.mehy.2020.109705
   Shabani M, 2020, BMC GASTROENTEROL, V20, DOI 10.1186/s12876-020-01284-1
   Singh PD, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.12838
   Xiao J, 2019, J TRANSL MED, V17, DOI 10.1186/s12967-019-1860-0
   Yadav Dhyan Chandra, 2020, Human-Intelligent Systems Integration, V2, P89, DOI 10.1007/s42454-020-00006-y
   YADAV DC, 2021, BIOMED PHARMACOL J, V14, P1633, DOI DOI 10.13005/bbj/2264
   Yadav DC, 2021, ENSEMBLE APPROACH BE, P225
   Yadav DC, 2021, COMPUT AIDED DESIGN, P293
NR 26
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41253
EP 41266
DI 10.1007/s11042-023-15188-1
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967652700002
PM 37362681
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Alaeddine, H
   Jihene, M
AF Alaeddine, Hmidi
   Jihene, Malek
TI Plant leaf disease classification using Wide Residual Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wide Residual Networks; Convolution Neural Network; Plant village; Plant
   leaf disease; Transfer Learning
ID RECOGNITION
AB Most plant diseases have clear symptoms that can be recognized and diagnosed with the naked eye by an experienced plant pathologist. The process of diagnosing a disease with the naked eye is manual and slow, and its success rate depends on the ability of the pathologist. Today, many machine learning (ML) models are used to detect and classify plant diseases. In this article, an effort is made to apply the WRN (Wide Residual Networks) model in the field of plant disease classification. This model was trained to perform this classification task. WRN training is promoted using a transfer learning approach. In addition, a detailed experimental study of the WRN for the plant disease classification task on a PlantVillage test image set that includes 55,480 images is presented. The choice of WRN was mainly due to its enormous potential for image classification for various databases and its homogeneous structure. The WRN model represents a shallowest network with also a shorter training time and improved accuracy compared to the residual network (ResNet). The proposed WRN model achieved an accuracy of 99.9611% on a test set, illustrating the viability of the proposed model. The results obtained from the test showed that the model achieved the highest values compared to other deep learning models in the PlantVillage datasets. Overall, the process of training WRN models provides a robust way to classify plant diseases using automated networks on a huge global scale.
C1 [Alaeddine, Hmidi; Jihene, Malek] Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
   [Jihene, Malek] Sousse Univ, Higher Inst Appl Sci & Technol Sousse, Sousse 4000, Tunisia.
C3 Universite de Monastir; Universite de Sousse
RP Alaeddine, H (corresponding author), Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
EM alaeddine.hmidi@fsm.rnu.tn; jihenemalek14@gmail.com
CR Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Anari MS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6504616
   [Anonymous], 2009, J AGR MECH RES
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Bodhwani Vinit, 2019, Procedia Computer Science, V152, P186, DOI 10.1016/j.procs.2019.05.042
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen JD, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100415
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Cruz AC, 2017, 2017 ASABE ANN INT M, P1, DOI DOI 10.13031/AIM.201700241
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gavhale KR, 2014, IOSR journal of computer engineering (iosr-jce), V16, P10, DOI [DOI 10.9790/0661-16151016, 10.9790/0661-16151016]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Lee SH, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.601250
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Lu JZ, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080707
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Pandian JA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5102290
   PANTAZI XE, 2016, LEAF DIS RECOGNITION, P319, DOI DOI 10.1007/978-3-319-44944-9_27
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun Jun Sun Jun, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P209
   't Hooft G, 2016, FUND THEOR PHYS, V185
   Tian YouWen Tian YouWen, 2007, Transactions of the Chinese Society of Agricultural Engineering, V23, P175
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Wallelign Serawork., 2018, PROC 31 INT FLORIDA, P146
   Wang Guan, 2017, Comput Intell Neurosci, V2017, P2917536, DOI 10.1155/2017/2917536
   Xie CJ, 2018, COMPUT ELECTRON AGR, V152, P233, DOI 10.1016/j.compag.2018.07.014
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhang SW, 2015, J ANIM PLANT SCI, V25, P42
NR 41
TC 1
Z9 1
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40953
EP 40965
DI 10.1007/s11042-023-15226-y
EA APR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000963639900003
DA 2024-07-18
ER

PT J
AU Ucar, M
AF Ucar, Murat
TI Deep neural network model with Bayesian optimization for tuberculosis
   detection from X-Ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep neural networks; Feature extraction; Bayesian optimization;
   Tuberculosis
ID CLASSIFICATION
AB Tuberculosis is a chronic lung disease caused by bacterial infection, and more than 10 million people get this disease every year, especially in developing countries. Early diagnosis of tuberculosis is important for effective treatment. Thus, a new approach for diagnosing tuberculosis disease is proposed in this paper, which is based on the development of a deep neural network (DNN) model in which hyperparameters are determined using the Bayes optimization method. First, feature extraction was conducted using pre-trained deep learning models such as VGG16, EfficientNetB0, ResNet101, and DenseNet201 architectures in the proposed approach. Following that, four DNN models in which hyperparameters were selected using the Bayesian optimization method were developed utilizing these features extracted from pre-trained deep learning architectures. Finally, these DNN models were used to classify tuberculosis disease, and the classification performance of the developed models was compared. The results showed that the EfficientNetB0 model yields the best performance with 99.2857% accuracy, followed by VGG16 with an accuracy of 97.9286% and DenseNet201 with an accuracy of 97%. The ResNet101 model has the lowest accuracy with an accuracy of 95.6429%. Consequently, the best pre-trained model for extracting features from images as well as the most efficient and effective DNN structure for detecting tuberculosis disease has been revealed in this study.
C1 [Ucar, Murat] Iskenderun Tech Univ, Fac Business & Management Sci, Dept Management Informat Syst, Hatay, Turkiye.
C3 Iskenderun Technical University
RP Ucar, M (corresponding author), Iskenderun Tech Univ, Fac Business & Management Sci, Dept Management Informat Syst, Hatay, Turkiye.
EM murat.ucar@iste.edu.tr
OI UCAR, Murat/0000-0001-9997-4267
CR Ahsan M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P427, DOI [10.1109/EIT.2019.8833768, 10.1109/eit.2019.8833768]
   [Anonymous], 2020, Global Tuberculosis Report
   Ayaz M, 2021, PHYS ENG SCI MED, V44, P183, DOI 10.1007/s13246-020-00966-0
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Brochu E, 2010, Arxiv, DOI arXiv:1012.2599
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   Chandra TB, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113514
   Chauhan A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112980
   Chollet F., 2018, Towards Data Science
   Fati SM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147092
   Furin J, 2019, LANCET, V393, P1642, DOI 10.1016/S0140-6736(19)30308-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howell Joel D, 2016, Trans Am Clin Climatol Assoc, V127, P341
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hwang S, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216198
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lopes UK, 2017, COMPUT BIOL MED, V89, P135, DOI 10.1016/j.compbiomed.2017.08.001
   Munadi K, 2020, IEEE ACCESS, V8, P217897, DOI 10.1109/ACCESS.2020.3041867
   Oloko-Oba M, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.830515
   Pasa F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42557-4
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   scikit-optimize.github, BAYES OPT LIB
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   SILVERMAN C, 1949, AM REV TUBERC PULM, V60, P466
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snoek J, 2012, Arxiv, DOI [arXiv:1206.2944, DOI 10.48550/ARXIV.1206.2944]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tasci E, 2021, NEURAL COMPUT APPL, V33, P15541, DOI 10.1007/s00521-021-06177-2
   Vajda S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0991-9
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wong ALXD, 2021, Arxiv, DOI arXiv:2104.03165
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
NR 36
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 5
PY 2023
DI 10.1007/s11042-023-15212-4
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C7JO8
UT WOS:000963639900005
DA 2024-07-18
ER

PT J
AU Hanouti, C
   Le Borgne, H
AF Hanouti, Celina
   Le Borgne, Herve
TI Learning semantic ambiguities for zero-shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-shot learning; Generative latent space; Semantic ambiguity
AB Zero-shot learning (ZSL) aims at recognizing classes for which no visual sample is available at training time. To address this issue, one can rely on a semantic description of each class. A typical ZSL model learns a mapping between the visual samples of seen classes and the corresponding semantic descriptions, in order to do the same on unseen classes at test time. State of the art approaches rely on generative models that synthesize visual features from the prototype of a class, such that a classifier can then be learned in a supervised manner. However, these approaches are usually biased towards seen classes whose visual instances are the only one that can be matched to a given class prototype. We propose a regularization method that can be applied to any conditional generative-based ZSL method, by leveraging only the semantic class prototypes. It learns to synthesize discriminative features for possible semantic description that are not available at training time, that is the unseen ones. The approach is evaluated for ZSL and GZSL on four datasets commonly used in the literature, either in inductive or transductive settings, with results on-par or above state of the art approaches. The code is available at https://github.com/hanouticelina/lsa-zsl.
C1 [Hanouti, Celina] Wefox, Berlin, Germany.
   [Le Borgne, Herve] Univ Paris Saclay, CEA, List, F-91120 Palaiseau, France.
C3 CEA; Universite Paris Saclay; Universite Paris Cite
RP Le Borgne, H (corresponding author), Univ Paris Saclay, CEA, List, F-91120 Palaiseau, France.
EM celina.hanouti@wefox.com; herve.le-borgne@cea.fr
OI Le Borgne, Herve/0000-0003-0520-8436
FU Ile-de-France Regional Council; CPS4EU project by H2020-ECSEL-2018-IA
   [826276]; MEERQAT project [ANR-19-CE23-0028]; CEA; Agence Nationale de
   la Recherche (ANR) [ANR-19-CE23-0028] Funding Source: Agence Nationale
   de la Recherche (ANR)
FX this work relied on the use of the FactoryIA cluster, financially
   supported by the Ile-de-France Regional Council. HLB is partially funded
   by CPS4EU project funded from the H2020-ECSEL-2018-IA call- Grant
   Agreement: 826276 and the ANR-19-CE23-0028 MEERQAT project. CH was
   funded by CEA for her master internship
CR Adjali Omar, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P463, DOI 10.1007/978-3-030-45439-5_31
   [Anonymous], 2012, PROC CVPR IEEE
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Arora G, 2017, ARXIV
   Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308
   Chami I, 2017, P 2017 ACM INT C MUL
   Chou Y-Y, 2021, INT C LEARN REPR
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Le Cacheux Y, 2020, AS C COMP VIS
   Le Cacheux Y, 2020, ECCV 2020 WORKSHOP T
   Le Cacheux Y, 2021, MULTIFACETED DEEP LE, P273
   Le Cacheux Y, 2019, LECT NOTES COMPUT SC, V11296, P465, DOI 10.1007/978-3-030-05716-9_38
   Le Cacheux Y, 2019, IEEE I CONF COMP VIS, P10332, DOI 10.1109/ICCV.2019.01043
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Myoupo D, 2010, LECT NOTES COMPUT SC, V6242, P177, DOI 10.1007/978-3-642-15751-6_20
   Narayan Sanath, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P479, DOI 10.1007/978-3-030-58542-6_29
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Paul A, 2019, PROC CVPR IEEE, P7049, DOI 10.1109/CVPR.2019.00722
   Reed S, 2016, PROC CVPR IEEE
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Schonfeld E, 2019, PROC CVPR IEEE
   Tamaazousti Y, 2020, IEEE T PATTERN ANAL, V42, P2212, DOI 10.1109/TPAMI.2019.2913857
   Tran TQN, 2015, P ACM INT C MULT RET
   Tran TQN, 2016, PROC CVPR IEEE
   Tran TQN, 2016, ACM MULTIMEDIA 2016
   Verma VK, 2017, LECT NOTES ARTIF INT
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Ye M, 2017, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR.2017.542
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Znaidia A, 2012, ACM INT C MULT RETR
NR 34
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40745
EP 40759
DI 10.1007/s11042-023-14877-1
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961632300006
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Kusakunniran, W
   Borwarnginn, P
   Imaromkul, T
   Aukkapinyo, K
   Thongkanchorn, K
   Wattanadhirach, D
   Mongkolluksamee, S
   Thammasudjarit, R
   Ritthipravat, P
   Tuakta, P
   Benjapornlert, P
AF Kusakunniran, Worapan
   Borwarnginn, Punyanuch
   Imaromkul, Thanandon
   Aukkapinyo, Kittinun
   Thongkanchorn, Kittikhun
   Wattanadhirach, Disathon
   Mongkolluksamee, Sophon
   Thammasudjarit, Ratchainant
   Ritthipravat, Panrasee
   Tuakta, Pimchanok
   Benjapornlert, Paitoon
TI Automated tongue segmentation using deep encoder-decoder model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tongue segmentation; Deep U-Net; Encoder-decoder
AB This paper proposes a solution of tongue segmentation in images. The solution relies on a convolutional neural network, using deep U-Net with deep layers of encoder-decoder modules. The model is trained with a starting resolution of 512 x 512 pixels. To enhance the segmentation performances of the trained model across recording environments, three main types of data augmentations are added in the training process, including additive gaussian noise, multiply and add to brightness, and change color temperature. They could also handle an inadequate number of data samples in the limited datasets. The proposed method is evaluated based on four measurement metrics of Dice coefficient, mean IoU, Jaccard distance, and accuracy. The model is successfully trained on publicly available datasets, and then transferred to be tested with the self-collected dataset in the real-world environment.
C1 [Kusakunniran, Worapan; Borwarnginn, Punyanuch; Imaromkul, Thanandon; Aukkapinyo, Kittinun; Thongkanchorn, Kittikhun; Wattanadhirach, Disathon] Mahidol Univ, Fac Informat & Commun Technol, Nakhon Pathom, Thailand.
   [Mongkolluksamee, Sophon] Srinakharinwirot Univ, Fac Sci, Dept Comp Sci, Bangkok, Thailand.
   [Thammasudjarit, Ratchainant] Mahidol Univ, Fac Med Ramathibodi Hosp, Dept Epidemiol & Biostat, Bangkok, Thailand.
   [Ritthipravat, Panrasee] Mahidol Univ, Fac Engn, Dept Biomed Engn, Nakhon Pathom, Thailand.
   [Tuakta, Pimchanok; Benjapornlert, Paitoon] Mahidol Univ, Fac Med Ramathibodi Hosp, Dept Rehabil Med, Bangkok, Thailand.
C3 Mahidol University; Srinakharinwirot University; Mahidol University;
   Mahidol University; Mahidol University
RP Borwarnginn, P (corresponding author), Mahidol Univ, Fac Informat & Commun Technol, Nakhon Pathom, Thailand.
EM punyanuch.bor@mahidol.edu
OI Borwarnginn, Punyanuch/0000-0002-6309-5022
FU Mahidol University [BRF1-011/2564]
FX This research project is supported by Mahidol University (Basic Research
   Fund: fiscal year 2021). (BRF1-011/2564)
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BioHit, 2014, TONG
   Cai YZ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5849
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Guo JW, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1386, DOI 10.1109/CISP-BMEI.2016.7852933
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Johnson PM, 2019, LECT NOTES COMPUT SC, V11905, P71, DOI 10.1007/978-3-030-33843-5_7
   Lachinov D, 2019, LECT NOTES COMPUT SC, V11384, P189, DOI 10.1007/978-3-030-11726-9_17
   Li J, 2017, COOPERATIVE DESIGN V, P252, DOI DOI 10.1007/978-3-319-66805-5_32
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li XL, 2017, IEEE INT C BIOINFORM, P561, DOI 10.1109/BIBM.2017.8217710
   Lin BQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1035, DOI 10.1109/ICASSP.2018.8462650
   Liu WX, 2020, IEEE ACCESS, V8, P41372, DOI 10.1109/ACCESS.2020.2976826
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Pinheiro PO, 2015, Arxiv, DOI arXiv:1506.06204
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saparudin E, 2017, IOP C SERIES MAT SCI, V190, DOI [10.1088/1757-899X/190/1/012041, DOI 10.1088/1757-899X/190/1/012041]
   Shen X, 2016, LECT NOTES COMPUT SC, V9905, P92, DOI 10.1007/978-3-319-46448-0_6
   Shi D, 2020, DATA BRIEF, V32, DOI 10.1016/j.dib.2020.106153
   Shi MJ, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-011-4428-z
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tang Chunlei, 2019, HarvardDataverse, V7, DOI 10.7910/DVN/COJZMQ
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wu KB, 2015, EXPERT SYST APPL, V42, P8027, DOI 10.1016/j.eswa.2015.06.032
   Xue YS, 2018, LECT NOTES COMPUT SC, V11307, P542, DOI 10.1007/978-3-030-04239-4_49
   Yating Huang, 2020, ICCPR 2020: Proceedings of the 2020 9th International Conference on Computing and Pattern Recognition, P244, DOI 10.1145/3436369.3437428
   Zhang PB, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113717
   Zhenchao Cui, 2013, Intelligence Science and Big Data Engineering. 4th International Conference, IScIDE 2013. Revised Selected Papers: LNCS 8261, P328, DOI 10.1007/978-3-642-42057-3_42
NR 38
TC 2
Z9 2
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 20
PY 2023
DI 10.1007/s11042-023-15061-1
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PJ6
UT WOS:000984224700002
DA 2024-07-18
ER

PT J
AU Reis, HC
   Turk, V
   Khoshelham, K
   Kaya, S
AF Reis, Hatice Catal
   Turk, Veysel
   Khoshelham, Kourosh
   Kaya, Serhat
TI MediNet: transfer learning approach with MediNet medical visual database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MediNet; Medical images; Classification; Transfer learning; RdiNet; Deep
   neural networks
ID CLASSIFICATION; DIAGNOSIS; COVID-19; IMAGES
AB The rapid development of machine learning has increased interest in the use of deep learning methods in medical research. Deep learning in the medical field is used in disease detection and classification problems in the clinical decision-making process. Large amounts of labeled datasets are often required to train deep neural networks; however, in the medical field, the lack of a sufficient number of images in datasets and the difficulties encountered during data collection are among the main problems. In this study, we propose MediNet, a new 10-class visual dataset consisting of Rontgen (X-ray), Computed Tomography (CT), Magnetic Resonance Imaging (MRI), Ultrasound, and Histopathological images such as calcaneal normal, calcaneal tumor, colon benign colon adenocarcinoma, brain normal, brain tumor, breast benign, breast malignant, chest normal, chest pneumonia. AlexNet, VGG19-BN, Inception V3, DenseNet 121, ResNet 101, EfficientNet B0, Nested-LSTM + CNN, and proposed RdiNet deep learning algorithms are used in the transfer learning for pre-training and classification application. Transfer learning aims to apply previously learned knowledge in a new task. Seven algorithms were trained with the MediNet dataset, and the models obtained from these algorithms, namely feature vectors, were recorded. Pre-training models were used for classification studies on chest X-ray images, diabetic retinopathy, and Covid-19 datasets with the transfer learning technique. In performance measurement, an accuracy of 94.84% was obtained in the traditional classification study for the InceptionV3 model in the classification study performed on the Chest X-Ray Images dataset, and the accuracy was increased 98.71% after the transfer learning technique was applied. In the Covid-19 dataset, the classification success of the DenseNet121 model before pre-trained was 88%, while the performance after the transfer application with MediNet was 92%. Inthe Diabetic retinopathy dataset, the classification success of the Nested-LSTM + CNN model before pre-trained was 79.35%, while the classification success was 81.52% after the transfer application with MediNet. The comparison of results obtained from experimental studies observed that the proposed method produced more successful results.
C1 [Reis, Hatice Catal] Gumushane Univ, Dept Geomat Engn, TR-2900 Gumushane, Turkiye.
   [Turk, Veysel] Univ Harran, Dept Comp Engn, Sanliurfa, Turkiye.
   [Khoshelham, Kourosh] Univ Melbourne, Dept Infrastruct Engn, Parkville 3052, Australia.
   [Kaya, Serhat] Dicle Univ, Dept Min Engn, Diyarbakir, Turkiye.
C3 Gumushane University; Harran University; University of Melbourne; Dicle
   University
RP Reis, HC (corresponding author), Gumushane Univ, Dept Geomat Engn, TR-2900 Gumushane, Turkiye.
EM hatice.catal@yahoo.com.tr
RI Catal Reis, Hatice/J-8592-2017; Türk, Veysel/ABG-6392-2021
OI Catal Reis, Hatice/0000-0003-2696-2446; Türk, Veysel/0000-0003-1250-0590
CR Abbas A, 2020, IEEE ACCESS, V8, P74901, DOI 10.1109/ACCESS.2020.2989273
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   An GZ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83503-7
   Ayana G, 2022, CANCERS, V14, DOI 10.3390/cancers14051280
   Borkowski A.A., 2019, arXiv
   Bukhari S., 2020, MedRxiv, V2020, P1, DOI [10.1101/2020.08.15.20175760, DOI 10.1101/2020.08.15.20175760]
   Chaitanya K, 2019, LECT NOTES COMPUT SC, V11492, P29, DOI 10.1007/978-3-030-20351-1_3
   Chakrabarty N, IMAGES BRAIN TUMOR D
   Cho K., 2014, ARXIV14061078
   Dabral I, 2019, INT C DEEP LEARN ART, P290, DOI DOI 10.1007/978-3-030-67187-7_30
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Darma I. W. A. S., 2020, 2020 4 INT C INF COM, P1, DOI [10.1109/ICICoS51170.2020.9299021, DOI 10.1109/ICICOS51170.2020.9299021]
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Enguehard J, 2019, IEEE ACCESS, V7, P11093, DOI 10.1109/ACCESS.2019.2891970
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Github, 2017, DIABETIC RETINOPATHY
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He X. etal, 2020, medRxiv
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hwang JH, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020274
   Jain R, 2020, MEASUREMENT, V165, DOI 10.1016/j.measurement.2020.108046
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan HA, 2020, MATH BIOSCI ENG, V17, P6203, DOI 10.3934/mbe.2020328
   Kim YD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61519-9
   Kingma D. P., 2014, arXiv
   Kogilavani SV, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/7672196
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Kwon G, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74653-1
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li XH, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103853
   Moniz Joel Ruben Antony, 2017, PMLR, V77, P530, DOI [10.48550/arXiv.1801.10308, DOI 10.48550/ARXIV.1801.10308]
   Narayanan BN, 2020, AI-BASEL, V1, P539, DOI 10.3390/ai1040032
   Narayanan BN, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.3.034501
   Negi A., 2022, Cyber-Physical Systems, P1
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Rajpurkar P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61055-6
   Rehman A, 2020, CIRC SYST SIGNAL PR, V39, P757, DOI 10.1007/s00034-019-01246-3
   Reis HC., 2017, INT J ONCOL CANC THE, V2, P20
   Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Wacker J, 2020, INT MICCAI BRAINLESI, P241
   Wang L, 2019, IEEE T MED IMAGING, V38, P2219, DOI 10.1109/TMI.2019.2901712
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
NR 51
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39211
EP 39254
DI 10.1007/s11042-023-14831-1
EA MAR 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000984224700012
PM 37362724
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Singh, P
   Singh, P
   Farooq, U
   Khurana, SS
   Verma, JK
   Kumar, M
AF Singh, Paramjeet
   Singh, Parvinder
   Farooq, Umar
   Khurana, Surinder Singh
   Verma, Jitendra Kumar
   Kumar, Munish
TI CottonLeafNet: cotton plant leaf disease detection using deep neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cotton; CNN; Smart agriculture; Image processing; Leaf disease
ID ALGEBRA
AB India is a cover crop region whereby agricultural production sustains a substantial proportion of the populace and upon which the whole Indian economy is heavily reliant. As per research, it provides subsistence for around 70% of rural households. In terms of agricultural output and exports, India ranks second and ninth, respectively. However, it accomplishes the first position globally in terms of cotton exports thereby adequately contributing to the economy of the country. However, it has been documented that various crops especially cotton plants are severely harmed by various pests, extreme climatic variations, nutrient inadequacy and toxicity, and so on. Cotton plant diseases cause a wide range of illnesses ranging from bacterial to nutritional deficiency giving a hard time for the human eye to recognize. However, most of the researchers have considered only a few types of cotton leaf diseases and excluded many. Keeping these constraints in consideration, this research seeks to aid the detection of these diseases by employing deep learning paradigms. The research begins with acquiring a near-balanced dataset with 22 leaf disease types including bacterial, fungal, viral, nutrient deficiency, etc. followed by data augmentation to boost the performance of the models. Many algorithms were tested, however, CNN happens to be very efficient and productive. The proposed model when evaluated on the test set achieves an accuracy of 99.39% with a negligible error rate, thus outperforming all the existing approaches by consuming less computational time. The outcome portrays that the proposed approach has the efficiency to be implemented in real-time detection systems to aid the precise detection of cotton leaf diseases to help the farmers in taking appropriate actions.
C1 [Singh, Paramjeet; Verma, Jitendra Kumar] Natl Informat Ctr, Jaipur, Rajasthan, India.
   [Singh, Parvinder; Farooq, Umar; Khurana, Surinder Singh] Cent Univ Punjab, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Bathinda, India.
C3 Central University of Punjab
RP Singh, P (corresponding author), Cent Univ Punjab, Bathinda, India.
EM parvinder.singh@cup.edu.in
RI Verma, Jitendra Kumar/AAQ-5538-2021; Kumar, Munish/O-2142-2019; Singh,
   Parvinder/AAM-5012-2021
OI Kumar, Munish/0000-0003-0263-0009; Singh, Parvinder/0000-0001-7258-7769;
   Farooq, Umar/0000-0002-3786-2574
CR Amara J., 2017, DATENBANKSYSTEME BUS
   [Anonymous], 2014, Int. J. Eng. Res.
   Arivazhagan S., 2018, INT J PURE APPL MATH, V120, P11067
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chopda J., 2018, P 2018 INT C SMART C
   Deepalakshmi P, 2021, INT J INF SYST MODEL, V12, P1, DOI 10.4018/IJISMD.2021010101
   Guo TM, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA), P721, DOI 10.1109/ICBDA.2017.8078730
   Harakannanavar S. S., 2022, Global Trans. Proc, V3, P305, DOI [10.1016/j.gltp.2022.03.016, DOI 10.1016/J.GLTP.2022.03.016]
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hilbert O, 2018, COTTON SUPPLY CHAIN, P8
   Jia SY, 2020, Arxiv, DOI arXiv:2007.13484
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lin K, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00155
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lyu YT, 2019, CHEMOMETR INTELL LAB, V189, P8, DOI 10.1016/j.chemolab.2019.03.008
   Memon MS, 2022, COMPUTERS, V11, DOI 10.3390/computers11070102
   Hughes DP, 2016, Arxiv, DOI [arXiv:1511.08060, DOI 10.48550/ARXIV.1511.08060]
   Parikh A, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P594, DOI 10.1109/DSAA.2016.81
   Pawan DS., 2015, INT RES J ENG TECHNO, V2, P426
   Prajapati BS, 2016, P INT C EL EL OPT TE, P1
   Rothe PR, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATION AND COMPUTATIONAL ENGINEERING (ICECCE), P67, DOI 10.1109/ICECCE.2014.7086637
   Santos TT, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105247
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Zhang J, 2021, INT J DISTRIB SENS N
   Zhang M, 2021, IEEE ACCESS, V9
   Zhang N, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101756
NR 33
TC 6
Z9 6
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-14954-5
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0HO6
UT WOS:000952027100003
DA 2024-07-18
ER

PT J
AU Tabassum, S
   Gowre, SC
AF Tabassum, Shabana
   Gowre, SanjayKumar C.
TI Optimal image Denoising using patch-based convolutional neural network
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning architecture; PCNN (Patch-based CNN); KODAK; CNN
   architecture; CNN-backed architecture
ID COLOR DEMOSAICKING; RESTORATION; SPARSE
AB Traditional CNN uses fixed location which is irrelevant and they show the inability to capture edges and texture which causes the smoothness of artefacts, thus many details are lost. Hence, this research work designs and develops a novel CNN-backed architecture i.e. PCNN (Patch-based CNN). PCNN sets network depth based on patch size. Moreover, research work follows various steps, first patch similarity identification is carried out later it is given to the designed customized CNN for denoising, and then these patches are integrated to achieve the efficient denoised image. Performance evaluation of the proposed PCNN architecture was carried out on the KODAK dataset by comparing and considering different parameters like PSNR and SSIM. A further different signal level is used for deep evaluation. Comparative analysis with different state-of-art techniques including deep learning-based shows that PCNN simply outperforms the other model. Further analysis is carried out on three random images i.e. image 8, image 19, and image 20 are considered for PSNR and SSIM comparison and it is observed that in terms of PSNR, PCNN achieves 93.03%, 62.01% and 67.78% improvised over the existing model. Further, SSIM is considered for the same images and PCNN achieves 42.55%, 19.84%, and 15.63% improvisation over the existing model. Further, this research compares PSNR values over different signal levels of 2, 4, 6, 8, and 10 and achieves improvisation of 45.51%, 38.72%, 38.57%, 56.2%, and 35.06% respectively. Furthermore, Average PSNR is compared considering Red, Green, Blue, and RGB, PCNN achieves improvisation of 5.65%, 2.34%, 8.62%, and 4.87%.
C1 [Tabassum, Shabana] KBN Coll Engn, Kalaburagi, Karnataka, India.
   [Gowre, SanjayKumar C.] Bheemanna Khandre Inst Technol, Bhalki, Karnataka, India.
RP Tabassum, S (corresponding author), KBN Coll Engn, Kalaburagi, Karnataka, India.
EM shabana_tabassum2k22@rediffmail.com; sanjaygowre@gmail.com
RI Tabassum, Shabana/IVV-6526-2023
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   [Anonymous], KODAK LOSSLESS TRUE
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H., 2012, CVPR
   Condat L, 2012, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2012.6467476
   Cui K, 2021, IEEE J-STSP, V15, P174, DOI 10.1109/JSTSP.2020.3043148
   Cui K, 2018, IEEE IMAGE PROC, P2177, DOI 10.1109/ICIP.2018.8451020
   Danielyan A, 2010, WORKSH INF THEOR MET
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong N, 2021, ARXIV
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Elgendy OA, 2021, IEEE T COMPUT IMAG, V7, P137, DOI 10.1109/TCI.2021.3052694
   Gharbi M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982399
   Gnanasambandam A, 2019, OPT EXPRESS, V27, P17298, DOI 10.1364/OE.27.017298
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo S, 2021, IEEE T IMAGE PROCESS, V30, P6930, DOI 10.1109/TIP.2021.3100312
   Hirakawa K, 2005, IEEE T IMAGE PROCESS, V14, P360, DOI 10.1109/TIP.2004.838691
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Khadidos AO, 2021, MULTIMEDIA SYST, V27, P807, DOI 10.1007/s00530-020-00707-z
   Kiku D, 2014, I N PROC SPIE, V9023
   Kiku D, 2016, IEEE T IMAGE PROCESS, V25, P1288, DOI 10.1109/TIP.2016.2518082
   Kokkinos F, 2019, IEEE T IMAGE PROCESS, V28, P4177, DOI 10.1109/TIP.2019.2905991
   Lee M, 2019, IEEE ACCESS, V11, DOI [10.1109/access.2019.290841, DOI 10.1109/ACCESS.2019.290841]
   Li Q, 2017, IEEE INT CONF COMM, P29, DOI 10.1109/ICCW.2017.7962629
   Liang ZT, 2021, IEEE T IMAGE PROCESS, V30, P2248, DOI 10.1109/TIP.2021.3051486
   Liu D., 2017, When Image Denoising Meets High-Level Vision Tasks: A Deep Learning Approach
   Monno Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122787
   Philbin J., 2007, P IEEE C COMPUTER VI
   Shao K, 2021, IEEE ACCESS, V9, P33385, DOI 10.1109/ACCESS.2021.3061118
   Shi BS, 2018, IEEE ACCESS, V6, P46266, DOI 10.1109/ACCESS.2018.2865997
   Tan R., 2017, P INT C MULT EXP ICM, P6
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2005, IEEE T IMAGE PROCESS, V14, P2167, DOI 10.1109/TIP.2005.857260
   Zhang L, 2017, IEEE SIGNAL PROC MAG, V34, P172, DOI 10.1109/MSP.2017.2717489
   [张黎明 ZHANG Liming], 2011, [生态环境学报, Ecology and Environmental Sciences], V20, P1
NR 37
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29805
EP 29821
DI 10.1007/s11042-023-15014-8
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950429600005
DA 2024-07-18
ER

PT J
AU Xia, HF
   Zhan, YZ
AF Xia, Hui-fen
   Zhan, Yong-zhao
TI Deep cascaded action attention network for weakly-supervised temporal
   action localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weakly-supervised; Temporal action localization; Deep cascaded action
   attention; Non-action suppression
ID ACTION RECOGNITION
AB Weakly-supervised temporal action localization (W-TAL) is to locate the boundaries of action instances and classify them in an untrimmed video, which is a challenging task due to only video-level labels during training. Existing methods mainly focus on the most discriminative action snippets of a video by using top-k multiple instance learning (MIL), and ignore the usage of less discriminative action snippets and non-action snippets. This makes the localization performance improve limitedly. In order to mine the less discriminative action snippets and distinguish the non-action snippets better in a video, a novel method based on deep cascaded action attention network is proposed. In this method, the deep cascaded action attention mechanism is presented to model not only the most discriminative action snippets, but also different levels of less discriminative action snippets by introducing threshold erasing, which ensures the completeness of action instances. Besides, the entropy loss for non-action is introduced to restrict the activations of non-action snippets for all action categories, which are generated by aggregating the bottom-k activation scores along the temporal dimension. Thereby, the action snippets can be distinguished from non-action snippets better, which is beneficial to the separation of action and non-action snippets and enables the action instances more accurate. Ultimately, our method can facilitate more precise action localization. Extensive experiments conducted on THUMOS14 and ActivityNet1.3 datasets show that our method outperforms state-of-the-art methods at several t-IoU thresholds.
C1 [Xia, Hui-fen; Zhan, Yong-zhao] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Xia, Hui-fen] Changzhou Vocat Inst Mechatron Technol, Changzhou 213164, Jiangsu, Peoples R China.
   [Zhan, Yong-zhao] Jiangsu Engn Res Ctr Big Data Ubiquitous Percept &, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University; Changzhou Vocational Institute of Mechatronic
   Technology
RP Zhan, YZ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.; Zhan, YZ (corresponding author), Jiangsu Engn Res Ctr Big Data Ubiquitous Percept &, Zhenjiang 212013, Jiangsu, Peoples R China.
EM yzzhan@ujs.edu.cn
RI jin, li/IWU-4648-2023; Zhang, Zhentao/JQV-7389-2023
FU National Natural Science Foundation of China [61672268]
FX AcknowledgementsThis research was supported in part by National Natural
   Science Foundation of China (Grant No. 61672268).
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ge YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107686
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Huang LJ, 2020, AAAI CONF ARTIF INTE, V34, P11053
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Kay W., 2017, CORR ABS170506950
   Kingma D. P., 2014, arXiv
   Lee P, 2020, AAAI CONF ARTIF INTE, V34, P11320
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu Z, 2021, IEEE I CONF COMP VIS, DOI [10.1109/TPAMI:3078798, DOI 10.1109/TPAMI:3078798]
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Narayan S, 2019, IEEE I CONF COMP VIS, P8678, DOI 10.1109/ICCV.2019.00877
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Peisen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P539, DOI 10.1007/978-3-030-58598-3_32
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Qin XL, 2020, IEEE SIGNAL PROC LET, V27, P1520, DOI 10.1109/LSP.2020.3018914
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Rashid M, 2020, IEEE WINT CONF APPL, P604, DOI [10.1109/wacv45572.2020.9093404, 10.1109/WACV45572.2020.9093404]
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wedel Andreas, 2009, Statistical and Geometrical Approaches to Visual Motion Analysis. International Dagstuhl Seminar. Revised Papers, P23, DOI 10.1007/978-3-642-03061-1_2
   Xu M., 2020, CVPR, P10156
   Yu JR, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103276
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zeng RH, 2019, IEEE T IMAGE PROCESS, V28, P5797, DOI 10.1109/TIP.2019.2922108
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhong JX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P35, DOI 10.1145/3240508.3240511
NR 37
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29769
EP 29787
DI 10.1007/s11042-023-14670-0
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000950119600004
DA 2024-07-18
ER

PT J
AU Wu, B
   Lang, B
AF Wu, Bo
   Lang, Bo
TI MSGCN: a multiscale spatio graph convolution network for 3D point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiscale spatio graph; Self-adaptive graph convolution; Chebyshev
   polynomial; Point clouds
AB We propose a multiscale spatio graph neural network (MSGCN) for 3D point cloud. The core of MSGCN is a multiscale spatio graph(MSG) that explicitly models the relations at various spatial scales. Different from many previous hierarchical structures, the MSG is built in a data adaptive fashion. MSG supports multiscale analysis of point clouds in the scale space and can obtain the dimensional features of point cloud data at different scales. Because traditional convolutional neural networks are not applicable to graph data with irregular vertex neighborhoods, this paper presents an sef-adaptive graph convolution kernel that uses the Chebyshev polynomial to fit an irregular convolution filter based on the theory of optimal approximation. In experiments conducted on four widely used public datasets, The results show that the proposed model outperforms most state-of-the-art methods.
C1 [Wu, Bo] Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Peoples R China.
   [Wu, Bo] Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Nanjing 211189, Peoples R China.
   [Wu, Bo; Lang, Bo] Beihang Univ, Beijing 100083, Peoples R China.
C3 Nanchang Hangkong University; Southeast University - China; Beihang
   University
RP Wu, B (corresponding author), Nanchang Hangkong Univ, Sch Software, Nanchang 330063, Peoples R China.; Wu, B (corresponding author), Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Nanjing 211189, Peoples R China.; Wu, B (corresponding author), Beihang Univ, Beijing 100083, Peoples R China.
EM wubo@pmlabs.com.cn; langbo@buaa.edu.cn
RI wu, bo/GZN-0213-2022; Lang, Bo/AAA-7966-2022
OI wu, bo/0000-0002-0214-234X; 
FU Opening Foundation of Key Laboratory of Computer Network and Information
   Integration(Southeast University), Ministry of Education [K93-9-2021-05]
FX This paper is supported by Opening Foundation of Key Laboratory of
   Computer Network and Information Integration(Southeast University),
   Ministry of Education (K93-9-2021-05).
CR Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   [Anonymous], 2001, P IMR 2001 NEWP BEAC
   [Anonymous], 2014, P 20 ACM SIGKDD INT, DOI DOI 10.1145/2623330.2623732
   [Anonymous], 2017, 31 INT CONFNEURAL IN
   [Anonymous], 2018, PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation
   Benson D, 2002, ACM T GRAPHIC, V21, P785, DOI 10.1145/566570.566652
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao D., 2021, Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Cheng XJ, 2017, JOINT CLASSIFICATION, V44
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He MY, 2018, LASER OPTOELECTRON P, V55, DOI 10.3788/LOP55.042803
   Henaff M., 2015, ARXIV150605163
   Hsu SH, 2009, INT J ADV MANUF TECH, V42, P940, DOI 10.1007/s00170-008-1651-x
   Jin WG, 2018, PR MACH LEARN RES, V80
   Junbo Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11492, DOI 10.1109/CVPR42600.2020.01151
   Kim SK, 2013, MULTIMED TOOLS APPL, V63, P265, DOI 10.1007/s11042-012-0999-y
   Kingma D. P., 2014, arXiv
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Lim T., 2016, Proc. ICLR
   Manyun H, 2018, BUILDING EXTRACTION, V4
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meng Q, 2021, WEAKLY SUPERVISED FR
   Meng QH, 2022, IEEE T PATTERN ANAL, V44, P4454, DOI 10.1109/TPAMI.2021.3063611
   Nascimento ER, 2012, IEEE INT C INT ROBOT, P1720, DOI 10.1109/IROS.2012.6385693
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Sadeghi D, 2021, ARXIV
   Shoeibi A., 2020, ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760
   Wu B, 2018, NEUROCOMPUTING, V321, P346, DOI 10.1016/j.neucom.2018.09.008
   Wu J, 2011, PROC SPIE, V8009, DOI 10.1117/12.896198
   Yan S, 2018, IEEE T IMAGE PROCESS
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yin JB, 2023, IEEE T PATTERN ANAL, V45, P9822, DOI 10.1109/TPAMI.2021.3125981
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   You JX, 2018, ADV NEUR IN, V31
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zheng C, 2020, MULTIMODAL DEEP NETW
NR 49
TC 2
Z9 2
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35949
EP 35968
DI 10.1007/s11042-023-14639-z
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000948950300004
DA 2024-07-18
ER

PT J
AU Buyukarikan, B
   Ulker, E
AF Buyukarikan, Birkan
   Ulker, Erkan
TI Classification of physiological disorders in apples using deep
   convolutional neural network under different lighting conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Lighting; Physiological disorders in
   apples; Classification; Computer vision; Friedman; Nemenyi
ID NEAR-INFRARED SPECTROSCOPY; BITTER PIT; STATISTICAL COMPARISONS; QUALITY
   INSPECTION; COMPUTER VISION; REFLECTANCE; CLASSIFIERS; IMAGES; FRUITS
AB Non-destructive testing of apple fruit, an important product in the world fresh fruit trade, according to physiological disorders, can be done with a computer vision system. However, in the vision system, images may be affected by the brightness values created by different lighting conditions. For this reason, it is a necessity to use algorithms that accurately and quickly detect physiological disorders. By using a convolutional neural network (CNN), an algorithm that enables easy extraction of features from images, determining physiological disorders becomes easier. This study aims to classify the images of apples with physiological disorders obtained under different lighting conditions with CNN models. This study created a dataset (images of different light colors, angles, and distances) with some physiological disorder images. A 5-fold cross-validation method was applied to improve the generalization ability of the models, and CNN models were trained end-to-end. In addition, the Friedman hypothesis test and post-hoc Nemenyi test were performed to compare the evaluation indicators of different CNN models. The average accuracy, precision, recall, and F1-score of the Xception model were 0.996, 0.994, 0.996, and 0.998, respectively. The classification accuracy of this model is followed by the ResNet101, MobileNet, ResNet152, ResNet18, ResNet34, ResNet50, EfficientNetB0, AlexNet, VGG16, and VGG19. Finally, Xception performed well, according to Friedman/Nemenyi test results.
C1 [Buyukarikan, Birkan] Selcuk Univ, Sarayonu Vocat High Sch, Dept Comp Technol, Konya, Turkiye.
   [Ulker, Erkan] Konya Tech Univ, Fac Engn & Nat Sci, Dept Comp Engn, Konya, Turkiye.
C3 Selcuk University; Konya Technical University
RP Buyukarikan, B (corresponding author), Selcuk Univ, Sarayonu Vocat High Sch, Dept Comp Technol, Konya, Turkiye.
EM birkan@selcuk.edu.tr
RI Buyukarikan, Birkan/F-4244-2019
OI Buyukarikan, Birkan/0000-0002-9703-9678
FU Scientific Research Project at Konya Technical University, Konya, Turkey
   [201113006]
FX This work was supported by the Scientific Research Project at Konya
   Technical University, Konya, Turkey (No. 201113006).
CR Abdel-Salam R, 2022, NEURAL COMPUT APPL, V34, P6085, DOI 10.1007/s00521-021-06762-5
   Adler A, 2016, ARXIV
   Alharbi A.G., 2020, 2 INT C COMP INF SCI, P1, DOI [10.1109/ICCIS49240.2020.9257640, DOI 10.1109/ICCIS49240.2020.9257640]
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Altuntas Y, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104874
   Anagnostis A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020469
   Arefi A, 2016, POSTHARVEST BIOL TEC, V112, P266, DOI 10.1016/j.postharvbio.2015.09.001
   Ariana D, 2006, COMPUT ELECTRON AGR, V50, P148, DOI 10.1016/j.compag.2005.10.002
   Ayaz H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146422
   Baltruschat IM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42294-8
   Bansal P, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11070617
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Brosnan T, 2004, J FOOD ENG, V61, P3, DOI 10.1016/S0260-8774(03)00183-3
   Buyukarikan B., 2020, ULUDA U J FAC ENG, V25, P81, DOI [10.17482/uumfd.628166, DOI 10.17482/UUMFD.628166]
   Buyukarikan B, 2022, NEURAL COMPUT APPL, V34, P16973, DOI 10.1007/s00521-022-07350-x
   Cainelli N, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms222413425
   Carranza-García M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   Chen YR, 2002, COMPUT ELECTRON AGR, V36, P173, DOI 10.1016/S0168-1699(02)00100-X
   Chollet F., 2017, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Colantoni A, 2018, AGRICULTURE-BASEL, V8, DOI 10.3390/agriculture8040047
   Cubero S, 2011, FOOD BIOPROCESS TECH, V4, P487, DOI 10.1007/s11947-010-0411-8
   Cusano C, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061410
   Cusano C, 2016, J OPT SOC AM A, V33, P17, DOI 10.1364/JOSAA.33.000017
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Espejo-Garcia B, 2020, COMPUT ELECTRON AGR, V171, DOI 10.1016/j.compag.2020.105306
   Fan SX, 2020, J FOOD ENG, V286, DOI 10.1016/j.jfoodeng.2020.110102
   Finlayson GD, 2000, INT C PATT RECOG, P191, DOI 10.1109/ICPR.2000.905301
   Garcia Nachtigall Lucas, 2017, International Journal of Monitoring and Surveillance Technologies Research, V5, P1, DOI 10.4018/IJMSTR.2017040101
   García S, 2008, J MACH LEARN RES, V9, P2677
   Gómez-Sanchis J, 2008, J FOOD ENG, V85, P191, DOI 10.1016/j.jfoodeng.2007.06.036
   Haciefendioglu K, 2022, IJST-T CIV ENG, V46, P1621, DOI 10.1007/s40996-021-00671-2
   Hao X, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105847
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G. E., 2012, 12070580 ARXIV
   Hornberg A., 2017, Handbook of Machine and Computer Vision: The Guide for Developers and Users, DOI [DOI 10.1002/9783527413409, 10.1002/9783527413409]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang M, 2010, POSTHARVEST BIOL TEC, V58, P168, DOI 10.1016/j.postharvbio.2010.08.002
   Ijjina EP, 2015, LECT NOTES COMPUT SC, V9008, P316, DOI 10.1007/978-3-319-16628-5_23
   inik O., 2017, Gaziosmanpasa Journal of Scientific Research, V6, P85
   Ismail A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124353
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jarolmasjed S, 2017, J FOOD MEAS CHARACT, V11, P987, DOI 10.1007/s11694-017-9473-x
   Jiang B, 2019, ARTIF INTELL AGR, V1, P1, DOI 10.1016/j.aiia.2019.02.001
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kafle GK, 2016, POSTHARVEST BIOL TEC, V120, P188, DOI 10.1016/j.postharvbio.2016.06.013
   Kang J, 2022, MULTIMED TOOLS APPL, V81, P22355, DOI 10.1007/s11042-021-11282-4
   Khan Altaf, 2021, In Silico Pharmacology, V10, P1, DOI [10.1007/s40203-021-00116-8, 10.1504/IJCISTUDIES.2021.113831]
   Kizrak MA., 2018, BILISIM TEKNOLOJILER, V11, P263, DOI [10.17671/gazibtd.419205, DOI 10.17671/GAZIBTD.419205]
   Kludt C, 2021, TM-TECH MESS, V88, P330, DOI 10.1515/teme-2021-0021
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Y, 2022, NEURAL COMPUT APPL, V34, P8411, DOI 10.1007/s00521-020-05310-x
   Lashgari M, 2020, J FOOD SCI TECH MYS, V57, P2233, DOI 10.1007/s13197-020-04259-y
   LeCun Y, 1988, P 1988 CONN MOD SUMM, V1, P21, DOI DOI 10.3168/JDS.S0022-0302(88)79586-7
   Li QQ, 2020, FOOD CHEM, V321, DOI 10.1016/j.foodchem.2020.126707
   Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107
   Lötze E, 2006, POSTHARVEST BIOL TEC, V40, P287, DOI 10.1016/j.postharvbio.2006.02.004
   Lu Y, 2018, T ASABE, V61, P1831, DOI 10.13031/trans.12930
   Marsland S., 2011, Machine learning: an algorithmic perspective, DOI DOI 10.1201/9781420067194
   Mogollon MR, 2020, POSTHARVEST BIOL TEC, V161, DOI 10.1016/j.postharvbio.2019.111060
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.75, 10.1109/ICTAI.2016.0078]
   Nicolaï BM, 2006, POSTHARVEST BIOL TEC, V40, P1, DOI 10.1016/j.postharvbio.2005.12.006
   Noris M, 2020, THESIS U CAFOSCARI V
   Nuske S, 2014, J FIELD ROBOT, V31, P837, DOI 10.1002/rob.21541
   Özden C, 2021, TURK J AGRIC FOR, V45, P775, DOI 10.3906/tar-2010-100
   Rodríguez FJ, 2018, PROG ARTIF INTELL, V7, P119, DOI 10.1007/s13748-017-0137-1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Santos L, 2020, ADV INTELL SYST COMP, V1092, P139, DOI 10.1007/978-3-030-35990-4_12
   Sharma R., 2020, SENSOR BASED QUALITY, P231
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stein M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111915
   Sun SaShuang Sun SaShuang, 2019, Information Processing in Agriculture, V6, P200, DOI 10.1016/j.inpa.2018.08.011
   Sun Y, 2019, POSTHARVEST BIOL TEC, V151, P68, DOI 10.1016/j.postharvbio.2019.01.011
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tao Y, 1996, OPT ENG, V35, P344, DOI 10.1117/1.600902
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Tian Hong-kun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006
   Toivonen PMA, 2011, ABIOTIC STRESS IN PLANTS - MECHANISMS AND ADAPTATIONS, P39
   Toivonen PMA, 2003, POSTHARVEST OXIDATIVE STRESS IN HORTICULTURAL CROPS, P225
   Toivonen PMA, 2004, HORTSCIENCE, V39, P938, DOI 10.21273/HORTSCI.39.5.938
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Unay D, 2007, J FOOD ENG, V78, P597, DOI 10.1016/j.jfoodeng.2005.10.038
   Wang CY, 2021, ARTIF INTELL REV, V54, P5205, DOI 10.1007/s10462-021-10018-y
   Wang SH, 2020, MULTIMED TOOLS APPL, V79, P15117, DOI 10.1007/s11042-018-6661-6
   Watkins CB., 2017, POSTHARVEST PHYSL DI, P315, DOI [10.1016/b978-0-12-394807-6.00217-3, DOI 10.1016/B978-0-12-394807-6.00217-3, 10.1016/B978-0-12-394807-6.00217-3]
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
   Yang J, 2018, MOBILE NETW APPL, V23, P188, DOI 10.1007/s11036-017-0930-x
   Zeng Peng, 2017, 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). Proceedings, P1292, DOI 10.1109/APSIPA.2017.8282223
   Zhang BH, 2014, FOOD RES INT, V62, P326, DOI 10.1016/j.foodres.2014.03.012
   Zhao W, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010023
NR 95
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32463
EP 32483
DI 10.1007/s11042-023-14766-7
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000946885800002
DA 2024-07-18
ER

PT J
AU Liu, PP
   Lu, JX
   Huang, SJ
   Lu, P
   Wang, JG
AF Liu, Pingping
   Lu, Jiaxing
   Huang, Shujuan
   Lu, Ping
   Wang, Jianguo
TI Real-time performance analysis of network buffer under multi-core
   scheduling platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network buffer; Network buffer allocation algorithm; Multi-core
   scheduling algorithm; Buffer management mechanism
ID ALLOCATION; TASKS
AB The network buffer is a key factor affecting the communication efficiency of a multi-core embedded real-time system protocol stack. Therefore, it requires that the buffer structure should be simple, effective, stable and easy to manage. The buffer mBlk in the Vxworks system is a more complex buffer designed based on the buffer pool. Its advantage is that the data is shared by reference, so as to achieve "zero copy" and improve efficiency. However, the disadvantage is that its structure is too complicated and trouble to use. Therefore, according to the actual project requirements, this paper first improves its complex structure and designs a network buffer named sbuf. Secondly, according to the problem of insufficient use of the designed buffer management mechanism in multithreading, a network buffer allocation algorithm is designed to solve this problem. Finally, the designed network buffer is tested under different multi-core scheduling algorithms on litmus RT multi-core platform. The results show that the performance of the improved buffer has been significantly improved in three aspects: response time, preemption and execution time.
C1 [Liu, Pingping; Lu, Jiaxing; Huang, Shujuan; Lu, Ping; Wang, Jianguo] Xian Technol Univ, Sch Comp Sci & Engn, Xian 710021, Peoples R China.
C3 Xi'an Technological University
RP Liu, PP (corresponding author), Xian Technol Univ, Sch Comp Sci & Engn, Xian 710021, Peoples R China.
EM pingpingliu2@outlook.com
RI Lu, Jia/JVO-6891-2024; Wang, Zejun/KBB-8454-2024; Wang,
   Han/JJF-2614-2023; WU, LINXIN/KEI-8742-2024; xu, wei/JZD-2112-2024;
   Zhang, Yusi/JNS-2335-2023; li, wenjing/JMP-7498-2023; WANG,
   JINGYI/GSJ-1241-2022; zhang, quan/KHY-9180-2024
FU Special project of Shaanxi Provincial Department of Education
   [17JK0388]; General Project of Key Research and Development Plan of
   Shaanxi Province, China [2022GY-119]
FX This work was supported by the Special project of Shaanxi Provincial
   Department of Education undergrant No.17JK0388. This work was supported
   by the General Project of Key Research and Development Plan of Shaanxi
   Province, China (No.2022GY-119).
CR Ahmed, 2020, SOFT REAL TIME OPTIM, DOI [10.1109/RTCSA50079.2020.9203605, DOI 10.1109/RTCSA50079.2020.9203605]
   Asheralieva A, 2016, IEEE T VEH TECHNOL, V65, P9787, DOI 10.1109/TVT.2016.2531290
   Chen HK, 2021, IEEE T SERV COMPUT, V14, P1167, DOI 10.1109/TSC.2018.2866421
   Chwa HS, 2017, IEEE T PARALL DISTR, V28, P1331, DOI 10.1109/TPDS.2016.2614669
   Díaz NL, 2017, IEEE T POWER ELECTR, V32, P5202, DOI 10.1109/TPEL.2016.2606653
   Elwalid A, 2001, IEEE INFOCOM SER, P1300, DOI 10.1109/INFCOM.2001.916625
   Feng WC, 2002, IEEE ACM T NETWORK, V10, P513, DOI 10.1109/TNET.2002.801399
   Greenstein B, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL WORKSHOP ON SENSOR NETWORK PROTOCOLS AND APPLICATIONS, P163, DOI 10.1109/SNPA.2003.1203367
   Han G, 2014, IEEE T IND INFORM, V10, P903, DOI 10.1109/TII.2013.2290585
   Haque MS, 2018, IEEE T COMPUT AID D, V37, P2720, DOI 10.1109/TCAD.2018.2857081
   Phan H, 2019, IEEE T BIO-MED ENG, V66, P1285, DOI 10.1109/TBME.2018.2872652
   KATEVENIS M, 1991, IEEE J SEL AREA COMM, V9, P1265, DOI 10.1109/49.105173
   Kedar G, 2017, IEEE T COMPUT, V66, P717, DOI 10.1109/TC.2016.2608775
   Lai CF, 2017, IEEE COMMUN MAG, V55, P68, DOI 10.1109/MCOM.2017.1601142
   Li XM, 2019, IEEE T IND INFORM, V15, P4225, DOI 10.1109/TII.2019.2899679
   Liu J, 2016, IEEE INT SYMP INFO, P1451, DOI 10.1109/ISIT.2016.7541539
   Melani A, 2017, IEEE T COMPUT, V66, P339, DOI 10.1109/TC.2016.2584064
   Merl R., 2016, P IEEE AER C, P1, DOI [10.1109/AERO.2016.7500849, DOI 10.1109/AERO.2016.7500849]
   Merl R, 2018, AEROSP CONF PROC
   Pathan R, 2018, IEEE T PARALL DISTR, V29, P915, DOI 10.1109/TPDS.2017.2777449
   Sharma V, 2010, IEEE T WIREL COMMUN, V9, P1326, DOI 10.1109/TWC.2010.04.080749
   Supratak A, 2017, IEEE T NEUR SYS REH, V25, P1998, DOI 10.1109/TNSRE.2017.2721116
   Takeuchi H, 2001, INSECT MOL BIOL, V10, P487, DOI 10.1046/j.0962-1075.2001.00288.x
   Wind River Systems, 2011, HIGH PERF MULT NETW
   Xiang L, 2017, IEEE T VEH TECHNOL, V66, P11366, DOI 10.1109/TVT.2017.2720481
   Xiong YJ, 2000, IEEE J SEL AREA COMM, V18, P1838, DOI 10.1109/49.887906
   Yuehong Z, 2019, SOFTW ENG, V22, P35
   Zhang DY, 2018, IEEE T VEH TECHNOL, V67, P1684, DOI 10.1109/TVT.2017.2754273
   Zhao N, 2016, IEEE T TRANSP ELECTR, V2, P480, DOI 10.1109/TTE.2016.2562360
   Zhao YW, 2019, IEEE T DEPEND SECURE, V16, P127, DOI 10.1109/TDSC.2017.2672983
NR 30
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34653
EP 34677
DI 10.1007/s11042-023-14820-4
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700018
DA 2024-07-18
ER

PT J
AU Hao, XL
   Pei, LL
   Li, W
   Hou, Q
   Sun, ZY
   Sun, XX
AF Hao, Xueli
   Pei, Lili
   Li, Wei
   Hou, Qing
   Sun, Zhaoyun
   Sun, Xingxing
TI Cervical cell deep-learning automatic classification method based on
   fusion features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical cell classification; Feature selection; Deep learning; VGG16
ID SEGMENTATION; EXTRACTION; ALGORITHM; NUCLEI; IMAGES
AB To overcome the limitations of single-model feature extraction and further improve the accuracy of automatic cervical cell classification, this paper proposes a classification method based on the fusion of features of cervical cells. First, an image set of cervical nuclei after segmentation was constructed and the shallow features of the images were obtained by extracting the shape, chromaticity, and texture features of the nuclei. Then, based on the VGG16 network pretrained by transfer learning, the training image was inputted into the network and the deep features of the image were automatically extracted by the convolution layer. The two types of features were then normalized and spliced to expand the feature dimension and generate new features. Finally, the new feature group was inputted into the classification network for retraining and the classification result after fusion of the features was obtained. The accuracy of the second and seventh classifications could reach 0.981 and 0.923, respectively. The proposed method has practical significance for promoting the automatic application process of cervical cancer screening.
C1 [Hao, Xueli; Pei, Lili; Li, Wei; Sun, Zhaoyun; Sun, Xingxing] Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
   [Hou, Qing] Shaanxi Univ Chinese Med, Xian Yang 710064, Shaanxi, Peoples R China.
   [Hao, Xueli] Anhui Keli Informat Ind Co Ltd, Anhui Key Lab Intelligent Transportat, Hefei 230088, Peoples R China.
C3 Chang'an University; Shaanxi University of Chinese Medicine
RP Li, W (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
EM grandy@chd.edu.cn
RI Hao, Xue-Li/AAC-1470-2022
FU Fundamental Research Funds for the Central Universities [300102240206,
   300102249301]
FX AcknowledgementsThis research is funded by the Fundamental Research
   Funds for the Central Universities, CHD (300102240206, 300102249301).
CR Bora K, 2017, COMPUT METH PROG BIO, V138, P31, DOI 10.1016/j.cmpb.2016.10.001
   Chankong T, 2014, COMPUT METH PROG BIO, V113, P539, DOI 10.1016/j.cmpb.2013.12.012
   Chen K., ARXIV
   Devi MA, 2016, PROCEDIA COMPUT SCI, V89, P465, DOI 10.1016/j.procs.2016.06.105
   Garcia-Gonzalez D, 2016, EXPERT SYST APPL, V64, P512, DOI 10.1016/j.eswa.2016.08.015
   Gençtav A, 2012, PATTERN RECOGN, V45, P4151, DOI 10.1016/j.patcog.2012.05.006
   Glez-Pe AD., 2009, BMC BIOINFORMATICS, V10, P1
   Guo L, 2017, RES CERVICAL CYTOPAT
   Hu H., 2018, 2018 IEEE 3 INT C SI, V230, P23
   Hu YY, 2018, ASIAN J PSYCHIATR, V37, P90, DOI 10.1016/j.ajp.2018.08.015
   Hyeon J, 2017, INT CONF BIG DATA, P390, DOI 10.1109/BIGCOMP.2017.7881741
   Li W, 2016, MULTICLASSIFIER FUSI
   Liao X, 2018, CHIN J LIQ CRYST DIS, V33, P528, DOI 10.3788/YJYXS20183306.0528
   Lili P, 2022, 2022 INT C INTELLIGE, P7
   Lin HM, 2019, IEEE ACCESS, V7, P71541, DOI 10.1109/ACCESS.2019.2919390
   Lu C, 2019, DETECTION RECOGNITIO
   Marinakis Y, 2009, COMPUT BIOL MED, V39, P69, DOI 10.1016/j.compbiomed.2008.11.006
   Moore TJ, 2014, JAMA INTERN MED, V174, P90, DOI 10.1001/jamainternmed.2013.11813
   Mulmule P.V., 2022, BIOMED PHARMACOL J, V15, P277, DOI DOI 10.13005/bpj/2364
   Mulmule PV, 2023, VISUAL COMPUT, V39, P2381, DOI 10.1007/s00371-022-02463-9
   Mulmule PV, 2021, 2021 ASIAN C INNOVAT, P8
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pei LL, 2020, CONSTR BUILD MATER, V256, DOI 10.1016/j.conbuildmat.2020.119356
   Phoulady HA, 2016, IEEE IMAGE PROC, P2658, DOI 10.1109/ICIP.2016.7532841
   Sato M, 2018, ONCOL LETT, V15, P3518, DOI 10.3892/ol.2018.7762
   Sulaiman SN, 2011, INT J KNOWL-BASED IN, V15, P131, DOI 10.3233/KES-2011-0217
   Teeyapan K, 2016, IEEE INT C CONTROL S, P2
   Wang XW, 2009, J BIOMED OPT, V14, DOI 10.1117/1.3081545
   William W, 2018, 2018 IST-AFRICA WEEK CONFERENCE (IST-AFRICA)
   Xueli H., 2022, MATH PROBL ENG, V2022
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
   Zhang L, 2017, COMPUT MED IMAG GRAP, V56, P38, DOI 10.1016/j.compmedimag.2017.01.002
   Zhao LL, 2016, COMPUT BIOL MED, V71, P46, DOI 10.1016/j.compbiomed.2016.01.025
   Zhen X., 2017, PHYS MED BIOL, V16, P33, DOI [10.1016/j.brachy.2017.04.042, DOI 10.1016/J.BRACHY.2017.04.042]
NR 34
TC 0
Z9 0
U1 9
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33183
EP 33202
DI 10.1007/s11042-023-14973-2
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200017
DA 2024-07-18
ER

PT J
AU Yadav, AS
   Singh, N
   Kushwaha, DS
AF Yadav, Amrendra Singh
   Singh, Nikita
   Kushwaha, Dharmender Singh
TI Evolution of Blockchain and consensus mechanisms & its real-world
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Consensus algorithm; Bitcoin; Real-world application
ID SYSTEMS
AB Distributed Ledger Technology (DLT) and blockchain are two terms that have been used interchangeably for the longest of time ever since the concept of the bitcoin cryptocurrency system was introduced by Satoshi Nakamoto in 2008. DLT can be thought of as an umbrella term that encompasses the blockchain and other type of distributed ledgers. It is a decentralized, permisionless, distributed database where each participant maintains its own copy of the distributed ledger and the records are distributed as a chain of blocks across a peer-to-peer network. This implies that a replicated database is maintained and it does not rely on a single party or an intermediary for its operation. This also happens to be the most ground breaking feature of this technology. Bitcoin blockchain can be understood as the first fully functional DLT that exists. Blockchain is rapidly evolving as the next disruptive innovation in secure connectivity, with the potential to fundamentally alter how we work and live in the twenty-first century. The key components of this technology include the miner, the consensus protocols, hashing and an asymmetric cryptography system to encrypt the data through the use of the public and the private key. All transaction in the blockchain is recorded in the form of chain of blocks. Each block contains a unique header which is mathematically and cryptographically computed and to this feature is attributed the immutable nature of the blockchain. This computed hash commits to the header of the previous block, storing the contents of the block in the form of a hash function. All the transactions in the blockchain are recorded in a block that contains a unique header which is cryptographically computed and this attributes to the immutability of the blockchain. This computed hash is stored in the header of the next block. Before a transaction is committed to the ledger, it has to be agreed upon by the active participants of the network in order to guarantee the trustworthiness of the information being incorporated into the blocks. This is where the distributed ledger consensus protocols become important. The consensus mechanism is used to determine which state of the database is chosen to be valid and true. It is only when consensus is achieved that the new transaction is recorded into the block and is linked to the already existing chain of blocks using a hash pointer to the previous block. Despite their initial success, existing blockchain technologies have gaps and limitations regarding flexibility, governance, and scalability. The aim of this research paper is to explore and review existing algorithms and mechanisms that can be deployed on open source blockchain platforms. To deploy and implement any blockchain application, various platforms such as Ethereum, Coinbase, and Embark etc. are available and widely used. In order for a researcher to choose the right blockchain architecture and consensus mechanism for implementing any given application, an in-depth knowledge of the existing state of the art is pertinent. Finally, this article discusses the benefits of blockchain technology in various real-world applications, including land records, finance, healthcare, digital scarcity, supply chain management, and food safety.
C1 [Yadav, Amrendra Singh] Atal Bihari Vajpayee Indian Inst Informat Technol, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
   [Singh, Nikita] RV Univ, Sch Comp Sci & Engn, Bangalore, India.
   [Kushwaha, Dharmender Singh] Motilal Nehru Natl Inst Technol Allahabad, Dept Comp Sci & Engn, Prayagraj, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Yadav, AS (corresponding author), Atal Bihari Vajpayee Indian Inst Informat Technol, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
EM asy@iiitm.ac.in; nikitas@rvu.edu.in; dsk@mnnit.ac.in
OI Yadav, Dr. Amrendra Singh/0000-0003-0241-3661
CR Agi MAN, 2022, INT J PROD ECON, V247, DOI 10.1016/j.ijpe.2022.108458
   Agrawal D, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105100
   Alhadhrami Z., 2017, 2017 INT C ELECT COM
   Alm James., 2004, Stamp Duties In Indian States: A Case for Reform
   Ameyaw PD, 2021, LAND-BASEL, V10, DOI 10.3390/land10030239
   [Anonymous], 2014, Distributed consensus from proof of stake is impossible
   [Anonymous], 1978, For a New Liberty: The Libertarian Manifesto
   [Anonymous], 2016, BARCL SAYS COND 1 BL
   Aste T, 2017, COMPUTER, V50, P18, DOI 10.1109/MC.2017.3571064
   Back A., 2002, Hashcash-a denial of service counter-measure
   Baird L., 2016, Swirlds, Tech. Rep. SWIRLDS-TR-2016-01, V34, P9
   Bano S, 2017, Arxiv, DOI arXiv:1711.03936
   Bayer D., 1992, Sequences II: Methods in Communication, Security, and Computer Science, V2, P329, DOI 10.1007/978-1-4613-9323-8_24
   Biswas S, 2019, IEEE INTERNET THINGS, V6, P4650, DOI 10.1109/JIOT.2018.2874095
   Buchman E, 2016, THESIS U GUELPH
   CHAUM D, 1990, LECT NOTES COMPUT SC, V403, P319
   Chaum D., 1983, Advances in Cryptology, Proceedings of Crypto 82, P199
   Cocco L, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030025
   Crookes L, 2018, Contemporary Issues in Accounting, P61
   Dawei Li, 2019, 2019 18th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/13th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE), P491, DOI 10.1109/TrustCom/BigDataSE.2019.00072
   DENNING DE, 1984, COMMUN ACM, V27, P388, DOI 10.1145/358027.358052
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dorri A, 2016, Arxiv, DOI [arXiv:1608.05187, DOI 10.48550/ARXIV.1608.05187]
   Dubovitskaya Alevtina, 2017, AMIA Annu Symp Proc, V2017, P650
   Dwork C., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P139
   Ehsan I, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/7358354
   Esposito C, 2018, IEEE CLOUD COMPUT, V5, P31
   Fan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0993-7
   Foundation, PROOF EX TOP BITC BL
   Freni P, 2022, BLOCKCHAIN-RES APPL, V3, DOI 10.1016/j.bcra.2022.100069
   Friedman N, 2022, TECHNOL FORECAST SOC, V175, DOI 10.1016/j.techfore.2021.121403
   Gai FY, 2018, LECT NOTES COMPUT SC, V10828, P666, DOI 10.1007/978-3-319-91458-9_41
   Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x
   Guo Y, 2016, FINANC INNOV, V2, DOI 10.1186/s40854-016-0034-9
   Haber S., 1991, Journal of Cryptology, V3, P99, DOI 10.1007/BF00196791
   Halpin H, 2017, 2017 2ND IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW), P1, DOI 10.1109/EuroSPW.2017.43
   Hassija V, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102145
   Ismail L, 2019, IEEE ACCESS, V7, P149935, DOI 10.1109/ACCESS.2019.2947613
   Jo BW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124268
   Kabaklarli E., FUTURE MONEY CRYPTOC
   Khalid MI, 2022, APPL BIONICS BIOMECH, V2022, DOI 10.1155/2022/3859629
   Khan MA, 2022, SMART AGRI, VTechnol
   Kherbouche M, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5010010
   Kim HM, 2018, INTELL SYST ACCOUNT, V25, P18, DOI 10.1002/isaf.1424
   King S., 2012, Self-Published Paper
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kosba A, 2016, P IEEE S SECUR PRIV, P839, DOI 10.1109/SP.2016.55
   LAMPORT L, 1982, ACM T PROGR LANG SYS, V4, P382, DOI 10.1145/357172.357176
   Lamport L, 2019, PART TIME PARLIAMENT, P277
   Li Z., 2019, IEEE Transactions on Industrial Informatics
   Lin QJ, 2019, IEEE ACCESS, V7, P20698, DOI 10.1109/ACCESS.2019.2897792
   Liu MT, 2019, IEEE T WIREL COMMUN, V18, P695, DOI 10.1109/TWC.2018.2885266
   Ma ZF, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0327-1
   Mazieres D, 2022, STELLAR CONSENSUS PR
   Merkle R. C., 1980, Proceedings of the 1980 Symposium on Security and Privacy, P122
   Mettler M, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P520
   Moyano JP, 2017, BUS INFORM SYST ENG+, V59, P411, DOI 10.1007/s12599-017-0504-2
   Mukne H., 2019, INT CONF COMPUT, DOI DOI 10.1109/icccnt45670.2019.8944471
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Notheisen B, 2017, BUS INFORM SYST ENG+, V59, P425, DOI 10.1007/s12599-017-0499-8
   Oguntegbe KF, 2022, TECHNOL SOC, V68, DOI 10.1016/j.techsoc.2022.101927
   Panicker S., 2016, INT J INNOV RES SCI, V5, P20074
   Parra-Moyano J., 2019, INT J BLOCKCHAINS CR, V1, P85, DOI [10.1504/IJBC.2019.101854, DOI 10.1504/IJBC.2019.101854]
   Paul T, 2022, IND MARKET MANAG, V101, P238, DOI 10.1016/j.indmarman.2021.12.003
   R, 2017, REUTERS
   Saberi S, 2019, INT J PROD RES, V57, P2117, DOI 10.1080/00207543.2018.1533261
   SCHWARTZ D, 2014, RIPPLE LABS INC WHIT, V5, P151
   Serada A, 2021, GAMES CULT, V16, P457, DOI 10.1177/1555412019898305
   Shahnaz A, 2019, IEEE ACCESS, V7, P147782, DOI 10.1109/ACCESS.2019.2946373
   Shuaib M, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/5670714
   Singh K, 2018, 2018 INT C COMPUTING
   Singh N., 2019, INT J BLOCKCHAINS CR, V1, P67, DOI [10.1504/IJBC.2019.101853, DOI 10.1504/IJBC.2019.101853]
   Singh N., 2018, J MECH CONTIN MATH S, V13, P73
   Singh N, 2021, CLUSTER COMPUT, V24, P851, DOI 10.1007/s10586-020-03163-6
   Singh N, 2019, INT J CLOUD APPL COM, V9, P60, DOI 10.4018/IJCAC.2019040104
   Singh S, 2022, FUTURE GENER COMP SY, V129, P380, DOI 10.1016/j.future.2021.11.028
   Thakur V, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.04.013
   Tian F, 2017, I C SERV SYST SERV M
   Viriyasitavat W, 2022, J IND INF INTEGR, V26, DOI 10.1016/j.jii.2022.100326
   Wahab A, 2018, Arxiv, DOI [arXiv:1810.03357, 10.48550/arXiv.1810.03357]
   Wang BC, 2018, PROCEDIA COMPUT SCI, V129, P234, DOI 10.1016/j.procs.2018.03.063
   Wang C, 2022, IEEE INTERNET THINGS
   Wang ZY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P447, DOI 10.1109/Blockchain.2019.00068
   Xu XJ, 2024, PROD PLAN CONTROL, V35, P917, DOI 10.1080/09537287.2022.2044073
   Xu XW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2017), P243, DOI 10.1109/ICSA.2017.33
   Yadav AS, 2022, CLUSTER COMPUT, V25, P1475, DOI 10.1007/s10586-022-03535-0
   Yadav AS, 2022, INT J SYST ASSUR ENG, V13, P735, DOI 10.1007/s13198-021-01335-0
   Yadav AS, 2021, PEER PEER NETW APPL, V14, P3540, DOI 10.1007/s12083-021-01207-1
   Yadav AS, 2022, J KING SAUD UNIV-COM, V34, P6414, DOI 10.1016/j.jksuci.2021.02.002
   Yadav AS, 2022, IETE TECH REV, V39, P799, DOI 10.1080/02564602.2021.1908859
   Yadav AS, 2021, ING NIERIE SYST MES, V26, P13, DOI [10.18280/isi.260102, DOI 10.18280/ISI.260102]
   Yang J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071370
   Yli-Huumo J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163477
   Zaman S, 2014, ARTICLE MONEY TO JAN
   Zhang P, 2017, Arxiv, DOI arXiv:1706.03700
   Zhang R, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3316481
   Zheng ZB, 2018, INT J WEB GRID SERV, V14, P352, DOI 10.1504/IJWGS.2018.095647
   Zhou QH, 2020, IEEE ACCESS, V8, P16440, DOI 10.1109/ACCESS.2020.2967218
   Zou L., 2022, 2022 IEEE 2 INT C PO
   Zulkifl Z, 2022, IEEE ACCESS, V10, P15644, DOI 10.1109/ACCESS.2022.3149046
   US
NR 101
TC 7
Z9 7
U1 9
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34363
EP 34408
DI 10.1007/s11042-023-14624-6
EA MAR 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943970200008
DA 2024-07-18
ER

PT J
AU Kolivand, H
   Asadianfam, S
   Akintoye, KA
   Rahim, MS
AF Kolivand, Hoshang
   Asadianfam, Shiva
   Akintoye, Kayode Akinlekan
   Rahim, Mohd Shafry
TI Finger vein recognition techniques: a comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Vein recognition system; Finger vein; Biometric system; Vein
   identification; Vein matching
ID INFRARED FACE RECOGNITION; SOFT BIOMETRIC TRAIT; SHAPE REPRESENTATION;
   IMAGE RECOGNITION; ZERNIKE MOMENTS; ENHANCEMENT; FUSION; SYSTEM;
   ALGORITHM; AUTHENTICATION
AB This paper discusses a comprehensive review of the previous research in the field of the finger vein recognition system with a focus on finger vein enhancements and features extraction advances and shortcomings. It starts with a general introduction of the biometric system followed by detailed descriptions on finger vein identification, and its architecture archival of it, which includes image acquisition, preprocessing of the image, feature extraction, and vein matching. This study focuses on related work proposed by previous researchers, issues in the field that originated from the related work, and a discussion of each of the issues associated and the proposed solutions to each of them. Next a comprehensive discussion on the advances and shortcomings of the existing techniques based on the qualities, capturing device, database, and feature of that quality is presented. Accurate comparisons between existing techniques are presented as tables to make it easy for new researchers to come up with advances and drawbacks of each technique without spending time on all existing research in this area.
C1 [Kolivand, Hoshang] Liverpool John Moores Univ, Sch Comp Sci & Math, Liverpool L3 3AF, England.
   [Kolivand, Hoshang] Staffordshire Univ, Sch Comp & Digital Technol, Stoke On Trent, England.
   [Kolivand, Hoshang; Akintoye, Kayode Akinlekan; Rahim, Mohd Shafry] Univ Teknol Malaysia, Inst Human Ctr Engn, Media & Game Innovat Ctr Excellence, Johor Baharu 81310, Johor, Malaysia.
   [Asadianfam, Shiva] Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.
   [Asadianfam, Shiva] Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
   [Akintoye, Kayode Akinlekan; Rahim, Mohd Shafry] Univ Teknol Malaysia, Fac Engn, Sch Comp, Johor Baharu 81310, Johor, Malaysia.
C3 Liverpool John Moores University; Staffordshire University; Universiti
   Teknologi Malaysia; Islamic Azad University; Universiti Teknologi
   Malaysia
RP Asadianfam, S (corresponding author), Qom Univ Technol, Fac Elect & Comp Engn, Qom, Iran.; Asadianfam, S (corresponding author), Islamic Azad Univ, Dept Comp Engn, Qom Branch, Qom, Iran.
EM H.Kolivand@ljmu.ac.uk; sh_asadianfam@yahoo.com; A.akin@live.Utm.my;
   Shafry@utm.my
RI Kolivand, Hoshang/F-4736-2011; asadianfam, shiva/ABF-1231-2021;
   Kolivand, Hoshang/B-2501-2016
OI asadianfam, shiva/0000-0002-0062-7079; Kolivand,
   Hoshang/0000-0001-5460-5679
CR Abukaroug SEA, 2015, THESIS U TEKNOLOGI M
   Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Ahmad Radzi S, 2016, TURK J ELECTR ENG CO, V24, P1863, DOI 10.3906/elk-1311-43
   Akintoye KA., 2017, INT J COMPUT APPL, V157, P16, DOI 10.5120/ijca2017912637
   Al-Nuzaili Qais, 2016, International Journal of Intelligent Systems Technologies and Applications, V15, P240
   [Anonymous], 2015, Int J Sig Process Image Process Pattern Recognit, DOI DOI 10.14257/IJSIP.2015.8.8.23
   [Anonymous], 2014, IJCSI
   Arun R, 2011, ENG LET, V19, P159
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   Avci A, 2019, 2019 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO 2019), P580, DOI [10.23919/eleco47770.2019.8990612, 10.23919/ELECO47770.2019.8990612]
   Beining Huang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1269, DOI 10.1109/ICPR.2010.316
   Beniwal P, 2013, INT J MED RES HEALTH, V1
   Biggio B, 2012, IET BIOMETRICS, V1, P11, DOI 10.1049/iet-bmt.2011.0012
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   Dai YG, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 4, PROCEEDINGS, P501
   Damavandinejadmonfared S., 2012, 2012 IEEE International Conference on Intelligent Computer Communication and Processing (ICCP 2012). Proceedings, P249, DOI 10.1109/ICCP.2012.6356194
   Daniels M, 2018, GOOGLE PATENTS
   Das R, 2019, IEEE T INF FOREN SEC, V14, P360, DOI 10.1109/TIFS.2018.2850320
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102261
   de Luis-García R, 2003, SIGNAL PROCESS, V83, P2539, DOI 10.1016/j.sigpro.2003.08.001
   Ding Y, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P2106
   Du Y.E., 2013, Biometrics: From Fiction to Practice
   El-Sayed MA., 2013, INT J COMPUT SCI ISS, V10, P11
   Ezhilmaran D, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P271, DOI 10.1109/I-SMAC.2017.8058353
   Fang YX, 2018, NEUROCOMPUTING, V290, P100, DOI 10.1016/j.neucom.2018.02.042
   Farokhi S, 2015, INFORM SCIENCES, V316, P234, DOI 10.1016/j.ins.2015.04.030
   Farokhi S, 2014, DIGIT SIGNAL PROCESS, V31, P13, DOI 10.1016/j.dsp.2014.04.008
   Fengxu Guan, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P93, DOI 10.1109/CISP.2010.5646294
   Galbally J., 2016, Biometrics and Forensics (IWBF), 2016 4th International Workshop on, P1, DOI DOI 10.1109/IWBF.2016.7449676
   Gayathri R., 2012, INT J ENG RES APPL I, V2, P1048
   Gou J., 2012, J. Inf. Comput. Sci, V9, P1429
   Gupta A., 2014, INT J CURR ENG TECHN, V4, P3904
   Gupta P, 2015, DIGIT SIGNAL PROCESS, V38, P43, DOI 10.1016/j.dsp.2014.12.003
   Haiying Liu, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P314, DOI 10.1007/978-3-319-69923-3_34
   Han NT, 2021, INT J INTEGR ENG, V13, P177, DOI 10.30880/ijie.2021.13.01.016
   Harsha P., 2012, Proceedings of the 2012 International Conference on Emerging Trends in Electrical Engineering and Energy Management (ICETEEEM), P271, DOI 10.1109/ICETEEEM.2012.6494494
   Hartung D., 2012, Vascular pattern recognition: And its application in privacy-preserving biometric online-banking systems
   Hartung D., 2011, BIOM IJCB 2011 INT J, P1
   Hashimoto J., 2006, S VLSI CIRC, P5, DOI DOI 10.1109/VLSIC.2006.1705285
   Himaga M., 2008, Advances in Biometrics: Sensors, Algorithms and Systems, P89
   Himaga M, 2009, FINGER VEIN PATTERN, P428
   Hoshyar AN, 2011, J AM SCI, V7
   Hossain M, 2018, APPL INTELL, V48, P4824, DOI 10.1007/s10489-018-1257-4
   Hsia CH, 2017, MULTIMED TOOLS APPL, V76, P25179, DOI 10.1007/s11042-016-4296-z
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jinfeng Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1148, DOI 10.1109/ICPR.2010.287
   Kang BJ, 2009, OPT ENG, V48, DOI 10.1117/1.3212651
   Kang WX, 2019, IEEE T INF FOREN SEC, V14, P858, DOI 10.1109/TIFS.2018.2866330
   Kang WX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097548
   Karabat C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0255-5
   Kaur M, 2015, FINGER VEIN DETECTIO, V6, P3280
   Khellat-kihel S, 2014, 2014 FIRST INTERNATIONAL IMAGE PROCESSING, APPLICATIONS AND SYSTEMS CONFERENCE (IPAS)
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kono M., 2000, PROC 5 S PATTERN MEA, P9
   Kuan-Quan Wang, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P196, DOI 10.1109/ICWAPR.2012.6294778
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Kutemate S, 2015, INT J ENG RES TECHNO, V4, P2278
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Lee EC, 2009, INT J IMAG SYST TECH, V19, P179, DOI 10.1002/ima.20193
   Lee HC, 2010, J ZHEJIANG U-SCI C, V11, P514, DOI 10.1631/jzus.C0910550
   Li B, 2012, INT SYM COMPUT INTEL, P54, DOI 10.1109/ISCID.2012.165
   Liu BC., 2016, J ELECT COMPUTER ENG, V2016, P1
   Liu CX, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P395, DOI 10.1109/CISP.2013.6744026
   Liu T, 2013, IMAGING SCI J, V61, P491, DOI 10.1179/1743131X12Y.0000000013
   Liu Z, 2012, IEEE T CONSUM ELECTR, V58, P522, DOI 10.1109/TCE.2012.6227456
   Liu Z, 2010, J NETW COMPUT APPL, V33, P275, DOI 10.1016/j.jnca.2009.12.006
   Lu Y, 2017, FUTURE GENER COMP SY, V77, P149, DOI 10.1016/j.future.2017.07.013
   Lu Y, 2014, INT C PATT RECOG, P1758, DOI 10.1109/ICPR.2014.309
   Lu Y, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P410, DOI 10.1109/CISP.2013.6744030
   Lu Y, 2014, KSII T INTERNET INF, V8, P1766, DOI 10.3837/tiis.2014.05.015
   Lu Y, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P61, DOI 10.1109/ICTC.2013.6675307
   Madhan M., 2015, IJCSMC, V4, P521
   Malik I., 2013, INT J COMPUTER TREND, V4, P1301
   Market B, 2008, IND REPORT 2009 2014
   Maser B, 2021, ARXIV
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Mohammadi P., 2014, ARXIV
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Mulyono D, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P134
   Park KR, 2011, COMPUT INFORM, V30, P295
   Perez Vega Abrahan, 2014, 2014 International Work Conference on Bio-Inspired Intelligence (IWOBI), P65, DOI 10.1109/IWOBI.2014.6913940
   Pflug A., 2012, INFORM SECURITY TECH, V17, P26
   Pi W., 2010, P INT C EL INF ENG K, V1, pV1
   Podgantwar UD., 2013, INT J ENG RES TECHNO, V2, P3294
   Prabhakar P, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC 2013), P196, DOI 10.1109/ICACC.2013.45
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Qin Bin, 2009, Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS 2009), P357, DOI 10.1109/CIS.2009.144
   Qin HF, 2012, ASIAPAC SIGN INFO PR
   Qin HF, 2011, OPT ENG, V50, DOI 10.1117/1.3572129
   Robinson TL, 2016, GOOGLE PATENTS
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Saini M., 2016, J FORENSIC MED, V1, P2
   Saini R., 2014, INT J ADV SCI TECHNO, V2, P2
   Sapkale M, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P306
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2018, INFORMATION, V9, DOI 10.3390/info9090213
   Shang-Hung Lin, 2000, Informing Science, V3, P1
   Shangqing Wei, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P1693, DOI 10.1109/TMEE.2011.6199537
   SHARMA S, 2014, INT J ADV SCI TECHNO, V2, P32
   Shi YH, 2012, INT CONF SIGN PROCES, P1605, DOI 10.1109/ICoSP.2012.6491887
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   Shrikhande SP, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1646, DOI 10.1109/ICACCI.2015.7275849
   Singh B., 2012, INT J ADV COMPUT SC, V2, P400
   Song W, 2011, PATTERN RECOGN LETT, V32, P1541, DOI 10.1016/j.patrec.2011.04.021
   Souley B, 2020, INT J PURE APPL SCI, V19
   Sugandhi N., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1183, DOI 10.1109/ICCSP.2014.6950040
   Syarif MA, 2017, MULTIMED TOOLS APPL, V76, P6859, DOI 10.1007/s11042-016-3315-4
   Syazana-Itqan K., 2016, Indian J. Sci. Technol, V9, P1
   Tagkalakis F, 2017, I S BIOMED IMAGING, P659, DOI 10.1109/ISBI.2017.7950606
   Tang JS, 2003, IEEE SIGNAL PROC LET, V10, P289, DOI 10.1109/LSP.2003.817178
   Tome P, 2015, INT CONF BIOMETR, P513, DOI 10.1109/ICB.2015.7139067
   Ton BT, 2013, INT CONF BIOMETR
   Usha R., 2016, ADV COMPUTING INT J, V7, P67
   Vallabh H., 2012, AUTHENTICATION USING
   Vanoni M, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P30, DOI 10.1109/BIOMS.2014.6951532
   Veluchamy S, 2017, IET BIOMETRICS, V6, P232, DOI 10.1049/iet-bmt.2016.0112
   Videkar P, 2017, INT RES J ENG TECHNO, V4, P3403
   Vlachos M, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/868493
   Wang YX, 2008, CHIN OPT LETT, V6, P657, DOI 10.3788/COL20080609.0657
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wu JD, 2011, EXPERT SYST APPL, V38, P14284, DOI 10.1016/j.eswa.2011.05.086
   Wu JD, 2011, EXPERT SYST APPL, V38, P5423, DOI 10.1016/j.eswa.2010.10.013
   Xi XM, 2013, SENSORS-BASEL, V13, P11243, DOI 10.3390/s130911243
   Xie SJ, 2015, SENSORS-BASEL, V15, P17089, DOI 10.3390/s150717089
   Xuebing Wen, 2010, Proceedings 2010 Asia-Pacific Conference on Power Electronics and Design (APPED 2010), P97, DOI 10.1109/APPED.2010.32
   Yanagawa T., 2007, MHF PREPR SER, V12, P1
   Yang GP, 2013, SENSORS-BASEL, V13, P12093, DOI 10.3390/s130912093
   Yang GP, 2012, J BIOMED BIOTECHNOL, DOI 10.1155/2012/324249
   Yang GP, 2012, SENSORS-BASEL, V12, P1738, DOI 10.3390/s120201738
   Yang J., 2011, 2011 INT C HAND BASE, P1
   Yang JF, 2009, IEEE IMAGE PROC, P2709, DOI 10.1109/ICIP.2009.5414165
   Yang JF, 2014, INFORM SCIENCES, V268, P33, DOI 10.1016/j.ins.2013.10.009
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2010, INT CONF SIGN PROCES, P1706, DOI 10.1109/ICOSP.2010.5656832
   Yang JF, 2011, COMPUT HUM BEHAV, V27, P1565, DOI 10.1016/j.chb.2010.10.029
   Yang L, 2014, LECT NOTES COMPUT SC, V8833, P234, DOI 10.1007/978-3-319-12484-1_26
   Yang L, 2014, NEUROCOMPUTING, V135, P218, DOI 10.1016/j.neucom.2013.12.029
   Yang W, 2011, HAND BAS BIOM ICHB 2, P1
   Yang Y, 2012, INT J DIGITAL CONTEN, V6, P86
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Yu CB, 2009, INTERDISCIP SCI, V1, P280, DOI 10.1007/s12539-009-0046-5
   Yusoff S., 2015, INT J RES ENG TECHNO, V4, P833
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang C., 2013, Biometric recognition, P282
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhao DD, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103221
   Zheng HY, 2017, IEEE T VEH TECHNOL, V66, P4300, DOI 10.1109/TVT.2016.2604369
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
   Zou H, 2016, J PHYS C SER, V680
NR 153
TC 2
Z9 2
U1 14
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33541
EP 33575
DI 10.1007/s11042-023-14463-5
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943159500001
DA 2024-07-18
ER

PT J
AU Nguyen, NH
   Pham, V
AF Nguyen, Ngoc-Hung
   Pham, Van-At
TI An efficient IPVO based reversible data hiding method using four
   pixel-pairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPVO; Pixel pairs; Reversible data hiding; Pixel block; Embedding
ID DIFFERENCE EXPANSION; PREDICTION; SCHEME; WATERMARKING; IMAGES; PVO
AB In the Improved Pixel Value Ordering (IPVO) reversible data hiding method first, a block of n pixels is sorted in ascending order. Then two pixel-pairs are established from the first two pixels and the last two pixels of the sorted block to embed at most two data bits. This paper uses the first three pixels and the last three pixels of the sorted block to form four pixel pairs for embedding at most four data bits. In fact, on the right, using the IPVO technique to embed data bits in the pair of (n - 2)-th and (n - 1)-th pixels and the pair of (n - 1)-th and n-th pixels. Embedding data bits in two pairs of pixels on the left is done similarly. The pixel pairs here all consist of two consecutive pixels in a sorted pixel block, so the embedding efficiency is high. Compared with IPVO-method, the proposed method has doubled the number of pixel pairs used, and the embedding capacity increased from 1.5 to 1.9 times depending on the smoothness of the original images. The experiment results are shown that the proposed method has a superior embedding capacity compared to the existing Pixel Value Ordering(PVO)-based reversible data hiding methods while maintaining good stego image quality.
C1 [Nguyen, Ngoc-Hung] Vietnam Acad Sci & Technol, Inst Informat Technol, Dept Telemat, Hanoi, Vietnam.
   [Pham, Van-At] Univ Transport & Commun, Fac Informat Technol, Hanoi, Vietnam.
C3 Vietnam Academy of Science & Technology (VAST); University of Transport
   & Communications (UTC)
RP Nguyen, NH (corresponding author), Vietnam Acad Sci & Technol, Inst Informat Technol, Dept Telemat, Hanoi, Vietnam.
EM nnhung@ioit.ac.vn; phamvanat83@gmail.com
RI Nguyen, Ngoc Hung/D-8838-2016
OI Nguyen, Ngoc Hung/0000-0002-2854-2122
CR Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alattar AM, 2003, IEEE IMAGE PROC, P501
   Bharanitharan K., 2016, International Journal of Network Security, V18, P750
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen S, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/6359248
   Chen XY, 2015, MULTIMED TOOLS APPL, V74, P5747, DOI 10.1007/s11042-014-1881-x
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang HJ, 2010, KSII T INTERNET INF, V4, P655, DOI 10.3837/tiis.2010.08.0012
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kaur Gurjinder, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P727, DOI 10.1109/SPIN48934.2020.9071330
   Khodaei M., 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P31, DOI 10.1109/ICSPS.2010.5555649
   Kukreja S, 2019, MULTIMED TOOLS APPL, V78, P6139, DOI 10.1007/s11042-018-6169-0
   Kumar R, 2020, MULTIMED TOOLS APPL, V79, P22635, DOI 10.1007/s11042-020-09069-0
   Kumar R, 2020, INFORM SCIENCES, V536, P101, DOI 10.1016/j.ins.2020.05.047
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Li J., 2018, Int. J. Netw. Secur, V20, P65
   Li JJ, 2019, IEEE ACCESS, V7, P142947, DOI 10.1109/ACCESS.2019.2941500
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Macq B, 2000, 2000 10 EUR SIGN PRO, P1
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2010, INT WORKSHOP DIGITAL, P170, DOI [10.1007/978-3-642-18405-5_14, DOI 10.1007/978-3-642-18405-5_14]
   Ou B, 2019, LECT NOTES COMPUT SC, V11378, P169, DOI 10.1007/978-3-030-11389-6_13
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Pan G, 2001, LECT NOTES COMPUT SC, P261, DOI 10.1007/3-540-45600-7_30
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P26047, DOI 10.1007/s11042-019-7692-3
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sao NK., 2020, Journal of Computer Science and Cybernetics, V36, P139, DOI [10.15625/1813-9663/36/2/14084, DOI 10.15625/1813-9663/36/2/14084]
   Shin SY, 2014, REVERSIBLE WATERMARK, P147
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HR, 2019, J REAL-TIME IMAGE PR, V16, P685, DOI 10.1007/s11554-019-00867-w
   Yaqub MK., 2006, INT J COMPUTING INFO, V4, P134
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 55
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33303
EP 33332
DI 10.1007/s11042-023-14669-7
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941926100010
DA 2024-07-18
ER

PT J
AU Gan, MX
   Li, DY
   Zhang, XT
AF Gan, Mingxin
   Li, Danyang
   Zhang, Xiongtao
TI A disaggregated interest-extraction network for click-through rate
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CTR prediction; Disaggregating; Deep learning; Recommendation systems
AB Click-through rate (CTR) prediction is of crucial significance to computational advertising and recommendation systems. In recent years, deep learning has shown great potential in personalized recommendation. However, existing studies ignored the multi-objective nature of users' click behaviors, i.e., that users tend to buy more than one item at the same time. In spite of the fact that user rating data can be used to make up for missing information among items, particularly items that share the same tags, the existing deep models for recommendation fail to exploit user ratings and do not reflect user interests adequately. To address this problem, we propose a CTR prediction model named the Disaggregated Interest-Extraction Network (Di-Net) to disaggregate a user's click-through sequence into three sub-sequences, namely the basic feature sub-sequence, the consistent feature sub-sequence, and the correlated feature sub-sequence. Di-Net uses a Gated Recurrent Unit with a user-item rating update gate (URGRU) to extract sufficient multiple-layer features hidden behind user ratings. The experimental results on two public datasets (Amozon product dataset and MovieLens dataset) show that Di-Net outperforms the state-of-the-art models, such as DIEN and AutoInt. The AUCs of Di-Net on Books subset of Amozon, Clothing, Shoes, and Jewelry subset of Amozon and MovieLens dataset reach 0.8523, 0.7421 and 0.8612, respectively. Additional experiments show that the use of disaggregated sequences supports the modeling of user interests adequately.
C1 [Gan, Mingxin; Li, Danyang; Zhang, Xiongtao] Univ Sci & Technol Beijing, Sch Econ & Management, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Gan, MX (corresponding author), Univ Sci & Technol Beijing, Sch Econ & Management, Beijing 100083, Peoples R China.
EM ganmx@ustb.edu.cn; ldyakc@163.com; zhangxiongtao1@163.com
FU National Natural Science Foundation of China [72271024, 71871019,
   71729001]
FX AcknowledgementsThis work was partly funded by the National Natural
   Science Foundation of China (Nos. 72271024, 71871019, 71729001).
CR Anh-Phuong TA, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2889, DOI 10.1109/BigData.2015.7364112
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chapelle O, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532128
   Chen SQ, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22495-4
   Chen T, 2019, ARXIV
   Chen XY, 2022, NAT MACH INTELL, V4, P116, DOI 10.1038/s42256-021-00432-w
   Cheng H., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [DOI 10.1145/2988450.2988454, 10.1145/2988450.2988454]
   Chung Junyoung, 2014, ARXIV14123555
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   He X, 2014, P 8 INT WORKSHOP DAT, P1, DOI [DOI 10.1145/2648584.2648589, 10.1145/2648584.2648589]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal S, 2019, MULTIMED TOOLS APPL, V78, P14231, DOI 10.1007/s11042-018-6755-1
   Juan YC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P43, DOI 10.1145/2959100.2959134
   Juan YC, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P680, DOI 10.1145/3041021.3054185
   Khurana V, 2021, IEEE T COGN DEV SYST, V13, P732, DOI 10.1109/TCDS.2021.3065200
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Li ZY, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P313, DOI 10.1145/3336191.3371785
   Lian JX, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1754, DOI 10.1145/3219819.3220023
   Liu Q, 2021, NAT MACH INTELL, V3, P536, DOI 10.1038/s42256-021-00333-y
   Liu Q, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2101344118
   Lyu Z, 2020, AAAI CONF ARTIF INTE, V34, P156
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Pan JW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1349, DOI 10.1145/3178876.3186040
   Pi Q, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2671, DOI 10.1145/3292500.3330666
   Qu YR, 2016, IEEE DATA MINING, P1149, DOI [10.1109/ICDM.2016.0151, 10.1109/ICDM.2016.57]
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1161, DOI 10.1145/3357384.3357925
   Tao ZL, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102076
   Trofimov Ilya., 2012, P 6 INT WORKSHOP DAT, P1, DOI DOI 10.1145/2351356.2351358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang RX, 2017, ADKDD'17: 23RD ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2017), DOI 10.1145/3124749.3124754
   Xiao J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3119
   Xie R, 2020, 20 9 INT JOINT C ART
   Zhai SF, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1295, DOI 10.1145/2939672.2939759
   Zhang JY, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P32, DOI 10.1109/ISISE.2009.113
   Zhou C, 2018, AAAI CONF ARTIF INTE, P4564
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
NR 44
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27771
EP 27793
DI 10.1007/s11042-023-14584-x
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000936501100001
DA 2024-07-18
ER

PT J
AU Luo, D
   Xiong, SH
   He, XH
   Chen, HG
   Li, Z
   Ren, C
AF Luo, Dan
   Xiong, Shuhua
   He, Xiaohai
   Chen, Honggang
   Li, Zeng
   Ren, Chao
TI Block-correlation-based intra prediction for VVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block-correlation; Intra prediction; VVC; Multi-modes fusion; Template
   matching; CCLM
ID COMPONENT LINEAR-MODEL
AB The new generation video coding standard Versatile Video Coding (VVC) has been officially released. Many novel technologies were utilized to improve the coding performance. In this paper, we propose an efficient intra prediction algorithm based on block correlation to improve the performance of VVC. First, since the single prediction mode sometimes does not predict very well and the high correlation of neighboring blocks is not fully used, we propose a multi-modes fusion method to merge the modes of adjacent blocks. Second, to better predict complex areas, we design an adaptive template matching method. Different weighting methods are utilized for different size blocks because they show different texture features. In addition, we combine Derived Mode (DM) with Cross-Component Linear Model (CCLM) in an adaptive way to form a new chroma mode which compensates for the shortcomings of single linear prediction. Experimental results indicated the superior performance of our algorithm. Compared with the VVC anchor (VTM 9.1), our proposed algorithm saved the bitrate of 0.78%, 0.87%, and 0.99% on average for Y, Cb, and Cr. Furthermore, the using probabilities of our designed modes were higher than that of many other traditional modes in VVC.
C1 [Luo, Dan; Xiong, Shuhua; He, Xiaohai; Chen, Honggang; Li, Zeng; Ren, Chao] Sichuan Univ, Coll Elect & Informat Engn, South Sect No 24, 1 Yihuan Rd, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, South Sect No 24, 1 Yihuan Rd, Chengdu 610065, Peoples R China.
EM hxh@scu.edu.cn
RI Ren, Chao/L-8078-2019
FU National Natural Science Foundation of China [62271336, 62211530110];
   Fundamental Research Funds for the Central Universities [2021SCU12061]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (Grant No. 62271336 and Grant No.
   62211530110), and the Fundamental Research Funds for the Central
   Universities (grant number 2021SCU12061).
CR Bjontegaard G., 2001, CALCULATION AVERAGE
   Blanch MG, 2021, IEEE J-STSP, V15, P366, DOI 10.1109/JSTSP.2020.3044482
   Bossen F, 2019, JVETN1010, P19
   Bross B., 2020, JVET-S2001
   Bross B., 2018, document JVET-L0283
   Chang YJ, 2019, IEEE DATA COMPR CONF, P559, DOI 10.1109/DCC.2019.00071
   Chen J, 2019, JVETP2002
   Coding HEV, 2013, REC ITU T H 265 HIGH
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   Ghaznavi-Youvalari R, 2020, INT CONF ACOUST SPEE, P4417, DOI [10.1109/ICASSP40776.2020.9054405, 10.1109/icassp40776.2020.9054405]
   Hernandez S. De Luxan, 2018, JVETK0049
   Huo J, 2019, JOINT VIDEO EXPERTS
   Kidani Y, 2019, IEEE IMAGE PROC, P4125, DOI [10.1109/icip.2019.8803456, 10.1109/ICIP.2019.8803456]
   Laroche G, 2018, JOINT VIDEO EXPLORAT
   Lei M, 2020, IEEE IMAGE PROC, P1137, DOI 10.1109/ICIP40778.2020.9190915
   Li JR, 2020, IEEE T IMAGE PROCESS, V29, P7245, DOI 10.1109/TIP.2020.3000351
   Li YC, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414838
   Racape F, 2018, JOINT VIDEO EXPLORAT
   Rath G, 2021, 2020 28 EUROPEAN SIG, P1, DOI [10.23919/Eusipco47968.2020.9287723, DOI 10.23919/EUSIPCO47968.2020.9287723]
   Said A, 2016, IEEE IMAGE PROC, P534, DOI 10.1109/ICIP.2016.7532414
   Schäfer M, 2019, IEEE IMAGE PROC, P1089, DOI [10.1109/ICIP.2019.8803724, 10.1109/icip.2019.8803724]
   Schafer M, 2019, JOINT VIDEO EXPERTS
   Schneider J, 2021, PICT COD SYMP, P206, DOI 10.1109/PCS50896.2021.9477474
   Sullivan G, 2018, M REP 11 M JOINT VID
   Venugopal G, 2019, IEEE IMAGE PROC, P4115, DOI [10.1109/icip.2019.8803445, 10.1109/ICIP.2019.8803445]
   Venugopal G, 2019, IEEE DATA COMPR CONF, P606, DOI 10.1109/DCC.2019.00118
   Yoon YU, 2019, ELECTRON LETT, V55, P188, DOI 10.1049/el.2018.7452
   Yoon YU, 2020, IEICE T INF SYST, VE103D, P469, DOI 10.1587/transinf.2019EDL8045
   Youvalari Ramin Ghaznavi, 2020, IEEE INT WORKSH MULT, P1, DOI [10.1109/MMSP48831.2020.9287167, DOI 10.1109/mmsp48831.2020.9287167]
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P3983, DOI 10.1109/TIP.2018.2830640
   Zhao L, 2018, JOINT VIDEO EXPLORAT
   Zhao L, 2019, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2019.00013
   Zhao X, 2018, PICT COD SYMP, P139, DOI 10.1109/PCS.2018.8456305
   Zhu LW, 2021, IEEE T CIRC SYST VID, V31, P3168, DOI 10.1109/TCSVT.2020.3035356
NR 34
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23635
EP 23653
DI 10.1007/s11042-023-14700-x
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936501100012
DA 2024-07-18
ER

PT J
AU Roy, M
   Chakraborty, S
   Mali, K
AF Roy, Mousomi
   Chakraborty, Shouvik
   Mali, Kalyani
TI An optimized image encryption framework with chaos theory and EMO
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Bitplane decomposition; Electromagnetism-like
   optimization; Chaos theory; Local binary pattern
ID ELECTROMAGNETISM-LIKE MECHANISM; TRANSFORM; MATRIX; SCHEME; MAP
AB Security of digital data is one of the prime concerns of advanced data communication technologies. Images possess a major share of the overall data communication. Image data contains several sensitive pieces of information that are to be protected during transmission, storage, and other stages. There are several algorithms that exist in the literature that addresses this issue. The ever-increasing need for image communication demands sophisticated and robust image encryption approaches that can be effectively applied in real-life scenarios. In this work, a local binary pattern is used to produce the binary image, and the electromagnetism-like optimization approach is used to maximize the transition of 0 and 1 and generate the shuffled image. The shuffled image is decomposed into the constituting bitplanes using any one of three bitplane decomposition techniques. Chaos theory is used to generate some synthetic bitplanes for substitution purposes where the electromagnetism-like optimization process optimizes the uniformity in the histogram. This approach is further secured using a final layer scrambling approach. The proposed approach is tested using both qualitative and quantitative metrics. Moreover, the proposed approach is tested against different types of attacks that prove the practical applicability and robustness of the proposed approach.
C1 [Roy, Mousomi; Chakraborty, Shouvik; Mali, Kalyani] Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
C3 Kalyani University
RP Chakraborty, S (corresponding author), Univ Kalyani, Dept Comp Sci & Engn, Kalyani, India.
EM iammouroy@gmail.com; shouvikchakraborty51@gmail.com;
   kalyanimali1992@gmail.com
CR AGAIAN S, 1995, SIGNAL PROCESS, V41, P101, DOI 10.1016/0165-1684(94)00093-F
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   [Anonymous], 463 FIPS COMP SEC DI
   [Anonymous], CVG-UGR-Image Database
   Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Chakraborty S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114142
   Chakraborty S, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106800
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Chakraborty S, 2016, INT J SECUR APPL, V10, P205, DOI 10.14257/ijsia.2016.10.2.19
   Cui GZ, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P37, DOI 10.1109/BICTA.2008.4656701
   Daemen J, 1999, UNDEFINED RIJNDAEL B
   Gálvez J, 2018, APPL INTELL, V48, P2580, DOI 10.1007/s10489-017-1090-1
   Gehani A., 2000, DNA Based Computers V. DIMACS Workshop (Series in Discrete Mathematics and Theoretical Computer Science Vol.54), P233
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   GEVORKIAN DZ, 1995, IEEE T SIGNAL PROCES, V43, P286, DOI 10.1109/78.365308
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Gupta S, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107224
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kamal FM, 2021, CHAOS SOLITON FRACT, V144, DOI 10.1016/j.chaos.2021.110686
   Kamali S. H., 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P141, DOI 10.1109/ICEIE.2010.5559902
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   Kumar S., 2020, 2 INT C DATA ENG APP, P1, DOI 10.1109/IDEA49133.2020.9170703
   Leong MP, 2000, ANN IEEE SYM FIELD P, P122, DOI 10.1109/FPGA.2000.903399
   Li PY, 2020, IET SIGNAL PROCESS, V14, P475, DOI 10.1049/iet-spr.2019.0276
   Li S, 2019, MULTIMEDIA SECURITY, P133
   Li YH, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5182
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   LINDHOLM FA, 1979, IEEE T ELECTRON DEV, V26, P165, DOI 10.1109/T-ED.1979.19400
   Liu S., 2001, PROGR CRYPTOLOGY IND, V2247, P316, DOI [DOI 10.1007/3-540-45311-3_30, 10.1007/3-540-45311-3_30.]
   Mali K, 2015, IJSRD-Int J Sci Res Dev, V3, P2321
   Mali K, 2015, INT J SECUR APPL, V9, P279, DOI 10.14257/ijsia.2015.9.12.26
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P27941, DOI 10.1007/s11042-020-09279-6
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Narkhede BE, 2020, INT J ADV MANUF TECH, V108, P3193, DOI 10.1007/s00170-020-05486-5
   Niyishaka P, 2021, MULTIMED TOOLS APPL, V80, P2161, DOI 10.1007/s11042-020-09707-7
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Patidar V, 2009, INFORM-J COMPUT INFO, V33, P441
   Ramanathan TT, 2020, J Electric Eng Comp Sci Indonesian, P1428
   Roy M, 2020, Biomedical Image Security Using Matrix Manipulation and DNA Encryption
   Roy M, 2020, Data Security Techniques Based on DNA Encryption
   Roy M, 2021, An image security method based on low dimensional chaotic environment and DNA encoding, P267
   Roy M, 2021, MICROSYST TECHNOL, V27, P3617, DOI 10.1007/s00542-020-05120-0
   Roy M, 2019, 2019 INTERNATIONAL CONFERENCE ON OPTO-ELECTRONICS AND APPLIED OPTICS (OPTRONIX 2019), DOI 10.1109/optronix.2019.8862350
   Roy M, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P881, DOI [10.1109/aicai.2019.8701382, 10.1109/AICAI.2019.8701382]
   Seal A, 2017, NEW RESILIENT IMAGE
   SerElkhetm S, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P222, DOI [10.1109/ITCE48509.2020.9047777, 10.1109/itce48509.2020.9047777]
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Talhaoui MZ, 2021, INFORM SCIENCES, V550, P13, DOI 10.1016/j.ins.2020.10.048
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tsamardinos I, 2006, MACH LEARN, V65, P31, DOI 10.1007/s10994-006-6889-7
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang B, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165737
   Wang XN, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON FUTURE INFORMATION NETWORKS, P1, DOI 10.1109/ICFIN.2009.5339613
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang YF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124812
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu YF, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107911
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zahmoul R, 2017, OPT LASER ENG, V96, P39, DOI 10.1016/j.optlaseng.2017.04.009
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu Jiren., 2018, HiDDeN: Hiding Data With Deep Networks
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 78
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30309
EP 30343
DI 10.1007/s11042-023-14438-6
EA FEB 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000939670800007
DA 2024-07-18
ER

PT J
AU Mohiuddin, SK
   Malakar, S
   Sarkar, R
AF Mohiuddin, S. k
   Malakar, Samir
   Sarkar, Ram
TI An ensemble approach to detect copy-move forgery in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery; Copy-move; Frame duplication; GLCM; Haralick; LBP
ID DUPLICATION FORGERY; FRAME; CLASSIFICATION
AB In the recent past, video forgery has increased rapidly due to the easy availability of the required tools to accomplish that. Temporal copy-move or frame duplication is one of the most common video forgery methods in which a set of consecutive frames is copied somewhere in the same video. This work proposes an ensemble based method to detect duplicate frames from a video. In this method, first, the frames are pre-processed and then three different kinds of features - Haralick, custom Haralick and Local Binary Pattern (LBP) are extracted from each frame of a video. Next, lexicographical sorting is performed to arrange the frames having similar feature values consecutively. A filter method is applied to eliminate the false detection and it also creates a duplicate sequence for each category. In the end, a voting mechanism is employed to predict the duplicate frames, if they exist. The proposed method performs very well (detection accuracy is 99.32%, the true positive rate is 99.79%, and the true negative rate is 99.19%) over an in-house dataset containing 300 videos of seven different types. The robustness of the proposed method has also been tested by adding various postprocessing to the video samples. The proposed method outperforms many state-of-the-art methods used here for comparison.
C1 [Mohiuddin, S. k; Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM myselfmohiuddin@gmail.com; malakarsamir@gmail.com; raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086
CR Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bakas J, 2018, LECT NOTES COMPUT SC, V11281, P304, DOI 10.1007/978-3-030-05171-6_16
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Chen H, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P37, DOI 10.1109/IITA.2008.451
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   Fadl S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116066
   Fadl S, 2020, MULTIMED TOOLS APPL, V79, P17619, DOI 10.1007/s11042-019-08603-z
   Fadl S, 2020, MULTIDIM SYST SIGN P, V31, P1365, DOI 10.1007/s11045-020-00711-6
   Farooq S, 2017, COMPUT ELECTR ENG, V62, P459, DOI 10.1016/j.compeleceng.2017.05.008
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu Y., 2010, J. Pattern Recognit. Res., V5, P140, DOI 10.13176/11.167
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Li Q, 2018, INFORMATION, V9, DOI 10.3390/info9120301
   Malegori C, 2016, J FOOD ENG, V185, P48, DOI 10.1016/j.jfoodeng.2016.04.001
   Mohiuddin, 2021, P 3 INT C COMPUTATIO, P1
   Mohiuddin S. K., 2022, Mathematics and its Applications in New Computer Systems: MANCS-2021. Lecture Notes in Networks and Systems (424), P197, DOI 10.1007/978-3-030-97020-8_18
   Nguyen X.H., 2020, Int. J. Image, V3, P1
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park JY, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P18, DOI 10.1109/ICCE.2002.1013909
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zheng L, 2015, LECT NOTES COMPUT SC, V9023, P18, DOI 10.1007/978-3-319-19321-2_2
NR 29
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24269
EP 24288
DI 10.1007/s11042-023-14554-3
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000929502800002
DA 2024-07-18
ER

PT J
AU Avuçlu, E
   Özçifçi, A
   Elen, A
AF Avuclu, Emre
   Ozcifci, Ayhan
   Elen, Abdullah
TI Designing a dynamic system to control building components and computers
   with voice commands for disabled individuals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disabled individuals; Social problems; Social life; Voice control;
   Quality of life
AB Nowadays, with the development of technology, there have been many innovations in human life. Technology has made many things easier in human life depending on these innovations. In this study, an application has been developed to more easily solve the needs of people in their daily lives. The developed application is designed to control the internal units of the house with voice commands. The doors, windows, lamps, etc. that we use daily in our house can be controlled by voice commands through wireless headphones. Voice commands can be sent from inside or outside the house. In addition to these external units, all applications on the personal computer are controlled by voice commands without using a keyboard and mouse. The application developed in C # programming language, provides control of newly installed programs to the computer without coding. To do so, it is enough to add that program and voice command to the interface. Moreover, the application provides a lot of convenience for disabled-aged citizens and some dangerous situations in the industrial environment.
C1 [Avuclu, Emre] Aksaray Univ, Fac Engn, Dept Software Engn, Aksaray, Turkiye.
   [Ozcifci, Ayhan] Aksaray Univ, Fac Engn, Dept Ind Engn, Aksaray, Turkiye.
   [Elen, Abdullah] Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Dept Software Engn, Bandirma, Balikesir, Turkiye.
C3 Aksaray University; Aksaray University; Bandirma Onyedi Eylul University
RP Avuçlu, E (corresponding author), Aksaray Univ, Fac Engn, Dept Software Engn, Aksaray, Turkiye.
EM emreavuclu@aksaray.edu.tr; ayhanozcifci@aksaray.edu.tr;
   aelen@bandirma.edu.tr
RI Elen, Abdullah/A-8678-2015
OI Elen, Abdullah/0000-0003-1644-0476
FU Aksaray University Scientific Research Projects Coordinatorship
   /Aksaray, Turkey [2018-061]
FX AcknowledgementsThis work was supported by the Aksaray University
   Scientific Research Projects Coordinatorship /Aksaray, Turkey. Project
   Number: 2018-061.
CR Abushariah A., 2010, INT C COMPUTER COMMU, P1, DOI DOI 10.1109/ICCCE.2010.5556819
   Aktar N, 2019, 2 INT C EL COMP COMM, P1, DOI [10.1109/ECACE.2019.8679163, DOI 10.1109/ECACE.2019.8679163]
   AlShu'eili H., 2011, 2011 4th International Conference on Mechatronics (ICOM), P1, DOI DOI 10.1109/ICOM.2011.5937116
   [Anonymous], 2012, 2012 IEEE 5 POWER IN
   [Anonymous], 2011, INT SYMPO INTELL SIG
   Aripin NB, 2014, 2014 ELECTRICAL POWER, ELECTRONICS, COMMUNICATIONS, CONTROLS AND INFORMATICS SEMINAR (EECCIS), P142, DOI 10.1109/EECCIS.2014.7003735
   Asad CM, 2018, 2018 IEEE 12 INT C A, P1, DOI [10.1109/ICAICT.2018.8747123, DOI 10.1109/ICAICT.2018.8747123]
   Asyali MH, 2011, TURK J ELECTR ENG CO, V19, P33, DOI 10.3906/elk-0912-315
   Axelson J., 1997, Parallel Port Complete: Programming, Interfacing Using PC's Parallel Printer Port
   Aygun O, 2006, KONUSMACI TANIMA SIS
   Bala A., 2010, International Journal of Engineering Science and Technology, V2, P7335
   Baygun MK, 2009, PAMUKKALE U, P1
   Baygun MK, 2006, DEV SPEECH RECOGNITI
   Bolat B, 2004, AKILLI SISTEMLERDE Y, P23
   Demirci MD, 2005, BILGISAYAR DESTEKLI
   Edizkan R, 2007, SES KOMUT TANIMA ILE, P583
   Ege Y, 2006, TASARIM IMALAT ANALI, P394
   Ege Y, 2005, FERROMANYETIK MALZEM
   Ferrando F, 2009, ADV MATER RES-SWITZ
   Fezari M, 2006, 9TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P261, DOI 10.1109/AMC.2006.1631668
   Gor Nikunj Janak, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P1163, DOI 10.1109/ICECDS.2017.8389624
   Hrncar M, 2000, ACS APPL MATER INTER, P1
   Huang X., 2001, SPOKEN LANGUAGE PROC, P980
   Karakas M, 2010, THESIS DOKUZ EYLUL U
   Kaur G., 2017, IEEE SIGNAL PROC MAG, V6, P118, DOI [10.23956/ijermt.v6i8.126, DOI 10.23956/IJERMT.V6I8.126]
   Kumar K, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P40, DOI 10.1109/ISPCC.2015.7374995
   Luo ZZ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON INTELLIGENT MECHATRONICS AND AUTOMATION, P960
   Manssor SAF, 2015, 2015 International Conference on Computing, Control, Networking, Electronics and Embedded Systems Engineering (ICCNEEE), P374, DOI 10.1109/ICCNEEE.2015.7381394
   Matousek J, 2020, J MULTIMODAL USER IN, V14, P219, DOI 10.1007/s12193-020-00323-1
   Muda Lindasalwa, 2010, Journal of Computing, DOI DOI 10.48550/ARXIV.1003.4083
   Ozisik S, 2001, PROGRAMLAMA, V1
   Ozturk B, 2007, GERCEK ZAMANLI SES T
   Ozturk N, 2010, MICROPROCESSOR BASED
   Petrushin VA, 2000, EMOTION SPEECH RECOG, P1
   Price J, 2006, 9 INT C ENG ED T4J 1, P1
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Singh P, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P723, DOI [10.1109/AICAI.2019.8701409, 10.1109/aicai.2019.8701409]
   Smith SW., 1999, SCI ENG GUIDE DIGITA, P650
   Umchid S, 2018, 2018 11 BIOM ENG INT, P1, DOI [10.1109/BMEiCON.2018.8609955, DOI 10.1109/BMEICON.2018.8609955]
   Vineeth KVS, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2235, DOI 10.1109/ICACCI.2017.8126178
   Yagimli M, 2004, DIJITAL ELEKT, V4
NR 41
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22687
EP 22704
DI 10.1007/s11042-023-14471-5
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000933104800004
DA 2024-07-18
ER

PT J
AU Kao, CC
AF Kao, Chi-Chou
TI Performance-oriented FPGA-based convolution neural network designs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; FPGA; Optimize; Performance; Architecture
ID ACCELERATOR
AB Convolutional neural network (CNN) is the most well-known algorithm that it has been widely utilized in the applications of the image recognition and classification. Various Field Programmable Gate Array based (FPGA-based) CNN architectures had been proposed for the capability of the fast reconfigurability. However, the high-performance designs are necessary to reduce the computational time. The contributions of the paper include: 1) using heterogeneous and two-dimensional dispatcher technologies to implement FPGA-based CNN accelerators at different computational levels of CNN so that the computational time of CNN can be reduced and 2) proposing a flexible and integrated pipeline software and hardware (SW/HW) architecture to reduce the integration overheads of using a CNN framework. The experimental results show that the proposed architectures have the best performance and minimum FPGA resource requirements.
C1 [Kao, Chi-Chou] Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
C3 National University Tainan
RP Kao, CC (corresponding author), Natl Univ Tainan, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
EM cckao@mail.nutn.edu.tw
OI Kao, Chi-Chou/0000-0003-3174-9367
FU Ministry of Science and Technology, Taiwan [MOST 110-2221-E-024-001]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   MOST 110-2221-E-024-001.
CR Akira Jinguji, 2018, 2018 International Conference on Field-Programmable Technology (FPT). Proceedings, P310, DOI 10.1109/FPT.2018.00061
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cheng Yang, 2016, arXiv
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han  S., 2015, ARXIV151000149
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1, DOI 10.1109/RTEICT.2016.7807769
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Noronha D. H, 2018, FSP Workshop 2018; Fifth International Workshop on FPGAs for Software Programmers, P1
   Rosenberg Chuck., 2013, Google AI Blog
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wei XC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240856
   Xilinx, 2012, LARG FPGA METH GUID
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI [DOI 10.1145/2684746.2689060, 10.1145/2684746.2689060]
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
NR 28
TC 1
Z9 1
U1 19
U2 74
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21019
EP 21030
DI 10.1007/s11042-023-14537-4
EA FEB 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000931751400003
DA 2024-07-18
ER

PT J
AU Pooja, S
   Mallikarjunaswamy, M
   Sharmila, S
AF Pooja, S.
   Mallikarjunaswamy, M.
   Sharmila, S.
TI Image region driven prior selection for image deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deblurring; Blind deconvolution; Maximum a posteriori estimation;
   Image priors; Regularization; Ringing artifacts reduction
ID SPARSE REPRESENTATION; RESTORATION; ALGORITHM
AB Deblurring an image has been a long researched problem. This problem is very complex due to the lack of sufficient information about the blur parameters. Image deblurring is important in applications such as remote sensing where the same image scene comprising of moving objects cannot be captured again. Since the captured image is the only known quantity, from which the blur parameters affecting it and the sharp image has to be estimated it is an illposed problem. In this paper we present a novel image deblurring algorithm which makes use of region specific priors and techniques for image deblurring. This is based on the idea that different image regions require different techniques for effective image deblurring. Applying the same technique to deblur the entire image results in a deblurred image which is sharp in only some regions whereas some regions are not effectively deblurred or have ringing artifacts. The proposed method makes use of a l1 relaxed l0 prior on the sharp edges of the image to effectively enhance the true edges of the image. An l(1)/l(2) norm on the low peaks to avoid blurring while retaining the true values in these regions and lp norm prior on the uniform regions to avoid the generation of ringing artifacts. On an average there is about 18% increase in PSNR values and a 5% increase in the SSIM values in comparison with the existing state of the art methods.
C1 [Pooja, S.] KS Inst Technol, Bengaluru 560109, India.
   [Mallikarjunaswamy, M.] JSS Acad Tech Educ, Bengaluru 560060, India.
   [Sharmila, S.] JSS Sci & Technol Univ, Mysore 570006, India.
C3 JSS Science & Technology University
RP Mallikarjunaswamy, M (corresponding author), JSS Acad Tech Educ, Bengaluru 560060, India.
EM poojas@ksit.edu.in; pruthvi.malli@gmail.com; sharmilan@jssstuniv.in
RI S, Mallikarjunaswamy/X-7181-2019; S, Pooja/JMB-2706-2023
OI S, Mallikarjunaswamy/0000-0003-1106-5515; S, Pooja/0000-0002-4524-8558
CR Adam T, 2021, MULTIMED TOOLS APPL, V80, P18503, DOI 10.1007/s11042-021-10583-y
   Anwar S, 2019, IEEE T PATTERN ANAL, V41, P2112, DOI 10.1109/TPAMI.2018.2855177
   Babacan SD, 2012, LECT NOTES COMPUT SC, V7577, P341, DOI 10.1007/978-3-642-33783-3_25
   Batra D, 2012, LECT NOTES COMPUT SC, V7576, P1, DOI 10.1007/978-3-642-33715-4_1
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen L, 2014, MEDICAL IMAGE FUSION, V484, P12, DOI [10.1007/978-3-662-45643-9_2, DOI 10.1007/978-3-662-45643-9_2]
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Elmi Y, 2020, MULTIMED TOOLS APPL, V79, P29433, DOI 10.1007/s11042-020-09511-3
   Fang X, 2018, IEEE T CYBERNETICS
   Feng Mingbin., 2013, Industrial Engineering and Management Sciences
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Ge X, 2021, IEEE T IMAGE PROCESS
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gribonval R, 2003, IEEE T INFORM THEORY, V49, P3320, DOI 10.1109/TIT.2003.820031
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Javaran TA, 2019, MULTIMED TOOLS APPL, V78, P22555, DOI 10.1007/s11042-019-7402-1
   Kotera J, 2020, IEEE T IMAGE PROCESS, V29, P8577, DOI 10.1109/TIP.2020.3016490
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Lim H, 2020, IEEE J-STARS, V13, P3094, DOI 10.1109/JSTARS.2020.2999961
   Lin YZ, 2016, IEEE SW SYMP IMAG, P33, DOI 10.1109/SSIAI.2016.7459168
   Liu HS, 2019, IEEE T IMAGE PROCESS, V28, P72, DOI 10.1109/TIP.2018.2862357
   LIU JB, 2019, IEEE INT SYMP CIRC S, pNIL39, DOI DOI 10.1109/iscas.2019.8702329
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu YH, 2018, LECT NOTES COMPUT SC, V11205, P467, DOI 10.1007/978-3-030-01246-5_28
   Lyu YC, 2019, IEEE INT SYMP CIRC S
   McGaffin MG, 2015, IEEE T IMAGE PROCESS, V24, P1273, DOI 10.1109/TIP.2015.2400813
   Palmer JA, 2010, LECT NOTES COMPUT SC, V6365, P303, DOI 10.1007/978-3-642-15995-4_38
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Perrone D, 2016, IEEE T PATTERN ANAL, V38, P1041, DOI 10.1109/TPAMI.2015.2477819
   Poobathy D., 2014, International Journal of Image, Graphics and Signal Processing, V6, P55, DOI 10.5815/ijigsp.2014.10.07
   Portilla J, 2015, IEEE T IMAGE PROCESS, V24, P5046, DOI 10.1109/TIP.2015.2478405
   Rameshan RM, 2012, P 8 IND C COMP VIS G, P1
   Ramirez C, 2013, IND ENG MANAGEMENT S
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau AO, 2020, RECENT TRENDS IMAGE, P19
   Salau AO, 2021, J KING SAUD UNIV-COM, V33, P399, DOI 10.1016/j.jksuci.2019.01.011
   Satish P, 2020, TRAIT SIGNAL, V37, P527, DOI 10.18280/ts.370321
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shapri AHM, 2017, IMAGING SCI J, V65, P327, DOI 10.1080/13682199.2017.1341457
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Sroubek F, 2014, IEEE IMAGE PROC, P4492, DOI 10.1109/ICIP.2014.7025911
   Sun T, 2019, IEEE T IMAGE PROCESS, V28, P6211, DOI 10.1109/TIP.2019.2924339
   Tikhonov AN, 1977, GREAT FALLS
   Vijayarani, 2013, International Journal of Innovative Research in Computer and Communication Engineering, V1, P1760
   Weiss Y, 2012, ARXIV
   Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3
   Xu L., 2010, LECT NOTES COMPUT SC, DOI 10.1007/ 978-3-642-15549-9_12
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Yan YY, 2017, PROC CVPR IEEE, P6978, DOI 10.1109/CVPR.2017.738
   You YL, 1999, IEEE T IMAGE PROCESS, V8, P396, DOI 10.1109/83.748894
   Yu J, 2019, MULTIMED TOOLS APPL, V78, P18549, DOI 10.1007/s11042-019-7237-9
   Zha ZY, 2020, IEEE T IMAGE PROCESS, V29, P8561, DOI 10.1109/TIP.2020.3015545
   Zuo WM, 2016, IEEE T IMAGE PROCESS, V25, P1751, DOI 10.1109/TIP.2016.2531905
NR 60
TC 1
Z9 1
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24181
EP 24202
DI 10.1007/s11042-023-14335-y
EA JAN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000920970600002
DA 2024-07-18
ER

PT J
AU Garg, D
   Verma, GK
   Singh, AK
AF Garg, Divya
   Verma, Gyanendra Kumar
   Singh, Awadhesh Kumar
TI A review of Deep Learning based methods for Affect Analysis using
   Physiological Signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Deep learning; Affective computing; Emotion recognition; Human Computer
   Interaction
ID CONVOLUTIONAL NEURAL-NETWORKS; EMOTION RECOGNITION; EEG; FEATURES;
   DECOMPOSITION; FUSION; MODEL
AB Emotions are distinct reactions to internal or external events with implications for the organism. Automatic emotion recognition is a demanding task for pattern recognition and a required information retrieval method for diagnosing the condition of emotions in the peripheral nervous system and psychotherapy. In recent years, scientists have extensively considered physiological signals since they can give a modest, inexpensive, convenient, and easy-to-utilize result for recognizing emotions. Deep Learning has recently demonstrated incredible guarantees in figuring out physiological signals because of its ability to extract useful features and achieve better emotion recognition performance. In this survey, we analyzed a review of the neuro-physiological exploration made from 2012 to 2022, giving a complete outline of the current works in feeling acknowledgment from physiological signals utilizing deep learning strategies. We center our examination on the fundamental viewpoints engaged with the acknowledgment procedure (e.g., stimulus, features extracted, architectures). Our investigation reveals that most researchers have used Convolutional Neural Networks over other deep networks for classifying physiological-based emotions, as deep learning permits automatic end-to-end learning of pre-processing, including extraction and classification components. We determine many challenges and practice suggestions to help the exploration network, especially for the individuals entering this research field.
C1 [Garg, Divya; Singh, Awadhesh Kumar] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
   [Verma, Gyanendra Kumar] Natl Inst Technol Raipur, Dept Informat Technol, Raipur, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; National Institute of Technology (NIT System);
   National Institute of Technology Raipur
RP Garg, D (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
EM divya29garg@gmail.com; gkverma.it@nitrr.ac.in; aksingh@nitkkr.ac.in
RI Garg, Divya/JBJ-4506-2023; Singh, A K/A-2586-2016
OI Garg, Divya/0000-0003-3632-0797
CR Akter L., 2021, SN Comput Sci, V2, P1, DOI DOI 10.1007/S42979-021-00551-6
   Al-Nafjan A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121239
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Algarni M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082976
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   An Y, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102743
   [Anonymous], EEG BASED EMOTION RE
   [Anonymous], 1995, Optom. Vis. Sci., DOI DOI 10.1097/00006324-199511000-00013
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Arjun, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103547
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Awais M, 2021, IEEE INTERNET THINGS, V8, P16863, DOI 10.1109/JIOT.2020.3044031
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bagherzadeh S, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103544
   Balconi M, 2009, INT J PSYCHOPHYSIOL, V74, P158, DOI 10.1016/j.ijpsycho.2009.08.006
   Bao GC, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.834952
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bethel CL, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P727
   Bhardwaj H, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6524858
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chang S, 2020, J COMPUT DES ENG, V7, P551, DOI 10.1093/jcde/qwaa045
   Chao H, 2021, IEEE SENS J, V21, P2024, DOI 10.1109/JSEN.2020.3020828
   Chao H, 2020, IEEE ACCESS, V8, P33002, DOI 10.1109/ACCESS.2020.2974009
   Chao H, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/9750904
   Chen JX, 2019, IEEE ACCESS, V7, P118530, DOI 10.1109/ACCESS.2019.2936817
   Chen JX, 2019, IEEE ACCESS, V7, P44317, DOI 10.1109/ACCESS.2019.2908285
   Chen JX, 2020, COMPUT COMMUN, V154, P58, DOI 10.1016/j.comcom.2020.02.051
   Chen T, 2018, COMPUT ELECTR ENG, V72, P383, DOI 10.1016/j.compeleceng.2018.09.022
   Chen Y, 2021, IEEE ACCESS, V9, P47491, DOI 10.1109/ACCESS.2021.3068316
   Dar MN, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105327
   Das S, 2019, 1 INT C ADV SCI ENG
   Du GL, 2021, IEEE T INTELL TRANSP, V22, P4570, DOI 10.1109/TITS.2020.3007357
   Du XB, 2022, IEEE T AFFECT COMPUT, V13, P1528, DOI 10.1109/TAFFC.2020.3013711
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Fang WC, 2019, IEEE J EM SEL TOP C, V9, P645, DOI 10.1109/JETCAS.2019.2951232
   Feng L, 2022, IEEE J BIOMED HEALTH, V26, P5406, DOI 10.1109/JBHI.2022.3198688
   Ferdib-Al-Islam, 2021, INT C ROB EL SIGN PR
   Fox Elaine., 2008, EMOTION SCI COGNITIV
   Ganapathy N, 2021, J MED SYST, V45, DOI 10.1007/s10916-020-01676-6
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Gao ZK, 2020, IEEE T IND INFORM, V16, P7159, DOI 10.1109/TII.2019.2955447
   Garg Divya, 2020, Procedia Computer Science, V171, P857, DOI 10.1016/j.procs.2020.04.093
   Garg D, 2021, IMPROVED DCNN BASED
   Garg D, 2022, ENG RES EXPRESS, V4, DOI 10.1088/2631-8695/ac93e8
   Garg S., 2021, Appl Comput Informat, P1, DOI [10.1108/ACI-05-2021-0130, DOI 10.1108/ACI-05-2021-0130]
   Ghosh L, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106573
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hinton GeoffreyE., A Fast Learning Algorithm for Deep Belief Nets Yee-Whye Teh
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hockenbury DonH Sandra E Hockenbury., 2010, Discovering psychology
   Hssayeni MD, 2021, IEEE ACCESS, V9, P21642, DOI 10.1109/ACCESS.2021.3055933
   Hu JZ, 2021, NEUROCOMPUTING, V463, P177, DOI 10.1016/j.neucom.2021.08.018
   Huang D, 2012, IEEE IJCNN
   Huang HP, 2020, IEEE ACCESS, V8, P3265, DOI 10.1109/ACCESS.2019.2962085
   Hwang S, 2020, PATTERN ANAL APPL, V23, P1323, DOI 10.1007/s10044-019-00860-w
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam M.M., 2020, MEDRXIV
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jatupaiboon N, 2013, INT JOINT CONF COMP, P21
   Jeong DK, 2023, IEEE T COGN DEV SYST, V15, P651, DOI 10.1109/TCDS.2022.3179427
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Joshi VM, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102755
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kim BH, 2020, IEEE T AFFECT COMPUT, V11, P230, DOI 10.1109/TAFFC.2018.2790939
   Kim MK, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/573734
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kwon YH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051383
   Lee TMC, 2005, MOL PSYCHIATR, V10, P450, DOI 10.1038/sj.mp.4001595
   Li C, 2023, IEEE T AFFECT COMPUT, V14, P957, DOI 10.1109/TAFFC.2021.3130387
   Li C, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102185
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Li MA, 2016, ADV SOC SCI EDUC HUM, V47, P728
   Li Mu, 2009, Annu Int Conf IEEE Eng Med Biol Soc, V2009, P1323, DOI 10.1109/IEMBS.2009.5334139
   Li RL, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-020-09677-3
   Li X., 2015, Advances in Computational Psychophysiology, P28
   Li X, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00087
   Li X, 2016, IEEE INT C BIOINFORM, P352, DOI 10.1109/BIBM.2016.7822545
   Li YK, 2021, IEEE T SYST MAN CY-S, V51, P6040, DOI [10.1109/TSMC.2019.2958861, 10.1109/TCDS.2020.2999337]
   Li YJ, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101060
   Liang Z, 2021, IEEE T NEUR SYS REH, V29, P1913, DOI 10.1109/TNSRE.2021.3111689
   Lin Q, 2016, LECT NOTES ARTIF INT, V9773, P802, DOI 10.1007/978-3-319-42297-8_74
   Lin WQ, 2017, LECT NOTES COMPUT SC, V10667, P385, DOI 10.1007/978-3-319-71589-6_33
   Liu JY, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-9189-7
   Liu MF, 2018, NEUROCOMPUTING, V275, P288, DOI 10.1016/j.neucom.2017.08.039
   Liu SQ, 2022, IEEE J BIOMED HEALTH, V26, P5321, DOI 10.1109/JBHI.2021.3083525
   Liu YS, 2011, LECT NOTES COMPUT SC, V6670, P256, DOI 10.1007/978-3-642-22336-5_13
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Miranda-Correa JA, 2018, IEEE INT CONF AUTOMA, P373, DOI 10.1109/FG.2018.00060
   Mishra A, 2020, MULTIMED TOOLS APPL, V79, P18611, DOI 10.1007/s11042-020-08714-y
   Mousavinasr SMR, 2019, J MED SIGNALS SENS, V9, P77, DOI 10.4103/jmss.JMSS_34_17
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Nathan K, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00708
   Niedermeyer E., 2005, ELECTROEN CLIN NEURO, DOI DOI 10.1016/B978-0-323-04233-8.50007-X
   Ozdemir MA, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P314, DOI [10.1109/tiptekno.2019.8895158, 10.1109/TIPTEKNO.2019.8895158]
   Ozdemir MA, 2021, BIOMED ENG-BIOMED TE, V66, P43, DOI 10.1515/bmt-2019-0306
   Park KwangShin., 2011, International Journal of Medicine and Medical Sciences, V3, P201, DOI DOI 10.1016/J.NEUROIMAGE.2016.05.059
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Rahman MM, 2020, IEMTRONICS 2020 INT
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Ramzan M, 2023, INT J NEUROSCI, V133, P587, DOI 10.1080/00207454.2021.1941947
   Ribas GC, 2010, NEUROSURG FOCUS, V28, DOI 10.3171/2009.11.FOCUS09245
   Rosalind W.P., 2000, Affective Computing
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Sakalle A, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2020.114516
   Salama ES, 2021, EGYPT INFORM J, V22, P167, DOI 10.1016/j.eij.2020.07.005
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Samavat A, 2022, IEEE ACCESS, V10, P24520, DOI 10.1109/ACCESS.2022.3155647
   Sarkar P, 2022, IEEE T AFFECT COMPUT, V13, P1541, DOI 10.1109/TAFFC.2020.3014842
   Sengür D, 2020, ELECTRON LETT, V56, DOI 10.1049/el.2020.2685
   Shu YY, 2017, INT CONF ACOUST SPEE, P2871, DOI 10.1109/ICASSP.2017.7952681
   Siddharth, 2022, IEEE T AFFECT COMPUT, V13, P96, DOI 10.1109/TAFFC.2019.2916015
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Song TF, 2019, IEEE ACCESS, V7, P12177, DOI 10.1109/ACCESS.2019.2891579
   Suhaimi NS, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875426
   Sun TY, 2017, IEEE GLOBE WORK
   Teplan M., 2002, Measurement science review, V2, DOI DOI 10.1021/PR070350L
   Topic A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093248
   Torres EP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185083
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Wang Dan, 2013, Int J Inf Educ Technol, V3, P505, DOI 10.7763/IJIET.2013.V3.326
   Wang H, 2022, J NEURAL ENG, V19, DOI 10.1088/1741-2552/ac41ac
   Wang YX, 2019, IEEE ENG MED BIO, P1209, DOI [10.1109/embc.2019.8857499, 10.1109/EMBC.2019.8857499]
   Wang YQ, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9060231
   Wankhade SB, 2020, INT J UNCERTAIN FUZZ, V28, P153, DOI 10.1142/S0218488520500075
   Wilaiprasitporn T, 2020, IEEE T COGN DEV SYST, V12, P486, DOI 10.1109/TCDS.2019.2924648
   Wu YH, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106002
   Xiao GW, 2022, COGN NEURODYNAMICS, V16, P805, DOI 10.1007/s11571-021-09751-5
   Xing XF, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00037
   Yanagimoto M, 2016, 2016 IEEE 9TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P27, DOI 10.1109/IWCIA.2016.7805744
   Yang H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214736
   Yang KN, 2023, IEEE T AFFECT COMPUT, V14, P1082, DOI 10.1109/TAFFC.2021.3100868
   Yang Y, 2018, 2018 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC)
   Yang Y, 2022, IEEE J BIOMED HEALTH, V26, P589, DOI 10.1109/JBHI.2021.3092412
   Yin YQ, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106954
   Zeng H, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9110326
   Zhang JM, 2018, COMPUT METH PROG BIO, V164, P181, DOI 10.1016/j.cmpb.2018.07.015
   Zhang PW, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.738167
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhang YQ, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.622759
   Zhang Y, 2022, MULTIMED TOOLS APPL, V81, P33253, DOI 10.1007/s11042-022-13149-8
   Zheng W.-L., 2014, In 2014 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI [DOI 10.1109/ICME.2014.6890166, 10.1109/ICME.2014.6890166]
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng XW, 2021, INT J INTELL SYST, V36, P6312, DOI 10.1002/int.22551
   Zhong QH, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.589001
   Zhou L, 2021, DISCRETE DYN NAT SOC, V2021, DOI 10.1155/2021/1272502
   Zhu JY, 2015, IFMBE PROC, V51, P1188, DOI 10.1007/978-3-319-19387-8_288
   Zhu ML, 2022, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.741086
NR 161
TC 8
Z9 8
U1 9
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26089
EP 26134
DI 10.1007/s11042-023-14354-9
EA JAN 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000917999700001
DA 2024-07-18
ER

PT J
AU Mewada, H
AF Mewada, Hiren
TI 2D-wavelet encoded deep CNN for image-based ECG classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; ECG; Image classification; MIT-BIH
   datasets; Wavelet transform
ID CONVOLUTIONAL NEURAL-NETWORK; FEATURES; MODEL
AB Cardiovascular is nowadays a common and threatening disease for humans. Computer-aided diagnostic (CAD) can diagnose cardiovascular by finding anomalies in an electrocardiogram (ECG). However, this conventional diagnostic approach is inefficient and needs extensive analysis and medical knowledge to diagnose accurately. Deep learning can help in the timely detection of anomalies. ECG being a multi-tone signal, CNN-based temporal features are not sufficient for classification. A classification can be improved by integrating multi-spectral information with temporal features. Furthermore, the one-dimension (1D) ECG signal needs complex preprocessing, including signal cleaning and RR peak detection, whereas deep CNN is more efficient for 2D signals. This paper proposes an automated CAD system for ECG classification using a 2D deep-convolution network (CNN). The proposed CNN uses multi-spectral information by integrating wavelet-based spectral features with CNN's temporal features. The 1D ECG is reshaped to a 2D image, and a wavelet-encoded 2D CNN is proposed to classify these 2D images into four classes. The proposed model is evaluated using MIT-BIH datasets containing two-channel ambulatory ECG signals. A comparative study of both 1D and 2D approaches using deep CNN is presented in the paper initially. Later, the proposed network is validated by evaluating various quantitative parameters using the MIT-BIH dataset, and a comparative analysis is shown. The proposed CNN outperformed other models achieving the highest accuracy of 99.52% and 95.64% F1 score. The study reveals that the proposed model avoids the complex preprocessing of the ECG signals of cleaning, RR point detection, and waveform cropping. Further integration of wavelet-based multi-spectral features in CNN has improved the classification accuracy.
C1 [Mewada, Hiren] Prince Mohammad Bin Fahd Univ, Dept Elect Engn, Al Khobar 31952, Saudi Arabia.
C3 Prince Mohammad Bin Fahd University
RP Mewada, H (corresponding author), Prince Mohammad Bin Fahd Univ, Dept Elect Engn, Al Khobar 31952, Saudi Arabia.
EM hmewada@pmu.edu.sa
RI /AFP-4400-2022
OI /0000-0002-3579-8708
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2016, IEEE SYS MAN CYBERN, P533, DOI 10.1109/SMC.2016.7844294
   Afkhami RG, 2016, PATTERN RECOGN LETT, V70, P45, DOI 10.1016/j.patrec.2015.11.018
   Ahmad Z, 2021, IEEE ACCESS, V9, P100615, DOI 10.1109/ACCESS.2021.3097614
   Alfaras M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00103
   Avanzato R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060951
   Celin S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1083-6
   Curtin AE, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2844195
   Desai MM, 2021, INT J COMPUTING DIGI, V10
   Du N, 2021, INFORM SCIENCES, V549, P164, DOI 10.1016/j.ins.2020.10.014
   Ebrahimi Z., 2020, Expert Syst. Appl.: X, V7, P100033, DOI [10.1016/j.eswax.2020.100033, DOI 10.1016/J.ESWAX.2020.100033]
   Elhaj FA, 2016, COMPUT METH PROG BIO, V127, P52, DOI 10.1016/j.cmpb.2015.12.024
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Inan OT, 2006, IEEE T BIO-MED ENG, V53, P2507, DOI 10.1109/TBME.2006.880879
   Ji YS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112558
   Jun TJ, 2018, ARXIV
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Li TY, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080285
   Liao Y., 2014, Proc. IEEE Canada International Humanitarian Technology Conference-(IHTC), P1
   Liu PJ, 2019, IEEE ACCESS, V7, P74973, DOI 10.1109/ACCESS.2019.2921451
   Mahapatra S, 2016, PROCEDIA COMPUT SCI, V92, P175, DOI 10.1016/j.procs.2016.07.343
   Makimoto H, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65105-x
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P888, DOI 10.1016/j.bspc.2013.08.008
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P437, DOI 10.1016/j.bspc.2013.01.005
   Mathews SM, 2018, COMPUT BIOL MED, V99, P53, DOI 10.1016/j.compbiomed.2018.05.013
   Mathunjwa BM, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102262
   Melgani F, 2008, IEEE T INF TECHNOL B, V12, P667, DOI 10.1109/TITB.2008.923147
   Mewada H, 2020, ENG COMPUTATION, V37, P3525, DOI 10.1108/EC-11-2019-0529
   Mewada HK, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.4.043029
   Mewada HK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174747
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Naz M, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.386
   Patel H., 2018, INT J APPL ENG RES, V13, P7811
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Sadhukhan D, 2012, PROC TECH, V4, P873, DOI 10.1016/j.protcy.2012.05.143
   Tanoh IC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062758
   Venkatesan C, 2018, IEEE ACCESS, V6, P9767, DOI 10.1109/ACCESS.2018.2794346
   Wang GJ, 2019, INFORM SCIENCES, V501, P523, DOI 10.1016/j.ins.2018.06.062
   Wang JK, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106006
   Wang SB, 2016, SCI REP-UK, V6, DOI 10.1038/srep19444
   Wang T, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010119
   Weimann K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84374-8
   Williams T, 2018, INT C LEARN REPR
   Wu Y., 2018, ARXIV
   Yan ZL, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102170
   Zhang P, 2020, INT C ARTIFICIAL INT, P278
   Zidelmal Z, 2012, COMPUT METH PROG BIO, V107, P490, DOI 10.1016/j.cmpb.2011.12.004
   Zihlmann M, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.070-060
NR 49
TC 7
Z9 7
U1 12
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20553
EP 20569
DI 10.1007/s11042-022-14302-z
EA JAN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000926801100002
DA 2024-07-18
ER

PT J
AU Chole, V
   Gadicha, V
AF Chole, Vikrant
   Gadicha, Vijay
TI Hybrid fly optimization tuned artificial neural network for AI-based
   chess playing system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Chess game; Artificial neural network; Portable
   game notation file; Optimization
ID PLAYERS
AB Artificial intelligence (AI) has grown considerably in the present environment and acts as a subject still possessing substantial space for development, making most of its noteworthy advancements in the current era. While considering the chess game based on AI, the end-to-end pipeline was employed, in which the prior knowledge concerning chess is not essential, but in contrast, the efficient learning makes the method more efficient for making the optimal move. This paper proposes the Hybrid Fly-based artificial neural network (Hybridfly-ANN) model for attaining the maximum possible legal moves by rectifying the drawbacks of conventional position evaluation strategies. The Portable Game Notation (PGN) file acts as the input database comprising the details and the games played by the players over 1 month. The possible legal moves corresponding to the opponent's single move are evaluated through the proposed method and the mini-max algorithm is utilized for evaluating the best optimal move. The implication of the research relies on the proposed Hybrid Fly optimization algorithm that tunes the ANN classifier's weight optimally, leading to enhanced system performance by hybridizing the behavior of the Photinus and ephemera flies. Thus, the ANN's weights tuned with the proposed Hybrid Fly optimization's global best solution reduces the training loss thereby, improving the prediction accuracy. The effectiveness of the proposed method is examined in terms of the evaluation metrics which showed the average accuracy above 98% and minimal computation time of 180 secs.
C1 [Chole, Vikrant; Gadicha, Vijay] G H Raisoni Univ, Amravati, India.
RP Chole, V (corresponding author), G H Raisoni Univ, Amravati, India.
EM vikrant.chole@raisoni.net; vijay.gadicha@raisoni.net
RI Chole, Vikrant/AEH-7227-2022
OI Chole, Vikrant/0000-0003-4234-4541
CR Adams JA, 2001, AI Mag., V22, P105, DOI [10.1609/aimag.v22i2.1567, DOI 10.1609/AIMAG.V22I2.1567]
   Adegun A, 2020, INT J ENG RES TECHNO, V13, P191
   Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   [Anonymous], 2016, PREDICTING MOVES CHE
   [Anonymous], PGN FILE
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Bennett S, 2014, COMPUT VIS IMAGE UND, V118, P197, DOI 10.1016/j.cviu.2013.10.008
   Berliner H., 1990, Proceedings of Supercomputing '90 (Cat. No.90CH2916-5), P336, DOI 10.1109/SUPERC.1990.130039
   Binu D, 2020, IEEE T IND ELECT, V1
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Felstiner C, 2019, ALPHA BETA PRUNING
   FUNK Philippe, 2021, FIGSHARE, DOI [10.6084/m9.figshare.14844870.v2, DOI 10.6084/M9.FIGSHARE.14844870.V2]
   Gao Z-M, 2020, Journal of physics: conference series, V1684
   García S, 2012, IEEE T PATTERN ANAL, V34, P417, DOI 10.1109/TPAMI.2011.142
   Guid M, 2008, LECT NOTES COMPUT SC, V5131, P192, DOI 10.1007/978-3-540-87608-3_18
   Hongyue Li, 2020, ISBDAI '20: Proceedings of the 2020 2nd International Conference on Big Data and Artificial Intelligence, P9, DOI 10.1145/3436286.3436289
   Hübner D, 2020, BRAIN-COMPUT INTERFA, V7, P22, DOI 10.1080/2326263X.2020.1741072
   Jiwani N, 2021, P 5 INT C INF SYST C, P1, DOI DOI 10.1109/ISCON52037.2021.9702493
   Khoche K, 2019, INT J COMPUT SCI TRE, V7
   Kolosowski P, 2020, 15TH INTERNATIONAL CONFERENCE MECHATRONIC SYSTEMS AND MATERIALS, MSM'20, P83, DOI 10.1109/msm49833.2020.9202398
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Li XL, 2019, IEEE ACCESS, V7, P121922, DOI 10.1109/ACCESS.2019.2938240
   Liaqat A, 2020, IEEE ACCESS, V8, P174179, DOI 10.1109/ACCESS.2020.3024929
   Liu TZ, 2020, CHIN CONT DECIS CONF, P220, DOI 10.1109/CCDC49329.2020.9164607
   Mehta F., 2020, J ENG RES APPL, V10, P05
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Mishraa A, 2017, INT J CONTROL THEORY, V10
   Nitsche T, 1982, ADV COMPUTER CHESS, P113
   Pan SW, 2020, CHIN CONT DECIS CONF, P4818, DOI 10.1109/CCDC49329.2020.9164878
   Patel SD, 2023, COGNITION EMOTION, V37, P128, DOI 10.1080/02699931.2022.2155622
   Pawlewicz J, 2016, THEOR COMPUT SCI, V644, P127, DOI 10.1016/j.tcs.2016.06.027
   Prince J, 2018, EXPLORING EFFECT DIF
   Rawat A. S., 2018, IAES Int. J. Artif Intell., V7, P138, DOI [DOI 10.11591/IJAI.V7.I3.PP138-142, 10.1109/RICE.2018.8509069, DOI 10.1109/RICE.2018.8509069]
   Reingold EM, 2001, PSYCHOL SCI, V12, P48, DOI 10.1111/1467-9280.00309
   Reingold EM, 2001, PSYCHON B REV, V8, P504, DOI 10.3758/BF03196185
   Sabatelli M, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P276, DOI 10.5220/0006535502760283
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Sharma D, 2014, INT J COMPUTER APPL, P0975
   Sharma D, 2013, INT J ADV RES COMPUT, V4
   Song Z, 2018, ICGA J, V40, P269, DOI 10.3233/ICG-180059
   Zheng Y, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P784, DOI 10.1109/ASE.2019.00077
NR 42
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20453
EP 20475
DI 10.1007/s11042-022-14136-9
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000915219100001
DA 2024-07-18
ER

PT J
AU Sheng, LS
   Li, C
AF Sheng, Longshuai
   Li, Ce
TI Weakly supervised coarse-to-fine learning for human action segmentation
   in HCI videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal action segmentation; Weakly supervised learning; Coarse-to-fine
   loss; Fine partition model; HCI video
AB Human action segmentation in the video analysis for HCI (human-computer interaction) applications has been extensively studied to get the category and start time of actions that occur in videos. However, it remains an unsolved problem due to the lack of large amounts of accurate annotation of begin frame, end frame, and action category annotation data in the applications of video analysis. To handle this issue, weakly supervised action segmentation based on the transcript only uses the action annotation on the whole sequence in a long video instead of specific labeling of each frame, which significantly reduces the difficulty of obtaining delicately labeled video datasets. However, the task remains challenging for the video's complex temporal length partition of actions. In this paper, we use the Viterbi algorithm to generate the initial and coarse action segmentation as the baseline and then design a coarse-to-fine learning framework to refine the length partition. By connecting the candidate frames of the initial segmentation points in an orderly fashion and constructing a fully connected directed graph, a new coarse-to-fine loss function is designed to learn the scores of valid and invalid segmentation paths, respectively. The framework learns the coarse-to-fine loss function in an end-to-end manner to reduce the weight of the scores of invalid segmentation paths and obtain the best video segmentation. Compared with the state-of-the-art methods, the experiments on the breakfast and 50salads datasets show that our fine partition model and coarse-to-fine loss function can obtain higher frame accuracy and significantly reduce the time spent for human action segmentation in HCI videos. The source code will be made publicly available ().
C1 [Sheng, Longshuai; Li, Ce] China Univ Min & Technol, Comp Sci & Technol, Xueyuan Rd, Beijing 100083, Peoples R China.
   [Sheng, Longshuai] Ant Grp, Z Space 556 Xixi Rd, Hangzhou 310099, Zhejiang, Peoples R China.
C3 China University of Mining & Technology
RP Li, C (corresponding author), China Univ Min & Technol, Comp Sci & Technol, Xueyuan Rd, Beijing 100083, Peoples R China.
EM shenglongshuai@outlook.com; celi@cumtb.edu.cn
FU National Natural Science Foundation of China [62076016, 61972016,
   62176260]; Beijing Nova Program of Science and Technology
   [Z191100001119106, Z211100002121147]; Beijing Municipal Natural Science
   Foundation [4202065]; Fundamental Research Funds for the Central
   Universities [2022YJSJD11, J210409]
FX This study was funded by National Natural Science Foundation of China
   (62076016, 61972016, 62176260), Beijing Nova Program of Science and
   Technology (Z191100001119106,Z211100002121147), Beijing Municipal
   Natural Science Foundation (4202065), and supported by the Fundamental
   Research Funds for the Central Universities (2022YJSJD11, J210409).
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   AbuFarha Y, 2020, IEEE T PATTERN ANAL
   Adiono Trio, 2017, IEIE Transactions on Smart Processing & Computing, V6, P455, DOI 10.5573/IEIESPC.2017.6.6.455
   Alayrac JB, 2016, PROC CVPR IEEE, P4575, DOI 10.1109/CVPR.2016.495
   Arunlal KS., 2012, INT J COMP SCI ENG A, V2, P95, DOI 10.5121/ijcsea.2012.2110
   Bojanowski P, 2014, LECT NOTES COMPUT SC, V8693, P628, DOI 10.1007/978-3-319-10602-1_41
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Chang CY, 2019, PROC CVPR IEEE, P3541, DOI 10.1109/CVPR.2019.00366
   Ding L, 2018, PROC CVPR IEEE, P6508, DOI 10.1109/CVPR.2018.00681
   Fayyaz M, 2020, PROC CVPR IEEE, P498, DOI 10.1109/CVPR42600.2020.00058
   Gao J., 2017, arXiv
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Granger N, 2017, LECT NOTES COMPUT SC, V10635, P147, DOI 10.1007/978-3-319-70096-0_16
   Kalsotra R, 2022, VISUAL COMPUT, V38, P4151, DOI 10.1007/s00371-021-02286-0
   Koller O, 2017, PROC CVPR IEEE, P3416, DOI 10.1109/CVPR.2017.364
   Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412
   Kuehne H, 2020, IEEE T PATTERN ANAL, V42, P765, DOI 10.1109/TPAMI.2018.2884469
   Kuehne H, 2017, COMPUT VIS IMAGE UND, V163, P78, DOI 10.1016/j.cviu.2017.06.004
   Kuehne H, 2016, IEEE WINT CONF APPL
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lei P, 2019, IEEE C COMPUTER VISI, P6243
   Lei P, 2018, PROC CVPR IEEE, P6742, DOI 10.1109/CVPR.2018.00705
   Li J, 2021, PROC CVPR IEEE, P9801, DOI 10.1109/CVPR46437.2021.00968
   Li Jun, 2020, CVPR, P10820, DOI 10.1109/CVPR42600.2020.01083
   Li Z, 2021, PROC CVPR IEEE, P8361, DOI 10.1109/CVPR46437.2021.00826
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Oord A., 2016, ARXIV160903499
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Richard A, 2018, PROC CVPR IEEE, P7386, DOI 10.1109/CVPR.2018.00771
   Richard A, 2018, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2018.00627
   Richard A, 2017, PROC CVPR IEEE, P1273, DOI 10.1109/CVPR.2017.140
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Souri Y., 2021, IEEE T PATTERN ANAL
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Viterbi AJ, 2006, IEEE SIGNAL PROC MAG, V23, P120, DOI 10.1109/MSP.2006.1657823
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Yeung S, 2016, PROC CVPR IEEE, P2678, DOI 10.1109/CVPR.2016.293
   Yu J, 2020, VISUAL COMPUT, V36, P1457, DOI 10.1007/s00371-019-01751-1
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
NR 46
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12977
EP 12993
DI 10.1007/s11042-022-13792-1
EA DEC 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000915219100002
DA 2024-07-18
ER

PT J
AU Vaish, A
AF Vaish, Ankita
TI Joint image compression and encryption using set partitioning in
   hierarchical tree in MSVD domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression ratio; Image compression; Multi-resolution singular value
   decomposition; Peak signal to noise ratio; Set partitioning in
   hierarchical tree coding
ID INFORMATION; SYSTEM; CHAOS
AB This paper presents a joint compression and encryption technique using Set Partitioning in Hierarchical Tree (SPIHT) in Multi-resolution Singular Value Decomposition (MSVD) domain. The main idea of this work is to identify significant and less significant information in the MSVD domain. The core information is encrypted using pseudo-random number sequence and less significant information is encrypted using pseudo random permutation. For compression, a pseudo randomly encrypted image is compressed using quantization and coding while the irrelevant information in the encrypted less significant part is compressed by quantization and SPIHT coding technique. At the receiver end, an efficient decompression and decryption technique is used to reconstruct the original image from the compressed bit streams. The efficiency of proposed work is computed using some mathematical measures such as Compression Ratio (CR) and Peak-Signal-to-Noise Ratio (PSNR). The experimental results and security analysis show the superiority of proposed work over existing work on joint compression and encryption.
C1 [Vaish, Ankita] Banaras Hindu Univ, Dept Comp Sci, Varanasi 221005, India.
C3 Banaras Hindu University (BHU)
RP Vaish, A (corresponding author), Banaras Hindu Univ, Dept Comp Sci, Varanasi 221005, India.
EM av21lko@gmail.com
FU Banaras Hindu University, under the seed grant IoE;  [R/Dev/D/IoE/Seed
   Grant/2020-21/6031]
FX AcknowledgementsThis work is supported by Banaras Hindu University,
   under the seed grant IoE (no. R/Dev/D/IoE/Seed Grant/2020-21/6031).
CR Alfalou A, 2013, OPT COMMUN, V307, P67, DOI 10.1016/j.optcom.2013.05.053
   Alfalou A, 2010, J OPT-UK, V12, DOI 10.1088/2040-8978/12/11/115403
   Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   Alfalou A, 2013, IEEE T INFORM THEORY, P167
   Alfalou A, 2011, OPTICAL DIGITAL IMAG, P463
   [Anonymous], 2009, PROC TENCON 2009 IEE
   Chaudhary P, 2020, PROCEDIA COMPUT SCI, V167, P244, DOI 10.1016/j.procs.2020.03.218
   GALLAGER RG, 1962, IRE T INFORM THEOR, V8, P21, DOI 10.1109/tit.1962.1057683
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Jung P, 1997, ELECTRON LETT, V33, P2102, DOI 10.1049/el:19971444
   Kamm Julie L., 1998, THESIS
   Kang, 2000, SUBIEEE T INF THEORY, P167
   Klinc D, 2012, IEEE T INFORM THEORY, V58, P6989, DOI 10.1109/TIT.2012.2210752
   Kumar AA, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P764
   Kumar M., 2016, SOCPROS 2015 SPRINGE, P729
   Kumar M, 2017, DIGIT SIGNAL PROCESS, V60, P81, DOI 10.1016/j.dsp.2016.08.011
   Lazzeretti R., 2008, P 16 EUR SIGN PROC C, P1
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Liu XB, 2014, J MOD OPTIC, V61, P1570, DOI 10.1080/09500340.2014.946565
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Malini S, 2015, PROCEDIA COMPUT SCI, V46, P1708, DOI 10.1016/j.procs.2015.02.114
   MARCELLIN MW, 1990, IEEE T COMMUN, V38, P82, DOI 10.1109/26.46532
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   Ranade A, 2007, IMAGE VISION COMPUT, V25, P771, DOI 10.1016/j.imavis.2006.07.004
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schonberg D., 2005, 43 ANN ALL C ALL IL
   Schonberg D, 2006, IEEE IMAGE PROC, P269, DOI 10.1109/ICIP.2006.313177
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Vaish, 2022, J KING SAUD UNIV SCI
   Vaish A, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P228, DOI 10.1145/2818567.2818611
   Wang CT, 2015, SIGNAL PROCESS-IMAGE, V39, P141, DOI 10.1016/j.image.2015.09.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Yadav A, 2021, J DISCRET MATH SCI C, V24, P2233, DOI 10.1080/09720529.2021.2011102
   Zhang M, 2020, IEEE ACCESS, V8, P40838, DOI 10.1109/ACCESS.2020.2976798
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhang XP, 2014, MULTIMED TOOLS APPL, V72, P489, DOI 10.1007/s11042-013-1392-1
   Zhang XP, 2012, IEEE T IMAGE PROCESS, V21, P3108, DOI 10.1109/TIP.2012.2187671
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 50
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18781
EP 18797
DI 10.1007/s11042-022-14275-z
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000915133800002
DA 2024-07-18
ER

PT J
AU Vucic, D
   Barakovic, S
   Skorin-Kapov, L
AF Vucic, Dunja
   Barakovic, Sabina
   Skorin-Kapov, Lea
TI Survey on user perceived system factors influencing the QoE of
   audiovisual calls on smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; Influence factors; Audiovisual calls; Smartphones; User perception
ID VIDEO QUALITY
AB With the widespread use of applications and services supporting audiovisual calls via smartphones, both in business and leisure contexts, a key challenge for service providers is meeting end user Quality of Experience (QoE) expectations and requirements. To successfully meet this challenge, there is a need to identify and analyze the key system-related factors impacting user perceived quality. In this paper, we contribute beyond state-of-the-art by conducting a large scale web-based questionnaire survey to investigate the system-related factors that subjects identify as most influential in contributing to their overall experience and quality perception. We focus in particular on leisure audiovisual calls, established via mobile devices. Our initial survey (Phase 1) was conducted in Feb. 2020, just prior to the outbreak of the COVID-19 pandemic (272 participants). To investigate if the importance of factors has changed due to increased usage of the service caused by the pandemic among the general population, we conducted a second survey (Phase 2) in October 2021 with 249 participants. Based on obtained results, we identify key system-related QoE influence factors belonging to three categories: media quality, functional support, and usability and service design. We observe no significant differences in user opinions and expectations prior to and during the period of increased service usage, despite different participant demographics and study time frames, thus contributing to generalizability of obtained results. Study results contribute to providing insights for designing future user studies investigating QoE, in terms of key factors that should be considered.
C1 [Vucic, Dunja] Ericsson Nikola Tesla Dd, Krapinska 45, Zagreb 10000, Croatia.
   [Barakovic, Sabina] Univ Sarajevo, Fac Traff & Commun, Zmaja Od Bosne 8, Sarajevo 71000, Bosnia & Herceg.
   [Skorin-Kapov, Lea] Univ Zagreb, Fac Elect Engn & Comp, Unska 3, Zagreb 10000, Croatia.
C3 Ericsson; University of Sarajevo; University of Zagreb
RP Vucic, D (corresponding author), Ericsson Nikola Tesla Dd, Krapinska 45, Zagreb 10000, Croatia.
EM dunja.vucic@ericsson.com; sabina.barakovic@fsk.unsa.ba;
   Lea.Skorin-Kapov@fer.hr
RI Baraković, Sabina/JMR-0897-2023
FU Croatian Science Foundation [IP-2019-04-9793]
FX This work has been supported by the Croatian Science Foundation under
   the project IP-2019-04-9793 (Q-MERSIVE).
CR Ammar Doreid, 2018, International Journal of New Computer Architectures and their Applications, V8, P89
   Ammar D, 2019, C LOCAL COMPUT NETW, P406, DOI [10.1109/lcn44214.2019.8990677, 10.1109/LCN44214.2019.8990677]
   [Anonymous], Video Conferencing, Meetings, Calling | Microsoft Teams
   [Anonymous], GLOBAL INTERNET PHEN
   [Anonymous], P EUR NETW QUAL EXP
   [Anonymous], 2014, P 3 INT WORKSHOP SOC
   Balihodzic M, 2020, INT S INN INT APPL A, P255
   Bouraqia K, 2020, IEEE ACCESS, V8, P13341, DOI 10.1109/ACCESS.2020.2965099
   Carofiglio G, 2021, PROCEEDINGS OF THE ACM SIGCOMM 2021 WORKSHOP ON NETWORK-APPLICATION INTEGRATION (NAI '21), P20, DOI 10.1145/3472727.3472800
   Coppens-Hofman MC, 2016, FOLIA PHONIATR LOGO, V68, P175, DOI 10.1159/000450548
   DASARI M, 2018, 2018 IEEEACM 26 INT, pNI124
   Dasari M, 2018, IMC'18: PROCEEDINGS OF THE INTERNET MEASUREMENT CONFERENCE, P1, DOI 10.1145/3278532.3278533
   De Masi A, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P86, DOI 10.1145/3524273.3528183
   De Moor K., 2017, 2017 9 INT C QUALITY, P1
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Feldmann Anja, 2020, IMC '20: Proceedings of the ACM Internet Measurement Conference, P1, DOI 10.1145/3419394.3423658
   García B, 2019, COMPUTING, V101, P1585, DOI 10.1007/s00607-018-0669-7
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Holub J, 2022, IEEE ACCESS, V10, P9321, DOI 10.1109/ACCESS.2022.3143814
   Hosfeld T., 2011, Proceedings of the 2011 23rd International Teletraffic Congress (ITC 2011), P103
   Husic JB, 2017, 2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P428, DOI 10.23919/MIPRO.2017.7973463
   Husic JB, 2022, COMPUT HUM BEHAV, V129, DOI 10.1016/j.chb.2021.107155
   Husic JB, 2020, INT J NETW MANAG, V30, DOI 10.1002/nem.2083
   ITU-T Rec, 2016, P807 ITUT
   ITU-T Rec, 2017, P1301 ITUT
   Jana S, 2016, MULTIMED TOOLS APPL, V75, P7957, DOI 10.1007/s11042-015-2711-5
   Jumisko-Pyykko S, 2011, USER CENTERED QUALIT, P12
   Jumisko-Pyykkö S, 2010, INT J MOB HUM COMPUT, V2, P1, DOI 10.4018/jmhci.2010100101
   Kale V., 2019, Digital Transformation of Enterprise Architecture, DOI [10.1201/9781351029148, DOI 10.1201/9781351029148]
   Laghari AA, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0179-6
   Lee I, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3583, DOI 10.1145/3474085.3475523
   LIU M, 2022, 2022 IEEE INT S BROA, P1
   Matulin M., 2021, Future Access Enablers for Ubiquitous and Intelligent Infrastructures. FABULOUS 2021. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, V382, DOI [DOI 10.1007/978-3-030-78459-1_22, 10.1007/978- 3-030-78459-1_22]
   Mrvelj S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182202
   Oie EB, 2021, INT WORK QUAL MULTIM, P137, DOI 10.1109/QoMEX51781.2021.9465376
   Rao N, 2019, INT WIREL COMMUN, P1267, DOI 10.1109/IWCMC.2019.8766591
   Silva AFD., 2018, ELECT IMAGING, V2018, P234
   Skowronek J, 2017, THESIS TECHNICAL U B
   Skowronek J, 2014, T-LAB SER TELECOMMUN, P213, DOI 10.1007/978-3-319-02681-7_15
   Skowronek Janto, 2022, IEEE ACCESS
   Usman MA, 2017, IETE TECH REV, V34, P309, DOI 10.1080/02564602.2016.1185975
   Vega MT, 2018, IEEE T BROADCAST, V64, P220, DOI 10.1109/TBC.2017.2781125
   Vuci D., 2019, 2019 15 INT C TEL, P1
   Vucic D., 2016, SCREEN, V18, P19
   Vucic D, 2020, IEEE ACCESS, V8, P107669, DOI 10.1109/ACCESS.2020.3000467
   Vucic D, 2019, LECT NOTES COMPUT SC, V11295, P459, DOI 10.1007/978-3-030-05710-7_38
   Wac K., 2011, P 1 ACM SIGCOMM WORK, P7, DOI DOI 10.1145/2018602.2018605
   Yu CG, 2014, IEEE INFOCOM SER, P1456, DOI 10.1109/INFOCOM.2014.6848080
   Zeng K, 2014, PROC SPIE, V9014, DOI 10.1117/12.2043128
NR 49
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24681
EP 24706
DI 10.1007/s11042-022-14173-4
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000915133800001
PM 36467436
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Bandhu, KC
   Litoriya, R
   Lowanshi, P
   Jindal, M
   Chouhan, L
   Jain, S
AF Bandhu, Kailash Chandra
   Litoriya, Ratnesh
   Lowanshi, Pradeep
   Jindal, Manav
   Chouhan, Lokendra
   Jain, Suresh
TI Making drug supply chain secure traceable and efficient: a Blockchain
   and smart contract based implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthcare supply chain; Blockchain; Transparency; Traceability;
   Stakeholders; Fake drugs; Data security
ID SYSTEMS
AB The healthcare supply chain involves obtaining resources, managing supplies, and delivering goods and services to patients across multiple teams, stakeholders, and geographical boundaries. With such a complex structure, the healthcare supply chain is vulnerable to fraud, inaccurate data, and lack of transparency. These misdeeds cost businesses money and harm health. To address these issues, the health care supply chain needs an end-to-end decentralized track-and-trace system. Most centralized systems risk drug and data safety. This paper presents an Ethereum blockchain-based solution for a health care supply chain track-and-trace mechanism that uses smart contracts and data immutability. Hash functions store data in a public distributed ledger. This protects and discloses data. Smart contracts automate agreement execution so all parties know the outcome instantly, without an intermediary or time loss. It also outlined decentralized healthcare supply chain application architecture and algorithms. This paper proposes a system to address the lack of transparency and tracking in traditional supply chains. The blockchain-based method proposed in this paper runs on Solidity smart contracts. The system's algorithms and methods are tested against a variety of inputs, and the results are presented as an average gas cost for specific functionality. The proposed system tracks goods' histories (medicine). The average gas cost for all accounts is 18,027.2. Overall, log gas costs 48,118.6 to buy medicine, gas costs 229,607.5, and to log out 14,275.The results of the proposed system are compared to state-of-the-art methods. Thus, the presented work allows a seamless flow of medicines via blockchain and smart contracts without intermediaries. Finally, it addresses building a secure pharma supply chain application for blockchain 4.0.
C1 [Bandhu, Kailash Chandra; Litoriya, Ratnesh; Lowanshi, Pradeep; Jindal, Manav; Chouhan, Lokendra; Jain, Suresh] Medi Caps Univ, Indore, India.
RP Litoriya, R (corresponding author), Medi Caps Univ, Indore, India.
EM kailashchandra.bandhu@etnail.com; litoriyaratnesh@gmail.com;
   pradeeplowanshi17@grnail.com; manavjindal114@gmail.com;
   chouhanraj484@gmail.com; suresh.jain@rediffmail.com
RI Jain, Suresh/KVZ-3026-2024; Bandhu, Kailash Chandra/ABF-4912-2020;
   Chouhan (Ph.D.), Lokendra/AAY-7399-2021
OI Jain, Suresh/0000-0002-4092-8298; Bandhu, Kailash
   Chandra/0000-0002-4337-4198; Chouhan (Ph.D.),
   Lokendra/0000-0001-9232-4077; Litoriya, Ratnesh/0000-0002-7285-422X
CR Al-Safi H, 2022, MULTIMED TOOLS APPL, V81, P8719, DOI 10.1007/s11042-022-12164-z
   Chohan UW, 2019, DISCUSSION PAPER SER, DOI [10.2139/ssrn.3338560, DOI 10.2139/SSRN.3338560]
   Decker C, 2013, IEEE INT CONF PEER, P1, DOI [DOI 10.1109/P2P.2013.6688704, 10.1109/P2P.2013.6688704, 10.1109/P2P. 2013.6688704]
   Demestichas K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124113
   Fiorini RA, 2020, INT J SOFTW SCI COMP, V12, P1, DOI 10.4018/IJSSCI.2020070101
   Gan CQ, 2021, MULTIMED TOOLS APPL, V80, P30605, DOI 10.1007/s11042-020-09322-6
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Gopie N, 2018, What are smart contracts on blockchain?
   Gururaj H., 2020, INT J BLOCKCHAINS CR, V1, P107, DOI [10.1504/IJBC.2020.108996, DOI 10.1504/IJBC.2020.108996]
   Gururaj HL., 2021, INT J BLOCKCHAINS CR, V2, P68, DOI [10.1504/IJBC.2021.117809, DOI 10.1504/IJBC.2021.117809]
   Huang Y, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1137, DOI 10.1109/Cybermatics_2018.2018.00206
   Humayun Mamoona, 2020, IEEE Internet of Things Magazine, V3, P58, DOI 10.1109/IOTM.0001.1900097
   HYPERLEDGER, WALM BROUGHT UNPR TR
   Jabbar A, 2020, INT J PROD RES, V58, P3423, DOI 10.1080/00207543.2020.1754487
   Jamil F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050505
   jmcook1186, 2021, INTRO SMART CONTRACT
   Kaleido, TRUFFL BLOCKCH SMART
   Kamble SS, 2023, ANN OPER RES, V327, P575, DOI 10.1007/s10479-021-04129-6
   Khan U, 2020, IEEE ACCESS, V8, P217045, DOI 10.1109/ACCESS.2020.3041317
   Lansiti M, 2017, HARVARD BUS REV, V95, P119
   Lee W.-M., 2019, Beginning Ethereum Smart Contracts Programming: With Examples in Python, Solidity, and JavaScript, P93, DOI [10.1007/978-1-4842-5086-0_5, DOI 10.1007/978-1-4842-5086-0_5]
   Lingayat Vishwesh, 2021, ITM Web of Conferences, V37, DOI 10.1051/itmconf/20213701013
   Lu JQ, 2022, IEEE T IND INFORM, V18, P5422, DOI 10.1109/TII.2021.3112601
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mohana M, 2019, INTI J, V35
   Moralis, 2022, GAN EXPL WHAT IS GAN
   Musamih A, 2021, IEEE ACCESS, V9, P9728, DOI 10.1109/ACCESS.2021.3049920
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Olugbenga E, 2021, INTRO SOLIDITYNO TIT
   Pandey P, 2021, WIRELESS PERS COMMUN, V117, P7, DOI 10.1007/s11277-020-07041-7
   Pandey P, 2021, NATL ACAD SCI LETT, V44, P225, DOI 10.1007/s40009-020-00978-0
   Pandey P, 2020, HEALTH POLICY TECHN, V9, P69, DOI 10.1016/j.hlpt.2020.01.004
   Pandey P, 2020, CRYPTOLOGIA, V44, P341, DOI 10.1080/01611194.2019.1706060
   Pandey V., 2021, BBC NEWS
   Park A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041726
   Poonia V, 2021, J CLEAN PROD, V312, DOI 10.1016/j.jclepro.2021.127737
   Seed, 2021, PHARMA TIMES
   Settanni E, 2017, OPER RES PERSPECT, V4, P74, DOI 10.1016/j.orp.2017.05.002
   Singh AP, 2021, IEEE T IND INFORM, V17, P5779, DOI 10.1109/TII.2020.3037889
   Soner S, 2022, WIRELESS PERS COMMUN, V125, P3001, DOI 10.1007/s11277-022-09695-x
   Sumathi M, 2020, INT J CLOUD APPL COM, V10, P77, DOI 10.4018/IJCAC.2020040105
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   TRUFFLE SUITE, TRUFFLE SMART CONTRA
   Uddin M, 2021, HEALTH INFORM J, V27, DOI 10.1177/14604582211011228
   Wan SH, 2020, MULTIMED TOOLS APPL, DOI 10.1007/s11042-019-08541-w
   World Health Organization, 2017, A Study on the Public Health and Socioeconomic Impact of Substandard and Falsified Medical Products
NR 47
TC 10
Z9 10
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23541
EP 23568
DI 10.1007/s11042-022-14238-4
EA NOV 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000888710500007
PM 36467435
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Mokeddem, ML
   Belahcene, M
   Bourennane, S
AF Mokeddem, Mohammed Lakhdar
   Belahcene, Mebarka
   Bourennane, Salah
TI COVID-19 risk reduce based YOLOv4-P6-FaceMask detector and DeepSORT
   tracker
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detection; Localization; Deep learning; Scaled-YOLOv4; Tracking
ID CONVOLUTIONAL NETWORKS; OBJECT DETECTION
AB Wearing masks in public areas is one of the effective protection methods for people. Although it is essential to wear the facemask correctly, there are few research studies about facemask detection and tracking based on image processing. In this work, we propose a new high performance two stage facemask detector and tracker with a monocular camera and a deep learning based framework for automating the task of facemask detection and tracking using video sequences. Furthermore, we propose a novel facemask detection dataset consisting of 18,000 images with more than 30,000 tight bounding boxes and annotations for three different class labels namely respectively: face masked/incorrectly masked/no masked. We based on Scaled-You Only Look Once (Scaled-YOLOv4) object detection model to train the YOLOv4-P6-FaceMask detector and Simple Online and Real-time Tracking with a deep association metric (DeepSORT) approach to tracking faces. We suggest using DeepSORT to track faces by ID assignment to save faces only once and create a database of no masked faces. YOLOv4-P6-FaceMask is a model with high accuracy that achieves 93% mean average precision, 92% mean average recall and the real-time speed of 35 fps on single GPU Tesla-T4 graphic card on our proposed dataset. To demonstrate the performance of the proposed model, we compare the detection and tracking results with other popular state-of-the-art models of facemask detection and tracking.
C1 [Mokeddem, Mohammed Lakhdar; Belahcene, Mebarka] MKhider Univ, LI3C, RB IAIM, Biskra, Algeria.
   [Bourennane, Salah] Ecole Cent, Fresnel Inst, GSM, Marseille, France.
RP Mokeddem, ML (corresponding author), MKhider Univ, LI3C, RB IAIM, Biskra, Algeria.
EM mohammedlakhdar.mokeddem@univ-biskra.dz;
   mebarka.belahcene@univ-biskra.dz; salah.bourennane@fresnel.fr
OI mokeddem, mohammed lakhdar/0000-0001-8517-2781
CR Ameur B, 2019, Efficient hybrid descriptor for face verification in the wild using the deep learning approach, DOI [10.3103/S1060992X19030020, DOI 10.3103/S1060992X19030020]
   [Anonymous], 2020, FMD
   [Anonymous], 2020, MMD
   [Anonymous], 2020, SMFD
   Belahcene M., 2013, THESIS M KHIDER U BI
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen J, 2021, IEEE IMAGE PROC, P699, DOI 10.1109/ICIP42928.2021.9506347
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chu P, 2019, IEEE WINT CONF APPL, P161, DOI 10.1109/WACV.2019.00023
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Ding M., 2022, arXiv
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Elaggoune H, 2022, MULTIMED TOOLS APPL, V81, P9403, DOI 10.1007/s11042-021-11849-1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan XQ, 2021, IEEE SYS MAN CYBERN, P832, DOI 10.1109/SMC52423.2021.9659271
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goyal H, 2022, MULTIMED TOOLS APPL, V81, P14999, DOI 10.1007/s11042-022-12166-x
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jiang M., 2020, ARXIV
   Jiang XB, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070837
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Kim M, 2016, ARXIV
   Kumar A, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166744
   Li XC, 2020, IEEE ACCESS, V8, P174922, DOI 10.1109/ACCESS.2020.3023782
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z., 2022, ARXIV
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Luo S, 2019, IEEE ACCESS, V7, P171609, DOI 10.1109/ACCESS.2019.2955757
   Milan A., 2016, ARXIV
   Misra D., 2019, ARXIV190808681
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Prasad Praagna, 2022, 2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS), P382, DOI 10.1109/ICAIS53314.2022.9742863
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan Q., 2021, Efficientnetv2: Smaller models and faster training, P10096, DOI DOI 10.48550/ARXIV.2104.00298
   Tripathi S, 2022, MEDRXIV
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu PS, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104341
   Xiru Wu, 2021, 2021 China Automation Congress (CAC), P2322, DOI 10.1109/CAC53003.2021.9728245
   Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zou Z, 2019, ARXIV
NR 58
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23569
EP 23593
DI 10.1007/s11042-022-14251-7
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000888710500005
PM 36467437
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Corbin, A
   Marques, O
AF Corbin, Adam
   Marques, Oge
TI Exploring strategies to generate Fitzpatrick skin type metadata for
   dermoscopic images using individual typology angle techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Machine learning; Dermatology; Fairness; Image
   analysis
ID SEGMENTATION
AB When building machine learning models for dermatology one should strive to ensure that the resulting solutions do not exhibit any bias, which could cause a misdiagnosis of some patients - for example, due to the patient's skin type being under-represented in the datasets used to build those models. Public dermatology datasets usually lack representativeness for certain skin tones, which are typically encoded using the Fitzpatrick skin type (a range of 1-6, where higher numbers mean darker skin tones). Moreover, those datasets usually lack metadata containing skin type information. To address the lack of such metadata, the Fitzpatrick skin type can be estimated based on pixel contents by computing the image's Individual Typology Angle (ITA) and subsequently mapping ranges of ITA values to the corresponding Fitzpatrick skin type. This work focuses on computing the ITA for skin lesion images without binary masks indicating the location of the lesions. Four different approaches are proposed, experimentally evaluated using three datasets from the International Skin Imaging Collaboration (ISIC) and compared. The approaches were evaluated based on the estimated ITA value (essentially a regression task) and the resulting Fitzpatrick skin type (a classification task). Experimental results showed that the Structured Patches and Center Cropped methods performed best overall. The proposed algorithms can be used as a proxy for generating the Fitzpatrick skin type metadata for datasets that lack that metadata and without the need for segmentation masks.
C1 [Corbin, Adam; Marques, Oge] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Corbin, A (corresponding author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.
EM acorbin3@fau.edu; omarques@fau.edu
OI Corbin, Adam/0000-0002-7731-2606
CR Bakhshali MA, 2021, SKIN RES TECHNOL, V27, P1162, DOI 10.1111/srt.13081
   Berseth M., 2017, ARXIV
   Chan S, 2020, DERMATOLOGY THER, V10, P365, DOI 10.1007/s13555-020-00372-0
   CHARDON A, 1991, INT J COSMETIC SCI, V13, P191, DOI 10.1111/j.1467-2494.1991.tb00561.x
   Codella N., 2019, ARXIV
   Codella N.C.F., 2018, ARXIV
   Combalia M, 2019, ARXIV
   Daneshjou R, 2021, ARXIV
   Daneshjou R, 2021, JAMA DERMATOL, V157, P1362, DOI 10.1001/jamadermatol.2021.3129
   Das S, 2021, AUTOMATED BIAS REDUC, V15
   Edinburgh TU, 2019, ED INN DERM IM LIB
   FITZPATRICK TB, 1988, ARCH DERMATOL, V124, P869, DOI 10.1001/archderm.124.6.869
   Giotis I, 2015, EXPERT SYST APPL, V42, P6578, DOI 10.1016/j.eswa.2015.04.034
   Groh M., 2021, arXiv
   Gutman D, 2016, ARXIV
   Jafari MH, 2016, INT C PATT RECOG, P337, DOI 10.1109/ICPR.2016.7899656
   Kamulegeya LH, 2019, bioRxiv
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kim H. J., 2021, ARXIV
   Kinyanjui N.M., 2020, Medical Image Computing and Computer Assisted Intervention-MICCAI 2020, V12266, P320, DOI [DOI 10.1007/978-3-030-59725-231, 10.1007/978-3-030-59725-231]
   Kinyanjui NM, 2019, ARXIV
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Merler M, 2019, ARXIV
   Ozkan I.A., 2017, Int. J. Intell. Syst. Appl. Eng., V5, P285, DOI DOI 10.18201/IJISAE.2017534420
   Raumanns R, 2021, ARXIV
   Rotemberg V, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00815-z
   Sun XX, 2016, LECT NOTES COMPUT SC, V9910, P206, DOI 10.1007/978-3-319-46466-4_13
   Tadesse GA, 2021, AUTOMATED EVALUATION, V5
   Nguyen THV, 2018, BIORESOURCES, V13, P6250
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tschandl P, 2019, LANCET ONCOL, V20, P938, DOI 10.1016/S1470-2045(19)30333-X
   Wilkes M, 2015, JAMA DERMATOL, V151, P902, DOI 10.1001/jamadermatol.2015.0351
   Wu Y., 2020, Bioimages, V28, P1
   Yang JF, 2020, IEEE T NEUR NET LEAR, V31, P2832, DOI 10.1109/TNNLS.2019.2917524
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
NR 36
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23771
EP 23795
DI 10.1007/s11042-022-14211-1
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000886859100004
DA 2024-07-18
ER

PT J
AU Qiu, YZ
   Chen, YT
   Zheng, YX
   Wang, YH
   Wu, K
   Wu, SL
   Guo, R
   Zhao, YL
   Dong, EB
AF Qiu, Yuze
   Chen, Yutao
   Zheng, Yuxiang
   Wang, Yahao
   Wu, Kai
   Wu, Shaolei
   Guo, Rui
   Zhao, Yuliang
   Dong, Erbao
TI Adaptive uneven illumination correction method for autonomous live-line
   maintenance robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hot-line work robot; Image enhancement; Image segmentation; Uneven
   illumination correction; Illumination-reflection model; Gamma correction
ID HISTOGRAM EQUALIZATION; WORKING ROBOT; IMAGE; ALGORITHM; RETINEX; SYSTEM
AB With the development of the robot in electricity, more and more autonomous live-line maintenance robots (ALMRs) have been developed and put into use. However, in outdoor environment, complicated and uneven illumination lead to huge challenges for visual feedback and target recognition of ALMRs. Aiming at easing the disturbance brought by the strong uneven illumination, we collect a Hot-Line dataset containing fieldwork photos of the ALMR and propose an image enhancement method for uneven illumination images based on image brightness segmentation and multi-methods fusion. Through image segmentation based on illuminance, the proposed algorithm enhances the over- and under-illuminated parts of the image differently while taking the approximate illumination component as a reference. We introduce an adaptive weighted summation strategy to ease the problem of edge transition in the output. The proposed algorithm improves the overall performance of a fieldwork image of ALMR properly, making the image clearer and better. For six indexes (Laplacian, SMD2, Energy of Gradient (EOG), and Entropy for image clarity; Structural similarity index measure (SSIM) and Peak signal-to-noise ratio (PSNR) for the degree of image information retention), the proposed method provided good results on both our Hot-Line dataset (for example, on EOG, the proposed method achieves nearly double the performance index value than CLAHE) and other image datasets, and finished the enhancement within a relatively short time (within 0.02s with image size 275 x 275). The proposed algorithm has been verified on an ALMR for the power distribution network and archived good results.
C1 [Qiu, Yuze; Chen, Yutao; Zheng, Yuxiang; Wang, Yahao; Dong, Erbao] Univ Sci & Technol China, Dept Precis Machinery & Precis Instrumentat, Hefei 230026, Peoples R China.
   [Wu, Kai; Wu, Shaolei] State Grid Anhui Elect Power Co, Elect Power Res Inst, Hefei 230601, Peoples R China.
   [Guo, Rui; Zhao, Yuliang] State Grid Intelligent Technol Co Ltd, Jinan 250001, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; State Grid Corporation of China
RP Dong, EB (corresponding author), Univ Sci & Technol China, Dept Precis Machinery & Precis Instrumentat, Hefei 230026, Peoples R China.
EM qyz1921@mail.ustc.edu.cn; cyt@mail.ustc.edu.cn; zyx39@mail.ustc.edu.cn;
   wyh218@mail.ustc.edu.cn; wu_kay@163.com; wushaolei@sina.com;
   guoruihit@qq.com; 350628539@qq.com; ebdong@ustc.edu.cn
RI 亚豪, 王/KHY-9154-2024; qin, cheng/KHC-3344-2024
OI 亚豪, 王/0000-0002-3323-4968; 
FU National Key R&D Program of China [2018YFB1307400]
FX The work is supported by the National Key R&D Program of China
   (2018YFB1307400).
CR Allan J-F, 2012, 2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI 2012), P96, DOI 10.1109/CARPI.2012.6473344
   [Anonymous], 2016, 2016 IEEE 2 ANN SO P, DOI DOI 10.1109/SPEC.2016.7846151
   [Anonymous], 2011, INT J COMPUT SCI TEC
   [Anonymous], 2007, COLOUR CONSTANCY
   Aracil R., 1995, ESMO-95 Proceedings. Seventh International Conference on Transmission and Distribution Construction and Live Line Maintenance (Cat. No.95CH35755), P205, DOI 10.1109/TDCLLM.1995.485058
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen YT, 2019, LECT NOTES ARTIF INT, V11743, P221, DOI 10.1007/978-3-030-27538-9_19
   DALEJONES R, 1993, PATTERN RECOGN, V26, P1373, DOI 10.1016/0031-3203(93)90143-K
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Goswami S, 2020, PATTERN RECOGN LETT, V138, P392, DOI 10.1016/j.patrec.2020.08.013
   Guo TX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2021), P1158, DOI 10.1109/ICMA52036.2021.9512827
   Hu YM, 2017, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.2017.43
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li CL, 2021, APPL INTELL, V51, P202, DOI 10.1007/s10489-020-01792-3
   Li P, 2018, CHIN CONTR CONF, P9584, DOI 10.23919/ChiCC.2018.8483674
   Li Yu-feng, 2010, Application Research of Computers, V27, P1534, DOI 10.3969/j.issn.1001-3695.2010.04.093
   Liu Zhi-cheng, 2016, Transactions of Beijing Institute of Technology, V36, P191, DOI 10.15918/j.tbit1001-0645.2016.02.016
   Lu Shouyin, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P1716, DOI 10.1109/ICIEA.2009.5138489
   Mu Q, 2021, COMPUT VIS MEDIA, V7, P529, DOI 10.1007/s41095-021-0232-x
   NAKASHIMA M, 1995, IEEE INT CONF ROBOT, P843, DOI 10.1109/ROBOT.1995.525388
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park S, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0192-3
   Petrol AB, 2014, IMAGE PROCESS ON LIN, V4, P71, DOI 10.5201/ipol.2014.107
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qiu YH, 2020, IEEE ACCESS, V8, P190663, DOI 10.1109/ACCESS.2020.3032108
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Taeyoung Son, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P749, DOI 10.1007/978-3-030-58545-7_43
   Takaoka K, 2001, PROCEEDINGS OF THE 2001 IEEE INTERNATIONAL SYMPOSIUM ON ASSEMBLY AND TASK PLANNING (ISATP2001), P423, DOI 10.1109/ISATP.2001.929071
   Tang MD, 2019, ROBOT AUTON SYST, V119, P247, DOI 10.1016/j.robot.2019.07.008
   Tang MD, 2017, IND ROBOT, V44, P479, DOI 10.1108/IR-11-2016-0320
   Huynh-The T, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-44
   Triantafyllidou Danai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P103, DOI 10.1007/978-3-030-58601-0_7
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang W, 2008, INT C WAVEL ANAL PAT, P80, DOI 10.1109/ICWAPR.2008.4635754
   Wang WC, 2021, J SENSORS, V2021, DOI 10.1155/2021/5563698
   Wang YK, 2014, J REAL-TIME IMAGE PR, V9, P407, DOI 10.1007/s11554-012-0301-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Xiao Lv, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2282, DOI 10.1109/ROBIO.2012.6491309
   Xiao WH, 2022, CONNECT SCI, V34, P709, DOI 10.1080/09540091.2022.2038543
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Zhan YT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030431
   Zhang L, 2016, IET IMAGE PROCESS, V10, P840, DOI 10.1049/iet-ipr.2015.0844
   Zhao B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21154986
   Zhao L, 2019, DESTECH T ENG TECHNO, DOI [10.12783/dtetr/amsms2019/31870, DOI 10.12783/DTETR/AMSMS2019/31870]
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 57
TC 0
Z9 0
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23453
EP 23481
DI 10.1007/s11042-022-14249-1
EA NOV 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000886864400003
DA 2024-07-18
ER

PT J
AU Jagat, RR
   Sisodia, DS
   Singh, P
AF Jagat, Rikhi Ram
   Sisodia, Dilip Singh
   Singh, Pradeep
TI DISET: a distance based semi-supervised self-training for automated
   users' agent activity detection from web access log
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web robot; Automated user agent activity; Web access log;
   Semi-supervised learning; Self-training; XGBoost
ID ROBOT DETECTION
AB Detecting automated users' agent activities at any web application through users' web access logs is a challenging issue. Many machines learning based automated solutions exist to address this issue. However, the existing supervised learning methods are heavily dependent on fully labeled data. But the scarcity of labeled log access data and the cost of labeling still make the issue challenging. Some unsupervised learning-based solutions are also proposed, but their performance accuracy is questionable. The semi-supervised based self-training method works with a small set of partially labeled data but lacks a suitable selection metric for a set of predictions with a high degree of confidence and a reliable base learner. In this paper, we propose a new semi-supervised learning based self-training method using probability-based selection criteria with Mahalanobis distance, named DIstance-based SElf-Training (DISET) for detecting automated users' agent activities. The DISET used probability-based selection criteria with Mahalanobis distance to achieve high-confidence subset selection. The DISET framework works in four steps. First, it performs the data cleaning, session identification, feature extraction, and session labeling during the data preprocessing step. The second step segments the data into labeled and unlabeled datasets. The third step of model self-training performs the subset selection using six different supervised base learners independently. Lastly, the fourth step tests the performance of the used model. The performance of DISET is evaluated on NASA95 and E-commerce weblog datasets using three-fold cross-validation training and testing. The used datasets are also divided into different ratios of labeled and unlabeled instances for experiments. The performance is recorded on the accuracy, precision, recall, and the f-1 score, and the Matthews Correlation Coefficient (MCC) measures and compares the model's performance with six different base classifiers. We also plotted the ROC and PR curves to confirm and compare the performance of different base learners with the DISET method. Out of the six-base learners, XGBoost outperformed both datasets in the 30:70 data segmentation ratio. The results show that DISET achieves a minimum percentage improvement of 1.91% in accuracy, 2.70% in precision, 3.65% in sensitivity, and 1.00% in F-1 score with large unlabeled datasets.
C1 [Jagat, Rikhi Ram; Sisodia, Dilip Singh; Singh, Pradeep] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur 492010, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Jagat, RR (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Raipur 492010, Madhya Pradesh, India.
EM rrjagat.phd2019.cse@nitrr.ac.in; dssisodia.cs@nitrr.ac.in;
   psingh.cs@nitrr.ac.in
RI Sisodia, Dilip Singh/AAF-4236-2020
OI Sisodia, Dilip Singh/0000-0001-9845-290X; Jagat, Rikhi
   Ram/0000-0002-5794-6660
CR Abubakar H, 2020, J THEOR APPL INF TEC, V98, P429
   Akamai, 2022, AK BOT MAN ADV STRAT
   Algiryage N, 2018, 2018 MORATUWA ENGINEERING RESEARCH CONFERENCE (MERCON) 4TH INTERNATIONAL MULTIDISCIPLINARY ENGINEERING RESEARCH CONFERENCE, P13, DOI 10.1109/MERCon.2018.8421894
   Alipour M, 2020, J CIV STRUCT HEALTH, V10, P313, DOI 10.1007/s13349-020-00386-4
   AlNoamany Y, 2013, ACM-IEEE J CONF DIG, P339
   Arlitt M, 1996, NASA WEBSITE ACCESS
   Bell B.A., 2013, SAS Global Forum Statistic and Data Analysis, paper 433, P1
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bomhardt C, 2005, STUD CLASS DATA ANAL, P113, DOI 10.1007/3-540-27373-5_14
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cabri A, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1536, DOI 10.1109/HPCC/SmartCity/DSS.2018.00252
   Chen H., 2020, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), P1, DOI DOI 10.1109/CYBERSECURITY49315.2020.9138856
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Courtney L, 2021, 2021 IEEE 11TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P451, DOI 10.1109/CCWC51732.2021.9375938
   CVE Details, 2022, VULN TYP
   Doran D, 2016, EXPERT SYST, V33, P592, DOI 10.1111/exsy.12184
   Doran D, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P7, DOI 10.1109/ICMLA.2012.11
   Fu J, 2019, COMMUN COMPUT PHYS, P1
   Guo YC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2428, DOI 10.1109/HPCC/SmartCity/DSS.2019.00339
   Hamidzadeh J, 2018, SOFT COMPUT, V22, P2175, DOI 10.1007/s00500-016-2476-4
   Hou YT, 2010, EXPERT SYST APPL, V37, P55, DOI 10.1016/j.eswa.2009.05.023
   Iliou C, 2019, 14TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2019), DOI 10.1145/3339252.3339267
   Imperva, 2021, BAD BOT REP 2021
   Imperva, 2022, IMP ADV BOT PROT MAN
   Kaur H, 2014, ADV INTELL SYST, V285, P241, DOI 10.1007/978-3-319-06740-7_21
   Krzywinksi M, 2017, NAT METHODS, V14, P757, DOI 10.1038/nmeth.4370
   Kwon S, 2012, J INF SCI, V38, P118, DOI 10.1177/0165551511435969
   Lagopoulos A, 2018, PROC INT C TOOLS ART, P968, DOI 10.1109/ICTAI.2018.00150
   Lee J, 2009, COMPUT SECUR, V28, P795, DOI 10.1016/j.cose.2009.05.004
   Lewandowski P, 2020, IEEE ACCESS, V8, P141292, DOI 10.1109/ACCESS.2020.3012969
   Liao KY, 2013, KNOWL-BASED SYST, V49, P123, DOI 10.1016/j.knosys.2013.05.003
   Livieris IE, 2018, ALGORITHMS, V11, DOI 10.3390/a11090139
   Mittal M., 2014, Int. J. Adv. Technol., V5, P153
   Mucherino A, 2009, SPRINGER SER OPTIM A, V34, P83, DOI 10.1007/978-0-387-88615-2_4
   Rahman RU, 2021, J COMPUT VIROL HACKI, V17, P75, DOI 10.1007/s11416-020-00368-6
   Renuka Devi, 2012, DETECTION APPL LAYER, P217, DOI [10.5121/csit.2012.2223, DOI 10.5121/CSIT.2012.2223]
   Rustogi R, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P456
   Sahu S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091568
   Sahu S, 2022, IEEE ACCESS, V10, P42030, DOI 10.1109/ACCESS.2022.3168161
   Sardar TH, 2014, 2014 INTERNATIONAL CONFERENCE ON THE IMPACT OF E-TECHNOLOGY ON US (IMPETUS), P13, DOI 10.1109/IMPETUS.2014.6775871
   Schapire Robert E, 2013, EMPIRICAL INFERENCE, P37, DOI [DOI 10.1007/978-3-642-41136-65, DOI 10.1007/978-3-642-41136-6_5]
   Sisodia D., 2015, Journal of Data Analysis and Information Processing, V03, P1, DOI DOI 10.4236/JDAIP.2015
   Sisodia DS, 2018, 2018 INT C ADV COMPU, P8, DOI [10.1109/ICACAT.2018.8933587, DOI 10.1109/ICACAT.2018.8933587]
   Stassopoulou A, 2009, COMPUT NETW, V53, P265, DOI 10.1016/j.comnet.2008.09.021
   Stevanovic D., 2011, Procedia CS, V5, P123, DOI [10.1016/j.procs.2011.07.018, DOI 10.1016/J.PROCS.2011.07.018]
   Stevanovic D, 2013, APPL SOFT COMPUT, V13, P698, DOI 10.1016/j.asoc.2012.08.028
   Stevanovic D, 2012, EXPERT SYST APPL, V39, P8707, DOI 10.1016/j.eswa.2012.01.210
   Suchacka G, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105875
   Tan PN, 2002, DATA MIN KNOWL DISC, V6, P9, DOI 10.1023/A:1013228602957
   Tanaka Takamasa, 2020, Procedia Computer Science, V176, P1621, DOI 10.1016/j.procs.2020.09.185
   Triguero I, 2015, KNOWL INF SYST, V42, P245, DOI 10.1007/s10115-013-0706-y
   udger, 2022, US AG
   Wan SY, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0023-1
   Webb G. I., 2010, Encyclopedia of Machine Learning, P713, DOI DOI 10.1007/978-0-387-30164-8_576
   Zabihimayvan M, 2017, EXPERT SYST APPL, V87, P129, DOI 10.1016/j.eswa.2017.06.004
   Zhu W, 2019, LECT NOTES COMPUTER, P507
   Zhu X, 2008, SciencesNew York, DOI 10.1.1.146.2352
NR 59
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19853
EP 19876
DI 10.1007/s11042-022-14258-0
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000886192700003
DA 2024-07-18
ER

PT J
AU Ahmed, HM
   Elsharkawy, ZF
   Elkorany, AS
AF Ahmed, Heba M.
   Elsharkawy, Zeinab F.
   Elkorany, Ahmed S.
TI Alzheimer disease diagnosis for magnetic resonance brain images using
   deep learning neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep CNN; ADNI; Alzheimer's disease; MRI; ROC
ID GRAY WOLF OPTIMIZER; CLASSIFICATION APPROACH
AB In this work, a Deep Convolutional Neural Network (DCNN) framework for Alzheimer's Disease (AD) diagnosis based on brain Magnetic Resonance Imaging (MRI) scans is presented. A multiclass DCNN classifier is used to discriminate between Normal Controls (NC), Mild Cognitive Impairment (MCI), and AD. The Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset was used to train and test the proposed DCNN. Different train-test ratios have been examined. Average accuracies of 100% for AD/NC, 92.93% for NC/MCI, and 99.21% for AD/MCI were obtained. The proposed system achieved an average accuracy of 93.86% for a three-way AD/MCI/NC classification. To further examine the proposed system performance, Receiver Operation Characteristics (ROC) analysis and Confusion Matrix (CM) were also used. For certain scenarios, the Area Under ROC Curve (AUC) values of 1, 1, and 0.989 were obtained for AD, NC, and MCI, respectively. The results show higher metrics compared to previously published studies concerning AD diagnosis.
C1 [Ahmed, Heba M.] Informat Res Inst IRI, City Sci Res & Technol Applicat SRTA City, Alexandria, Egypt.
   [Elsharkawy, Zeinab F.] Egyptian Atom Energy Author, Engn Dept, Nucl Res Ctr, Cairo, Egypt.
   [Elkorany, Ahmed S.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); City of Scientific Research &
   Technological Applications (SRTA-City); Egyptian Knowledge Bank (EKB);
   Egyptian Atomic Energy Authority (EAEA); Egyptian Knowledge Bank (EKB);
   Menofia University
RP Elsharkawy, ZF (corresponding author), Egyptian Atom Energy Author, Engn Dept, Nucl Res Ctr, Cairo, Egypt.
EM eng.heba55@gmail.com; zeinab_elsharkawy@yahoo.com;
   elkoranyahmed@yahoo.com
RI Elkorany, Ahmed S./AFS-0613-2022; Elkorany, Ahmed S./HNI-8465-2023
OI Elkorany, Ahmed S./0000-0003-3400-2971; Elkorany, Ahmed
   S./0000-0003-3400-2971; Elsharkawy, Zeinab/0000-0002-6167-8435
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Ahmed HM, 2019, MULTIMED TOOLS APPL, V78, P27983, DOI 10.1007/s11042-019-07876-8
   Ahmed HM, 2018, APPL OPTICS, V57, pB25, DOI 10.1364/AO.57.000B25
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Bäckström K, 2018, I S BIOMED IMAGING, P149, DOI 10.1109/ISBI.2018.8363543
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Bi XL, 2020, NEUROCOMPUTING, V392, P296, DOI 10.1016/j.neucom.2018.11.111
   Cárdenas-Peña D, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/9523849
   Goryawala M, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/865265
   Gupta Ashish, 2013, INT C MACH LEARN, P987
   Hon M, 2017, IEEE INT C BIOINFORM, P1166, DOI 10.1109/BIBM.2017.8217822
   Janghel RR, 2021, IRBM, V42, P258, DOI 10.1016/j.irbm.2020.06.006
   Korolev IO., 2014, MSRJ, V4, P24, DOI DOI 10.3402/MSRJ.V3I0.201333
   Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647
   Lee E, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116113
   Liu L, 2020, SIMUL MODEL PRACT TH, V99, DOI 10.1016/j.simpat.2019.102023
   Liu MH, 2020, NEUROIMAGE, V208, DOI 10.1016/j.neuroimage.2019.116459
   Lo Buono V, 2020, INT J NEUROSCI, V130, P243, DOI 10.1080/00207454.2019.1667798
   Nordberg A, 2010, NAT REV NEUROL, V6, P78, DOI 10.1038/nrneurol.2009.217
   Payan A, 2015, arXiv
   Puente-Castro A, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103764
   Raza M, 2019, EXPERT SYST APPL, V136, P353, DOI 10.1016/j.eswa.2019.06.038
   Richhariya B, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101903
   Sarraf S, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P816, DOI 10.1109/FTC.2016.7821697
   Senanayake U, 2018, I S BIOMED IMAGING, P1394, DOI 10.1109/ISBI.2018.8363832
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Vu TD, 2018, SOFT COMPUT, V22, P6825, DOI 10.1007/s00500-018-3421-5
   Tong T, 2017, PATTERN RECOGN, V63, P171, DOI 10.1016/j.patcog.2016.10.009
   Tong T, 2014, MED IMAGE ANAL, V18, P808, DOI 10.1016/j.media.2014.04.006
   Uysal G, 2020, J NEUROSCI METH, V337, DOI 10.1016/j.jneumeth.2020.108669
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Xiao RY, 2021, MULTIMED TOOLS APPL, V80, P3969, DOI 10.1007/s11042-020-09738-0
   Xiao Z, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/1952373
   Zhang F, 2019, NEUROCOMPUTING, V361, P185, DOI 10.1016/j.neucom.2019.04.093
NR 34
TC 2
Z9 2
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17963
EP 17977
DI 10.1007/s11042-022-14203-1
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886739000002
DA 2024-07-18
ER

PT J
AU Singh, L
   Aggarwal, N
   Singh, S
AF Singh, Lovejit
   Aggarwal, Naveen
   Singh, Sarbjeet
TI PUMAVE-D: panjab university multilingual audio and video facial
   expression dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal emotion dataset; Facial expressions; Multilingual speech;
   Tone-sensitive; Behavioural intelligence; Audio-video signals; Affective
   computing; Emotion recognition
ID SENTIMENT ANALYSIS; DATABASE
AB Due to the significance of human behavioural intelligence in computing devices, this paper presents the Panjab University Multilingual Audio and Video Facial Expression (PUMAVE) dataset for multimodal emotion recognition in the Indian context. It discusses the characteristics and distinguishing features of the PUMAVE dataset compared with existing datasets. It described the detail procedure followed in the construction of PUMAVE dataset. The validation and reliability analysis are performed on the recorded speech and facial expressions of subjects in six emotions. The effectiveness of the recorded emotion clips is analysed against the responses of annotators. During and after responses, inter-rater responses, and intra-rater responses are analysed to measure the quality of subjective assessment, homogeneity, and consistency in the annotator responses. The PUMAVE dataset is the first multilingual tone-sensitive audio-video facial expression dataset which provides emotional labelled clips of subjects who speak the native language (Punjabi and Hindi) and foreign language (English).
C1 [Singh, Lovejit] Chandigarh Univ, Univ Inst Engn, Mohali 140413, Punjab, India.
   [Aggarwal, Naveen; Singh, Sarbjeet] Panjab Univ, Univ Inst Engn & Technol, Sect 14, Chandigarh 160014, India.
C3 Chandigarh University; Panjab University
RP Singh, L (corresponding author), Chandigarh Univ, Univ Inst Engn, Mohali 140413, Punjab, India.
EM pu.lovejitjhajj@gmail.com; navagg@gmail.com; sarbjeet@pu.ac.in
FU University Grant Commission (UGC), Ministry of Human Resource
   Development (MHRD) of India [F.25-1/2013-14(BSR)/7-379/2012(BSR)]
FX This work was supported by University Grant Commission (UGC), Ministry
   of Human Resource Development (MHRD) of India under Basic Scientific
   Research (BSR) fellowship for meritorious fellows vide UGC letter no.
   F.25-1/2013-14(BSR)/7-379/2012(BSR) Dated 30.5. 2014.
CR Banziger T., 2006, PROC LREC WORKSHOP C, P15
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Battocchi A, 2005, LECT NOTES COMPUT SC, V3814, P303, DOI 10.1007/11590323_39
   BERRY KJ, 1988, EDUC PSYCHOL MEAS, V48, P921, DOI 10.1177/0013164488484007
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   CARIDAKIS G., 2010, Multimodal Corpora: Advances in Capturing, Coding and Analyzing Multimodality, P80
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie Ellen., 2008, Corpora for Research on Emotion and Affect Workshop, P1
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Erdem CE, 2015, MULTIMED TOOLS APPL, V74, P7429, DOI 10.1007/s11042-014-1986-2
   Fleiss J., 2003, STAT METHODS RATES P, P598, DOI DOI 10.1002/0471445428.CH18
   Haq S, 2008, P INT C AUDITORY VIS
   Hussain M. S., 2012, P 10 AUSTR DAT MIN C, V134, P103
   Kim J, 2005, 9 EUR C SPEECH COMM
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kossaifi J, 2019, ARXIV
   Li Y, 2017, J AMB INTEL HUM COMP, V8, P913, DOI 10.1007/s12652-016-0406-z
   Lin JC, 2012, IEEE T MULTIMEDIA, V14, P142, DOI 10.1109/TMM.2011.2171334
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   ORGI: Census of India, 2011, COMP SPEAK STRENGTH
   Papapicco C., 2020, ONLINE J COMMUN MEDI, V10, P2020
   Papapicco C., 2021, WORLD FUTUR, V77, P266, DOI [10.1080/02604027.2021.1914486, DOI 10.1080/02604027.2021.1914486]
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Rösner D, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2559
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Schuller B, 2007, INT CONF ACOUST SPEE, P733
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991
   Wöllmer M, 2013, IEEE INTELL SYST, V28, P46, DOI 10.1109/MIS.2013.34
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
NR 41
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10117
EP 10144
DI 10.1007/s11042-022-14102-5
EA NOV 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000884646200003
DA 2024-07-18
ER

PT J
AU Mahajan, HB
   Uke, N
   Pise, P
   Shahade, M
   Dixit, VG
   Bhavsar, S
   Deshpande, SD
AF Mahajan, Hemant B.
   Uke, Nilesh
   Pise, Priya
   Shahade, Makarand
   Dixit, Vandana G.
   Bhavsar, Swapna
   Deshpande, Sarita D.
TI Automatic robot Manoeuvres detection using computer vision and deep
   learning techniques: a perspective of internet of robotics things (IoRT)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geographical features; Visual features; Hybrid features; LSTM; Object
   segmentation; Visual sensor data; Video sequence
ID RECOMMENDATION SYSTEM; RECOGNITION; LOCALIZATION; DATASET
AB To minimize any impediments in real-time Internet of Things (IoT)-enabled robotics applications, this study demonstrated how to build and deploy a revolutionary framework using computer vision and deep learning. In contrast to robotic path planning algorithms based on geolocation. We focus on sensor-captured streams/images and geographical information to enable the Internet of Robotic Things (IoRT) to evolve. The application will collect real-time data from moving robotics at various situations and intervals and use it for research projects. The data collected in videos/image forms are delivered in the robotics application using visual sensor nodes. In this study, anticipating moving robot moves automatically early on can aid in issuing commands to monitor and regulate robots' future activities before they occur. To do so, we propose the framework using efficient computer vision techniques and a deep learning classifier. The computer vision methods are designed for frame quality improvement, object segmentation, and feature estimation. The Long-Term Short Memory (LSTM) classifier detects robot motions automatically from initial sequential features. We mainly designed the proposed model using an LSTM classifier to perform the earlier prediction from the initial sequential features of partial video frames and to overcome the problems of exploding and vanishing gradients. LSTM helps to reduce the prediction duration with higher accuracy. It also enables the central system of a certain robotic application to prevent collisions caused by impediments in the interior or outdoor situation. The simulation results utilizing publicly available research datasets demonstrate the proposed model's efficiency and robustness compared to state-of-the-art approaches. The overall accuracy of the proposed model has improved approximately by 5% and reduced computational complexity by 84% approximately.
C1 [Mahajan, Hemant B.] Godwit Technol, Pune, Maharashtra, India.
   [Uke, Nilesh] Trinity Acad Engn, Pune, Maharashtra, India.
   [Pise, Priya] Indira Coll Engn & Management, Pune, Maharashtra, India.
   [Shahade, Makarand] SVKMs Inst Technol, Behind Gurudwara, Dhule, India.
   [Dixit, Vandana G.; Bhavsar, Swapna; Deshpande, Sarita D.] PES Modern Coll Engn, Pune, Maharashtra, India.
RP Mahajan, HB (corresponding author), Godwit Technol, Pune, Maharashtra, India.
EM mahhemant@gmail.com
RI Shahade, Makarand/JTT-0083-2023; Bhavsar, Dr.Swapna
   Sameer/JDD-0022-2023; Uke, Nilesh/N-2382-2015; Mahajan, Hemant
   B./AAP-2042-2020
OI Mahajan, Hemant B./0000-0001-6703-7711
CR Alcácer V, 2019, ENG SCI TECHNOL, V22, P899, DOI 10.1016/j.jestch.2019.01.006
   Alhayani B, 2021, WIRELESS PERS COMMUN, V120, P665, DOI 10.1007/s11277-021-08484-2
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Calli B, 2017, INT J ROBOT RES, V36, P261, DOI 10.1177/0278364917700714
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366
   Chang CK, 2010, IEEE INT C INT ROBOT, P4147, DOI 10.1109/IROS.2010.5649136
   Chauhan A, 2021, J CLEAN PROD, V279, DOI 10.1016/j.jclepro.2020.123854
   Chen HY, 2012, IEEE T ROBOT, V28, P1069, DOI 10.1109/TRO.2012.2196309
   Chen MZ, 2021, TECHNOL FORECAST SOC, V164, DOI 10.1016/j.techfore.2020.120521
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Gil-Martín M, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106822
   Gualtieri L, 2021, ROBOT CIM-INT MANUF, V67, DOI 10.1016/j.rcim.2020.101998
   Ha J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125563
   Hasnain A, 2022, FRONT ENV SCI-SWITZ, V10, DOI 10.3389/fenvs.2022.945628
   Hu SJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P338, DOI 10.1109/ROBIO.2017.8324440
   Hussain A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3454167
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Jain A., 2016, ARXIV
   Jama M, 2011, J CONTROL SCI ENG, V2011, DOI 10.1155/2011/413074
   Khan IU, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22010323
   Kim JH, 2020, IEEE ACCESS, V8, P60179, DOI 10.1109/ACCESS.2020.2983427
   Kipper LM, 2021, TECHNOL SOC, V64, DOI 10.1016/j.techsoc.2020.101454
   Kose N, 2019, IEEE INT C INTELL TR, P3236, DOI 10.1109/ITSC.2019.8917460
   Kruijff GM, 2012, AAAI SPRING S DES IN
   Kumar P, 2021, RESOUR CONSERV RECY, V164, DOI 10.1016/j.resconrec.2020.105215
   Liang XW, 2015, IEEE T CONTR SYST T, V23, P2266, DOI 10.1109/TCST.2015.2411627
   Liu M, 2016, IEEE T CYBERNETICS, V46, P1217, DOI 10.1109/TCYB.2015.2430526
   Liu M, 2013, IEEE T ROBOT, V29, P1353, DOI 10.1109/TRO.2013.2272251
   Lu KY, 2015, SENSORS-BASEL, V15, P29594, DOI 10.3390/s151129594
   Ma CQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20040975
   Mahajan HB., 2018, INT J ADV SCI TECHNO, V2018, P37
   Mahajan HB., 2019, J ADV RES DYNAMICAL, V11, P1276, DOI [10.5373/JARDCS/V11I9/20193162, DOI 10.5373/JARDCS/V11I9/20193162]
   Mahajan HB., 2020, INT J ADV SCI TECHNO, V29, P214
   Mahajan HB, 2022, APPL NANOSCI, DOI 10.1007/s13204-021-02164-0
   Mahajan HB, 2021, WIRELESS PERS COMMUN, V121, P3125, DOI 10.1007/s11277-021-08866-6
   Mahajan HB, 2021, J AMB INTEL HUM COMP, V12, P7777, DOI 10.1007/s12652-020-02502-0
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Mikhail A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, CONTROL AND AUTOMATION (ICCUBEA)
   Ming Liu, 2011, 2011 IEEE International Conference on Robotics and Automation, P3269
   Momen S, 2016, 2016 2ND INTERNATIONAL SYMPOSIUM ON AGENT, MULTI-AGENT SYSTEMS AND ROBOTICS (ISAMSR), P73, DOI 10.1109/ISAMSR.2016.7810006
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Pavan A. H., 2022, Evolution in Signal Processing and Telecommunication Networks, P335, DOI [10.1007/978-981-16-8554-5_31, DOI 10.1007/978-981-16-8554-5_31]
   Ran LY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061341
   Ruiz-Sarmiento JR, 2017, INT J ROBOT RES, V36, P131, DOI 10.1177/0278364917695640
   Serpush Fatemeh, 2021, SN Comput Sci, V2, P94, DOI 10.1007/s42979-021-00484-0
   Seung-Hwan Lee, 2015, Journal of Automation and Control Engineering, V3, P368, DOI 10.12720/joace.3.5.368-372
   Shen H, 2016, 2016 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P349, DOI [10.1109/CTS.2016.67, 10.1109/CTS.2016.0069]
   Shi QHY, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00519-1
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tai L, 2016, ARXIV
   Tai L, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417703571
   Uke N., 2021, TURKISH J COMPUTER M, DOI [10.17762/turcomat.v12i11.5858, DOI 10.17762/TURCOMAT.V12I11.5858]
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Urban S, 2016, ARXIV
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wang HS, 2017, IEEE T IND ELECTRON, V64, P2893, DOI 10.1109/TIE.2016.2631514
   Werthen-Brabants L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08240-x
   Xia, 2015, INTELLIGENT MOBILE R
   Yoneda K, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY (IAT 2013), P216, DOI 10.1109/WI-IAT.2013.112
   Yong D, 2016, 2016 IEEE CHINESE GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC), P332, DOI 10.1109/CGNCC.2016.7828806
NR 70
TC 13
Z9 13
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23251
EP 23276
DI 10.1007/s11042-022-14253-5
EA NOV 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000884893500001
DA 2024-07-18
ER

PT J
AU Feng, Z
   Xie, JC
   Yan, ZW
   Mei, ZH
   Zheng, ZY
   Li, T
AF Feng, Zhao
   Xie, Jiacheng
   Yan, Zewen
   Mei, Zhenhuai
   Zheng, Ziying
   Li, Ting
TI An information processing method of software and hardware coupling for
   VR monitoring of hydraulic support groups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital twin; Hydraulic support; Virtual reality; Sensors; Information
   processing
ID DIGITAL TWINS; INTEROPERABILITY; INTEGRATION; PATHWAYS; POSTURE
AB The development of a digital twin virtual reality monitoring system for the hydraulic support group is the key to ensuring the safe and efficient operation of longwall mining face. Establishing a stable and reliable information processing channel to obtain information that is close to the actual working condition is an important link to ensure monitoring. Based on the prototype system of hydraulic support and the data of underground working conditions, an information interactive processing technology of software and hardware coupling is presented. The sensor's real-time data is filtered by hardware and denoised by software based on empirical mode decomposition to obtain the most accurate working condition data. Relevant experiments were carried out under the conditions of information channels with various software and hardware filtering configurations. Comprehensive experiments were conducted from three aspects: the absolute posture monitoring test of hydraulic support, the virtual posture monitoring under the undulating floor, and the real-time sensing data driving and control under the virtual reality environment. The experiments show that the hardware and software-coupled filtering method can obtain reliable attitude data in real-time and ensure the effectiveness of digital twin virtual monitoring and control, which can offer technical assistance for the condition monitoring of mechanical equipment under complex working conditions.
C1 [Feng, Zhao; Xie, Jiacheng; Yan, Zewen; Mei, Zhenhuai; Zheng, Ziying; Li, Ting] Taiyuan Univ Technol, Shanxi Key Lab Fully Mechanized Coal Min Equipmen, 216 Mailbox,HuYu Campus,18 XinKuangYuan Rd, Taiyuan 030024, Shanxi, Peoples R China.
   [Feng, Zhao; Xie, Jiacheng; Yan, Zewen; Mei, Zhenhuai; Zheng, Ziying; Li, Ting] Postdoctoral Res Workstn Taiyuan Min Machinery Gr, Taiyuan 030032, Peoples R China.
C3 Taiyuan University of Technology
RP Xie, JC (corresponding author), Taiyuan Univ Technol, Shanxi Key Lab Fully Mechanized Coal Min Equipmen, 216 Mailbox,HuYu Campus,18 XinKuangYuan Rd, Taiyuan 030024, Shanxi, Peoples R China.
EM xiejiacheng@tyut.edu.cn
RI Ting, Zhang/KGM-5479-2024; Li, Tingting/HKE-0812-2023
FU National Natural Science Foundation of China [52004174]; Major Science
   and Technology Projects in Shanxi Province [202101020101021]; Key
   project of the Chinese Society of Academic Degrees and Graduate
   Education; Central Government Guides Local Science and Technology
   Development Funds Projects [YDZJSX2022A014]; Fund for Shanxi "1331"
   Project; Scientific Research Planning for Higher Education in 2022
   [22SZH0306]
FX This work was supported by the National Natural Science Foundation of
   China [grant number 52004174], Major Science and Technology Projects in
   Shanxi Province [202101020101021], the Fund for Shanxi "1331" Project,
   Key project of the Chinese Society of Academic Degrees and Graduate
   Education [grant number 2020ZDA12], Scientific Research Planning for
   Higher Education in 2022 [grant number 22SZH0306], Central Government
   Guides Local Science and Technology Development Funds Projects
   [YDZJSX2022A014].
CR [Anonymous], 2010, AUSTR C ROB AUT ACRA
   Boloz L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207221
   [陈冬方 Chen Dongfang], 2016, [煤炭学报, Journal of China Coal Society], V41, P788
   Chen HY, 2022, MEASUREMENT, V187, DOI 10.1016/j.measurement.2021.110341
   [陈俊柏 Chen Junbai], 2021, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V47, P1687
   Farrelly CT, 2021, IEEE IND ELECTRON M, V15, P13, DOI 10.1109/MIE.2020.3029391
   Farrelly CT, 2021, IEEE IND ELECTRON M, V15, P22, DOI 10.1109/MIE.2020.3029388
   Gao KD, 2020, IEEE ACCESS, V8, P200789, DOI 10.1109/ACCESS.2020.3035576
   Garg H, 2022, MULTIMED TOOLS APPL, V81, P26873, DOI 10.1007/s11042-021-11578-5
   Ge X, 2020, MEASUREMENT, V158, DOI 10.1016/j.measurement.2020.107743
   Hu XP, 2020, INT J SIMUL MODEL, V19, P713, DOI 10.2507/IJSIMM19-4-CO20
   JANGWON SUH, 2019, [Journal of the Korean Society of Mineral and Energy Resources Engineers, 한국자원공학회지], V56, P468
   Jia PY, 2021, IEEE INTERNET THINGS, V8, P4548, DOI 10.1109/JIOT.2020.3029131
   [金江涛 Jin Jiangtao], 2021, [动力工程学报, Journal of Chinese Society of Power Engineering], V41, P214
   [李文华 Li Wenhua], 2021, [北京航空航天大学学报, Journal of Beijing University of Aeronautics and Astronautics], V47, P1927
   Li X, 2021, IEEE SYST J, V15, P114, DOI 10.1109/JSYST.2019.2958874
   Long Chen, 2021, 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), P469, DOI 10.1109/DTPI52967.2021.9540195
   Lu XL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195459
   Meng ZS, 2020, INT J SIMUL MODEL, V19, P399, DOI 10.2507/IJSIMM19-3-520
   Meng ZS, 2018, TEH VJESN, V25, P1110, DOI 10.17559/TV-20180306025203
   Ralston JC, 2017, INT J MIN SCI TECHNO, V27, P733, DOI 10.1016/j.ijmst.2017.07.027
   Ren P, 2019, INT J EMBED SYST, V11, P483
   Rozmus M, 2021, ENERGIES, V14, DOI 10.3390/en14092589
   Savolainen J, 2021, J INTELL MANUF, V32, P1953, DOI 10.1007/s10845-021-01740-z
   Semenov Y, 2020, E3S WEB CONF, V174, DOI 10.1051/e3sconf/202017401042
   Sengan S, 2022, MULTIMED TOOLS APPL, V81, P26839, DOI 10.1007/s11042-021-10842-y
   Suhua Li, 2021, International Journal of Coal Science & Technology, V8, P1149, DOI 10.1007/s40789-020-00389-y
   Toraño J, 2008, AUTOMAT CONSTR, V17, P413, DOI 10.1016/j.autcon.2007.07.001
   Wang BB, 2021, ARAB J SCI ENG, V46, P11739, DOI 10.1007/s13369-021-05689-2
   Wang X, 2021, J ENVIRON ENG GEOPH, V26, P99, DOI 10.32389/JEEG20-062
   Xie JC, 2022, ADV ENG INFORM, V53, DOI 10.1016/j.aei.2022.101694
   Xie JC, 2022, COMPUT IND ENG, V168, DOI 10.1016/j.cie.2022.108050
   Xie JC, 2022, INT J COAL SCI TECHN, V9, DOI 10.1007/s40789-022-00510-3
   Xie JC, 2019, P I MECH ENG C-J MEC, V233, P4805, DOI 10.1177/0954406219838574
   Xie JC, 2019, MIN TECHNOL, V128, P77, DOI 10.1080/25726668.2019.1569367
   Xu, 2017, KEY TECHNOLOGY RES H
   Yetkin ME, 2016, S AFR J IND ENG, V27, P162, DOI 10.7166/27-1-1366
   Yuan X, 2022, P I MECH ENG C-J MEC, V236, P8935, DOI 10.1177/09544062221091467
   Zhang, 2017, IND MINING AUTOM, V43, P65
   [张佳 Zhang Jia], 2020, [高压电器, High Voltage Apparatus], V56, P116
   Zhang Y, 2019, IEEE ACCESS, V7, P181842, DOI 10.1109/ACCESS.2019.2958981
   Zhou H, 2014, COMPUTER MODEL NEW T, V18, P82
NR 42
TC 2
Z9 2
U1 11
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 19067
EP 19089
DI 10.1007/s11042-022-14128-9
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000884893600001
DA 2024-07-18
ER

PT J
AU Cevik, T
   Cevik, N
   Zontul, M
AF Cevik, Taner
   Cevik, Nazife
   Zontul, Metin
TI A local-holistic graph-based descriptor for facial recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Graphs; Illumination; Noise; Facial expression
ID FACE RECOGNITION; EXPRESSION RECOGNITION; TEXTURE CLASSIFICATION;
   EIGENFACES
AB Face recognition remains critical and up-to-date due to its undeniable contribution to security. Many descriptors, the most vital figures used for face discrimination, have been proposed and continue to be done. This article presents a novel and highly discriminative identifier that can maintain high recognition performance, even under high noise, varying illumination, and expression exposure. By evolving the image into a graph, the feature set is extracted from the resulting graph rather than making inferences directly on the image pixels as done conventionally. The adjacency matrix is created at the outset by considering the pixels' adjacencies and their intensity values. Subsequently, the weighted-directed graph having vertices and edges denoting the pixels and adjacencies between them is formed. Moreover, the weights of the edges state the intensity differences between the adjacent pixels. Ultimately, information extraction is performed, which indicates the importance of each vertex in the graphic, expresses the importance of the pixels in the entire image, and forms the feature set of the face image. As evidenced by the extensive simulations performed, the proposed graphic-based identifier shows remarkable and competitive performance regarding recognition accuracy, even under extreme conditions such as high noise, variable expression, and illumination compared with the state-of-the-art face recognition methods.
C1 [Cevik, Taner] Istanbul Nisantasi Univ, Dept Comp Engn, Istanbul, Turkey.
   [Cevik, Nazife] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
   [Zontul, Metin] Istanbul Topkapi Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Nisantasi University; Istanbul Arel University; Istanbul
   Topkapi University
RP Cevik, T (corresponding author), Istanbul Nisantasi Univ, Dept Comp Engn, Istanbul, Turkey.
EM taner.cevik@nisantasi.edu.tr; nazifecevik@arel.edu.tr;
   metinzontul@topkapi.edu.tr
RI ÇEVİK, TANER/AAD-9997-2022
OI ÇEVİK, TANER/0000-0001-9653-5832
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2008, DATABASE FACES
   [Anonymous], 1990, Implementing Discrete Mathematics: Combinatorics and Graph Theory with Mathematica
   [Anonymous], 2007, Matrix algebra: theory, computations, and applications in statistics
   Barbu T, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/856876
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cevik N, 2019, PATTERN ANAL APPL, V23, P1, DOI DOI 10.1007/S10044-019-00803-5
   Cevik N, 2019, MULTIMED TOOLS APPL, V78, P15909, DOI 10.1007/s11042-018-6967-4
   Cevik N, 2019, IET IMAGE PROCESS, V13, P1097, DOI 10.1049/iet-ipr.2018.6423
   Cevik T, 2019, MULTIMED TOOLS APPL, V78, P26537, DOI 10.1007/s11042-019-07816-6
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Deng H, 2007, P INT JOINT C NEUR N
   Dubey SR, 2017, ARXIV
   Dwyer D. B., 2016, STRESS CONCEPTS COGN, P177
   Gao C, 2013, PHYSICA A, V392, P5490, DOI 10.1016/j.physa.2013.06.059
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hosseini H, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-15
   Islam M.S., 2014, TRENDS APPL SCI RES, V9, P113, DOI [10.3923/tasr.2014.113.120, DOI 10.3923/tasr.2014.113.120]
   Islam M.S., 2014, J. AI Data Min, V2, P33
   Jabid T., 2011, P INT C COMPUTER CON, P333
   Jabid T, 2010, IEEE ICCE
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Kepner J, 2011, SOFTW ENVIRON TOOLS, V22, P1, DOI 10.1137/1.9780898719918
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lezoray O., 2017, IMAGE PROCESSING ANA
   Li S.Z., 2005, Handbook of Face Recognition
   Liu J, 2016, PHYSICA A, V452, P209, DOI 10.1016/j.physa.2016.02.049
   Liu SS, 2014, CHIN CONTR CONF, P4664, DOI 10.1109/ChiCC.2014.6895725
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Melendez J, 2008, PATTERN ANAL APPL, V11, P365, DOI 10.1007/s10044-007-0097-3
   Mohammad T., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P572, DOI 10.1109/ICCITechn.2011.6164854
   Mulders PC., 2016, Systems Neuroscience in Depression, P209, DOI [10.1016/B978-0-12-802456-0.00007-8, DOI 10.1016/B978-0-12-802456-0.00007-8]
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Newman M.E., 2010, Networks: an introduction
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Qi XQ, 2012, INFORM SCIENCES, V194, P240, DOI 10.1016/j.ins.2011.12.027
   Saeidi N, 2019, J APPL SEC RES, V14, P169, DOI 10.1080/19361610.2019.1581877
   Songfan Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P866, DOI 10.1109/FG.2011.5771364
   Spacek D. L., 2008, COMPUTER VISION SCI
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Wang ZF, 2014, VISUAL COMPUT, V30, P359, DOI 10.1007/s00371-013-0861-x
   Xu Z, 2019, NEUROCOMPUTING, V355, P1, DOI 10.1016/j.neucom.2018.09.056
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yin QB, 2008, CHINESE J ELECTRON, V17, P646
   Yu H, 2013, ACTA PHYS SIN-CH ED, V62, DOI 10.7498/aps.62.020204
   Yu YF, 2017, PATTERN RECOGN, V67, P201, DOI 10.1016/j.patcog.2017.02.004
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zoppis I., 2019, ENCY BIOINFORMATICS, P495, DOI [10.1016/B978-0-12-809633-8.20341-5, DOI 10.1016/B978-0-12-809633-8.20341-5]
NR 62
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19275
EP 19298
DI 10.1007/s11042-022-14152-9
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000883287200005
DA 2024-07-18
ER

PT J
AU Sánchez-Caballero, A
   Fuentes-Jiménez, D
   Losada-Gutiérrez, C
AF Sanchez-Caballero, Adrian
   Fuentes-Jimenez, David
   Losada-Gutierrez, Cristina
TI Real-time human action recognition using raw depth video-based recurrent
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ConvLSTM; Action recognition; Depth maps; Video-surveillance
ID INFORMATION
AB This work proposes and compare two different approaches for real-time human action recognition (HAR) from raw depth video sequences. Both proposals are based on the convolutional long short-term memory unit, namely ConvLSTM, with differences in the architecture and the long-term learning. The former uses a video-length adaptive input data generator (stateless) whereas the latter explores the stateful ability of general recurrent neural networks but is applied in the particular case of HAR. This stateful property allows the model to accumulate discriminative patterns from previous frames without compromising computer memory. Furthermore, since the proposal uses only depth information, HAR is carried out preserving the privacy of people in the scene, since their identities can not be recognized. Both neural networks have been trained and tested using the large-scale NTU RGB+D dataset. Experimental results show that the proposed models achieve competitive recognition accuracies with lower computational cost compared with state-of-the-art methods and prove that, in the particular case of videos, the rarely-used stateful mode of recurrent neural networks significantly improves the accuracy obtained with the standard mode. The recognition accuracies obtained are 75.26% (CS) and 75.45% (CV) for the stateless model, with an average time consumption per video of 0.21 s, and 80.43% (CS) and 79.91%(CV) with 0.89 s for the stateful one.
C1 [Sanchez-Caballero, Adrian; Fuentes-Jimenez, David; Losada-Gutierrez, Cristina] Univ Alcala, Dept Elect, Ctra Madrid Barcelona,Km 33600, Alcala De Henares 28805, Spain.
C3 Universidad de Alcala
RP Losada-Gutiérrez, C (corresponding author), Univ Alcala, Dept Elect, Ctra Madrid Barcelona,Km 33600, Alcala De Henares 28805, Spain.
EM adrian.sanchez@uah.es; d.fuentes@edu.uah.es; cristina.losada@uah.es
RI Losada-Gutiérrez, Cristina/E-9306-2016
OI Losada-Gutiérrez, Cristina/0000-0001-9545-327X; Sanchez Caballero,
   Adrian/0000-0002-3395-7568; Fuentes Jimenez, David/0000-0001-6424-4782
FU Spanish Ministry of Science and Innovation [PID2020-113118RB-C31/C33];
   Community of Madrid [CM/JIN/2021-015]; University of Alcala under
   project ARGOS+ [PIUAH21/IA-016]
FX This work has been partially supported by the SpanishMinistry of Science
   and Innovation under projects EYEFUL (PID2020-113118RB-C31/C33), by the
   Community of Madrid under project CONCORDIA (CM/JIN/2021-015) and by the
   University of Alcala under project ARGOS+ (PIUAH21/IA-016)
CR [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   [Anonymous], 2015, PROC CVPR IEEE
   Babu RV, 2013, ENG APPL ARTIF INTEL, V26, P2010, DOI 10.1016/j.engappai.2013.07.008
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Breuel T. M., 2015, ARXIV
   Chen, 2022, IEEE SIGNAL PROC LET
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Günter A, 2020, INT CONF INTEL ENVIR, P1, DOI [10.1109/ie49459.2020.9154970, 10.1109/IE49459.2020.9154970]
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu YP, 2016, PATTERN RECOGN, V60, P215, DOI 10.1016/j.patcog.2016.05.010
   Huang M, 2018, NEUROCOMPUTING, V291, P84, DOI 10.1016/j.neucom.2018.02.056
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Katrompas Alexander, 2022, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys). Lecture Notes in Networks and Systems (294), P217, DOI 10.1007/978-3-030-82193-7_14
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Kingma D. P., 2014, arXiv
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Kong Y, 2017, INT J COMPUT VISION, V123, P350, DOI 10.1007/s11263-016-0982-6
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Liu JJ, 2020, NEUROCOMPUTING, V385, P22, DOI 10.1016/j.neucom.2019.11.048
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luo ZL, 2017, PROC CVPR IEEE, P7101, DOI 10.1109/CVPR.2017.751
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Park SU, 2016, PROCEDIA COMPUT SCI, V100, P78, DOI 10.1016/j.procs.2016.09.126
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sánchez-Caballero A, 2022, MULTIMED TOOLS APPL, V81, P24119, DOI 10.1007/s11042-022-12091-z
   Santofimia MJ, 2011, ENG APPL ARTIF INTEL, V24, P1432, DOI 10.1016/j.engappai.2011.05.008
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi XJ, 2015, ADV NEUR IN, V28
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh R, 2019, MULTIMED TOOLS APPL, V78, P30599, DOI 10.1007/s11042-018-6425-3
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Smith L. N., 2018, A disciplined approach to neural network hyper-parameters: Part 1 learning rate, batch size, momentum, and weight decay
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Song ZY, 2021, INT C PATT RECOG, P7087, DOI 10.1109/ICPR48806.2021.9412346
   Sugianto N, 2024, INFORM TECHNOL PEOPL, V37, P998, DOI 10.1108/ITP-07-2020-0534
   Sun YC, 2018, NEUROCOMPUTING, V297, P33, DOI 10.1016/j.neucom.2018.02.028
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tan ZC, 2018, ENG APPL ARTIF INTEL, V76, P214, DOI 10.1016/j.engappai.2018.08.009
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang L. Yu, 2019, arXiv
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang P., 2017, P IEEE C COMP VIS PA, P595
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2016, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2016.7899599
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wu H., 2019, INT J ADV ROBOT SYST, V16
   Wu HB, 2022, IEEE T CIRC SYST VID, V32, P1250, DOI [10.1109/TAI.2021.3092698, 10.1109/TCSVT.2021.3077512]
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Xu B., 2015, arXiv
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zheng ZX, 2019, NEUROCOMPUTING, V358, P446, DOI 10.1016/j.neucom.2019.05.058
   Zhu JG, 2019, NEUROCOMPUTING, V370, P109, DOI 10.1016/j.neucom.2019.08.043
NR 89
TC 7
Z9 7
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16213
EP 16235
DI 10.1007/s11042-022-14075-5
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000874425800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, DY
   Zhu, WJ
   Ding, X
   Yang, GB
   Li, F
   Deng, ZL
   Song, Y
AF Zhang, Dengyong
   Zhu, Wenjie
   Ding, Xianglinrg
   Yang, Gaobo
   Li, Feng
   Deng, Zelin
   Song, Yun
TI SRTNet: a spatial and residual based two-stream neural network for
   deepfakes detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deepfakes; CNN; Spatial domain; Residual domain
AB With the rapid development of Internet technology, the Internet is full of false information, and Deepfakes, as a kind of visual forgery content, brings the greatest impact to people. The existing mainstream Deepfakes public datasets often have millions of frames, and if the first N frames are used to train the model some key features may be lost. If all frames are used, the model is easily overfitted and training often takes several days, which greatly consumes computational resources. Therefore, we propose an adaptive video frame extraction algorithm to extract the required number of frames from all video frames. The algorithm is able to reduce data redundancy and increase feature richness. In addition, we design a two-stream Deepfakes detection network SRTNet by combining the image spatial domain and residual domain, which consists of spatial-stream and residual-stream. The spatial-stream uses the original RGB image as input to capture high-level tampering artifacts. Residual-stream uses three sets of high-pass filters to process the input image to obtain the image residuals to capture the tampering traces. Two-stream parallel training, and the features are concatenated to enable the model to capture tamper features from both spatial and residual domains to achieve better detection performance. The experimental results show that the proposed adaptive frame extraction algorithm can improve the model performance. And the proposed detection network SRTNet achieves better results than previous work on mainstream Deepfake dataset.
C1 [Zhang, Dengyong; Zhu, Wenjie; Li, Feng; Deng, Zelin; Song, Yun] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410004, Hunan, Peoples R China.
   [Zhang, Dengyong; Zhu, Wenjie; Li, Feng; Deng, Zelin; Song, Yun] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410004, Hunan, Peoples R China.
   [Ding, Xianglinrg] Hunan Univ Sci & Technol, Sch Comp & Commun Engn, Xiangtan 411201, Hunan, Peoples R China.
   [Ding, Xianglinrg] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Ding, Xianglinrg] Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 51000, Guangdong, Peoples R China.
   [Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology; Hunan University of Science & Technology; Chinese
   Academy of Sciences; Institute of Information Engineering, CAS; Hunan
   University
RP Ding, X (corresponding author), Hunan Univ Sci & Technol, Sch Comp & Commun Engn, Xiangtan 411201, Hunan, Peoples R China.; Ding, X (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Ding, X (corresponding author), Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 51000, Guangdong, Peoples R China.
EM zhdy@csust.edu.cn; wenjiezhu@stu.csust.edu.cn; xianglingding@163.com;
   yanggaobo@hnu.edu.cn; lif@csust.edu.cn; zl_deng@sina.com; sonie@126.com
RI Bueno, Regis Cortez/AAG-3852-2020
OI Bueno, Regis Cortez/0000-0002-2923-4930; ding,
   xiangling/0000-0002-6581-4633
FU National Natural Science Foundation of China [62172059, 62072055]; Hunan
   Provincial Natural Science Foundations of China [2020JJ4626,
   2020JJ4029]; Scientific Research Fund of Hunan Provincial Education
   Department of China [19B004, 16B004]; Opening Project of State Key
   Laboratory of Information Security [2021-ZD-07]; Opening Project of
   Guangdong Provincial Key Laboratory of Information Security Technology
   [2020B1212060078]; Postgraduate Scientific Research Innovation Project
   of Changsha University of Science and Technology [CX2021SS76]; "Double
   First-class" International Cooperation and Development Scientific
   Research Project of Changsha University of Science and Technology
   [2018IC25]
FX This project is supported in part by the National Natural Science
   Foundation of China under grant 62172059 and 62072055, Hunan Provincial
   Natural Science Foundations of China under Grant 2020JJ4626 and
   2020JJ4029, Scientific Research Fund of Hunan Provincial Education
   Department of China under Grant 19B004 and 16B004, the Opening Project
   of State Key Laboratory of Information Security under Grant 2021-ZD-07,
   the Opening Project of Guangdong Provincial Key Laboratory of
   Information Security Technology under Grant 2020B1212060078,
   Postgraduate Scientific Research Innovation Project of Changsha
   University of Science and Technology under Grant CX2021SS76, "Double
   First-class" International Cooperation and Development Scientific
   Research Project of Changsha University of Science and Technology under
   Grant 2018IC25.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Chen HN, 2020, IEEE T INF FOREN SEC, V15, P578, DOI 10.1109/TIFS.2019.2922241
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cozzolino D., 2018, ARXIV
   Cozzolino D, 2015, IEEE INT WORKS INFOR
   Deepfakes github, DEEPFAKES GITHUB
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fei JW, 2021, MULTIMED TOOLS APPL, V80, P30789, DOI 10.1007/s11042-020-09147-3
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gong CY, 2021, PROC CVPR IEEE, P1055, DOI 10.1109/CVPR46437.2021.00111
   Guo Z., 2020, arXiv
   Hu J, 2022, IEEE T CIRC SYST VID, V32, P1089, DOI 10.1109/TCSVT.2021.3074259
   Jin X, 2021, MULTIMED TOOLS APPL, P1
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P29303, DOI 10.1007/s11042-018-5959-8
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Kohli A, 2021, MULTIMED TOOLS APPL, V80, P18461, DOI 10.1007/s11042-020-10420-8
   Li HD, 2019, IEEE I CONF COMP VIS, P8300, DOI 10.1109/ICCV.2019.00839
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li Y., 2018, ARXIV
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li Yuezun, 2019, IEEE C COMPUTER VISI
   Trinh L, 2021, IEEE WINT CONF APPL, P1972, DOI 10.1109/WACV48630.2021.00202
   Loshchilov I, 2016, ARXIV
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen H, 2019, ARXIV
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Pan X, 2012, INT CONF E BUS ENG, P17, DOI 10.1109/ICEBE.2012.13
   Paszke A, 2019, ADV NEUR IN, V32
   Qian Y., 2020, EUROPEAN C COMPUTER, V12357, P86, DOI 10.1007/978-3- 030-58610-2 6
   Reinsel David., 2017, Don't Focus on Big Data, P2
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Shi XJ, 2015, ADV NEUR IN, V28
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tariq S, 2020, ARXIV
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tolosana Ruben, 2020, Information Fusion, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI [10.1109/icassp40776.2020.9053969, 10.1109/ICASSP40776.2020.9053969]
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
NR 44
TC 3
Z9 3
U1 4
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14859
EP 14877
DI 10.1007/s11042-022-13966-x
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865713700004
DA 2024-07-18
ER

PT J
AU Rehman, IU
   Ullah, S
   Khan, D
AF Rehman, Inam Ur
   Ullah, Sehat
   Khan, Dawar
TI FPSI-Fingertip pose and state-based natural interaction techniques in
   virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture-based interaction; Human-computer interaction; Desktop virtual
   reality; Leap motion controller
ID EGOCENTRIC NAVIGATION; GESTURE
AB Simple and natural interaction has a vital role in any realistic virtual environment (VE). This research proposes a set of lightweight gesture-based techniques for interaction in VEs with a focus on high accuracy, performance, and usability. The proposed techniques use a single fingertip pose and state for object/task selection, translation, navigation, rotation, and scaling. Four different techniques are proposed for interaction, i.e., MSGE (Menu-based task selection and gesture-based task execution), GSGE (Gesture-based task selection and gesture-based task execution), SGTE (Single gesture for task selection and execution), and TSGE (Time slice-based task selection and gesture-based task execution). Keeping in mind the concept of re-usability, the index-tip spatial position is used for task operation in all techniques. For experimental evaluation of the proposed techniques, a VE is designed in Unity3D, while interaction is carried out using the Leap Motion controller. The experimental study was conducted with forty (40) volunteer participants and two experts (authors). Experimental results show improved accuracy for TSGE (participants 97.22%, and experts 97.22%) as compared to others (participants: SGTE 95.55%, GSGE 94.44%, and MSGE 92.75%, experts: SGTE 94.44%, GSGE 94.44%, and MSGE 91.67%). Similarly, the results show high task performance for TSGE (participants 112.9 seconds, SD 5.3, experts 101.75 seconds, SD 3.3) as compared to others (participants: SGTE 117.2 seconds, SD 5.7, GSGE 121.8 seconds, SD 8.0, and MSGE 126.7 seconds, SD 12.9 and experts: SGTE 107.0, SD 5.7, GSGE 113.25, SD 3.5, and MSGE 122.0 seconds, SD 3.6). In addition, usability analysis shows high usability for the proposed interaction techniques, i.e., TSGE (SUS score 98.5), SGTE (SUS score 95.75), GSGE (SUS score 95.25), MSGE (SUS score 94.75). Furthermore, a comparative study with state-of-the-art interaction techniques showed a high accuracy rate, multiple tasks, and reusability support, use of easy to learn and use and fewer features-based gestures (fingertip gestures), and multiple interaction techniques (four techniques) support for the proposed techniques.
C1 [Rehman, Inam Ur; Ullah, Sehat] Univ Malakand, Dept CS & IT, Chakdara 18800, Khyber Pakhtunk, Pakistan.
   [Khan, Dawar] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Khan, Dawar] Univ Haripur, Dept Informat Technol, Haripur 22620, Khyber Pakhtunk, Pakistan.
C3 University of Malakand; Chinese Academy of Sciences; Shenzhen Institute
   of Advanced Technology, CAS
RP Rehman, IU (corresponding author), Univ Malakand, Dept CS & IT, Chakdara 18800, Khyber Pakhtunk, Pakistan.
EM inam.btk@gmail.com; sehatullah@uom.edu.pk; dawar.khan977@gmail.com
RI ullah, sehat/HTT-4581-2023
OI ullah, sehat/0000-0002-1193-9350; REHMAN, INAM UR/0000-0001-6625-6680;
   Khan, Dawar/0000-0001-5864-1888
CR Agarwal C, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P539, DOI 10.1109/ACPR.2015.7486561
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Barsanti SG, 2015, INT ARCH PHOTOGRAMM, V40-5, P165, DOI 10.5194/isprsarchives-XL-5-W7-165-2015
   Beattie N, 2015, PROC TECH, V20, P149, DOI 10.1016/j.protcy.2015.07.025
   Brooke J., 1996, USABILITY EVALUATION, P6
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Caggianese G, 2016, LECT NOTES COMPUT SC, V9769, P318, DOI 10.1007/978-3-319-40651-0_26
   Chan-Su Lee, 1999, Proceedings of International Conference on Virtual Systems and Multimedia VSMM '99, P361
   Chen Q, 2006, P 3 ANN SCI C LORNET
   Chifor M, 2015, ROCHI, P115
   Cisse Karim, 2020, 2020 IEEE S VISUAL L, P1, DOI DOI 10.1109/VL/HCC50065.2020.9127275
   Cohen J., 1988, STAT POWER ANAL BEHA
   de Paiva Batista Rui Miguel., 2016, Navigating Virtual Reality Worlds with Leap Motion Controller
   Dong YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3077967
   Hale K., 2015, HDB VIRTUAL ENV DESI
   Han Jihyun., 2014, LESSONS LEARNED EXPL
   Headleand CJ, 2016, STUD HEALTH TECHNOL, V220, P134, DOI 10.3233/978-1-61499-625-5-134
   Hernandez B, 2014, 2014 INT C COMPUTER, P1
   Hua J, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P254, DOI 10.1109/PCCGA.2001.962881
   Huang R., 2019, VIRTUAL REALITY INTE, V1, P1, DOI 10.3724/SP.J.2096-5796.2018.0007
   Ikram A, 2021, 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2021), P5, DOI 10.1109/ICVR51878.2021.9483844
   Juan W, 2021, J INTELL FUZZY SYST, V40, P7509, DOI 10.3233/JIFS-189572
   Katsuragawa K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P439, DOI 10.1145/3025171.3025234
   Kerefeyn S., 2015, INT J COMPUT SCI ISS, V12, P52
   Kharoub H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224861
   Khundam C, 2015, INT JOINT CONF COMP, P325, DOI 10.1109/JCSSE.2015.7219818
   Kim JS, 2000, IEEE SYS MAN CYBERN, P846, DOI 10.1109/ICSMC.2000.885955
   Kim K, 2015, SENSORS-BASEL, V15, P1022, DOI 10.3390/s150101022
   Kiyokawa M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P27
   Kommalapati R, 2016, IEEE ENG MED BIO, P5849, DOI 10.1109/EMBC.2016.7592058
   Kytö M, 2017, IEEE COMPUT GRAPH, V37, P70, DOI 10.1109/MCG.2015.117
   Lewis JR, 2017, J USABILITY STUD, V12, P73
   Lin W., 2017, Human-Computer Interaction. User Interface Design, V10271, P584, DOI [DOI 10.1007/978-3-319-58071-5_44, 10.1007/978-3-319-58071-5_44]
   Moore Alec G., 2015, 2015 IEEE S 3D USER, P205, DOI 10.1109/3DUI.2015.7131772
   Morse P, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Mousas C, 2017, COMPUT GRAPH-UK, V65, P1, DOI 10.1016/j.cag.2017.03.001
   Noor AK, 2015, ADV ENG SOFTW, V81, P1, DOI 10.1016/j.advengsoft.2014.10.004
   Oudah M, 2021, COMPUTERS, V10, DOI 10.3390/computers10010005
   Park KB, 2021, IEEE ACCESS, V9, P55448, DOI 10.1109/ACCESS.2021.3071364
   Raees M, 2019, INT J INTERACT MULTI, V5, P115, DOI 10.9781/ijimai.2019.01.002
   Raees M, 2019, INT J INTERACT DES M, V13, P35, DOI 10.1007/s12008-018-0481-9
   Raees M, 2018, INT J INTERACT MULTI, V5, P141, DOI 10.9781/ijimai.2018.08.002
   Rautaray SiddharthS., 2012, Int J UbiComp, V3, P21
   Rehman I, 2019, INT J INTERACT MULTI, V5, P128, DOI 10.9781/ijimai.2018.07.001
   Rehman IU, 2014, 2014 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P87, DOI 10.1109/ICOSST.2014.7029326
   Rehman IU, 2022, MULTIMED TOOLS APPL, V81, P1337, DOI 10.1007/s11042-021-11366-1
   Rehman IU, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9121986
   Rehman IU, 2020, INT J INTERACT MULTI, V6, P57, DOI 10.9781/ijimai.2020.11.002
   Rehman IU, 2014, LECT NOTES COMPUT SC, V8853, P53, DOI 10.1007/978-3-319-13969-2_4
   Rehman IU, 2016, SINDH U RES J SURJ S, V48
   Sampson H, 2018, INT CONF IMAG VIS
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Shao L., 2016, HAND MOVEMENT GESTUR
   Smith JW, 2021, IEEE ACCESS, V9, P10893, DOI 10.1109/ACCESS.2021.3051454
   VILLARREAL M, 2007, COMMONS WIKIMEDIA OR
   Wen F, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25637-w
   Wu HY, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0204-7
   Yang L., 2019, Virtual Real. Intell. Hardw, V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006, 10.3724/sp.j.2096-5796.2018.0006]
   Zhang Q, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012027
   Zhang Y, 2017, LECT NOTES COMPUT SC, V10324, P299, DOI 10.1007/978-3-319-60922-5_24
NR 60
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20711
EP 20740
DI 10.1007/s11042-022-13824-w
EA OCT 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000864966800004
DA 2024-07-18
ER

PT J
AU Fayaz, S
   Parah, SA
   Qureshi, GJ
AF Fayaz, Sheezan
   Parah, Shabir A.
   Qureshi, G. J.
TI Efficient underwater image restoration utilizing modified dark channel
   prior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Atmospheric light; Dark channel prior; Image restoration; Transmission
   map; Underwater dark channel prior
ID DE-SCATTERING; ENHANCEMENT; VISIBILITY; VISION; WEATHER
AB An effective algorithm called Modified Underwater Dark Channel Prior (MUWDCP) based on the image prior for haze removal in underwater images is proposed. The proposed algorithm computes underwater dark channel information using only blue-green channels exploiting the fact that red color due to low frequency undergoes high absorption and drops at about a depth of 3 m. To address the issue of atmospheric light estimation and enhance its robustness, we propose a novel global atmospheric light estimation method based on arithmetic Mode operation. MUWDCP does not rely only upon the bright pixels of the underwater dark channel for atmospheric light estimation instead, it computes global atmospheric light from the degraded image itself. Unlike most underwater image restoration methods, which estimate transmission maps of only one channel, MUWDCP estimates transmission of all three-color channels while maintaining less computational complexity. MUWDCP has been found to provide significantly improved visual quality of the restored underwater image. The proposed method has been evaluated using subjective and objective quality metrics like Entropy, Natural Image Quality Evaluator (NIQE), Underwater Color Image Quality Evaluation (UCIQE), and Underwater Image Quality Metrics (UIQM). The experimentation shows that MUWDCP performs better as compared to various state-of-the-art algorithms. The proposed algorithm proffers Entropy, NIQE, and UIQM scores of about 7.18, 2.88, and 4.57 respectively, which are better than the state-of-the-art. Thus, the results demonstrate the effectiveness of the proposed scheme.
C1 [Fayaz, Sheezan; Parah, Shabir A.] Univ Kashmir, Dept Elect & IT, Srinagar, India.
   [Qureshi, G. J.] Govt J & K, Higher Educ Dept, Jammu, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & IT, Srinagar, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912; Fayaz, Sheezan/0009-0002-9913-3753
CR Ahmad M, 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   [Anonymous], 2016, OCEANS 2016, DOI DOI 10.1109/OCEANSAP.2016.7485524
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   DUNTLEY SQ, 1957, J OPT SOC AM, V47, P499, DOI 10.1364/JOSA.47.000499
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fayaz S, 2021, IET IMAGE PROCESS, V15, P269, DOI 10.1049/ipr2.12041
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao YK, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043014
   Gao YK, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3141478
   He DM, 2004, OPT LASER ENG, V41, P217, DOI 10.1016/S0143-8166(02)00138-0
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hou GJ, 2020, MULTIMED TOOLS APPL, V79, P20199, DOI 10.1007/s11042-020-08759-z
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Huang SC, 2014, IEEE T INTELL TRANSP, V15, P2321, DOI 10.1109/TITS.2014.2314696
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jiang H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060945
   Levin A, 2006, PROC IEEE C COMPUTER
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2016, IEEE IMAGE PROC, P1993, DOI 10.1109/ICIP.2016.7532707
   Li CY, 2016, INT CONF ACOUST SPEE, P1731, DOI 10.1109/ICASSP.2016.7471973
   Li YJ, 2018, MOBILE NETW APPL, V23, P352, DOI 10.1007/s11036-017-0933-7
   Liu Chao, 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P35, DOI 10.1109/ICCET.2010.5485339
   Lu HM, 2017, STUD COMPUT INTELL, V672, P1, DOI 10.1007/978-3-319-46245-5_1
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Pan PW, 2019, FRONT INFORM TECH EL, V20, P862, DOI 10.1631/FITEE.1700744
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Sandbhor B., 2015, INT J ADV RES COMPUT, V5, P676
   Schechner Y. Y., 2004, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2004.1315078
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Sequeira G, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P427, DOI 10.1109/ESCI50559.2021.9397058
   Shen Y, 2015, REMOTE SENS-BASEL, V7, P11481, DOI 10.3390/rs70911481
   Singh D, 2017, IMAGING SCI J, V65, P282, DOI 10.1080/13682199.2017.1329792
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Song YF, 2022, PFG-J PHOTOGRAMM REM, V90, P243, DOI 10.1007/s41064-022-00206-y
   Sun LX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9100972
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Torres-Méndez LA, 2005, LECT NOTES COMPUT SC, V3757, P60, DOI 10.1007/11585978_5
   Wang N, 2017, IEEE ACCESS, V5, P18941, DOI 10.1109/ACCESS.2017.2753796
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
   Zomet A, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P27, DOI 10.1109/ACV.2002.1182150
NR 55
TC 3
Z9 3
U1 9
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14731
EP 14753
DI 10.1007/s11042-022-13828-6
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864589600003
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, P
   Jena, R
   Chakraborty, RS
AF Singh, Divakar
   Singh, Priyanka
   Jena, Riyanka
   Chakraborty, Rajat Subhra
TI An image forensic technique based on JPEG ghosts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery; JPEG compression; Quality; SSIM
ID EXPOSING DIGITAL FORGERIES
AB The unprecedented growth in the easy availability of photo-editing tools has endangered the power of digital images. An image was supposed to be worth more than a thousand words, but now this can be said only if it can be authenticated or the integrity of the image can be proved to be intact. In this paper, we propose a digital image forensic technique for JPEG images. It can detect any forgery in the image if the forged portion called a ghost image is having a compression quality different from that of the cover image. It is based on resaving the JPEG image at different JPEG qualities, and the detection of the forged portion is maximum when it is saved at the same JPEG quality as the cover image. Also, we can precisely predict the JPEG quality of the cover image by analyzing the similarity using Structural Similarity Index Measure (SSIM) or the energy of the images. The first maxima in SSIM or the first minima in energy correspond to the cover image JPEG quality. We created a dataset for varying JPEG compression qualities of the ghost and the cover images and validated the scalability of the experimental results. We also, experimented with varied attack scenarios, e.g. high-quality ghost image embedded in low quality of cover image, low-quality ghost image embedded in high-quality of cover image, and ghost image and cover image both at the same quality. The proposed method is able to localize the tampered portions accurately even for forgeries as small as 10 x 10 sized pixel blocks. Our technique is also robust against other attack scenarios like copy-move forgery, inserting text into image, rescaling (zoom-out/zoom-in) ghost image and then pasting on cover image.
C1 [Singh, Divakar] Indian Inst Technol Jammu, Jammu 181221, India.
   [Singh, Priyanka; Jena, Riyanka] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar 382004, Gujarat, India.
   [Chakraborty, Rajat Subhra] Indian Inst Technol Kharagpur, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) Jammu; Dhirubhai Ambani Institute of Information &
   Communication Technology; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur
RP Jena, R (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar 382004, Gujarat, India.
EM 2019pcs0020@iitjammu.ac.in; priyanka_singh@daiict.ac.in;
   201921012@daiict.ac.in; rschakraborty@cse.iitkgp.ac.in
RI singh, priyanka/JWP-2636-2024
OI SINGH, PRIYANKA/0000-0001-5002-8800
CR [Anonymous], 2017, IEEE INT WORKSHOP IN
   [Anonymous], 2017, FAKE NEWS ALERT 15 H
   Avcibas I, 2004, IEEE IMAGE PROC, P2645
   Azarian-Pour S, 2016, IRAN CONF ELECTR ENG, P1645, DOI 10.1109/IranianCEE.2016.7585785
   Bhardwaj D, 2018, SIGNAL PROCESS-IMAGE, V68, P155, DOI 10.1016/j.image.2018.07.011
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Express N, EXPRESS N I MALAYSIA
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Garcia L, 5 QUICK WAYS WE CAN
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hou JU, 2014, IEEE IMAGE PROC, P5287, DOI 10.1109/ICIP.2014.7026070
   Jarusek R, 2019, NEURAL NETWORKS, V116, P150, DOI 10.1016/j.neunet.2019.03.015
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Kumar S, 2023, MULTIMED TOOLS APPL, V82, P1431, DOI 10.1007/s11042-022-12391-4
   Kumawat C, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.116008
   Lukás J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Malathi J, 2019, J PHYS C SER
   Mullan P, 2019, DIGIT INVEST, V28, pS68, DOI 10.1016/j.diin.2019.01.016
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rahmati M, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103429
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Thai TH, 2017, IEEE T INF FOREN SEC, V12, P123, DOI 10.1109/TIFS.2016.2604208
   Wei XY, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101223
   Wu XT, 2020, MULTIMED TOOLS APPL, V79, P25657, DOI 10.1007/s11042-020-09253-2
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 33
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14153
EP 14169
DI 10.1007/s11042-022-13699-x
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219700001
PM 36196270
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Purohit, H
   Dadhich, M
   Ajmera, PK
AF Purohit, Himanshu
   Dadhich, Manish
   Ajmera, Pawan K.
TI Analytical study on users' awareness and acceptability towards adoption
   of multimodal biometrics (MMB) mechanism in online transactions: a
   two-stage SEM-ANN approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-model biometrics (MMB); Biometrics adoption (BA); Fusion; CFA; ANN
ID NEURAL NETWORK APPROACH; BEHAVIORAL BIOMETRICS; GREEN INITIATIVES;
   AUTHENTICATION; PERFORMANCE; TECHNOLOGY; DETERMINANTS; ACCEPTANCE;
   QUALITY; MANAGEMENT
AB The study analyses user awareness of multimodal biometrics and its acceptability for online transactions in the current dynamic world. The study was performed on the five underlying perspectives: User Acceptability, Cognizant Factors towards Biometrics, Technological factors, Perceptional Factors (Fingerprints, Iris, Face Recognition and Voice) and Data Privacy Factors. A questionnaire was prepared and circulated to the 530 biometrics users; on that basis, the corresponding answer was obtained for analysis. SEM is first employed to gauge the research model and test the prominent hypothesized predictors, which are then used as inputs in the neural network to evaluate the relative significance of each predictor variable. By considering the standardized significance of the feed-for-back-propagation of ANN algorithms, the study found a significant effect of DPF_3 (93%), DPF_2 (50%) and DPF_4 (34%) on the adoption of MMB. In the Perceptional construct, PRF_2 (49%) and PRF_3 (33%) was relatively the most important predictor, whereas, in User Acceptability, UAC_2 (37%), UAC_3 & UAC_5 (41%) was vital to be considered. Only one item, TCF_2 (35%), from Technological Factors, followed by Cognizant factors, i.e., CFG_1 (33%), confirmed the best fit model to adopt MMB. The research is a novel effort when compared to past studies as it considered cognizant and perceptual factors in the proposed model, thereby expanding the analytical outlook of MMB literature. Thus, the study also explored several new and valuable practical implications for adopting multimodal instruments of biometrics along with certain limitations.
C1 [Purohit, Himanshu; Ajmera, Pawan K.] Birla Inst Technol & Sci Pilani, EEE, Pilani, Rajasthan, India.
   [Dadhich, Manish] Sir Padampat Singhania Univ, SOM, Udaipur, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); Sir
   Padampat Singhania University
RP Purohit, H (corresponding author), Birla Inst Technol & Sci Pilani, EEE, Pilani, Rajasthan, India.
EM P2015502@pilani.bits-pilani.ac.in
RI purohit, himanshu/AAQ-4763-2021
OI purohit, himanshu/0000-0003-2193-2803
CR Abbas J, 2020, J CLEAN PROD, V244, DOI 10.1016/j.jclepro.2019.118806
   Abomhara M, 2021, TECHNOL SOC, V64, DOI 10.1016/j.techsoc.2020.101484
   Al-Ahmari AN, 2021, WORLD NEUROSURG, V146, pE811, DOI 10.1016/j.wneu.2020.11.015
   Anil AP, 2016, PROC TECH, V24, P554, DOI 10.1016/j.protcy.2016.05.103
   Arifin WN, 2016, SAGE OPEN, V6, DOI 10.1177/2158244016650240
   Asadi Z, 2020, EDUC INF TECHNOL, V25, P175, DOI 10.1007/s10639-019-09932-0
   Aslam F, 2021, J ECONOM ADM SCI, V37, P253, DOI 10.1108/JEAS-04-2020-0038
   Belhadi A, 2020, J CLEAN PROD, V252, DOI 10.1016/j.jclepro.2019.119903
   Bernard RM, 2014, J COMPUT HIGH EDUC, V26, P87, DOI 10.1007/s12528-013-9077-3
   Birda Kumar, 2019, ZENITH INT J MULTIDI, V9, P39
   Breitinger F, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101647
   Buckley O, 2019, J INF SECUR APPL, V47, P112, DOI 10.1016/j.jisa.2019.05.001
   Buriro A, 2019, J INF SECUR APPL, V44, P89, DOI 10.1016/j.jisa.2018.11.008
   Carrión-Ojeda D, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113967
   Chandra A, 2008, INT J PHARM HEALTHC, V2, P22, DOI 10.1108/17506120810865406
   Cherrat E, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.248
   Chong AYL, 2013, EXPERT SYST APPL, V40, P1240, DOI 10.1016/j.eswa.2012.08.067
   Choudhury SH, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107344
   Chowdary MK, 2019, INTELL DECIS TECHNOL, V13, P417, DOI 10.3233/IDT-190101
   Dadhich Manish, 2022, International Journal of Ambient Computing and Intelligence, P1, DOI 10.4018/IJACI.300798
   Dadhich Manish, 2022, Smart Health, DOI 10.1016/j.smhl.2022.100300
   Dadhich Manish, 2021, Advances in Mechanical Engineering. Select Proceedings of CAMSE 2020. Lecture Notes in Mechanical Engineering (LNME), P281, DOI 10.1007/978-981-16-0942-8_26
   Dadhich M, 2021, LIB PHILOS PRACT, V6281
   Dadhich M., 2017, ZENITH International Journal of Business Economics Management Research, V7, P20
   Dadhich M., 2018, INT J COMPUT SCI ENG, V06, P46, DOI [10.26438/ijcse/v6si9.4650, DOI 10.26438/IJCSE/V6SI9.4650]
   Dadhich M, 2022, J CLEAN PROD, V363, DOI 10.1016/j.jclepro.2022.132309
   Dadhich M, 2021, MATER TODAY-PROC, V46, P10870, DOI 10.1016/j.matpr.2021.01.889
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Dinh V.S., 2018, STRATEGIC DIRECTION, V34, P1
   Dubey R, 2015, INT J PROD ECON, V160, P120, DOI 10.1016/j.ijpe.2014.10.001
   Durdyev S, 2018, J CIV ENG MANAG, V24, P31, DOI 10.3846/jcem.2018.297
   Gad R, 2015, INT J ADV COMPUT SC, V6, P128
   Gokulkumari G, 2020, MULTIMED TOOLS APPL, V79, P31691, DOI 10.1007/s11042-020-09526-w
   Guan Y, 2014, IET BIOMETRICS, V3, P84, DOI 10.1049/iet-bmt.2013.0062
   Gupta G, 2023, GLOB BUS REV, V24, P860, DOI 10.1177/0972150920919880
   Gupta S, 2018, GLOB BUS REV, V19, P771, DOI 10.1177/0972150917713882
   Gutierrez A, 2015, J ENTERP INF MANAG, V28, P788, DOI 10.1108/JEIM-01-2015-0001
   Gyamfi NK, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P37, DOI 10.1109/IEMCON.2018.8614994
   Hair JF, 2010, Multivariate data analysis
   Heracleous L., 2006, Managing Service Q, V16, P12, DOI DOI 10.1108/09604520610639937
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ioannou A, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102122
   Jackson LA, 2009, INT J CONTEMP HOSP M, V21, P892, DOI 10.1108/09596110910985340
   Jagadiswary D, 2016, PROCEDIA COMPUT SCI, V85, P109, DOI 10.1016/j.procs.2016.05.187
   Joshi M, 2020, PATTERN RECOGN LETT, V138, P247, DOI 10.1016/j.patrec.2020.07.024
   Ju TL, 2006, TOTAL QUAL MANAG BUS, V17, P373, DOI 10.1080/14783360500451614
   Khan MHM, 2014, PROCEDIA COMPUT SCI, V32, P521, DOI 10.1016/j.procs.2014.05.456
   Khayer A, 2020, TECHNOL SOC, V60, DOI 10.1016/j.techsoc.2019.101225
   Königstorfer F, 2020, J BEHAV EXP FINANC, V27, DOI 10.1016/j.jbef.2020.100352
   Krishnakumar P, 2018, INTELL DECIS TECHNOL, V12, P265, DOI 10.3233/IDT-180332
   Kumar M., 2015, INT J MANAG IT ENG I, V5, P41
   Kumar N., 2014, EXCEL INT J MULTIDIS, V4, P103
   Kumar S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0224-1
   Leong LY, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.102047
   Liébana-Cabanillas F, 2018, TECHNOL FORECAST SOC, V129, P117, DOI 10.1016/j.techfore.2017.12.015
   Liébana-Cabanillas F, 2017, INT J INFORM MANAGE, V37, P14, DOI 10.1016/j.ijinfomgt.2016.10.008
   Liu Y, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2020.103369
   Mashelkar R.A., 2018, Review of Market Integration, V10, P138, DOI DOI 10.1177/0974929218774408
   Modisane P, 2021, PROCEDIA COMPUT SCI, V181, P784, DOI 10.1016/j.procs.2021.01.231
   Nappi M, 2018, IMAGE VISION COMPUT, V76, P27, DOI 10.1016/j.imavis.2018.05.001
   Noor AR, 2021, AQUACULT REP, V19, DOI 10.1016/j.aqrep.2020.100562
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Porwik P, 2021, ENG APPL ARTIF INTEL, V99, DOI 10.1016/j.engappai.2020.104135
   Psomas EL, 2016, INT J QUAL RELIAB MA, V33, P380, DOI 10.1108/IJQRM-07-2014-0090
   Purohit Himanshu, 2020, Modelling, Simulation and Intelligent Computing. Proceedings of MoSICom 2020. Lecture Notes in Electrical Engineering (LNEE 659), P345, DOI 10.1007/978-981-15-4775-1_37
   Purohit H, 2022, CLUSTER COMPUT, V25, P827, DOI 10.1007/s10586-021-03450-w
   Purohit H, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-020-01146-6
   Raut RD, 2018, TECHNOL FORECAST SOC, V134, P98, DOI 10.1016/j.techfore.2018.05.020
   Rogers EM, 2003, DIFFUSION INNOVATION
   Sadasivam G. S., 2016, International Journal of Big Data Intelligence, V3, P51, DOI [10.1504/IJBDI.2016.073895, DOI 10.1504/IJBDI.2016.073895]
   Sarier ND, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102243
   Singh GK., 2021, TURKISH J COMP MATH, V12, P22
   Sinha H, 2020, IET SIGNAL PROCESS, V14, P448, DOI 10.1049/iet-spr.2019.0381
   Sinha H, 2019, IET BIOMETRICS, V8, P259, DOI 10.1049/iet-bmt.2018.5081
   Sireesha V, 2018, INT J ENG RES TECHNO, V2, P3
   Siyal AW, 2019, DATA TECHNOL APPL, V53, P58, DOI 10.1108/DTA-04-2018-0022
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Stylios I, 2021, INFORM FUSION, V66, P76, DOI 10.1016/j.inffus.2020.08.021
   Teh PS, 2016, INT J PERVASIVE COMP, V12, P127, DOI 10.1108/IJPCC-01-2016-0005
   Timans W, 2016, TOTAL QUAL MANAG BUS, V27, P309, DOI 10.1080/14783363.2014.980140
   Tornatzky L.G., 1990, J. Technol. Transf, V16, P45, DOI [DOI 10.1007/BF02371446, 10.1007/BF02371446]
   Tortorella G, 2020, J MANUF TECHNOL MANA, V31, P524, DOI 10.1108/JMTM-05-2019-0200
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatraman Sitalakshmi, 2008, Information Management & Computer Security, V16, P415, DOI 10.1108/09685220810908813
   Vereycken AY, 2019, INT J HEALTH CARE Q, V32, P709, DOI 10.1108/IJHCQA-03-2018-0069
   Yacob P, 2019, J MANUF TECHNOL MANA, V30, P2, DOI 10.1108/JMTM-08-2017-0153
NR 89
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14239
EP 14263
DI 10.1007/s11042-022-13786-z
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859342300004
PM 36157357
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Girija, R
   Singh, H
   Abirami, G
AF Girija, R.
   Singh, H.
   Abirami, G.
TI Cryptanalysis of DRPE using complex S-Box based on linear canonical
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex S-Box; Nonlinearity; DRPE; Chosen plaintext analysis
ID OPTICAL-IMAGE ENCRYPTION; DISCRETE COSINE TRANSFORM; FRACTIONAL
   FOURIER-TRANSFORMS; CHOSEN-PLAINTEXT ATTACK; STRUCTURED PHASE MASKS;
   GYRATOR TRANSFORM; INTERFERENCE PRINCIPLE; ARNOLD TRANSFORM; HARTLEY
   DOMAIN; ALGORITHM
AB During recent decades, double random phase encoding grasped more attention for researchers. To achieve nonlinearity, it had been done with random S-Box. We exhibit this involvement that DRPE system is much vulnerable in the above methodology. Concatenating anything with DRPE needs an imaginary value, wherein S-Box unsuccessful in it. Used S-Box has been reformed into various sizes. Due to this scenario, S-Box values are replicating. So, complex S-Box has been employed and proposed size of the S-Box is similar to an input image. Numerical simulations such as performance analysis, histogram analysis and 3D plot analysis have been performed out to validate the practicability and trustworthiness of traditional DRPE system with complex S-Box. Moreover, in order to check the cryptanalysis, much other analysis done such as occlusion attack, noise attack, chosen plaintext analysis and sensitivity analysis also accomplished.
C1 [Girija, R.] Manav Rachna Univ, Dept Comp Sci & Technol, Faridabad, India.
   [Singh, H.] NorthCap Univ, Dept Appl Sci, Sect 23A, Gurugram, India.
   [Abirami, G.] SRMIST, Dept CTech, Kattankulathur, India.
C3 The Northcap University; SRM Institute of Science & Technology Chennai
RP Girija, R (corresponding author), Manav Rachna Univ, Dept Comp Sci & Technol, Faridabad, India.
EM Girija.srikanth09@gmail.com; hukumsingh@ncuindia.edu;
   abiramig@srmist.edu.in
OI GIRIJA, R/0000-0001-6635-7975
CR Abirami G, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107132
   Abirami G, 2019, INT CONF ADV COMPU, P372, DOI [10.1109/ICoAC48765.2019.246870, 10.1109/icoac48765.2019.246870]
   Abirami G., 2019, IJITEE, V8
   Abuturab MR, 2018, OPT LASER TECHNOL, V98, P298, DOI 10.1016/j.optlastec.2017.08.010
   Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Abuturab MR, 2012, OPT LASER ENG, V50, P1209, DOI 10.1016/j.optlaseng.2012.03.020
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Devaraj P, 2016, NONLINEAR DYNAM, V86, P927, DOI 10.1007/s11071-016-2934-7
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Farwa S, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0135-x
   Girija R, 2021, OPTIK, V244, DOI 10.1016/j.ijleo.2021.167568
   Girija R, 2020, MULTIMED TOOLS APPL, V79, P34717, DOI 10.1007/s11042-019-7733-y
   Girija R, 2019, OPTIK, V187, P238, DOI 10.1016/j.ijleo.2019.04.090
   Girija R., 2018, Procedia Computer Science, V132, P795, DOI 10.1016/j.procs.2018.05.091
   Girija R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0192-9
   Girija R, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0165-z
   Girija R, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1472-6
   Girija R, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES FOR SMART NATION (IC3TSN), P168, DOI 10.1109/IC3TSN.2017.8284470
   Girija R, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P199, DOI 10.1109/IC3I.2016.7917960
   Guo CL, 2016, APPL OPTICS, V55, P4720, DOI 10.1364/AO.55.004720
   Healy JJ, 2018, J OPTICS-UK, V20, DOI 10.1088/2040-8986/aa9e20
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hennelly BM, 2005, J OPT SOC AM A, V22, P928, DOI 10.1364/JOSAA.22.000928
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Hwang HE, 2006, J OPT SOC AM A, V23, P1870, DOI 10.1364/JOSAA.23.001870
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Javidi B, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/083001
   Kumar P, 2016, SPRINGER SER OPT SCI, V198, P367, DOI 10.1007/978-1-4939-3028-9_13
   Kumari E, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100009
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu ST, 2001, OPT COMMUN, V187, P57, DOI 10.1016/S0030-4018(00)01093-2
   Liu ST, 2001, OPT LETT, V26, P1242, DOI 10.1364/OL.26.001242
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Lu D, 2011, OPT ENG, V50, DOI 10.1117/1.3590724
   Maan P, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0205-8
   Matoba O, 1999, OPT LETT, V24, P762, DOI 10.1364/OL.24.000762
   Nishchal NK, 2003, OPT ENG, V42, P1583, DOI 10.1117/1.1570429
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Pei SC, 2016, IEEE T SIGNAL PROCES, V64, P855, DOI 10.1109/TSP.2015.2491891
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   Qin W, 2009, J OPT A-PURE APPL OP, V11, DOI 10.1088/1464-4258/11/7/075402
   Rajput SK, 2014, APPL OPTICS, V53, P418, DOI 10.1364/AO.53.000418
   Rakheja P, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106177
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rodrigo JA, 2007, OPT EXPRESS, V15, P2190, DOI 10.1364/OE.15.002190
   Singh H, 2015, OPT LASER ENG, V67, P145, DOI 10.1016/j.optlaseng.2014.10.011
   Singh H, 2014, APPL OPTICS, V53, P6472, DOI 10.1364/AO.53.006472
   Singh N, 2008, OPT LASER ENG, V46, P117, DOI 10.1016/j.optlaseng.2007.09.001
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Starchenko AP, 2011, J OPT TECHNOL+, V78, P176, DOI 10.1364/JOT.78.000176
   Sui LS, 2016, OPT EXPRESS, V24, P499, DOI 10.1364/OE.24.000499
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Unnikrishnan G, 2001, OPT COMMUN, V193, P51, DOI 10.1016/S0030-4018(01)01224-X
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang Q, 2013, APPL OPTICS, V52, P8854, DOI 10.1364/AO.52.008854
   Wang Q, 2013, APPL OPTICS, V52, P6849, DOI 10.1364/AO.52.006849
   Wei DY, 2016, J OPT SOC AM A, V33, P2470, DOI 10.1364/JOSAA.33.002470
   Wu JJ, 2015, OPT COMMUN, V338, P164, DOI 10.1016/j.optcom.2014.10.050
   Yadav PL, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0172-0
   Zamrani W, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103108
   Zhao JL, 2005, OPT COMMUN, V249, P493, DOI 10.1016/j.optcom.2005.01.037
   Zhao L, 2017, PROC SPIE, V10233, DOI 10.1117/12.2265863
   Zhao L, 2015, APPL OPTICS, V54, P9960, DOI 10.1364/AO.54.009960
NR 69
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12151
EP 12166
DI 10.1007/s11042-022-13752-9
EA SEP 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200027
DA 2024-07-18
ER

PT J
AU Gupta, V
   Bibhu, V
AF Gupta, Vimal
   Bibhu, Vimal
TI Deep residual network based brain tumor segmentation and detection with
   MRI using improved invasive bat algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Brain tumor detection; Data augmentation; Generative
   Adversarial Network (GAN); Magnetic resonance imaging (MRI)
ID CLASSIFICATION; DESIGN; FUSION
AB A brain tumor is the mass of abnormal and unnecessary cells growing in the brain and it is also considered a life-threatening disease. Hence, segmentation and detection of such tumors at an early stage with Magnetic Resonance Image (MRI) is more significant to save the life. MRI is very effective to find persons with brain cancer such that the detection rate of this modality is moderately higher rather than considering other imaging modalities. Due to the size, shape, and appearance variations, the detection of brain tumors is a major complex task in the system of medical imaging. Hence, an efficient brain tumor detection technique is designed using the proposed Improved Invasive Bat (IIB)-based Deep Residual network model. Accordingly, the proposed IIB algorithm is derived by incorporating the Improved Invasive Weed Optimization (IWO) and Bat algorithm (BA), respectively. The segmentation of tumors with MR images has a great impact on detecting the brain tumor at the beginning stage. The deep learning-based method effectively generated better detection results with MR images. With segmentation results, features are acquired from the tumor regions that are further used to make the detection process with the Deep Residual network. However, the proposed method achieved higher performance in terms of the measures, such as accuracy, sensitivity, and specificity by computing the values of 0.9256, 0.9003, and 0.9146, respectively.
C1 [Gupta, Vimal] JSS Acad Tech Educ, Comp Sci & Engn, C-20-1,Sect 62, Noida 201301, Uttar Pradesh, India.
   [Bibhu, Vimal] Amity Univ, Comp Sci & Engn, Plot 48 A,Knowledge Pk 3, Greater Noida 201308, Uttar Pradesh, India.
RP Gupta, V (corresponding author), JSS Acad Tech Educ, Comp Sci & Engn, C-20-1,Sect 62, Noida 201301, Uttar Pradesh, India.
EM vimalgupta09@gmail.com; drvimal@gn.amity.edu
OI /0000-0003-0482-0295; Bibhu, Vimal/0000-0003-4456-0512
CR Abdel-Gawad AH, 2020, IEEE ACCESS, V8, P136243, DOI 10.1109/ACCESS.2020.3009898
   Alboliras E. T., 2018, VISUAL GUIDE NEONATA
   Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   Amin J, 2020, NEURAL COMPUT APPL, V32, P15965, DOI 10.1007/s00521-019-04650-7
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   BRATS, 2021, BRATS DAT WAS TAK
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chen ZC, 2019, ENERG CONVERS MANAGE, V198, DOI 10.1016/j.enconman.2019.111793
   Dolz J, 2016, INT J COMPUT ASS RAD, V11, P43, DOI 10.1007/s11548-015-1266-2
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Ebrahimzadeh R., 2014, International Journal of Computer Applications, V104
   Figshare, 2021, FIGS DAT WAS TAK
   Gokulkumari G., 2020, MULTIMED RES, V3, P32
   Gopal A, 2020, MULTIMEDIA RES MR
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Kumar DM, 2021, J AMB INTEL HUM COMP, V12, P2867, DOI 10.1007/s12652-020-02444-7
   Laur O, 2022, SKELETAL RADIOL, V51, P257, DOI 10.1007/s00256-021-03824-6
   Misaghi M, 2019, J COMPUT DES ENG, V6, P284, DOI 10.1016/j.jcde.2019.01.001
   Ranschaert ER, 2019, Artificial Intelligence in Medical imaging: opportunities, Applications and Risks, DOI DOI 10.1007/978-3-319-94878-2_4
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Tanzi L, 2021, INT J COMPUT ASS RAD, V16, P1435, DOI 10.1007/s11548-021-02432-y
   Tanzi L, 2020, EUR J RADIOL, V133, DOI 10.1016/j.ejrad.2020.109373
   Tirupattur P, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P950, DOI 10.1145/3240508.3240641
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Tsolaki E, 2015, INT J COMPUT ASS RAD, V10, P1149, DOI 10.1007/s11548-014-1088-7
   Wang WG, 2020, IEEE ACCESS, V8, P152659, DOI 10.1109/ACCESS.2020.3016282
   Windisch P, 2020, NEURORADIOLOGY, V62, P1515, DOI 10.1007/s00234-020-02465-1
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
NR 30
TC 4
Z9 5
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12445
EP 12467
DI 10.1007/s11042-022-13769-0
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000003
DA 2024-07-18
ER

PT J
AU Ahmed, N
   Tan, X
   Ma, LZ
AF Ahmed, Noor
   Tan, Xin
   Ma, Lizhuang
TI A new method proposed to Melanoma-skin cancer lesion detection and
   segmentation based on hybrid convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lesion; Hybrid deep learning method; Skin lesions; Detection;
   Segmentation; Skin cancer; Melanoma
ID DEEP; CLASSIFICATION; DERMATOLOGISTS; ACCURATE; IMAGES; CNN
AB The number of deaths due to melanoma skin cancer has rapidly increased in recent years. The timely diagnosis of the lesions of melanoma skin cancer can potentially increase the survival rate of such a chronic disease. However, the detection of these lesions is a challenging task, especially in the presence of occlusions, such as clinical artifacts, blood vessels, and color contrast variation, etc. The current state-of-the-art detection and segmentation methods are based on fully convolutional neural networks, which utilize an encoder-decoder method. However, these methods produce coarse segmentation masks due to the loss of location information during the encoding layers. To overcome these challenges, this study proposes a highly effective Hybrid detection and segmentation method based on the integration of RetinaNet and MaskRCNN, which utilizes a pyramid module of lateral connections and top-down paths to compensate for the loss of spatial features information. The proposed method is trained and validated on Melanoma-ISIC-2018 and PH2 datasets. Experiment results on the unseen PH2 dataset illustrate the improved generalization ability of the method. The efficacy with other methods such as Encoder-Decoder, Generative Adversarial Network(GAN), UNet Deep Convolutional Neural Network-support vector machine(DCNN-SVM), Encoder-Fully Connected Network(EFCN), Enhanced Convolutional-Deconvolutional Networks(ECDNs), UNet, and Handcrafted has also been compared. The results, show that the proposed method outperforms above methods by 7.7%, 12.9%, 11.4%, 14.4%, 14.9%, 18.6%, 25.1%, respectively, in terms of accuracy. It is envisaged that with reliable accuracy, this method can be introduced for clinical practices in the future.
C1 [Ahmed, Noor; Tan, Xin; Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Ahmed, Noor; Tan, Xin; Ma, Lizhuang] Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, Shanghai, Peoples R China.
   [Ma, Lizhuang] East China Normal Univ, Sch Comp Sci Technol, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; East China
   Normal University
RP Ahmed, N (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.; Ahmed, N (corresponding author), Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, Shanghai, Peoples R China.
EM noorahmedakbar2016@yahoo.com; ma-lz@cs.sjtu.edu.cn
RI Li, Shiyu/KHE-1376-2024; Tan, Xin/GRJ-0367-2022; Sun, Peng/KDO-4243-2024
OI Tan, Xin/0000-0001-9346-1196; 
FU Shanghai Jiao Tong University [ZH2018ZDA25]; Shanghai Municipal Science,
   Technology Major Project [2021SHZDZX0102]; Shanghai Science and
   Technology Commission [21511101200]
FX We would thank the anonymous reviewers for their constructive
   suggestions and insightful comments. This work is partially supported by
   Shanghai Jiao Tong University (ZH2018ZDA25), Shanghai Municipal Science,
   Technology Major Project (2021SHZDZX0102), and Shanghai Science and
   Technology Commission (21511101200).
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   Al Nazi Z., 2020, PROC INT JOINT C COM, P371, DOI DOI 10.1007/978-981-13-7564-4_32
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bissoto A., 2018, ARXIV
   Brinker TJ, 2019, EUR J CANCER, V119, P11, DOI 10.1016/j.ejca.2019.05.023
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479
   Codella Noel, 2019, arXiv
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan CJ, 2022, IEEE T INTELL TRANSP, V23, P13559, DOI 10.1109/TITS.2021.3125737
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fu C, 2019, ARXIV
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Haenssle H A, 2019, Ann Oncol, V30, p130e, DOI 10.1093/annonc/mdy520
   Hardie RC, 2018, ARXIV
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Johnson JW, 2018, ARXIV
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   MILLER M, 1992, ARCH DERMATOL, V128, P559, DOI 10.1001/archderm.128.4.559
   Naqvi S, 2014, IEEE INT FUZZY SYST, P834, DOI 10.1109/FUZZ-IEEE.2014.6891831
   Nida N, 2019, INT J MED INFORM, V124, P37, DOI 10.1016/j.ijmedinf.2019.01.005
   Ninh QC, 2019, PROCEEDINGS OF 2019 6TH NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT (NAFOSTED) CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P575, DOI [10.1109/nics48868.2019.9023862, 10.1109/NICS48868.2019.9023862]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shahin AH, 2019, ARXIV
   Tan X, 2021, IEEE T IMAGE PROCESS, V30, P9085, DOI 10.1109/TIP.2021.3122004
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tschandl P, 2019, COMPUT BIOL MED, V104, P111, DOI 10.1016/j.compbiomed.2018.11.010
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vesal S, 2018, LECT NOTES COMPUT SC, V11041, P285, DOI 10.1007/978-3-030-01201-4_31
   Waleed A, 2017, GITHUB REPOSITORY
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Wolterink JM, 2016, MED IMAGE ANAL, V34, P123, DOI 10.1016/j.media.2016.04.004
   Wyant T, MELANOMA SURVIVAL RA
   Xue Y, 2017, ARXIV
   Xue Y, 2018, I S BIOMED IMAGING, P859, DOI 10.1109/ISBI.2018.8363707
   Yang RX, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.638182
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yuan YD, 2019, IEEE J BIOMED HEALTH, V23, P519, DOI 10.1109/JBHI.2017.2787487
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zheng QH, 2018, IEEE ACCESS, V6, P15844, DOI 10.1109/ACCESS.2018.2810849
   Zheng XY, 2021, IEEE T CIRC SYST VID, V31, P4370, DOI 10.1109/TCSVT.2021.3049408
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 52
TC 5
Z9 5
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11873
EP 11896
DI 10.1007/s11042-022-13618-0
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000852127600005
DA 2024-07-18
ER

PT J
AU Battistin, T
   Dalla Pozza, N
   Trentin, S
   Volpin, G
   Franceschini, A
   Rodà, A
AF Battistin, Tiziana
   Dalla Pozza, Nadir
   Trentin, Silvia
   Volpin, Giovanni
   Franceschini, Andrea
   Roda, Antonio
TI Co-designed mini-games for children with visual impairment: a pilot
   study on their usability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serious games; Large scale interactive environment; Children with visual
   impairment; Human-computer interaction
ID PEOPLE; SUS
AB Digital games aimed at improving cognitive and/or motor-sensory skills need to be carefully designed to take into account the characteristics and needs of particular categories of users. Several novel mini-games explicitly aimed at children with visual impairment (VI) were co-designed by a multidisciplinary team which involved computer engineers and a therapy team from the Robert Hollman Foundation (Padova, Italy). These games are played by children moving within a large-scale interactive environment - i.e., a floor portion placed under a motion capture system capable of tracking one or more people - with the game linking the players movements to the audio and visual output to produce meaningful interactions. We report on a pilot study of the usability of the system involving 11 children with VI. The results allowed us to improve the system and to define a set of guidelines useful for designers and developers of similar systems.
C1 [Battistin, Tiziana; Trentin, Silvia] Robert Hollman Fdn, Via Siena 1, I-35143 Padua, Italy.
   [Battistin, Tiziana] Univ Ferrara, Dept Neurosci & Rehabil, Via L Borsari 46, I-44121 Ferrara, Italy.
   [Dalla Pozza, Nadir; Volpin, Giovanni; Roda, Antonio] Univ Padua, Dept Informat Engn, Via Gradenigo 6b, I-35131 Padua, Italy.
   [Franceschini, Andrea] Univ Cambridge, Dept Comp Sci & Technol, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
C3 University of Ferrara; University of Padua; University of Cambridge
RP Rodà, A (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6b, I-35131 Padua, Italy.
EM btttzn@unife.it; dallapozza@dei.unipd.it;
   s.trentin@fondazioneroberthollman.it; giovanni.volpin@studenti.unipd.it;
   andrea.franceschini@cst.cam.ac.uk; roda@dei.unipd.it
RI Franceschini, Andrea/HTN-2302-2023
OI Franceschini, Andrea/0000-0001-8665-6147; Battistin,
   Tiziana/0000-0001-5712-7692
FU Universita degli Studi di Padova within the CRUI-CARE Agreement; Veneto
   Region [2105-0016-1463-2019, 2105-0051-1463-2019]
FX Open access funding provided by Universita degli Studi di Padova within
   the CRUI-CARE Agreement. Nadir Dalla Pozza was partially funded by a
   grant by the Veneto Region, project number 2105-0016-1463-2019. Andrea
   Franceschini was partially funded by a grant by the Veneto Region,
   project number 2105-0051-1463-2019. No further funding was received for
   conducting this study.
CR AITKEN RCB, 1969, P ROY SOC MED, V62, P989, DOI 10.1177/003591576906201005
   Archambault D, 2004, LECT NOTES COMPUT SC, V3118, P248
   Archambault D., 2007, DIGITAL J CEPIS, P43
   Archambault D, 2005, COMPUTER GAMES THAT, V165
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Brown T, 2009, BUS WEEK, P54
   Cappagli G., 2019, Visual Impairment and Blindness-What We Know and What We Have to Know, DOI [10.5772/intechopen.89273, DOI 10.5772/INTECHOPEN.89273]
   Ciman Matteo, 2013, WEBIST 2013. 9th International Conference on Web Information Systems and Technologies. Proceedings, P257
   De Bortoli A., 2011, 2011 IEEE 1st Int. Conf. Serious Games Appl. Heal, P1
   de Oliveira PA, 2016, BRAZIL SYMP GAME DIG, P135, DOI 10.1109/SBGames.2015.26
   Goodman-Deane J, 2013, CONTEMPORARY ERGONOMICS AND HUMAN FACTORS 2013, P347
   KESTENBERG JS, 1979, PSYCHOANAL QUART, V48, P493, DOI 10.1080/21674086.1979.11926889
   Leo F, 2017, IEEE T NEUR SYS REH, V25, P861, DOI 10.1109/TNSRE.2016.2619742
   Mahmud S, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P768, DOI [10.1109/CCWC47524.2020.9031244, 10.1109/ccwc47524.2020.9031244]
   Mandanici Marcella, 2018, Smart Objects and Technologies for Social Good. Third International Conference, GOODTECHS 2017. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 233), P11, DOI 10.1007/978-3-319-76111-4_2
   Mandanici M, 2014, INTERACTIVE ED ENV D, P1766
   Mandanici M, 2015, HARMONIC WALK ENACTI, P221
   Mandanici M, 2018, BRIT J EDUC TECHNOL, V49, P620, DOI 10.1111/bjet.12630
   Mandanici M, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/4027164
   Mandanici Marcella, 2020, Technological Trends in Improved Mobility of the Visually Impaired, P301, DOI DOI 10.1007/978-3-030-16450-8_12
   Mekhalfi ML, 2016, EXPERT SYST APPL, V46, P129, DOI 10.1016/j.eswa.2015.09.054
   Melthis J, 2015, I C DEV ESYST ENG, P165, DOI 10.1109/DeSE.2015.65
   Morelli F, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00768
   Omelina L., 2012, P 9 INT C DISABILITY, P195
   Purpura G, 2020, CHILD NERV SYST, V36, P911, DOI 10.1007/s00381-020-04554-1
   Rego P, 2010, SISTEMAS Y TECNOLOGIAS DE INFORMACION, P349
   Roda Antonio, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P175, DOI 10.1145/3462203.3475923
   Torres-Carazo MI, 2016, IEEE INT CONF SERIOU
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
NR 31
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5291
EP 5313
DI 10.1007/s11042-022-13665-7
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000852127600003
PM 36105660
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Amini, SM
AF Amini, Seyedeh Moloud
TI Head circumference measurement with deep learning approach based on
   multi-scale ultrasound images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Ultrasound Imaging; Image segmentation; Medical imaging;
   Fetal Head Segmentation
ID FETAL; SEGMENTATION
AB Checking up on the health of the fetus during pregnancy is an important issue that should be taken into account. Ultrasound imaging, as one useful medical imaging technique, helps specialists to monitor and diagnose the natural fetal growth process. Head Circumference (HC) measurement is considered as one of the remarkable criteria in fetus health assessment. In this study, I proposed a model to automatically extract the fetal head parameters based on three main phases, including pm-processing, fetal head extraction, and post-processing. In the fetal head extraction phase, I suggested a deep learning-based network based on multi-scale ultrasound images to diagnose and segment the fetal head using a loss function L-DeepLinkNet weights the fetal head border pixels during algorithm learning to improve the performance of fetal head parameter extraction methods by reducing the number of required parameters and training time. According to experimental results, the accuracy of segmentation and the power of network training have significantly increased, which leads my proposed method has better performance in terms of two evaluation criteria for HC measurement such as Hausdorff, and the absolute difference compared to other previous methods, and better efficiency than the Link-Net model in all criteria due to multi-scalability and fewer network layers.
C1 [Amini, Seyedeh Moloud] Waterloo Univ, Dept Elect & Comp Engn, Waterloo, ON, Canada.
C3 University of Waterloo
RP Amini, SM (corresponding author), Waterloo Univ, Dept Elect & Comp Engn, Waterloo, ON, Canada.
EM moloud.amini@uwaterloo.ca
CR Amin J, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1453-8
   Cerrolaza JJ, 2018, LECT NOTES COMPUT SC, V11070, P383, DOI 10.1007/978-3-030-00928-1_44
   Cerrolaza JJ, 2018, I S BIOMED IMAGING, P564, DOI 10.1109/ISBI.2018.8363639
   Cerrolaza JJ, 2017, LECT NOTES COMPUT SC, V10554, P25, DOI 10.1007/978-3-319-67561-9_3
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen HC, 2012, ULTRASOUND MED BIOL, V38, P811, DOI 10.1016/j.ultrasmedbio.2012.01.025
   Chen KT, 2021, Arxiv, DOI arXiv:2107.04191
   Emami A., 2020, 2020 25 INT COMP C C, P1
   Feng S, 2012, AUTOMATIC FETAL WEIG
   Gomez A, 2017, LECT NOTES COMPUT SC, V10554, P33, DOI 10.1007/978-3-319-67561-9_4
   Jardim SMGVB, 2005, ULTRASOUND MED BIOL, V31, P243, DOI 10.1016/j.ultrasmedbio.2004.11.003
   Kim HP, 2019, PHYSIOL MEAS, V40, DOI 10.1088/1361-6579/ab21ac
   Li J, 2018, IEEE J BIOMED HEALTH, V22, P215, DOI 10.1109/JBHI.2017.2703890
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Loughna P, 2009, ULTRASOUND, V17, P160, DOI 10.1179/174313409X448543
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Namburete AIL, 2018, MED IMAGE ANAL, V46, P1, DOI 10.1016/j.media.2018.02.006
   Namburete AIL, 2015, MED IMAGE ANAL, V21, P72, DOI 10.1016/j.media.2014.12.006
   Perez-Gonzalez JL, 2014, IFMBE PROC, V49, P329, DOI 10.1007/978-3-319-13117-7_85
   Ponomarev GV, 2012, P CHALLENGE US BIOME
   Rafiei S, 2018, 2018 25 IEEE INT C I
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rueda S, 2014, IEEE T MED IMAGING, V33, P797, DOI 10.1109/TMI.2013.2276943
   Schmidt U, 2014, EUR J OBSTET GYN R B, V178, P153, DOI 10.1016/j.ejogrb.2014.03.047
   Shrimali V, 2009, IEEE ENG MED BIO, P459, DOI 10.1109/IEMBS.2009.5334470
   Sobhaninia Z, 2018, Arxiv, DOI arXiv:1809.07786
   Sobhaninia Z, 2020, Arxiv, DOI arXiv:2002.01975
   Sobhaninia Z, 2019, IEEE ENG MED BIO, P6545, DOI [10.1109/EMBC.2019.8856981, 10.1109/embc.2019.8856981]
   Torrents-Barrena J, 2019, MED IMAGE ANAL, V51, P61, DOI 10.1016/j.media.2018.10.003
   van den Heuvel TLA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200412
   Wang J, 2021, MOBILE NETW APPL, V26, P351, DOI 10.1007/s11036-020-01672-7
   Wu LY, 2017, I S BIOMED IMAGING, P663, DOI 10.1109/ISBI.2017.7950607
   Yang X, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105519
   Zeng Y, 2021, J DIGIT IMAGING, V34, P134, DOI 10.1007/s10278-020-00410-5
   Zhang J, 2020, Medical Imaging with Deep Learning
NR 35
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32981
EP 32993
DI 10.1007/s11042-022-13107-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000843962500014
DA 2024-07-18
ER

PT J
AU Rehman, GU
   Ul Haq, MI
   Zubair, M
   Mahmood, Z
   Singh, M
   Singh, D
AF Rehman, Ghani Ur
   Ul Haq, Muhammad Inam
   Zubair, Muhammad
   Mahmood, Zafar
   Singh, Madhusudan
   Singh, Dhananjay
TI Misbehavior of nodes in IoT based vehicular delay tolerant networks
   VDTNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Smart selection routing; Node misbehavior; Vehicle
   delay tolerant networks; Selfishness; Data replication
ID EFFICIENT; PROTOCOL
AB Various Internet of Things (IoT) applications are based and deployed on unstable wireless networks like the Delay Tolerant Network (DTN). But effective DTN data transmission seems to be an important concern for IoT applications. Vehicular Delay Tolerant Network (VDTN) is also one of the DTN application areas. Despite communication problems, VDTNs' consist of mobile devices that communicate wirelessly with one another to transmit data. This article highlights the issue of certain nodes that tend to disrupt a VDTN's connection. The case of nodes that interrupt the transmission of messages, which is an immensely challenging type of misconduct to recognize, is described in the article. We investigate the influence of this type of misconduct on nine VDTN routing algorithms using two different types of scenarios as well as a wide range of simulations. The outcomes indicate that focusing on the form of inappropriate behavior, duplication of messages, and smart selection of a next-hop can assist routing methods to be resistant to misconduct by nodes.
C1 [Rehman, Ghani Ur; Ul Haq, Muhammad Inam; Zubair, Muhammad] Khushal Khan Khattak Univ, Dept Comp Sci & Bioinformat, Karak, Pakistan.
   [Mahmood, Zafar] Univ Gujrat, Dept Comp Sci, Gujrat, Pakistan.
   [Singh, Madhusudan] Woosong Univ, Endicott Coll Int Studies, Daejeon 300718, South Korea.
   [Singh, Dhananjay] Hankuk Univ Foreign Studies, Dept Elect Engn, Yongin 449791, South Korea.
C3 University of Gujrat; Woosong University; Hankuk University Foreign
   Studies
RP Singh, D (corresponding author), Hankuk Univ Foreign Studies, Dept Elect Engn, Yongin 449791, South Korea.
EM ghani.rehman@kkkuk.edu.pk; muhammad.inamulhaq@kkkuk.edu.pk;
   dr.muhammadzubair@kkkuk.edu.pk; zafar.mehmood@uog.edu.pk;
   msingh@wsu.ac.kr; dan.usn@ieee.org
RI rehman, ghani/AAS-3019-2021; Singh, Madhusudan/I-4513-2016; Singh, Dr.
   Madhusudan/HKN-9133-2023; Singh, Dhananjay/ABA-9824-2020
OI rehman, ghani/0000-0003-2944-4740; Singh,
   Madhusudan/0000-0001-6913-5200; Singh, Dhananjay/0000-0003-3822-9348;
   INAM UL HAQ, Muhammad/0000-0001-9275-8318; Zubair,
   Muhammad/0000-0001-6723-5486
CR Ahmed SH, 2015, CONSUM COMM NETWORK, P898, DOI 10.1109/CCNC.2015.7158095
   Alaoui EA, 2019, J NETW COMPUT APPL, V148, DOI 10.1016/j.jnca.2019.102456
   [Anonymous], 2013, 2013 FUTURE NETWORK
   Ashton K., RFID journal, V22 22, P97, DOI DOI 10.1145/2967977
   Avizienis A, 2017, I C DEPENDABLE SYST, P113, DOI 10.1109/DSN-W.2017.38
   Balasubramanian A, 2007, ACM SIGCOMM COMP COM, V37, P373, DOI 10.1145/1282427.1282422
   Benamar M, 2015, 2015 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM), P85
   Bose Paul A, 2020, INT C INNOVATIONS CO, P227
   Burgess J, 2006, IEEE INFOCOM SER, P1688, DOI 10.1109/infocom.2006.228
   Burleigh S, 2003, IEEE COMMUN MAG, V41, P128, DOI 10.1109/MCOM.2003.1204759
   Chhabra A, 2017, 51 ANN C INF SCI SYS, P1
   Dias J. A. F. F., 2017, THESIS U BEIRA INTER
   Ghani-Ur-Rehman, 2019, IEEE ACCESS, V7, P109026, DOI 10.1109/ACCESS.2019.2933873
   Huang TK, 2010, INT CON ADV INFO NET, P112, DOI 10.1109/AINA.2010.162
   Ilyas M, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720964358
   Kang H, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/325027
   Khalid W, 2018, COMPUT SECUR, V77, P442, DOI 10.1016/j.cose.2018.04.015
   Lindgren A, 2004, LECT NOTES COMPUT SC, V3126, P239
   Loudari SE, 2016, LECT NOTES ELECTR EN, V366, P301, DOI 10.1007/978-981-287-990-5_24
   Ma MM, 2019, IEEE INTERNET THINGS, V6, P8065, DOI 10.1109/JIOT.2019.2902840
   Manman L, 2020, PROC IEEE 8 INT C CO, P1
   Mao YX, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020243
   Massri K, 2016, J SENS ACTUAT NETW, V5, DOI 10.3390/jsan5020006
   Moetesum M, 2016, WIREL NETW, V22, P2189, DOI 10.1007/s11276-015-1085-y
   Mukherjee A, 2021, IEEE SENS J, V21, P25457, DOI 10.1109/JSEN.2020.3026647
   Mukherjee A, 2021, IEEE INTERNET THINGS, V8, P5194, DOI 10.1109/JIOT.2020.3035608
   Nagrath P, 2016, WIREL NETW, V22, P235, DOI 10.1007/s11276-015-0959-3
   Ning ZL, 2017, IEEE T VEH TECHNOL, V66, P3406, DOI 10.1109/TVT.2016.2593051
   Nobahary S, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1564-4
   Oorschot, 2020, COMPUTER SECURITY IN, P29
   Rehman GU, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4191
   Rehman GU, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.4455
   Rehman GU, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20103000
   Saleem MA, 2019, MOBILE NETW APPL, V24, P248, DOI 10.1007/s11036-018-1205-x
   Sharma A., 2016, IOSR J ELECT COMMUNI, V1, P110, DOI [10.9790/2834-15010110118, DOI 10.9790/2834-15010110118]
   Solis J, 2010, COMPUT COMMUN, V33, P2, DOI 10.1016/j.comcom.2009.07.019
   Souza C, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P1200, DOI 10.1109/ISCC.2016.7543899
   Spaho E, 2020, J AMB INTEL HUM COMP, V11, P3833, DOI 10.1007/s12652-019-01604-8
   Spyropoulos T., 2005, ACM SIGCOMM WORKSH D, P252
   Swati, 2019, INT J SENS NETW, V31, P156
   Wang HZ, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718757874
   Xiaofeng Lu, 2010, Proceedings of the 2010 IEEE International Conference on Networking, Architecture, and Storage (NAS 2010), P341, DOI 10.1109/NAS.2010.46
   You I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167913
NR 43
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7841
EP 7859
DI 10.1007/s11042-022-13624-2
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843996100001
DA 2024-07-18
ER

PT J
AU Bao, C
   Zhang, XD
   Chen, JZ
   Miao, YW
AF Bao, Chen
   Zhang, Xudong
   Chen, Jiazhou
   Miao, Yongwei
TI MMFL-net: multi-scale and multi-granularity feature learning for
   cross-domain fashion retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Visual search; Multi-scale features; Multi-granularity features;
   Content-based image retrieval(CBIR); Feature learning
ID RECOGNITION
AB Instance-level image retrieval in fashion industry is a challenging issue owing to its increasing importance in real-scenario visual fashion search. Cross-domain fashion retrieval aims to match the unconstrained customer images as queries for photographs provided by retailers; however, it is a difficult task due to a wide range of consumer-to-shop (C2S) domain discrepancies and also considering that clothing image is vulnerable to various non-rigid deformations. To this end, we propose a novel multi-scale and multi-granularity feature learning network (MMFL-net), which can jointly learn global-local aggregation feature representations of clothing images in a unified framework, aiming to train a cross-domain model for C2S fashion visual similarity. First, a new semantic-spatial feature fusion part is designed to bridge the semantic-spatial gap by applying top-down and bottom-up bidirectional multi-scale feature fusion. Next, a multi-branch deep network architecture is introduced to capture global salient, part-informed, and local detailed information, and extracting robust and discrimination feature embedding by integrating the similarity learning of coarse-to-fine embedding with the multiple granularities. Finally, the improved trihard loss, center loss, and multi-task classification loss are adopted for our MMFL-net, which can jointly optimize intra-class and inter-class distance and thus explicitly improve intra-class compactness and inter-class discriminability between its visual representations for feature learning. Furthermore, our proposed model also combines the multi-task attribute recognition and classification module with multi-label semantic attributes and product ID labels. Experimental results demonstrate that our proposed MMFL-net achieves significant improvement over the state-of-the-art methods on the two datasets, DeepFashion-C2S and Street2Shop. Specifically, our approach exceeds the current best method by a large margin of +4.2% and + 11.4% for mAP and Acc@1, respectively, on the most challenging dataset DeepFashion-C2S.
C1 [Bao, Chen; Chen, Jiazhou] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Zhang, Xudong] Zhejiang Shuren Univ, Sch Informat Sci & Technol, Hangzhou, Peoples R China.
   [Miao, Yongwei] Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang Shuren University; Hangzhou
   Normal University
RP Miao, YW (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Technol, Hangzhou, Peoples R China.
EM xdzhang@zjsru.edu.cn; ywmiao@hznu.edu.cn
OI Miao, Yongwei/0000-0002-5479-9060
FU National Natural Science Foundation of China [61972458, 62172367];
   Zhejiang Province Public Welfare Technology Application Research Project
   [LGF22F020006]
FX The authors would like to thank the anonymous reviewers for their
   helpful and valuable comments and suggestions. This work was supported
   in part by the National Natural Science Foundation of China under Grant
   No. 61972458, 62172367, in part by the Zhejiang Province Public Welfare
   Technology Application Research Project under Grant LGF22F020006.
CR Ak KE, 2018, PROC CVPR IEEE, P7708, DOI 10.1109/CVPR.2018.00804
   [Anonymous], 2014, Proceedings of the Eurographics Workshop on 3D Object Retrieval
   Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Bossard Lukas, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P321, DOI 10.1007/978-3-642-37447-0_25
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Chen W, 2022, Arxiv, DOI arXiv:2101.11282
   Cheng WH, 2021, ACM COMPUT SURV, V54, DOI [10.1145/3447239, 10.1145/3552468.3554360]
   Di W, 2013, IEEE COMPUT SOC CONF, P8, DOI 10.1109/CVPRW.2013.6
   Dong JF, 2021, IEEE T IMAGE PROCESS, V30, P8410, DOI 10.1109/TIP.2021.3115658
   Dong Q, 2017, IEEE WINT CONF APPL, P520, DOI 10.1109/WACV.2017.64
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   Hidayati SC, 2018, IEEE T CYBERNETICS, V48, P1647, DOI 10.1109/TCYB.2017.2712634
   Hou Y, 2021, P IEEECVF INT C COMP, P12147, DOI 10.1109/ICCV48922.2021.01193
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Ji X, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1654, DOI 10.1145/3123266.3123429
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kuang ZH, 2019, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2019.00316
   Kucer M, 2019, IEEE COMPUT SOC CONF, P344, DOI 10.1109/CVPRW.2019.00047
   Kuo YH, 2017, IEEE INT CONF COMP V, P298, DOI 10.1109/ICCVW.2017.44
   Lang YN, 2020, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR42600.2020.00267
   Li JP, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON OPTO-ELECTRONIC INFORMATION PROCESSING (ICOIP), P1, DOI 10.1109/OPTIP.2017.8030687
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu AA, 2021, MULTIMED TOOLS APPL, V80, P17169, DOI 10.1007/s11042-020-08973-9
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lu SF, 2021, PATTERN RECOGN LETT, V147, P150, DOI 10.1016/j.patrec.2021.04.009
   Lu YX, 2017, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2017.126
   Luo YD, 2019, Arxiv, DOI [arXiv:1904.02887, 10.48550/arXiv.1904.02887]
   Luo ZH, 2019, IEEE IMAGE PROC, P859, DOI 10.1109/ICIP.2019.8802938
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sharma V, 2021, IEEE WINT CONF APPL, P1347, DOI 10.1109/WACV48630.2021.00139
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan FW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12085, DOI 10.1109/ICCV48922.2021.01189
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Veit A, 2017, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2017.193
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   [王志伟 Wang Zhiwei], 2020, [计算机学报, Chinese Journal of Computers], V43, P740
   Wieczorek M., 2021, INT C NEUR INF PROC, P212
   Wieczorek M, 2020, Neural Information Processing, P294
   Yang F, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2101, DOI 10.1145/3097983.3098162
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang XM, 2020, NEUROCOMPUTING, V402, P375, DOI 10.1016/j.neucom.2020.03.096
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
NR 52
TC 2
Z9 2
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 22
PY 2022
DI 10.1007/s11042-022-13648-8
EA AUG 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X3EM
UT WOS:000842923700001
DA 2024-07-18
ER

PT J
AU Yazici, VO
   Yu, L
   Ramisa, A
   Herranz, L
   van de Weijer, J
AF Oguz Yazici, Vacit
   Yu, Longlong
   Ramisa, Arnau
   Herranz, Luis
   van de Weijer, Joost
TI Main product detection with graph networks for fashion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Main product detection; Graph networks; Fashion
AB Computer vision has established a foothold in the online fashion retail industry. Main product detection is a crucial step of vision-based fashion product feed parsing pipelines, focused on identifying the bounding boxes that contain the product being sold in the gallery of images of the product page. The current state-of-the-art approach does not leverage the relations between regions in the image, and treats images of the same product independently, therefore not fully exploiting visual and product contextual information. In this paper, we propose a model that incorporates Graph Convolutional Networks (GCN) that jointly represent all detected bounding boxes in the gallery as nodes. We show that the proposed method is better than the state-of-the-art, especially, when we consider the scenario where title-input is missing at inference time and for cross-dataset evaluation, our method outperforms previous approaches by a large margin.
C1 [Oguz Yazici, Vacit; Herranz, Luis; van de Weijer, Joost] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
   [Yu, Longlong] Wide Eyes Technol, Barcelona, Spain.
   [Ramisa, Arnau] Amazon Inc, Seattle, WA USA.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Amazon.com
RP Yazici, VO (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
EM voyazici@cvc.uab.es; longyu@wide-eyes.it; aramisay@amazon.com;
   lherranz@cvc.uab.es; joost@cvc.uab.es
RI van de Weijer, Joost/A-1643-2009; Herranz, Luis/B-4573-2016
OI van de Weijer, Joost/0000-0002-9656-9706; Herranz,
   Luis/0000-0002-7022-3395
FU Spanish projects [PID2019-104174GB-I00, RTI2018-102285-A-I00]; Ministry
   of Economy and Knowledge of the Generalitat de Catalunya, and its CERCA
   Program [2016 DI 039]; Ramon y Cajal grant [RYC2019-027020-I]
FX This work was supported by the Spanish projects PID2019-104174GB-I00 and
   RTI2018-102285-A-I00, the Industrial Doctorate Grant 2016 DI 039 of the
   Ministry of Economy and Knowledge of the Generalitat de Catalunya, and
   its CERCA Program, and the Ramon y Cajal grant RYC2019-027020-I.
CR Adrien, 2020, 9 FUT WORK TRENDS PO
   Ak KE, 2018, PATTERN RECOGN LETT, V112, P212, DOI 10.1016/j.patrec.2018.07.019
   Bastan M, 2020, IEEE C COMPUTER VISI
   Bruna J., 2013, INT C LEARNING REPRE
   Chen YX, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107321
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Cucurull G, 2019, PROC CVPR IEEE, P12609, DOI 10.1109/CVPR.2019.01290
   Cui ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P307, DOI 10.1145/3308558.3313444
   Defferrard M, 2016, ADV NEUR IN, V29
   Devlin J., 2018, BERT PRE TRAINING DE
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   Han XT, 2017, IEEE I CONF COMP VIS, P1472, DOI 10.1109/ICCV.2017.163
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kipf TN, 2016, ARXIV
   Kuang ZH, 2019, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2019.00316
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1571, DOI 10.1145/3240508.3240646
   Liu YS, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107596
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Paszke A, 2019, ADV NEUR IN, V32
   Rubio A, 2017, IEEE INT CONF COMP V, P2236, DOI 10.1109/ICCVW.2017.261
   Schmelzer R, 2019, 5 benefits of AI in the banking industry
   Vasileva MI, 2018, LECT NOTES COMPUT SC, V11220, P405, DOI 10.1007/978-3-030-01270-0_24
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang M, 2019, INT C LEARN REPR WOR, P1
   Wang WG, 2018, PROC CVPR IEEE, P4271, DOI 10.1109/CVPR.2018.00449
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang L., 2019, P 30 BRIT MACH VIS C, P254
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
NR 34
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 19
PY 2022
DI 10.1007/s11042-022-13572-x
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X0GI
UT WOS:000842724400004
OA Green Submitted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Attioui, S
   Najah, S
AF Attioui, Sanae
   Najah, Said
TI Multidimensional parallel capsule network for SAR image change detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Change detection; Synthetic-aperture radar (SAR); Deep learning; Capsule
   network; Multi-dimensional parallel capsule module (Mdp-CapsNet)
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION; SEGMENTATION;
   ALGORITHM
AB Since their advent, deep learning (DL) techniques have made great achievement in synthetic aperture radar (SAR) image change detection problem. Yet, their efficiency and accuracy with a presence of speckle noise and limited labeled training data are always full of challenges. To overcome these issues, this paper advocates an innovative approach by exploiting the advantage of the capsule network that can achieve a similar performance with less training samples thanks to its ability to make full use of the relative spatial relationships between features. The proposed multidimensional parallel capsule network (Mdp-CapsNet) includes an attention module to mitigate interference of speckle noise. By focusing more on prominent parts of the feature maps, the attention module guides the network to improve feature extraction. Moreover, a margin-focal loss function is suggested to overcome the influence of imbalanced samples during network optimization. The effectiveness and reliability of the proposed method are demonstrated by comparing its results with other state-of-the-art methods.
C1 [Attioui, Sanae; Najah, Said] Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Attioui, S (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci & Technol, Lab Intelligent Syst & Applicat LSIA, Fes, Morocco.
EM Sanae.attioui@usmba.ac.ma; Said.najah@usmba.ac.ma
OI ATTIOUI, SANAE/0000-0003-1616-730X
FU Laboratory of Intelligent Systems and Applications (LSIA)
FX The authors thankfully acknowledge the Laboratory of Intelligent Systems
   and Applications (LSIA) for its support in carrying out this work.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Akbari V, 2014, IEEE T GEOSCI REMOTE, V52, P3729, DOI 10.1109/TGRS.2013.2275203
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Ertugrul IO, 2018, IEEE COMPUT SOC CONF, P2211, DOI 10.1109/CVPRW.2018.00287
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hou YC, 2020, IEEE ACCESS, V8, P176217, DOI 10.1109/ACCESS.2020.3026469
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusetogullari H, 2015, IEEE J-STARS, V8, P2151, DOI 10.1109/JSTARS.2015.2427274
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Ma WP, 2019, INT J REMOTE SENS, V40, P1066, DOI 10.1080/01431161.2018.1524172
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P2145, DOI 10.1109/TGRS.2018.2871782
   Quan SN, 2018, IEEE J-STARS, V11, P458, DOI 10.1109/JSTARS.2017.2787591
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Sabour S, 2017, ADV NEUR IN, V30
   Sarp G, 2017, J TAIBAH UNIV SCI, V11, P381, DOI 10.1016/j.jtusci.2016.04.005
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Wang XD, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107443
   Xu QF, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3022512
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu KQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030223
NR 45
TC 0
Z9 0
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6727
EP 6746
DI 10.1007/s11042-022-13622-4
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840140800002
DA 2024-07-18
ER

PT J
AU Kingra, S
   Aggarwal, N
   Kaur, N
AF Kingra, Staffy
   Aggarwal, Naveen
   Kaur, Nirmal
TI Emergence of deepfakes and video tampering detection approaches: A
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forensics; Video forgery detection; Deepfake detection; Facial
   manipulation detection; Audio deepfake detection
ID FORGERY; NETWORKS; IMAGES; MOTION
AB Digital content, particularly the digital videos recorded at specific angle, though, provides a truthful picture of reality but the widespread proliferation of easy-to-use content editing softwares doubt about its authenticity. Recently, Artificial Intelligence (AI) based content altering mechanism, known as deepfake, became popular on social media platforms, wherein any person can be able to purport the behaviour of another person in a video who is actually not there. Depending on the type of manipulation performed, different types of deepfakes are described in this paper. Moreover, rely on digital content for trustworthy evidence as well as to avoid spread of misinformation, integrity and authenticity of digital content has-been of utmost concerns. This paper aims to present a survey of the state-of-art video integrity verification techniques with special emphasis on emerging deepfake video detection approaches. Seeing the advancement in creation of more realistic deepfake videos, this review facilitates the development of more generalized methods with a thorough discussion on different research trends in the wake of deepfake detection.
C1 [Kingra, Staffy; Aggarwal, Naveen; Kaur, Nirmal] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Kingra, S (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM staffysk@gmail.com; navagg@gmail.com; nirmaljul19@gmail.com
RI Kaur, Nirmal/AAD-5967-2020
OI Kaur, Nirmal/0000-0003-1725-4624
CR Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S, 2020, IEEE INT WORKS INFOR
   Agarwal S., 2019, P IEEE C COMP VIS PA, P38, DOI DOI 10.1109/ICCV.2015.425
   Agarwal S, 2021, DETECTING DEEP FAKE
   Ajder H, DEEPFAKE THREAT INTE
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], PROJECT R TOOLS DIGI
   [Anonymous], 2010, P EUROPEAN C COMPUTE
   [Anonymous], BAIDU TEXT TO SPEECH
   [Anonymous], 2010, J COMPUT INFORM SYST
   [Anonymous], APTLY AUDIO PROCESSI
   [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], 2019, DESSA DETECTING AUDI
   [Anonymous], 2019, THIEVES USED AUDIO D
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Aslani S., 2013, INT J EL COMP ENG SY, V7, P1252
   Baddar W J, 2017, ARXIV
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Barker J., 2013, The GRID Audiovisual Sentence Corpus"
   Bidokhti A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P13, DOI 10.1109/AISP.2015.7123529
   Bregler C., 1997, P 24 ANN C COMP GRAP, V31, P353, DOI DOI 10.1145/258734.258880
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Caldelli R, 2021, PATTERN RECOGN LETT, V146, P31, DOI 10.1016/j.patrec.2021.03.005
   Chakravarty P, 2016, LECT NOTES COMPUT SC, V9909, P285, DOI 10.1007/978-3-319-46454-1_18
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chatfield K., 2014, ARXIV
   Chen HC, 2018, MULTIMED TOOLS APPL, V77, P5303, DOI 10.1007/s11042-017-4434-2
   Chen HN, 2019, GEOPHYS RES LETT, V46, P10669, DOI 10.1029/2019GL084771
   Chen Ricky T. Q., 2018, Advances in neural information processing systems, V31, DOI DOI 10.5555/3327757.3327764
   Chen T., 2020, PROC ODYSSEY 2020 SP, P132
   Cheung GKM, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P373, DOI 10.1109/TDPVT.2004.1335262
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Cho W, 2019, PROC CVPR IEEE, P10631, DOI 10.1109/CVPR.2019.01089
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Ciftci U A, 2019, ARXIV
   Cole S., 2017, AI-assisted fake porn is here and we're all fucked
   collection D., XIPHORG VIDEO TEST M
   Cozzolino D, 2020, ARXIV
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Demir I., 2021, ARXIV
   Ding XL, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2019.163766
   Dolhansky B, 2019, ARXIV
   Dolhansky B., 2020, arXiv
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Dufour A., 2019, Google AI Blog, V1, P3
   Durall R, 2019, ARXIV
   Durall R., 2020, P IEEE CVF C COMP VI, P7890, DOI DOI 10.1109/CVPR42600.2020.00791
   Esser P, 2018, P EUROPEAN C COMPUTE
   Feng D., 2020, ICONIP, P316
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Fernando T, 2019, ARXIV
   Garg R, 2013, IEEE T INF FOREN SEC, V8, P1417, DOI 10.1109/TIFS.2013.2272217
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Grisham S, 2018, STEPHANIE GRISHAM TW
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Guan W, 2021, ARXIV
   Guarnera L, 2020, IEEE COMPUT SOC CONF, P2841, DOI 10.1109/CVPRW50498.2020.00341
   Guera D., 2019, ARXIV
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Guo Z., 2020, arXiv
   Haliassos A, 2020, ARXIV
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hecker C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360626
   Hernandez-Ortega J., 2020, arXiv
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hsieh CK, 2018, P INT COMP SOFTW APP, P353, DOI 10.1109/COMPSAC.2018.10257
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Ismael Al-Sanjary Omar, 2016, Forensic Sci Int, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Jiang L., 2020, ARXIV
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras Tero, 2019, arXiv
   Kaur N, 2020, FORENSIC SCI MED PAT, V16, P481, DOI 10.1007/s12024-020-00230-7
   Khalid H, 2020, IEEE COMPUT SOC CONF, P2794, DOI 10.1109/CVPRW50498.2020.00336
   Khalil SS, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13040093
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kingma DP, 2013, ARXIV
   Kingma Durk P., 2018, ADV NEURAL INFORM PR
   KINGRA S, 2016, INDIAN J SCI TECHNOL, V9, pN1094, DOI DOI 10.17485/ijst/2016/v9i44/105142
   Kingra S, 2017, MULTIMED TOOLS APPL, V76, P25767, DOI 10.1007/s11042-017-4762-2
   Kobayashi K., 2018, SPEAK LANG REC WORKS, P203
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Kohli A, 2021, MULTIMED TOOLS APPL, V80, P18461, DOI 10.1007/s11042-020-10420-8
   Korshunov P, 2019, INT C MACH LEARN CON
   Korshunov P., 2018, arXiv
   Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270
   Kumar N, 2020, PATTERN RECOGN IMAGE, V30, P382, DOI 10.1134/S1054661820030153
   Kumar Navdeep, 2020, Proceedings of International Conference on IoT Inclusive Life (ICIIL 2019). Lecture Notes in Networks and Systems (LNNS 116), P243, DOI 10.1007/978-981-15-3020-3_23
   Kumar P., 2020, ARXIV
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee S., 2006, P IEEE INT C AC SPEE, V2
   Lee SH, 2021, ARXIV
   Lee S, 2008, INT CONF ACOUST SPEE, P1237
   Li H, 2020, US Patent, Patent No. [10,535,163, 10535163]
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Li R, 2018, MULTIMED TOOLS APPL, V77, P663, DOI 10.1007/s11042-016-4268-3
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Li Y., 2019, ARXIV
   Li Y., 2018, ARXIV
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long C., 2019, CVPR WORKSHOPS, P1
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Maras MH, 2019, INT J EVID PROOF, V23, P255, DOI 10.1177/1365712718807226
   MASE K, 1991, IEICE TRANS COMMUN, V74, P3474
   Masi I., 2020, ARXIV
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mehra A., 2020, THESIS U TWENTE
   Milani S, 2012, IEEE INT WORKSH MULT, P112, DOI 10.1109/MMSP.2012.6343425
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Mittal T, 2020, ARXIV
   Mohammadi SH, 2019, US Patent, Patent No. [10,186,252, 10186252]
   Montserrat D M, 2020, ARXIV
   Nagothu D, 2019, PROC SPIE, V11017, DOI 10.1117/12.2519005
   Nagothu D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112424
   NGUYEN H, 2020, LECT NOTE INFORM, V306
   Nguyen H, 2019, ARXIV
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen T. T., 2019, arXiv
   Nguyen X., 2021, FORENSIC SCI INT DIG, DOI 10.1016/j.fsidi.2021.301108
   Nirkin Y, 2020, ARXIV
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Oord A., 2016, ARXIV160903499
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Ouyang JL, 2017, MULTIMED TOOLS APPL, V76, P2609, DOI 10.1007/s11042-015-3225-x
   Papadopoulou O., 2018, Invid fake video corpus v2. 0 (version 2.0)
   Pietikainen M., 2015, 11 IEEE INT C WORKSH, P1, DOI DOI 10.1109/FG.2015.7163155
   Posters B., 2018, BILL POSTERS INSTAGR
   Project A, 2017, AMI CORPUS DOWNLOAD
   Qadir G., 2012, IET C IMAGE PROCESSI
   Qi H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4318, DOI 10.1145/3394171.3413707
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2018, arXiv
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Sabir E., 2019, INTERFACES GUI, V3, P80
   Saikia N, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P694, DOI 10.1109/ICGCIoT.2015.7380552
   Sanderson C., 2002, The vidtimit database
   Saunders Jonathan., 2019, Detecting Deep Fakes With Mice: Machines vs Biology
   Saxena S, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1361, DOI 10.1109/TENCON.2016.7848236
   Seeling P, 2001, VIDEO TRACES RES GRO
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shang ZH, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107950
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Sowmya K., 2015, arXiv preprint arXiv: 1503. 00843, 2321-3469, V9, P17
   Stehouwer J, 2019, ARXIV
   Sun K., 2019, ARXIV
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sun X., 2020, ARXIV
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tachibana H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4784, DOI 10.1109/ICASSP.2018.8461829
   Tamgade Sukeshni N., 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P914, DOI 10.1109/ICETET.2009.154
   Tan M., 2019, arXiv
   Tariq S, 2020, ARXIV
   Theobalt Chris- tian, 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.262
   Thies J., 2019, arXiv
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tian YC, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P303, DOI 10.1145/3180155.3180220
   Todisco M., 2019, ARXIV
   Tolosana R., 2020, ARXIV
   TRECVID, TREC VID RETR EV
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Verdoliva L., 2020, ARXIV
   Vincent James, 2018, VERGE           0417
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wan L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4879, DOI 10.1109/ICASSP.2018.8462665
   Wang J., ARXIV
   Wang Q., 2014, Sens. Transducers, V166, P229
   Wang R., 2020, ARXIV
   Wang R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3444
   Wang S.-Y., 2020, P IEEE C COMPUTER VI, V7
   Wang T., 2018, ARXIV
   Wang W, 2014, LECT NOTES COMPUT SC, V8389, P244, DOI 10.1007/978-3-662-43886-2_18
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Wheatley T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017960
   Wiles O., 2018, ARXIV
   Wodajo D., 2021, arXiv
   Woo S S, 2020, ARXIV
   Xie WD, 2019, INT CONF ACOUST SPEE, P5791, DOI 10.1109/ICASSP.2019.8683120
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yoo DG, 2013, J DISP TECHNOL, V9, P840, DOI 10.1109/JDT.2013.2263374
   Zampoglou M, 2019, LECT NOTES COMPUT SC, V11295, P374, DOI 10.1007/978-3-030-05710-7_31
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
   Zhang ZQ, 2018, LECT NOTES COMPUT SC, V10843, P745, DOI 10.1007/978-3-319-93417-4_48
   Zhao T., 2020, ARXIV
   Zhu BQ, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P414, DOI 10.1145/3375627.3375849
NR 203
TC 8
Z9 8
U1 5
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10165
EP 10209
DI 10.1007/s11042-022-13100-x
EA AUG 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000836525000003
DA 2024-07-18
ER

PT J
AU Stellin, R
   Rukmani, P
   Anbarasi, LJ
   Narayanan, S
AF Stellin, Rena
   Rukmani, P.
   Anbarasi, L. Jani
   Narayanan, Sathiya
TI HandGCNN model for gesture recognition based voice assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Virtual voice; Sign language; Deep learning;
   Convolution neural network
AB Communication plays an important role in today's world. Before the evolution of the verbal communication, sign language was the only way of communication used by our ancestors. Later on, the verbal communication started evolving and different people from different region started to speak different languages. But there are some groups of people who cannot express themselves with verbal language; instead they use sign language to communicate. To bridge the gap between those people who use sign language for communication with those who use verbal language, a system is designed that recognizes the gestures of the sign language, interprets it and converts it into verbal language. Various researches have been carried out by capturing the hand signs of the speech impaired people through sensors like leap motion sensors and camera. This research works focusses on improving the gesture capturing through camera and process them through deep learning models. This work focussed on creating a hand gesture dataset "HandG" that includes 20,600 images for 10 classes (2060 images per category) using digital camera and image augmentation. A novel Convolution Neural Networks (CNN) based model, termed as "HandGCNN", is proposed achieving a high prediction accuracy of 99.13%. A real-time system with webcam being the input receptor unit is built which recognises the signal and generates the audio relevant to that. The generated audio will serve as voice assistance for impaired people.
C1 [Stellin, Rena; Rukmani, P.; Anbarasi, L. Jani] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Narayanan, Sathiya] Vellore Inst Technol, Ctr Adv Data Sci, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Narayanan, S (corresponding author), Vellore Inst Technol, Ctr Adv Data Sci, Chennai, Tamil Nadu, India.
EM sathiyanarayanan.s@vit.ac.in
RI l, j/JVZ-8480-2024; L, J/JEF-9564-2023
OI Sekar, Sathiya Narayanan/0000-0001-8064-7442
CR Apoorva A., 2021, ADV MACHINE LEARNING, P165, DOI DOI 10.1007/978-981-15-5243-4_14
   Badi Haitham, 2016, Intelligent Industrial Systems, V2, P179, DOI 10.1007/s40903-016-0046-9
   Bhoi Sourav Kumar, 2018, 2018 International Conference on Information Technology (ICIT), P155, DOI 10.1109/ICIT.2018.00041
   Dong YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3077967
   Gu LY, 2020, IEEE ACCESS, V8, P68787, DOI 10.1109/ACCESS.2020.2986473
   Gullapalli S, 2020, 2020 IEEE INT STUDEN, P1, DOI [10.1109/SCEECS48394.2020.66, DOI 10.1109/SCEECS48394.2020.66]
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jain A, 2018, INT J ENG SCI RES TE, P368
   Jain R, 2022, VISUAL COMPUT, V38, P1957, DOI 10.1007/s00371-021-02259-3
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Këpuska V, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P99, DOI 10.1109/CCWC.2018.8301638
   Khan T., 2015, INT J SCI ENG RES, V6, P338
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YK, 2021, COMPUT GRAPH-UK, V97, P191, DOI 10.1016/j.cag.2021.04.017
   Nikam AS, 2016, 2016 ONL INT C GREEN, P1, DOI DOI 10.1109/GET.2016.7916786
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Poornima N., 2019, I MANAGERS J PATTERN, V6, P17, DOI [10.26634/jpr.6.2.16754, DOI 10.26634/JPR.6.2.16754]
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rai Prakhyath, 2018, INT J COMPUT SCI MOB, V7, P164
   Reda MM, 2018, 1 INT C COMP APPL IN, P1
   Rougier NP, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.142
   Saha HN, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P91, DOI 10.1109/CCWC.2018.8301631
   Saxena A, 2014, INT CONF COMM SYST, P819, DOI 10.1109/CSNT.2014.170
   Shinde SS., 2016, JOURNALNX, V2, P39
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Zhang WJ, 2021, IEEE-CAA J AUTOMATIC, V8, P110, DOI 10.1109/JAS.2020.1003465
NR 29
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42353
EP 42369
DI 10.1007/s11042-022-13497-5
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000836525000008
DA 2024-07-18
ER

PT J
AU Arora, S
   Batra, I
   Malik, A
   Luhach, AK
   Alnumay, WS
   Chatterjee, P
AF Arora, Sofia
   Batra, Isha
   Malik, Arun
   Luhach, Ashish Kr.
   Alnumay, Waleed S.
   Chatterjee, Pushpita
TI Seed: secure and energy efficient data-collection method for IoT network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; IoT; Data collection; SEED
ID DATA AGGREGATION; INTERNET; THINGS; SCHEME
AB With increase in the demand of better data collection from various IoT devices, researchers are showing more interests in providing the enhanced data collection methods to the users. Many data collection methods have proposed, but still more efficiency and better results are required. In this paper, a novel and secure data collection method from IoT devices has proposed. In this paper, SEED (Secure and energy efficient data-collection) method has discussed. It includes creation of aggregator nodes and path discovery algorithms. Integrity of data is analysed by using MD5 hashing technique. This hashing technique is one of the most usable techniques as compared to other. In the regard of implementation of this novel secure and energy data collection method, MD5 is used to just hash the processing data in the entire process. In earlier scenarios, there were various issues regarding fault tolerance, congestion, energy wastage, path discovery and load balancing in a network. To resolve these issues, updating of the aggregator node is done after each failure or transmission. Transmission of huge amount of data can create different challenges in network. This research is completely different from other existing researches of data collection with routing as it deals with sink node by using a unique path discovery algorithm. This proposed mechanism provides the better results for all of the nodes and network in terms of energy efficiency and throughput.
C1 [Arora, Sofia; Batra, Isha; Malik, Arun] Lovely Profess Univ, Phagwara, Punjab, India.
   [Luhach, Ashish Kr.] Papua New Guinea Univ Technol, Lae 411, Papua N Guinea.
   [Alnumay, Waleed S.] King Saud Univ, Riyadh, Saudi Arabia.
   [Chatterjee, Pushpita] Tennessee State Univ, Dept CS, Nashville, TN 37203 USA.
C3 Lovely Professional University; King Saud University; Tennessee State
   University
RP Luhach, AK (corresponding author), Papua New Guinea Univ Technol, Lae 411, Papua N Guinea.
EM ashish.kumar@pnguot.ac.pg
RI Luhach, Ashish Kumar/R-8756-2019; Malik, Arun/ADT-8892-2022; Alnumay,
   Waleed/AAP-1781-2021; CHATTERJEE, PUSPITA/AAR-3862-2020
OI Luhach, Ashish Kumar/0000-0001-8759-0290; Malik,
   Arun/0000-0001-6704-6319; Alnumay, Waleed/0000-0001-5076-2060;
   CHATTERJEE, PUSPITA/0000-0002-0775-5540; Batra,
   Isha/0000-0003-2958-214X; , Sofia Singla/0009-0007-2123-4913
FU Lovely Professional University, Punjab, India; King Saud University,
   Riyadh, Saudi Arabia [RSP-2020/250]
FX This Work is funded by Lovely Professional University, Punjab, India.
   The work is also funded by the Researchers Supporting Project number
   (RSP-2020/250), King Saud University, Riyadh, Saudi Arabia.
CR Alduais NAM, 2018, ELECTR POWER ELECTR, P250, DOI 10.1109/EECCIS.2018.8692815
   Alhihi M, 2017, TELKOMNIKA TELECOMMU, V15, P1701, DOI [10.12928/telkomnika.v15i4.6597, DOI 10.12928/TELKOMNIKA.V15I4.6597]
   Balakrishna S., 2020, A handbook of internet of things in biomedical and cyber physical system, P275, DOI DOI 10.1007/978-3-030-23983-1_11
   Cheng CT, 2017, IEEE T IND INFORM, V13, P793, DOI 10.1109/TII.2016.2610139
   Cheng SY, 2019, COMPUT NETW, V150, P1, DOI 10.1016/j.comnet.2018.11.032
   Cherradi, 2016, JDSI, V16, P2509
   Ebrahimi D, 2019, IEEE INTERNET THINGS, V6, P1893, DOI 10.1109/JIOT.2018.2878834
   Gavali A, 2021, QUANTUM CRYPTOGR FUT, P203, DOI [10.21203/rs.3.rs-718321/v1, DOI 10.21203/RS.3.RS-718321/V1]
   Guan ZT, 2019, J NETW COMPUT APPL, V125, P82, DOI 10.1016/j.jnca.2018.09.019
   Gurunath R., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P104, DOI 10.1109/I-SMAC.2018.8653728
   Hernández-Vega JI, 2018, L N INST COMP SCI SO, V213, P108, DOI 10.1007/978-3-319-73323-4_11
   Hideg A, 2016, INT CONF COGN INFO, P193, DOI 10.1109/CogInfoCom.2016.7804548
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Jang J, 2018, APPL SOFT COMPUT, V68, P811, DOI 10.1016/j.asoc.2017.05.020
   Khosravi MR, 2018, J SUPERCOMPUT, V74, P6184, DOI 10.1007/s11227-018-2532-1
   Khosravi MR, 2018, J SUPERCOMPUT, V74, P696, DOI 10.1007/s11227-017-2148-x
   Ko H, 2019, FUTURE GENER COMP SY, V92, P1093, DOI 10.1016/j.future.2017.08.040
   Li GR, 2019, IEEE INTERNET THINGS, V6, P4176, DOI 10.1109/JIOT.2018.2875244
   Li HT, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0896-7
   Li XY, 2019, IEEE T WIREL COMMUN, V18, P3437, DOI 10.1109/TWC.2019.2914046
   Liu AF, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/2974021
   Liu YN, 2019, COMPUT NETW, V148, P340, DOI 10.1016/j.comnet.2018.11.028
   Luo ET, 2018, IEEE COMMUN MAG, V56, P163, DOI 10.1109/MCOM.2018.1700364
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Orsino A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060836
   Pu YW, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/3985232
   Qin ZJ, 2018, IEEE T IND INFORM, V14, P4457, DOI 10.1109/TII.2018.2846687
   Rahman T, 2018, IEEE ACCESS, V6, P51875, DOI 10.1109/ACCESS.2018.2869075
   Saleem A, 2020, IEEE INTERNET THINGS, V7, P6132, DOI 10.1109/JIOT.2019.2957314
   Shi FR, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P723, DOI 10.1109/WF-IoT.2016.7845498
   Tang WJ, 2019, IEEE INTERNET THINGS, V6, P8714, DOI 10.1109/JIOT.2019.2923261
   Tao H, 2019, IEEE INTERNET THINGS, V6, P410, DOI 10.1109/JIOT.2018.2854714
   Ullah Ata, 2019, 2019 IEEE International Conference on Smart Internet of Things (SmartIoT). Proceedings, P314, DOI 10.1109/SmartIoT.2019.00054
   Ullah A, 2020, PEER PEER NETW APPL, V13, P163, DOI 10.1007/s12083-019-00745-z
   Wang P, 2018, IEEE COMMUN MAG, V56, P87, DOI 10.1109/MCOM.2018.1701217
   Wang W, 2018, IEEE CLOUD COMPUT, V5, P77, DOI 10.1109/MCC.2018.111122026
   Xiang XM, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1490-5
   Zeng P, 2020, J SYST ARCHITECT, V106, DOI 10.1016/j.sysarc.2020.101713
   Zhang JH, 2019, IEEE ACCESS, V7, P70474, DOI 10.1109/ACCESS.2019.2919355
   Ziegler S, 2019, INTERNET THINGS SECU, P149, DOI [10.1007/978-3-030-04984-3_11, DOI 10.1007/978-3-030-04984-3_11]
NR 40
TC 5
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 3139
EP 3153
DI 10.1007/s11042-022-13614-4
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000834736500002
DA 2024-07-18
ER

PT J
AU Bhatia, M
   Bhatia, S
   Hooda, M
   Namasudra, S
   Taniar, D
AF Bhatia, Madhulika
   Bhatia, Surbhi
   Hooda, Madhurima
   Namasudra, Suyel
   Taniar, David
TI Analyzing and classifying MRI images using robust mathematical modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Medical diagnosis; Segmentation; Linear model
ID NEURAL-NETWORK; SEGMENTATION; FRAMEWORK; SELECTION
AB Medical imaging is an exponentially growing field, which consists of a set of tools and techniques used to extract useful information from medical images. Magnetic Resonance Imaging (MRI) is one of the most popular techniques among image modalities. This paper develops a linear model for classifying MRI images into the tumor and non-tumor categories. The proposed algorithm supports automatic extraction of features from brain MRI images, and focuses on extracting grey matter and white matter, so that the unhealthy MRI images can be isolated from the healthy MRI images. This technique takes advantage of preprocessing strategies and various filters for viable extraction and for classifying the brain MRI images. The samples of MRI images are taken from the BRAINIX and Neuroimaging data sources. The results are validated by applying the mathematical equations on 46 patients categorizing into 24 subjects as healthy and the remaining 22 as unhealthy. The novelty lies in formulating a general equation for both groups, which can be further used as a tool in computer-assisted medical systems for classifying patients.
C1 [Bhatia, Madhulika; Hooda, Madhurima] Amity Univ, Dept Comp Sci & Engn, Noida, India.
   [Bhatia, Surbhi] King Faisal Univ, Coll Comp Sci & Informat Technol, Dept Informat Syst, Al Hasa, Saudi Arabia.
   [Namasudra, Suyel] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
   [Namasudra, Suyel] Univ Int La Rioja, Logrono, Spain.
   [Taniar, David] Monash Univ, Fac Informat Technol, Clayton, Vic, Australia.
C3 Amity University Noida; King Faisal University; National Institute of
   Technology (NIT System); National Institute of Technology Patna;
   Universidad Internacional de La Rioja (UNIR); Monash University
RP Namasudra, S (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.; Namasudra, S (corresponding author), Univ Int La Rioja, Logrono, Spain.
EM suyelnamasudra@gmail.com
RI Namasudra, Suyel/AAV-1723-2020; Bhadauria, Madhulika/R-5073-2019;
   bhatia, surbhi/ADA-8643-2022
OI Bhadauria, Madhulika/0000-0001-6833-5657; ,
   Madhurima/0009-0008-9599-2757; Bhatia, Surbhi/0000-0003-3097-6568
CR Agrawal D, 2021, IEEE 15TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2021), P199, DOI 10.1109/SACI51354.2021.9465609
   Alguliyev RM, 2020, CAAI T INTELL TECHNO, V5, P9, DOI 10.1049/trit.2019.0048
   Ali HM, 2022, CLUSTER COMPUT, V25, P2143, DOI 10.1007/s10586-021-03389-y
   [Anonymous], 2009, ICGST GVIP J
   Ashraf R, 2020, IEEE ACCESS, V8, P105659, DOI 10.1109/ACCESS.2020.2998808
   Bhatia M., 2015, INDIAN J SCI TECHNOL, V8, P1, DOI [10.17485/ijst/2015/v8i22/72152, DOI 10.17485/IJST/2015/V8I22/72152]
   Bhattacharya S, 2020, ADV PROTEIN CHEM STR, V119, P1, DOI 10.1016/bs.apcsb.2019.09.003
   Chakraborty R, 2021, J AMB INTEL HUM COMP, V12, P7793, DOI 10.1007/s12652-020-02506-w
   Chithra PL, 2020, INT J IMAG SYST TECH, V30, P674, DOI 10.1002/ima.22407
   Chithra P.L., 2018, Int. J. Pure Appl. Math, V118, P1
   COHEN G, 1992, PSYCHIAT RES-NEUROIM, V45, P33, DOI 10.1016/0925-4927(92)90012-S
   Conturo TE, 1999, P NATL ACAD SCI USA, V96, P10422, DOI 10.1073/pnas.96.18.10422
   Dev K, 2020, ARXIV
   Dhanith PRJ, 2021, INT J INTERACT MULTI, V6, P122, DOI 10.9781/ijimai.2020.09.003
   Fong SJ, 2020, INT J INTERACT MULTI, V6, P132, DOI 10.9781/ijimai.2020.02.002
   Hamzenejad A, 2021, BIOMED RES INT, V2021, DOI 10.1155/2021/5516819
   Hashemi RH., 2010, MRI BASICS, V3rd
   Hua L, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.662674
   Jiang JF, 2012, BEHAV NEUROSCI, V126, P575, DOI 10.1037/a0029029
   Kasihmuddin MSM, 2021, INT J INTERACT MULTI, V6, P164, DOI 10.9781/ijimai.2020.06.002
   Kennedy DN, 2016, NEUROIMAGE, V124, P1069, DOI 10.1016/j.neuroimage.2015.05.074
   Kumar PM, 2022, IEEE J BIOMED HEALTH, V26, P973, DOI 10.1109/JBHI.2021.3106387
   Li S, 2019, CAAI T INTELL TECHNO, V4, P223, DOI 10.1049/trit.2019.0021
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Madhulika, 2015, ADV SCI LETT, V21, P74, DOI 10.1166/asl.2015.5744
   Mihaylova Antonia, 2020, International Journal of Reasoning-based Intelligent Systems, V12, P128
   MILLER AKH, 1980, NEUROPATH APPL NEURO, V6, P119, DOI 10.1111/j.1365-2990.1980.tb00283.x
   Namasudra S., 2018, Advances of DNA Computing in Cryptography, P181, DOI DOI 10.1201/9781351011419-9X
   Namasudra S, 2023, NEURAL PROCESS LETT, V55, P171, DOI 10.1007/s11063-021-10495-w
   Namasudra S, 2022, IEEE T SERV COMPUT, V15, P2289, DOI 10.1109/TSC.2020.3046471
   Namasudra S, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3392665
   Namasudra S, 2017, FUTURE GENER COMP SY, V73, P90, DOI 10.1016/j.future.2017.01.017
   Nikam P.B., 2013, INT J ENG RES TECHNO, V2, P1980
   Nitish, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P1175, DOI 10.1007/978-981-15-0751-9_108
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Rauf HT, 2021, SOFT COMPUT, V25, P12989, DOI 10.1007/s00500-021-06075-8
   Remya Ajai A. S., 2020, Advances in Communication Systems and Networks. Select Proceedings of ComNet 2019. Lecture Notes in Electrical Engineering (LNEE 656), P1, DOI 10.1007/978-981-15-3992-3_1
   Schalk G, 2010, PRACTICAL GUIDE TO BRAIN-COMPUTER INTERFACING WITH BCI2000, P9, DOI 10.1007/978-1-84996-092-2_2
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Sharma M., 2020, DEEP LEARNING TECHNI, P347
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   Warfield S, 1995, J Image Guid Surg, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C
   Winkler AM, 2010, NEUROIMAGE, V53, P1135, DOI 10.1016/j.neuroimage.2009.12.028
   Yildirim M, 2019, ANALOG INTEGR CIRC S, V100, P537, DOI 10.1007/s10470-019-01481-3
   Zhang F, 2020, COMP MULTIPLE TRACTO, DOI [10.1101/2020.09.19.304758, DOI 10.1101/2020.09.19.304758]
   Zhao XC, 2019, CAAI T INTELL TECHNO, V4, P159, DOI 10.1049/trit.2019.0018
NR 47
TC 7
Z9 7
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37519
EP 37540
DI 10.1007/s11042-022-13505-8
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000833514100004
DA 2024-07-18
ER

PT J
AU Xu, XQ
   Chen, SH
   Lv, X
   Wang, J
   Hu, XL
AF Xu, Xiuqi
   Chen, Shuhan
   Lv, Xiao
   Wang, Jian
   Hu, Xuelong
TI Guided multi-scale refinement network for camouflaged object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camouflaged object detection; Multi-scale global perception; Guided
   multi-scale refinement
ID SEMANTIC SEGMENTATION
AB The purpose of camouflaged object detection (COD) is to identify the hidden camouflaged object in an input image. Compared with other binary segmentation tasks like salient object detection, COD needs to deal with more complex scenes, such as low contrast, similar foreground and background. In this work, we proposed a novel guided multi-scale refinement network for COD. Specifically, we first design a global perception module for coarse localization by stacking multi-scale residual block on the top of the backbone in a recurrent manner. Then, we propose the guided multi-scale refinement module to refine such initial prediction progressively, which is combined with multi-level side-output features in a prediction-to-feature fusion strategy. By plugging into side-output features for multi-scale guidance, the missing object parts and false detection can be well remedied. Experimental results show that our proposed network can more accurately locate the camouflaged object and salient object with sharpened details than existing state-of-the-art approaches. In addition, our model is also very efficient and compact, which enables potential real-world applications.
C1 [Xu, Xiuqi; Chen, Shuhan; Wang, Jian; Hu, Xuelong] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Lv, Xiao] Chongqing Special Equipment Inspect & Res Inst, Chongqing, Peoples R China.
C3 Yangzhou University
RP Chen, SH (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM frequency.xu@foxmail.com; shchen@yzu.edu.cn; lvxiao87@126.com;
   Haixiaoqu@163.com; xlhu@yzu.edu.cn
OI Chen, Shuhan/0000-0002-0094-5157
FU Natural Science Foundation of China [61802336]; Jiangsu Province 7th
   Projects for Summit Talents in Six Main Industries, Electronic
   Information Industry [DZXX-149, 110]; Yangzhou University "Qinglan
   Project"
FX This work was supported by the Natural Science Foundation of China (No.
   61802336), Jiangsu Province 7th Projects for Summit Talents in Six Main
   Industries, Electronic Information Industry (DZXX-149, No.110) and
   Yangzhou University "Qinglan Project".
CR [Anonymous], 2016, P 2016 ACM MULT C
   [Anonymous], 2010, 2010 INT C E PRODUCT
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2022, IEEE T PATTERN ANAL, V44, P4339, DOI 10.1109/TPAMI.2021.3060412
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jaccard P, 1912, NEW PHYTOL, V11, P961
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Kim Y., 2018, AS C COMP VIS, P555, DOI DOI 10.1007/978-3-030-20876-9
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2015, IEEE I CONF COMP VIS, P190, DOI 10.1109/ICCV.2015.30
   Li MS, 2020, PROC CVPR IEEE, P211, DOI 10.1109/CVPR42600.2020.00029
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Q, 2017, IEEE T IMAGE PROCESS, V26, P4537, DOI 10.1109/TIP.2017.2703081
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Pan Y., 2011, Mod Appl Sci, V5, P152, DOI DOI 10.5539/MAS.V5N4P152
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Sengottuvelan P., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P6, DOI 10.1109/ICETET.2008.232
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Skurowski P., 2018, Animal camouflage analysis: Chameleon database
   Sun L, 2020, IEEE ROBOT AUTOM LET, V5, P5558, DOI 10.1109/LRA.2020.3007457
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu YY, 2019, IEEE I CONF COMP VIS, P3788, DOI 10.1109/ICCV.2019.00389
   Yan Q, 2017, INTERNALTIONAL C COM, P1155
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zheng YF, 2019, IEEE SIGNAL PROC LET, V26, P29, DOI 10.1109/LSP.2018.2825959
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 66
TC 5
Z9 6
U1 6
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5785
EP 5801
DI 10.1007/s11042-022-13274-4
EA JUL 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000833514100003
PM 35968408
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Mahajan, K
   Garg, U
AF Mahajan, Kriti
   Garg, Urvashi
TI An enhancement to the existing cyclostationary feature detection in CRN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio network (CRN); Signal to noise ratio (SNR); Primary
   users (PU); Secondary users (SU); Probability of false alarm (Pf);
   Probability of detection; Cyclostationary feature detection (CFD)
ID COGNITIVE RADIO; NETWORKS
AB With time there is an increase in demand and usage of wireless services and applications. For efficiently utilizing the network bandwidth and memory space resources, a cognitive radio network is necessary. Spectrum sensing is the major functionality in CRN. It is the most crucial state included since the entire functionality completely relies on this stage. Schemes like energy detector, matched filter, pilot-based coherent detection, etc. exist for spectrum sensing their performance degrades as the presence of noise increases. Thus cyclostationary detector fulfills the necessary specifications of discovering the spectrum in the presence of low SNR. In this technique, the periodicity exhibited by the signal is utilized and enhanced by taking the similarity using the auto-correlation. The peaks of frequencies thus form a resultant of the correlated signal with Fourier transform with certain specificity to the signal to determine the presence of a primary user. On the contrary, the non-periodicity and random nature of noise don't highlight it when taking correlation.
C1 [Mahajan, Kriti; Garg, Urvashi] Chandigarh Univ, Dept Comp Sci & Engn, Mohali, India.
C3 Chandigarh University
RP Mahajan, K (corresponding author), Chandigarh Univ, Dept Comp Sci & Engn, Mohali, India.
EM s.kritti98@gmail.com
RI mahajan, kriti/ABC-7558-2021
CR Abu Arqub O, 2020, SOFT COMPUT, V24, P12501, DOI 10.1007/s00500-020-04687-0
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   Camara TVRO, 2019, IEEE ACCESS, V7, P138512, DOI 10.1109/ACCESS.2019.2943300
   Chaurasiya RB, 2019, IEEE T CIRCUITS-I, V66, P4448, DOI 10.1109/TCSI.2019.2921831
   FCC, 2002, DOCKET 02 155
   Gardner WA, 2006, SIGNAL PROCESS, V86, P639, DOI 10.1016/j.sigpro.2005.06.016
   Koroupi F, 2012, SCI IRAN, V19, P767, DOI 10.1016/j.scient.2011.04.029
   Kriti Kaul A., 2017, INT J SCI RES COMPUT, V2, P127, DOI [10.32628/CSEIT174417, DOI 10.32628/CSEIT174417]
   Kriti Wasson V, 2015, INT J RES ELECT COMP, V3, P75
   KritiWasson V., 2015, FOREX IJCSR, V3, P149
   Lundén J, 2009, IEEE T SIGNAL PROCES, V57, P4182, DOI 10.1109/TSP.2009.2025152
   Mahapatra R, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS 2008), P253
   Serbes A, 2020, IEEE COMMUN LETT, V24, P57, DOI 10.1109/LCOMM.2019.2947043
   Shi YB, 2012, PHYSCS PROC, V25, P1720, DOI 10.1016/j.phpro.2012.03.301
   Srivastava V, 2005, IEEE COMMUN MAG, V43, P112, DOI 10.1109/MCOM.2005.1561928
   Tekbiyik K, 2019, IEEE ACCESS, V7, P138890, DOI 10.1109/ACCESS.2019.2942368
   Ustok RF, 2010, THESIS IZMIR I TECHN
   Xu ZJ, 2020, IEEE ACCESS, V8, P128930, DOI 10.1109/ACCESS.2020.3009181
NR 20
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37087
EP 37099
DI 10.1007/s11042-022-13527-2
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000832565900009
DA 2024-07-18
ER

PT J
AU Sun, J
   Zhang, Y
   Zhu, XL
   Zhang, YD
AF Sun, Jin
   Zhang, Yang
   Zhu, Xinglong
   Zhang, Yu-Dong
TI Enhanced individual characteristics normalized lightweight rice-VGG16
   method for rice seed defect recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rice seed; Defect recognition; Enhanced individual characteristics;
   Normalize; Lightweight; Convolutional neural network
AB The current rice seed defect recognition methods have several disadvantages, including the background segmentation of images, complex operation, and non-normalization processing. In this study, we proposed a enhanced individual characteristics normalized lightweight Rice-Visual Geometry Group Network 16(Rice-VGG16) method for rice seed defect recognition. Firstly, rice seed defects are divided, and the image processing steps are used to standardize the seed images and construct the datasets. Secondly, the fifth max-pooling layer is modified to the ave-pooling layer, and the activation function is defined as Leaky Rectified Linear Units(Leaky-ReLU) to enhance the individual characteristics and improve the recognition accuracy. Then, a batch normalization layer is added after the last convolution layer of each convolution group, the first full connection layer is removed, the node number of the second full connection layer is modified to 1024, and the model parameters are fine-tuned to carry out model lightweight. Thus the normalized lightweight Rice-VGG16 model is constructed to improve recognition speed. Experimental results with real datasets demonstrated that: the model was able to accurately identify rice seed defects, with the training accuracy of 99.63% and the recognition accuracy of 99.51%; compared with traditional VGG16 model, since the amount of training parameters has been reduced by 79.88%,the proposed method can reduce the training time per epoch and the recognition time by 18.83%,13.59%, respectively. The proposed method can be used for rice seed defect recognition or accurate grain grading and breeding.
C1 [Sun, Jin; Zhang, Yang] Yangzhou Univ, Coll Mech Engn, Yangzhou 225127, Jiangsu, Peoples R China.
   [Sun, Jin; Zhang, Yang; Zhu, Xinglong] Yangzhou Univ, China Joint Int Res Lab Agr & Agriprod Safety, Minist Educ China, Yangzhou 225009, Jiangsu, Peoples R China.
   [Sun, Jin; Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Yangzhou University; Yangzhou University; University of Leicester
RP Sun, J (corresponding author), Yangzhou Univ, Coll Mech Engn, Yangzhou 225127, Jiangsu, Peoples R China.; Sun, J (corresponding author), Yangzhou Univ, China Joint Int Res Lab Agr & Agriprod Safety, Minist Educ China, Yangzhou 225009, Jiangsu, Peoples R China.; Sun, J (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM sunjin1001@126.com
RI Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
FU National Natural Science Foundation of China [51,475,409]; Research
   Project of State Key Laboratory of Mechanical System and Vibration
   [MSV201810]; Yangzhou city -Yangzhou University of Science and
   Technology Cooperation Program Funds [YZ2020166]
FX The authors would like to thank all the reviewers for their valuable
   comments. This work is supported by National Natural Science Foundation
   of China (Grant No. 51,475,409), Research Project of State Key
   Laboratory of Mechanical System and Vibration (Grant No. MSV201810), and
   Yangzhou city -Yangzhou University of Science and Technology Cooperation
   Program Funds (No. YZ2020166).
CR Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   [Anonymous], 2013, P 2013 INT C MACH LE, DOI DOI 10.5555/2584691
   Bao YD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194119
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cui, 2019, AGR MECH RES, V41, P28, DOI [10.13427/j.cnki.njyi.2019.02.005, DOI 10.13427/J.CNKI.NJYI.2019.02.005]
   Desai SV, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0457-1
   Dubosclard P, 2015, PROC SPIE, V9534, DOI 10.1117/12.2182793
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Huang S, 2019, J SENSORS, V2019, DOI 10.1155/2019/2716975
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Labatut V., 2012, 5 INT C INF TECHN AL
   Liu ZH, 2020, J FOOD ENG, V266, DOI 10.1016/j.jfoodeng.2019.109698
   Lurstwut Benjamaporn, 2017, Agriculture and Natural Resources, V51, P383, DOI 10.1016/j.anres.2017.12.002
   Momin MA, 2017, COMPUT ELECTRON AGR, V140, P452, DOI 10.1016/j.compag.2017.06.023
   Muhammad NA., 2018, INDONESIAN J ELECT E, V12, P468, DOI [10.11591/ijeecs.v12.i2, DOI 10.11591/IJEECS.V12.I2.PP468-475]
   Nasiri A, 2019, POSTHARVEST BIOL TEC, V153, P133, DOI 10.1016/j.postharvbio.2019.04.003
   Patel VA, 2018, PROC SPIE, V10696, DOI 10.1117/12.2309482
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh KR, 2020, COMPLEX INTELL SYST, V6, P321, DOI 10.1007/s40747-020-00132-9
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vanitha, 2019, INT J RECENT TECH EN, V7, P534, DOI [10.1016/11940275, DOI 10.1016/11940275]
   Zhao ZC, 2014, LECT NOTES COMPUT SC, V8671, P680, DOI 10.1007/978-3-319-11331-9_81
   Zhou CQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143106
NR 28
TC 2
Z9 3
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3953
EP 3972
DI 10.1007/s11042-022-13420-y
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000828262900003
DA 2024-07-18
ER

PT J
AU Iriz, J
   Patricio, MA
   Berlanga, A
   Molina, JM
AF Iriz, Jesus
   Patricio, Miguel A.
   Berlanga, Antonio
   Molina, Jose M.
TI CONEqNet: convolutional music equalizer network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music equalization; Convolutional neural network; Music information
   retrieval
ID CLASSIFICATION
AB The process of parametric equalization of musical pieces seeks to highlight their qualities by cutting and/or stimulating certain frequencies. In this work, we present a neural model capable of equalizing a song according to the musical genre that is being played at a given moment. It is normal that (1) the equalization should adapt throughout the song and not always be the same for the whole song; and (2) songs do not always belong to a specific musical genre and may contain touches of different musical genres. The neural model designed in this work, called CONEqNet (convolutional music equalizer network), takes these aspects into account and proposes a neural model capable of adapting to the different changes that occur throughout a song and with the possibility of mixing nuances of different musical genres. For the training of this model, the well-known GTzan dataset, which provides 1,000 fragments of songs of 30 seconds each, divided into 10 genres, was used. The paper will show proofs of concept of the performance of the neural model.
C1 [Iriz, Jesus] MasMovil Engn Team, Madrid, Spain.
   [Patricio, Miguel A.; Berlanga, Antonio; Molina, Jose M.] Univ Carlos III Madrid, Appl Artificial Intelligence Grp, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Patricio, MA (corresponding author), Univ Carlos III Madrid, Appl Artificial Intelligence Grp, Madrid, Spain.
EM jesus.iriz.gonzalez@gmail.com; mpatrici@inf.uc3m.es; aberlan@ia.uc3m.es;
   molina@ia.uc3m.es
RI Patricio, Miguel A./AAZ-4876-2020; Berlanga, Antonio/L-2164-2014; Lopez,
   Jose/KHD-0318-2024; Molina, Jose/B-1956-2008
OI Patricio, Miguel A./0000-0002-9304-826X; Molina,
   Jose/0000-0002-7484-7357
FU public research projects of the Spanish Ministry of Science and
   Innovation [PID2020-118249RB-C22, PDC2021-121567-C22 -
   AEI/10.13039/501100011033]; Madrid Government (Comunidad de
   Madrid-Spain) [EPUC3M17]; private research project of Company BQ
FX This work was funded by the private research project of Company BQ, the
   public research projects of the Spanish Ministry of Science and
   Innovation PID2020-118249RB-C22 and PDC2021-121567-C22 -
   AEI/10.13039/501100011033, and the Madrid Government (Comunidad de
   Madrid-Spain) under the Multiannual Agreement with UC3M in the line of
   Excellence of University Professors (EPUC3M17) and in the context of the
   V PRICIT (Regional Programme of Research and Technological Innovation).
CR [Anonymous], LASTFM
   Bazgir O, 2021, BIOINFORMATICS, V37, pI42, DOI 10.1093/bioinformatics/btab336
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bohn DA, 1988, AUD ENG SOC C 6 INT
   Chen J., 2021, Applied Sciences, V11
   Cheng YH, 2021, ENG LET, V29, P312
   Choi YJ, 2021, 2021 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), DOI 10.1109/ICEIC51217.2021.9369805
   Dieleman S., 2014, Recommending music on Spotify with deep learning
   Eck D, 2005, INT COMP MUS C ICMC
   Elbir A., 2018, 2018 EL EL COMP SCI, P1
   George J, 2015, ARTIFICIAL INTELLIGE
   Goel Anshuman, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P285, DOI 10.1109/ICCCT.2014.7001506
   Hossan MA, 2010, 2010 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ICSPCS)
   Kaur C, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P465, DOI 10.1109/ICICI.2017.8365395
   Khonglah BK, 2016, DIGIT SIGNAL PROCESS, V48, P71, DOI 10.1016/j.dsp.2015.09.005
   Kundu P, 2022, LECT NOTES NETWORKS, V291
   Li T, 2019, IEEE INT CONF BIG DA, P6128, DOI [10.1109/BigData47090.2019.9005695, 10.1109/bigdata47090.2019.9005695]
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   Liu C, 2021, IEEE T WIREL COMMUN, V20, P1624, DOI 10.1109/TWC.2020.3034895
   Mandal Pratanu, 2020, Intelligent Computing in Engineering. Select Proceedings of RICE 2019. Advances in Intelligent Systems and Computing (AISC 1125), P17, DOI 10.1007/978-981-15-2780-7_3
   Narkhede Nandkishor, 2022, Information and Communication Technology for Competitive Strategies (ICTCS 2020): ICT: Applications and Social Interfaces. Lecture Notes in Networks and Systems (191), P155, DOI 10.1007/978-981-16-0739-4_15
   Narkhede Nandkishor, 2022, Computer Networks and Inventive Communication Technologies: Proceedings of Fourth ICCNCT 2021. Lecture Notes on Data Engineering and Communications Technologies (75), P439, DOI 10.1007/978-981-16-3728-5_33
   North A C., 1999, Psychology of Music, V27
   Patel R, 2021, LECT NOTES NETWORKS, V190
   Prabhu Nimesh Ramesh, 2018, Information Technology - New Generations. 15th International Conference on Information Technology. Advances in Intelligent Systems and Computing (AISC 738), P397, DOI 10.1007/978-3-319-77028-4_52
   Press W. H., 2007, NUMERICAL RECIPES 3, DOI [https://doi.org/10.1063/1.2820230, DOI 10.1063/1.2820230]
   Qiu L, 2021, MATHEMATICS-BASEL, V9
   Rentfrow PJ, 2012, SOC PERSONAL PSYCHOL, V6, P402, DOI 10.1111/j.1751-9004.2012.00434.x
   Santika IKG, 2021, KINETIK GAME TECHNOL
   Savchenko AV, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108248
   Schreiber H., 2015, ISMIR, P241
   Srinivasa Murthy YV., 2018, REV ACM COMPUT SURV, V51, P6
   Sturm BL, 2012, MIRUM 2012 P 2 INT A
   Tagtraum Industries, TAGTRAUM GENRE ANNOT
   Tjoa S, MEL FREQ CEPSTR COEF
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Välimäki V, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050129
   Yue ZY, 2021, COGN COMPUT, V13, P795, DOI 10.1007/s12559-019-09639-x
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3911
EP 3930
DI 10.1007/s11042-022-12523-w
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000826828100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Garg, A
AF Garg, Anil
TI Speech enhancement using long short term memory with trained speech
   features and adaptive wiener filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech processing; Speech enhancement; Empirical mean decomposition;
   Empirical mean curve decomposition; Wiener filter
ID NONNEGATIVE MATRIX FACTORIZATION; NOISE; MASKING; MODEL
AB Speech enhancement is the process of enhancing the clarity and intelligibility of speech signals that have been degraded due to background noise. With the assistance of deep learning, a novel speech signal enhancement model is introduced in this research. The proposed model is divided into two phases: (i) Training (ii) Testing. In the training phase, the noise spectrum and signal spectrum are estimated via a Non-negative Matrix Factorization (NMF) from the noisy input signal. Then, Empirical Mean Decomposition (EMD) features are extracted from the Wiener filter. The de-noised signal is acquired from EMD, the bark frequency is evaluated and the Fractional Delta AMS features are extracted. The key contribution of this study is the use of the Long Short Term Memory (LSTM) model to properly estimate the tuning factor eta of the Wiener filter for all input signals. The LSTM was trained by the extracted features (EMD) via a modified wiener filter for decomposing the spectral signal and the output of EMD is the denoised enhanced speech signal. A comparative evaluation is carried out between the proposed and existing models in terms of error measures.
C1 [Garg, Anil] Maharishi Markandeshwar Deemed Univ, Maharishi Markandeshwar Engn Coll, ECE Dept, Ambala 134007, Haryana, India.
RP Garg, A (corresponding author), Maharishi Markandeshwar Deemed Univ, Maharishi Markandeshwar Engn Coll, ECE Dept, Ambala 134007, Haryana, India.
EM anilgarg0778@gmail.com
RI Garg, Dr. Anil/KIB-3773-2024
CR Anita J. S., 2019, MULTIMEDIA RES, V2, P9
   Basabi Chakraborty, 2019, Multimedia Res, V2, P37
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Chai L, 2021, IEEE-ACM T AUDIO SPE, V29, P106, DOI 10.1109/TASLP.2020.3036783
   Chung H, 2017, SPEECH COMMUN, V87, P18, DOI 10.1016/j.specom.2016.11.003
   Cohen I, 2001, SIGNAL PROCESS, V81, P2403, DOI 10.1016/S0165-1684(01)00128-1
   Cui XY, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2021.107927
   Darekar A. P., 2019, Multimed Res., V2, P12
   Dionelis N, 2018, IEEE-ACM T AUDIO SPE, V26, P937, DOI 10.1109/TASLP.2018.2800525
   Garg A, 2020, ENHANCEMENT SPEECH S
   Garg A, 2020, COMM
   Gelderblom FB, 2019, IEEE-ACM T AUDIO SPE, V27, P583, DOI 10.1109/TASLP.2018.2882738
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Kim HY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020721
   Kolbæk M, 2019, IEEE-ACM T AUDIO SPE, V27, P283, DOI 10.1109/TASLP.2018.2877909
   Kuqi B, 2023, J SUSTAIN FINANC INV, V13, P92, DOI 10.1080/20430795.2021.1883986
   Lavanya T, 2020, IEEE-ACM T AUDIO SPE, V28, P1315, DOI 10.1109/TASLP.2020.2986877
   Michelsanti D, 2021, IEEE-ACM T AUDIO SPE, V29, P1368, DOI 10.1109/TASLP.2021.3066303
   Nicolson A, 2018, INTERSPEECH, P1606, DOI 10.21437/Interspeech.2018-1134
   NOIZEUS, NOIZEUS NOIS SPEECH
   Pfeifenberger L, 2019, IEEE-ACM T AUDIO SPE, V27, P2162, DOI 10.1109/TASLP.2019.2941592
   Plapous C, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P289
   Plapous C, 2006, IEEE T AUDIO SPEECH, V14, P2098, DOI 10.1109/TASL.2006.872621
   Reddy BG, 2020, EARLY PUBLIC OUTLOOK
   Sadeghi M, 2020, IEEE-ACM T AUDIO SPE, V28, P1788, DOI 10.1109/TASLP.2020.3000593
   Saleem N, 2021, APPL ACOUST, V178, DOI 10.1016/j.apacoust.2021.108007
   Saleem N, 2020, IEEE ACCESS, V8, P160581, DOI 10.1109/ACCESS.2020.3021061
   Santiago P, 2017, ARXIV PREPRINT ARXIV
   Shu XF, 2020, NEURAL PROCESS LETT, V51, P2945, DOI 10.1007/s11063-020-10212-z
   Sun XW, 2020, IEEE-ACM T AUDIO SPE, V28, P2837, DOI 10.1109/TASLP.2020.3030495
   Taha T.M., 2018, Int. J. Comput. Appl, V179, P1
   Triantafyllos A, 2018, ARXIV PREPRINT ARXIV
   Venkateswarlu S, 2011, GLOBAL J COMPUT SCI
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang ZY, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107647
   Wood SUN, 2019, IEEE-ACM T AUDIO SPE, V27, P2150, DOI 10.1109/TASLP.2019.2937174
   Xiang Y, 2020, IEEE-ACM T AUDIO SPE, V28, P1826, DOI 10.1109/TASLP.2020.2997118
   Xu LT, 2021, APPL ACOUST, V174, DOI 10.1016/j.apacoust.2020.107732
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yu HJ, 2020, SPEECH COMMUN, V125, P142, DOI 10.1016/j.specom.2020.10.007
   Yu HJ, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/bhi.2019.8834456
   Zhu YY, 2020, APPL ACOUST, V170, DOI 10.1016/j.apacoust.2020.107511
   Zou Xia, 2007, Journal of Electronics (China), V24, P332, DOI 10.1007/s11767-005-0174-y
NR 46
TC 6
Z9 6
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3647
EP 3675
DI 10.1007/s11042-022-13302-3
EA JUL 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825246000011
PM 35855772
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Sharma, SK
   Vijayakumar, K
   Kadam, VJ
   Williamson, S
AF Sharma, Sudhir Kumar
   Vijayakumar, K.
   Kadam, Vinod J.
   Williamson, Sheldon
TI Breast cancer prediction from microRNA profiling using random subspace
   ensemble of LDA classifiers via Bayesian optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; MiRNAs; Linear discriminant analysis; Ensemble learning;
   Random subspace; Bayesian optimization; Hyperparameter tuning; GEO
   dataset
ID GENE-EXPRESSION; CIRCULATING MICRORNAS; CLASSIFICATION; SELECTION;
   IDENTIFICATION; BIOMARKERS; VALIDATION; SIGNATURES; MECHANISM; GENOMICS
AB Breast cancer rates are rising. It also remains the second principal reason for cancer-related mortality in females, and the mortality rate is also drastically rising. In recent years, MicroRNAs (miRNAs) have emerged to have a large potential as biomarkers because of their effective roles in human disease diagnosis (including breast cancer). miRNAs are small (short), regulatory, and evolutionarily conserved non-coding RNAs (ncRNAs) molecules (with a length of about 22 nucleotides) that are present in all eukaryotic cells. There are many studies available in the literature that focus on recent circulating miRNAs research, their relationships to human diseases, their role as a potential biomarker, etc. Therefore, in this study we used three key techniques for classification of breast cancer using miRNAs features: Linear Discriminant Analysis (LDA), Random Subspace Ensemble (RSE) and Bayesian Hyperparameter optimization (BHO). Linear Discriminant Analysis (LDA) is a simple but most practical and computationally attractive classification approach. Random Subspace Ensemble (RSE) is capable of producing a robust ensemble for classification. Some previous research showed applications of Bayesian optimization in many engineering optimization problems. Notably, it is a recently applied for hyperparameter tuning in various ensemble classifiers. Therefore, the potential application of the RSE of LDA classifiers (LDA as a base classifier) with BHO method to boost the predicting accuracy of breast cancer diagnosis using miRNAs profiling dataset, has been studied in this study. A publicly available dataset of serum miRNA profiles obtained from the GEO dataset (accession code GSE106817) has been applied for validation. A variety of output measurements were employed to determine the performances and efficiencies of the proposed model and other classifiers. The proposed approach exhibited successful overall performance. The results were directly compared with the individual LDA classifier and other established state-of-the-art classifiers. The outcomes point out that the approach is superior in terms of different efficiency indicators to the LDA and all established state-of-the-art models used in the study. Study simulations, outcomes, and mathematical investigations have illustrated that the technique presented is a practical and advantageous model for the classification of breast cancer from miRNA profiling. This model may usefully be employed in other cancer classifications from miRNA profiling.
C1 [Sharma, Sudhir Kumar] Inst Informat Technol & Management, Dept Comp Sci, New Delhi, India.
   [Vijayakumar, K.] St Josephs Inst Technol, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Kadam, Vinod J.] Dr Babasaheb Ambedkar Technol Univ, Dept Informat Technol, Lonere, Maharashtra, India.
   [Williamson, Sheldon] Ontario Tech Univ, Fac Engn & Appl Sci, Oshawa, ON, Canada.
C3 Dr. Babasaheb Ambedkar Technological University
RP Sharma, SK (corresponding author), Inst Informat Technol & Management, Dept Comp Sci, New Delhi, India.
EM sharmasudhir08@gmail.com; mkvijay@msn.com; vjkadam@dbatu.ac.in;
   sheldon.williamson@ieee.org
RI Kadam, VJ/ABS-6090-2022; Sharma, Sudhir/ITT-7007-2023; K,
   VIJAYAKUMAR/I-6554-2019
OI Kadam, VJ/0000-0003-4798-7984; Sharma, Sudhir/0000-0001-6932-9160; K,
   VIJAYAKUMAR/0000-0002-5379-5703
CR Abolghasemi M, 2020, J CELL PHYSIOL, V235, P5008, DOI 10.1002/jcp.29396
   Adorada A, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS), P165
   Ali L, 2021, NEURAL COMPUT APPL, V33, P2783, DOI 10.1007/s00521-020-05157-2
   Ardekani Ali M., 2010, Avicenna Journal of Medical Biotechnology, V2, P161
   Barrett T, 2013, NUCLEIC ACIDS RES, V41, pD991, DOI 10.1093/nar/gks1193
   Bartel DP, 2004, CELL, V116, P281, DOI 10.1016/S0092-8674(04)00045-5
   Bhat RR, 2017, ARXIV PREPRINT ARXIV
   Bhat S.A., 2019, Advances in Biomarker Sciences and Technology, V1, P1, DOI DOI 10.1016/J.ABST.2019.05.001
   Biswas A, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4049742
   Blanco R, 2004, INT J PATTERN RECOGN, V18, P1373, DOI 10.1142/S0218001404003800
   Chang JTH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168284
   Chang JH, 2002, METHODS OF MICROARRAY DATA ANALYSIS II, P169, DOI 10.1007/0-306-47598-7_12
   Cookson VJ, 2012, CELL ONCOL, V35, P301, DOI 10.1007/s13402-012-0089-1
   Cuk K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076729
   Danaee Padideh, 2017, Pac Symp Biocomput, V22, P219, DOI 10.1142/9789813207813_0022
   Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94
   Drozdov I, 2009, CANCER-AM CANCER SOC, V115, P1638, DOI 10.1002/cncr.24180
   Edgar R, 2002, NUCLEIC ACIDS RES, V30, P207, DOI 10.1093/nar/30.1.207
   Fan TT, 2018, CANCER SCI, V109, P2897, DOI 10.1111/cas.13725
   Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Guillen P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P1403, DOI [10.1109/CSCI.2016.0270, 10.1109/CSCI.2016.269]
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hamam R, 2017, CELL DEATH DIS, V8, DOI 10.1038/cddis.2017.440
   He L, 2004, NAT REV GENET, V5, P522, DOI 10.1038/nrg1379
   Heneghan HM, 2010, ANN SURG, V251, P499, DOI 10.1097/SLA.0b013e3181cc939f
   Hickish B, 2020, INT J RAIL TRANSP, V8, P307, DOI 10.1080/23248378.2019.1669500
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Iorio MV, 2005, CANCER RES, V65, P7065, DOI 10.1158/0008-5472.CAN-05-1783
   Jarry J, 2014, MOL ONCOL, V8, P819, DOI 10.1016/j.molonc.2014.02.009
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jin X, 2006, LECT NOTES COMPUT SC, V3916, P106
   Kadam VJ, 2020, J DISCRET MATH SCI C, V23, P115, DOI 10.1080/09720529.2020.1721871
   Kadam VJ, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1397-z
   Karabulut EM, 2017, BIOMED RES-INDIA, V28, P1016
   Kodahl AR, 2014, MOL ONCOL, V8, P874, DOI 10.1016/j.molonc.2014.03.002
   Lan G, 2020, ARXIV PREPRINT ARXIV
   Li C., 2018, Deep learning in pan-cancer early detection based on gene expression
   Liu QZ, 2011, BMC GENOMICS, V12, DOI 10.1186/1471-2164-12-S5-S1
   Mar-Aguilar F, 2013, DIS MARKERS, V34, P163, DOI [10.1155/2013/259454, 10.3233/DMA-120957]
   Matamala N, 2015, CLIN CHEM, V61, P1098, DOI 10.1373/clinchem.2015.238691
   MathWorks, 2019, BAYES MATL R2019A DO
   McDermott AM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087032
   Mitchell PS, 2008, P NATL ACAD SCI USA, V105, P10513, DOI 10.1073/pnas.0804549105
   Estal RM, 2013, BREAST CANCER RES TR, V142, P19, DOI 10.1007/s10549-013-2723-7
   Ng EKO, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053141
   Ono S, 2015, J CLIN MED, V4, P1890, DOI 10.3390/jcm4101890
   Papadaki Chara, 2019, Oncotarget, V10, P966, DOI 10.18632/oncotarget.26629
   Papadaki C, 2018, BREAST CANCER RES, V20, DOI 10.1186/s13058-018-1001-3
   Qiu CX, 2012, SCI REP-UK, V2, DOI 10.1038/srep00318
   RAO CR, 1948, J ROY STAT SOC B, V10, P159
   Raza Khalid, 2015, Int J Bioinform Res Appl, V11, P397
   Rehman O, 2019, CANCERS, V11, DOI 10.3390/cancers11030431
   Sailim W, 2014, THESIS PRINCE SONGKL
   Sarkar JP, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCCO'19 COMPANION), P1846, DOI 10.1145/3319619.3326836
   Sathipati SY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34604-3
   Schrauder MG, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029770
   Schwarzenbach H, 2014, NAT REV CLIN ONCOL, V11, P145, DOI 10.1038/nrclinonc.2014.5
   Sharifi-Noghabi H., 2018, BIORXIV, DOI [10.1101/276055, DOI 10.1101/276055]
   Shimomura A, 2016, CANCER SCI, V107, P326, DOI 10.1111/cas.12880
   Shin J, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00236
   Swellam M, 2018, CLIN BIOCHEM, V56, P47, DOI 10.1016/j.clinbiochem.2018.04.013
   Tan AC., 2003, Appl Bioinformatics, V2, pS75, DOI DOI 10.1186/1471-2105-9-275
   Tran TH, 2019, INT J MACH LEARN CYB, V10, P1687, DOI 10.1007/s13042-018-0846-1
   Le TT, 2021, MATER STRUCT, V54, DOI 10.1617/s11527-021-01646-5
   Turgut S., 2018, 2018 ELECT ELECT COM, P1
   van Schooneveld E, 2012, BREAST CANCER RES, V14, DOI 10.1186/bcr3127
   Vijayakumar K, 2021, CONCURRENT ENG-RES A, V29, P275, DOI 10.1177/1063293X211025105
   Vijayakumar K, 2021, SIGNAL IMAGE PROCESS, DOI [10.1007/978-981-15-6141-2_9, DOI 10.1007/978-981-15-6141-2_9]
   Wang FJ, 2010, GYNECOL ONCOL, V119, P586, DOI 10.1016/j.ygyno.2010.07.021
   Wang Y, 2005, COMPUT BIOL CHEM, V29, P37, DOI 10.1016/j.compbiolchem.2004.11.001
   Williamson S, 2022, MULTIMED TOOLS APPL, V81, P36869, DOI 10.1007/s11042-021-11114-5
   Witwer KW, 2015, CLIN CHEM, V61, P56, DOI 10.1373/clinchem.2014.221341
   Won S.-B.C.a.H.-H., 2003, APBC, V19, P189
   Yokoi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06434-4
   Yu XK, 2018, J BREAST CANCER, V21, P363, DOI 10.4048/jbc.2018.21.e56
   Yuan MD, 2019, NEUROCOMPUTING, V356, P228, DOI 10.1016/j.neucom.2019.05.014
   Zhang K, 2017, GENE, V619, P10, DOI 10.1016/j.gene.2017.03.038
   Zhang L, 2015, BREAST CANCER RES TR, V154, P423, DOI 10.1007/s10549-015-3591-0
   Zheng G., 2003, Prof. of Critical Assessment of Microarray Data Analysis, P63
NR 81
TC 6
Z9 6
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41785
EP 41805
DI 10.1007/s11042-021-11653-x
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700011
DA 2024-07-18
ER

PT J
AU Song, XW
   Song, XL
   Yang, L
   Li, ML
   Hou, CP
   Xiong, ZX
AF Song, Xiaowei
   Song, Xianli
   Yang, Lei
   Li, Menglong
   Hou, Chunping
   Xiong, Zixiang
TI Body size measurement based on deep learning for image segmentation by
   binocular stereovision system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image segmentation; PSPNet; Binocular stereovision; Body
   size measurement
ID GARMENT PATTERN; PARAMETRIC DESIGN; DIMENSIONS; PREDICTION; PRECISION;
   RECOVERY
AB This paper proposes a body size measurement system based on deep learning for image segmentation by binocular stereovision for clothing design. A pair of binocular stereo cameras and a precise revolving platform are used to collect the stereo images of the entire human body. A more diverse human body dataset is constructed for deep learning. An optimized girth semantic segmentation model based on PSPNet network is well trained by deep learning to realize the automatic segmentation of more girth regions in human body images taken from multiple angles. Color subspaces with larger spacing in color spaces are designed to perform more effective stereo matching. The space coordinates of 3D point corresponding to each stereo matching point pair are calculated in the same coordinate system. The space coordinates are reversely revolved back to the intial coordinates of the same coordinate system according to the revolving angle of the platform. Girths of bust, waist, hip and thigh are measured by calculating the fitting curve length after girth fitting of the markers thereon. Height of bust, waist, hip, thigh and entire body are estimated according to the ratio of the 3D distance to the number of pixels between two adjacent markers on the same girth. Quantitative experiments on many human subjects demonstrate that the proposed system can measure body size intelligently and accurately for clothing design under the regulation of China national standards GB/T 2664-2017, GA258-2009, GB/T 2665-2017 and textile industry standard FZ/T 73029-2019, FZ/T 73017-2014, FZ/ T 73059-2017, FZ/T 73022-2019.
C1 [Song, Xiaowei; Song, Xianli; Yang, Lei] Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou, Peoples R China.
   [Song, Xiaowei] Kaifeng Univ, Kaifeng, Peoples R China.
   [Li, Menglong; Hou, Chunping] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Xiong, Zixiang] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.
C3 Zhongyuan University of Technology; Tianjin University; Texas A&M
   University System; Texas A&M University College Station
RP Yang, L (corresponding author), Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou, Peoples R China.
EM sxw-tju@163.com; annieyanglei@163.com
RI Li, Menglong/ITT-3281-2023
OI Li, Menglong/0000-0002-2766-7329; Yang, Lei/0000-0002-4864-2702
FU ZhongYuan Science and Technology Innovation Leading Talent Program
   [214200510013]; Key Research Project of Colleges and Universities in
   Henan Province [19A510005, 21A510016, 21A520052]; Scientific Research
   Grants and Start-up Projects for Overseas Student [HRSS2021[36]]; Major
   Project Achievement Cultivation Plan of Zhongyuan University of
   Technology [K2020ZDPY02]
FX This work was supported in part by the ZhongYuan Science and Technology
   Innovation Leading Talent Program under Grant 214200510013, in part by
   the Key Research Project of Colleges and Universities in Henan Province
   under Grant 19A510005, Grant 21A510016, and Grant 21A520052, in part by
   the Scientific Research Grants and Start-up Projects for Overseas
   Student under Grant HRSS2021[36], and in part by the Major Project
   Achievement Cultivation Plan of Zhongyuan University of Technology under
   Grant K2020ZDPY02.
CR Adikari SB, 2020, ADV HUM-COMPUT INTER, V2020, DOI 10.1155/2020/1314598
   [Anonymous], 2014, 730172014 MIIT FZT
   [Anonymous], VITUS SMART 30
   [Anonymous], LOOK PERSON
   [Anonymous], VITUS SMART LC3
   AQSIQ, 2017, 26652017 AQSIQ GBT
   AQSIQ, 2017, 161602017 AQSIQ GBT
   AQSIQ, 2009, 2582009 AQSIQ GA
   AQSIQ, 2017, 26642017 AQSIQ GBT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benard C, 2008, INT INTEG REL WRKSP, P7, DOI 10.1109/AFGR.2008.4813453
   Bragança S, 2018, WORK, V59, P325, DOI 10.3233/WOR-182684
   Bragança S, 2017, WORK, V57, P9, DOI 10.3233/WOR-172532
   Chen Y, 2016, IEEE T VIS COMPUT GR, V22, P2000, DOI 10.1109/TVCG.2015.2478779
   cyberbrics, US
   Daanen H, 1997, P SOC PHOTO-OPT INS, V3023, P6, DOI 10.1117/12.269757
   DApuzzo N., 2007, RECENT ADV 3D FULL B
   Dekker L., 2000, 3D HUMAN BODY MODELL
   Ditus, US
   Domingues A, 2016, TECHNOL HEALTH CARE, V24, P251, DOI 10.3233/THC-151116
   Gu BF, 2019, TEXT RES J, V89, P3792, DOI 10.1177/0040517518821914
   Gu BF, 2017, TEXT RES J, V87, P669, DOI 10.1177/0040517516636001
   Gu BF, 2017, J TEXT I, V108, P140, DOI 10.1080/00405000.2016.1160756
   Han H, 2010, INT J IND ERGONOM, V40, P530, DOI 10.1016/j.ergon.2010.06.002
   Hu JL, 2009, 2009 5TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND MOBILE COMPUTING, VOLS 1-8, P5154
   Jamil A., 2020, IOP Conference Series: Earth and Environmental Science, V542, DOI 10.1088/1755-1315/542/1/012036
   Jiang XY, 2021, INFORM FUSION, V73, P22, DOI 10.1016/j.inffus.2021.02.012
   Lei JJ, 2021, IEEE T CIRC SYST VID, V31, P2686, DOI 10.1109/TCSVT.2020.3027616
   Li HL, 2019, IEEE ACCESS, V7, P123334, DOI 10.1109/ACCESS.2019.2938179
   Li ZX, 2013, IEEE ENG MED BIO, P366, DOI 10.1109/EMBC.2013.6609513
   Liu KX, 2019, INT J IND ERGONOM, V72, P212, DOI 10.1016/j.ergon.2019.05.012
   Liu KX, 2019, IEEE ACCESS, V7, P48830, DOI 10.1109/ACCESS.2019.2906261
   Liu KX, 2018, COMPUT AIDED DESIGN, V104, P113, DOI 10.1016/j.cad.2018.07.003
   Liu KX, 2018, INT J IND ERGONOM, V65, P46, DOI 10.1016/j.ergon.2018.01.013
   Liu KX, 2017, J TEXT I, V108, P2107, DOI 10.1080/00405000.2017.1315794
   Liu KX, 2017, KNOWL-BASED SYST, V133, P174, DOI 10.1016/j.knosys.2017.07.007
   Liu YY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195600
   Liu ZB, 2017, IEEE T CYBERNETICS, V47, P695, DOI 10.1109/TCYB.2016.2524406
   Liu Z, 2014, INT J CLOTH SCI TECH, V26, P118, DOI 10.1108/IJCST-02-2013-0009
   Lu JM, 2010, IEEE T INSTRUM MEAS, V59, P2048, DOI 10.1109/TIM.2009.2031847
   Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI [10.1109/TMAG.2017.2763198, 10.1007/s11263-018-1117-z]
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   MIIT, 2017, 730592017 MIIT FZT
   MIIT, 2019, GUID DEV METH VEH SO
   National health commission of the People's Republic of China, 2019, GB/T 50123-2019
   Pan QJ, 2010, LASER INFRARED
   Penders B, 2015, J PEDIATR ENDOCR MET, V28, P1357, DOI 10.1515/jpem-2015-0172
   [彭三城 Peng Sancheng], 2005, [计算机应用研究, Application Research of Computers], V22, P1
   Ran Q, 2020, COMPUT GRAPH-UK, V87, P43, DOI 10.1016/j.cag.2020.01.003
   Rativa D, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2797983
   Shah J, 2019, 2019 INT C ADV COMPU
   Song X, 2013, NEW DEPTH MEASURING
   Su JQ, 2019, TEXT RES J, V89, P2199, DOI 10.1177/0040517518790975
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Treleaven P, 2007, COMPUTER, V40, P28, DOI 10.1109/MC.2007.225
   Uhm T, 2015, MEASUREMENT, V61, P169, DOI 10.1016/j.measurement.2014.10.044
   Vitali A, 2018, VIRTUAL PHYS PROTOTY, V13, P131, DOI 10.1080/17452759.2018.1474082
   Wang ZJ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061140
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Xia LK, 2019, MULTIMED TOOLS APPL, V78, P11291, DOI 10.1007/s11042-018-6645-6
   Xu HH, 2013, SENSORS-BASEL, V13, P11362, DOI 10.3390/s130911362
   Xu Yang Gan, 2020, Journal of Physics: Conference Series, V1529, DOI 10.1088/1742-6596/1529/2/022067
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang L, 2020, IEEE ACCESS, V8, P160338, DOI 10.1109/ACCESS.2020.3021019
   Yao M., 2019, IEEE ACCESS, P1
   Zhang JJ, 2020, J TEXT I, V111, P1324, DOI 10.1080/00405000.2019.1694351
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng XT, 2020, 2020 12TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P466, DOI [10.1109/icaci49185.2020.9177788, 10.1109/ICACI49185.2020.9177788]
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   US
NR 71
TC 1
Z9 1
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42547
EP 42572
DI 10.1007/s11042-021-11470-2
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700024
DA 2024-07-18
ER

PT J
AU Hu, Q
   Hu, SH
   Ma, XL
   Zhang, FZ
   Fang, J
AF Hu, Qiu
   Hu, Shaohai
   Ma, Xiaole
   Zhang, Fengzhen
   Fang, Jing
TI MRI Image Fusion Based on Optimized Dictionary Learning and Binary Map
   Refining in Gradient Domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clinical application; Medical image fusion; Dictionary learning; Fast
   iterative shrinkage thresholding algorithm; Gradient domain guided image
   filtering
ID WAVELET TRANSFORM; MULTI-FOCUS; ALGORITHM
AB The insufficient ability of edge feature extraction and high complexity limit the ability of sparse representation to obtain better medical image fusion performance. In this letter, we propose a novel multimodal medical image fusion method with optimized dictionary learning and binary map refining. The optimized dictionary learning uses loop iterations between separable FISTA and manifold-based conjugate gradient algorithm to catch detail texture features in detail layer, and the binary map refining solution adopts Gabor energy measurement with GDGIF to reserve structure and brightness characteristics in base layer. Experimental results of various medical images and clinical applications indicate the effectiveness of the proposed method.
C1 [Hu, Qiu; Hu, Shaohai; Ma, Xiaole] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Hu, Qiu; Hu, Shaohai; Ma, Xiaole] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Zhang, Fengzhen] Chinese Acad Sci, Natl Astron Observ, Key Lab Solar Act, Beijing 100101, Peoples R China.
   [Fang, Jing] Shandong Normal Univ, Sch Phys & Elect, Shandong Prov Key Lab Med Phys & Image Proc Techn, Jinan 250014, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Chinese
   Academy of Sciences; National Astronomical Observatory, CAS; Shandong
   Normal University
RP Hu, SH (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.; Hu, SH (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM shhu@bjtu.edu.cn
FU Natural Science Foundation of China [62002208]; Fundamental Research
   Funds for the Central Universities [2021JBM009]; Youth Science
   Foundation Project of China [61902371]
FX This work was supported by the Natural Science Foundation of China
   [Grant No. 62172030]; the Fundamental Research Funds for the Central
   Universities [Grant No. 2021JBM009]; Youth Science Foundation Project of
   China [Grant No. 61902371]; the Natural Science Foundation of China
   [Grant No. 62002208].
CR Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Daneshvar S, 2010, INFORM FUSION, V11, P114, DOI 10.1016/j.inffus.2009.05.003
   Elad M, 2009, IEEE T INFORM THEORY, V55, P4701, DOI 10.1109/TIT.2009.2027565
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   He C, 2002, IEEE T MULTIMEDIA, V4, P528, DOI 10.1109/TMM.2002.806534
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu Q, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2019.115758
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kim M, 2016, INFORM FUSION, V27, P198, DOI 10.1016/j.inffus.2015.03.003
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Lalotra B, 2016, MATEC WEB CONF, V57, DOI 10.1051/matecconf/20165701021
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li X, 2021, IEEE SYST J, V15, P114, DOI 10.1109/JSYST.2019.2958874
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu SQ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/156043
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qi GQ, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040061
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Shi JR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138028
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   Wang L, 2014, IEEE T BIO-MED ENG, V61, P197, DOI 10.1109/TBME.2013.2279301
   Wang QZ, 2015, INFORM FUSION, V26, P103, DOI 10.1016/j.inffus.2015.01.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang Y, 2016, IEEE SENS J, V16, P3735, DOI 10.1109/JSEN.2016.2533864
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao WD, 2017, IEEE T INSTRUM MEAS, V66, P2283, DOI 10.1109/TIM.2017.2700198
   Zhu ZQ, 2019, IEEE ACCESS, V7, P20811, DOI 10.1109/ACCESS.2019.2898111
   Zhu ZQ, 2016, NEUROCOMPUTING, V214, P471, DOI 10.1016/j.neucom.2016.06.036
   Zong JJ, 2017, BIOMED SIGNAL PROCES, V34, P195, DOI 10.1016/j.bspc.2017.02.005
NR 48
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2539
EP 2561
DI 10.1007/s11042-022-12225-3
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000819342400006
DA 2024-07-18
ER

PT J
AU Lau, LK
   Chan, K
AF Lau, L. K.
   Chan, Kwok
TI Tree structure convolutional neural networks for gait-based gender and
   age classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender classification; Age estimation; Gait energy image; Convolutional
   neural network
AB Gender classification and age estimation are tasks in which humans excel. If gender and age of human can be recognized automatically from images, it will be very helpful in many applications such as intelligent surveillance, micromarketing, etc. We propose a framework for gender and age classification through gait analysis. Gait-based recognition is a feasible approach as the gait of human subject can still be perceived at a long distance. The spatio-temporal gait features are concisely represented as Gait Energy Image (GEI), which is then input to a tree structure convolutional neural network (CNN). We train and test the first model on a single-view gait dataset. Based on the tree structure CNN framework, we propose a larger model for gender and age classification with the multi-view gait dataset. Our models can achieve gender classification accuracy of 97.42% and 99.11% on single-view gait and multi-view gait respectively. We then use our model to perform age group estimation and binary (young and elder groups) classification. Also, our models can achieve the best performance in specific age estimation in terms of various numerical measures than various recently proposed methods.
C1 [Lau, L. K.; Chan, Kwok] City Univ Hong Kong, Dept Elect Engn, 83 Tat Chee Ave, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Chan, K (corresponding author), City Univ Hong Kong, Dept Elect Engn, 83 Tat Chee Ave, Hong Kong, Peoples R China.
EM lokklau2-c@my.cityu.edu.hk; itklchan@cityu.edu.hk
RI Chan, Kwok-Leung/HNI-1105-2023
FU Hong Kong Innovation and Technology Commission (InnoHK Project CIMDA)
FX The work described in this paper was supported by Hong Kong Innovation
   and Technology Commission (InnoHK Project CIMDA).
CR [Anonymous], OU ISIR GAIT DATABAS
   [Anonymous], CASIA GAIT DATABASE
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   ChewYean Yam, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P1
   Chi Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P386, DOI 10.1007/978-3-030-58529-7_23
   De Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3834, DOI 10.1109/ICPR.2010.934
   Dey Emon Kumar, 2013, International Journal of Advanced Computer Science, V3, P428
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Harb H, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P733
   Hema M., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1163, DOI 10.1109/ICOEI.2019.8862788
   Hu MD, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P869, DOI 10.1109/ICIG.2009.94
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li X, 2018, MULTIMED TOOLS APPL, V77, P28333, DOI 10.1007/s11042-018-6049-7
   Mansouri N, 2018, IET COMPUT VIS, V12, P69, DOI 10.1049/iet-cvi.2017.0055
   Nabila M, 2018, IET BIOMETRICS, V7, P116, DOI 10.1049/iet-bmt.2016.0176
   Russel NS, 2021, IET IMAGE PROCESS, V15, P239, DOI 10.1049/ipr2.12024
   Sakata Atsuya, 2019, IPSJ Transactions on Computer Vision and Applications, V11, DOI 10.1186/s41074-019-0054-2
   Sakata A, 2020, P IEEE INT JOINT C B, P1, DOI DOI 10.1109/IJCB48548.2020.9304914
   Samangooei S., 2011, Multibiometrics for Human Identification
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Tian Q, 2018, IMAGE VISION COMPUT, V69, P9, DOI 10.1016/j.imavis.2017.10.003
   XU C, 2021, P IEEE WINT C APPL C, P3460, DOI DOI 10.1109/WACV48630.2021.00350
   Xu C., 2017, IPSJ TCVA, V9, P24, DOI DOI 10.1186/S41074-017-0035-2
   Xu C, 2019, MACH VISION APPL, V30, P629, DOI 10.1007/s00138-019-01015-x
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
   Zaghbani S, 2018, COMPUT ELECTR ENG, V68, P337, DOI 10.1016/j.compeleceng.2018.04.012
   Zhang C, 2016, INT CONF ACOUST SPEE, P2832, DOI 10.1109/ICASSP.2016.7472194
   Zhang D, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P62
NR 30
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2145
EP 2164
DI 10.1007/s11042-022-13186-3
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000813560600001
DA 2024-07-18
ER

PT J
AU Barges, E
   Thabet, E
AF Barges, Entesar
   Thabet, Eman
TI GLDM and Tamura features based KNN and particle swarm optimization for
   automatic diabetic retinopathy recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinopathy recognition; SVM; KNN; GLDM; GLCM; GLRLM; PSO; Tamura
   features
ID BLOOD-VESSEL; CLASSIFICATION; SEGMENTATION; TEXTURE; IDENTIFICATION
AB Diabetic retinopathy is one of the significant investigated topics in the last few years since blindness could be the outcome of unchecked and serious diabetic retinopathy cases. Detection and recognition of DR at the beginning can help in reducing the risk of vision loss and save health significantly. Therefore, this paper proposes three different approaches in terms of features extraction and classification. The proposed approaches introduced three classifiers which are SVM, KNN, and DA as well as three types of the statistical texture features techniques: GLDM, GLCM, and GLRLM. So that for every approach, each proposed classifier is tested on every single technique of adopted texture features independently, performing quite effective comparative study based on accuracy. The main objective of this study is to come up with an appropriate approach for DR recognition, in terms of accuracy enhancement. Therefore, this research proposes one more method based on particle swarm (PSO) for KNN classifier optimization and Tamura features. Tyler Coye algorithm is used for blood vessel segmentation in retinal images. The experiments are implemented based on retina images of the Drive dataset. As a result, the KNN based GLDM approach have gained an accuracy rate reached of (95%) while the announced optimization method of PSO-KNN on Tamura features achieved higher accuracy (100%) among other proposed approaches and state of art methods.
C1 [Barges, Entesar; Thabet, Eman] Univ Basrah, Coll Educ Pure Sci, Dept Comp Sci, Basrah, Iraq.
C3 University of Basrah
RP Thabet, E (corresponding author), Univ Basrah, Coll Educ Pure Sci, Dept Comp Sci, Basrah, Iraq.
EM Entesar.barges@gmail.com; Eman.alasadi@uobasrah.edu.iq
RI khalid, Eman Thabet/F-3320-2019
CR Afrin R, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P527, DOI [10.1109/icrest.2019.8644123, 10.1109/ICREST.2019.8644123]
   Ahmad I., 2019, AUTOMATIC DETECTION
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Ali KH., 2016, INT J COMP SCI INFOR, V14, P666
   Amin J, 2018, MICROSC RES TECHNIQ, V81, P990, DOI 10.1002/jemt.23063
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   Bandara AMRR, 2017, INT CONF IND INF SYS, P535
   Behera MK., 2020, 2020 INT C COMPUTER
   Bourouis S, 2018, LECT NOTES COMPUT SC, V10882, P687, DOI 10.1007/978-3-319-93000-8_78
   Cao J, 1996, MED BIOL ENG COMPUT, V34, P369, DOI 10.1007/BF02520008
   Cao P, 2018, COMPUT MED IMAG GRAP, V69, P112, DOI 10.1016/j.compmedimag.2018.08.008
   Chevrefils C, 2007, LECT NOTES COMPUT SC, V4633, P1017
   David D. S., 2020, Artech J. Eff. Res. Eng. Technol, V1, P28
   Deepa R, 2020, INT C INN TRENDS INF, P1
   Dhakal A, 2019, Int J Adv Res Publ (IJARP), V3, P191
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Ganesan K, 2014, MED BIOL ENG COMPUT, V52, P663, DOI 10.1007/s11517-014-1167-5
   García G, 2012, J DIGIT IMAGING, V25, P369, DOI 10.1007/s10278-011-9417-7
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Ghaffar F, 2020, ARXIV PREPRINT ARXIV
   GS, 2017, BIOMED RES 0970 938X, V28
   Hacisoftaoglu RE, 2020, PATTERN RECOGN LETT, V135, P409, DOI 10.1016/j.patrec.2020.04.009
   Halym HAAE, 2009, PROCEEDING 13 INT C
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hashia B, 2018, MULTIMED TOOLS APPL, P1
   Huang F, 2016, J OPHTHALMOL, V2016, DOI 10.1155/2016/6259047
   Janney B., 2015, J CHEM PHARM SCI, V8, P541
   Jeyavathana B., 2017, Int J Appl Environ Sci, V12, P227
   Karmakar P, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P461
   Kaur S, 2018, L N COMPUT VIS BIOME, V28, P1072, DOI 10.1007/978-3-319-71767-8_92
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Mahmoud Mohamed H., 2023, Personal and Ubiquitous Computing, P751, DOI 10.1007/s00779-020-01519-8
   MERLIN M, 2015, BIOMED PHARMACOL J, V8, P1111
   Mobeen-ur-Rehman, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P244, DOI [10.1109/AICAI.2019.8701231, 10.1109/aicai.2019.8701231]
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Akande ON, 2020, SCIENTIFICA, V2020, DOI 10.1155/2020/4972527
   Pan XJ, 2020, GRAEF ARCH CLIN EXP, V258, P779, DOI 10.1007/s00417-019-04575-w
   Qu M, 2017, PERVASIVE MOB COMPUT, V41, P490, DOI 10.1016/j.pmcj.2017.04.003
   Rahim SS., 2020, IMAGE PROCESSING MAC, P136
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Rymut B, 2011, LECT NOTES ARTIF INT, V6923, P455, DOI 10.1007/978-3-642-23938-0_46
   Shaharum Syamimi Mardiah, 2019, 10th National Technical Seminar on Underwater System Technology 2018 (NUSYS'18). Proceedings: Lecture Notes in Electrical Engineering (LNEE 538), P495, DOI 10.1007/978-981-13-3708-6_43
   Shankar K, 2020, PATTERN RECOGN LETT, V133, P210, DOI 10.1016/j.patrec.2020.02.026
   Sharma HS, 2019, DETECTION DIABETIC R, DOI [10.2139/ssrn.3419210, DOI 10.2139/SSRN.3419210]
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tavakoli M, 2020, PROC SPIE, V11318, DOI 10.1117/12.2548526
   VANGOOL L, 1985, COMPUT VISION GRAPH, V29, P336, DOI 10.1016/0734-189X(85)90130-6
   Zhang B, 2012, INFORM SCIENCES, V200, P78, DOI 10.1016/j.ins.2012.03.003
NR 48
TC 5
Z9 5
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 271
EP 295
DI 10.1007/s11042-022-13282-4
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806683200002
DA 2024-07-18
ER

PT J
AU Kala, K
AF Kala, K.
TI An effective text mining framework using adaptive principle component
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Association rule mining; Medical health records; Genetic
   algorithm; Adaptive principal component analysis
ID ASSOCIATION; RISK
AB In data mining, the medical health records can be served as a rich knowledge sources. Due to the availability of numerous medical data, the constructive facts can be extracted by utilizing different data mining approaches. Many researches are conducted in the medical data mining field. However it faces various issues such as increased computational time, inaccurate results and computational complexities. To overcome these issues, a new approach is proposed in this work. Here the input medical records are taken as an input raw data. Then the raw data can be preprocessed using the process of parsing, stemming, stop word removal and POS tagging. Here the POS tagging helps to determine the medical terms in the sentences of the data. From the preprocessed data, the useful information can be extracted by applying association rule using genetic Principal Component Analysis algorithm. The best association rules are selected using Adaptive Principal Component Analysis and obtained the best association rules as a result. The performance of the proposed methodology is evaluated and compared with the existing techniques. For the AWFR, JRR and EHR dataset the precision value is obtained as 0.94%, 0.948% and 0.95% respectively compared with integral and SDM-3NC approach as 0.90 and 0.94 respectively. This proves the superiority of the proposed approach than the other techniques.
C1 [Kala, K.] Nachiappa Swamigal Arts & Sci Coll, Dept Comp Sci, Karaikkudi, Koviloor, India.
RP Kala, K (corresponding author), Nachiappa Swamigal Arts & Sci Coll, Dept Comp Sci, Karaikkudi, Koviloor, India.
EM kasinathan71@gmail.com
CR Azevedo A, 2018, ENCYCLOPEDIA OF INFORMATION SCIENCE AND TECHNOLOGY, 4TH EDITION, P1907, DOI 10.4018/978-1-5225-2255-3.ch166
   Borah A, 2018, EXPERT SYST APPL, V113, P233, DOI 10.1016/j.eswa.2018.07.010
   Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331
   Chen XY, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03608-0
   Nguyen D, 2016, KNOWL-BASED SYST, V103, P73, DOI 10.1016/j.knosys.2016.03.025
   Fu CH, 2018, AIP CONF PROC, V1955, DOI 10.1063/1.5033699
   Gautam J, 2015, INT J ADV COMPUT SC, V6, P224
   Ji YQ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1129-z
   Ji YQ, 2016, INFORM HEALTH SOC CA, V41, P387, DOI 10.3109/17538157.2015.1064427
   Kargupta H, 2000, ADVANCES IN DISTRIBUTED AND PARALLEL KNOWLEDGE DISCOVERY, P409
   Kavakiotis I, 2017, COMPUT STRUCT BIOTEC, V15, P104, DOI 10.1016/j.csbj.2016.12.005
   Khamparia Aditya, 2020, International Journal of Data Analysis Techniques and Strategies, V12, P99
   Li LC, 2016, IEEE T INF FOREN SEC, V11, P1847, DOI 10.1109/TIFS.2016.2561241
   Muangprathub J., 2016, J TELECOMMUN ELECT C, V8, P37
   Nandhini M, 2015, SADHANA-ACAD P ENG S, V40, P1683, DOI 10.1007/s12046-015-0410-6
   Nguyen D, 2015, ENG APPL ARTIF INTEL, V37, P115, DOI 10.1016/j.engappai.2014.08.013
   Patel A, 2017, INT RES J ENG TECHNO, V4
   Patel BM, 2018, ANAL STUDY ASS RULE
   Ramezankhani A, 2015, INT J ENDOCRINOL MET, V13, DOI 10.5812/ijem.25389
   Sachan A., 2013, INT J INNOVATIONS EN, V2, P8
   Seera M, 2014, EXPERT SYST APPL, V41, P2239, DOI 10.1016/j.eswa.2013.09.022
   Shen CC, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-016-0405-1
   Simon GJ, 2015, IEEE T KNOWL DATA EN, V27, P130, DOI 10.1109/TKDE.2013.76
   Sohail Muhammad Noman, 2019, Recent Developments in Intelligent Computing, Communication and Devices. Proceedings of International Conference on Intelligent Computing, Communication and Devices (ICCD 2017). Advances in Intelligent Systems and Computing (AISC 752), P21, DOI 10.1007/978-981-10-8944-2_3
   Sun WC, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4302425
   Sundermann AJ, 2019, INFECT CONT HOSP EP, V40, P314, DOI 10.1017/ice.2018.343
   Urmela S, 2019, COMPUT COMMUN, V147, P58, DOI 10.1016/j.comcom.2019.08.010
   Yang HD, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700482
NR 28
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44467
EP 44485
DI 10.1007/s11042-022-13285-1
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805908000003
DA 2024-07-18
ER

PT J
AU Nyo, MT
   Mebarek-Oudina, F
   Hlaing, SS
   Khan, NA
AF Nyo, Myat Thet
   Mebarek-Oudina, F.
   Hlaing, Su Su
   Khan, Nadeem A.
TI Otsu's thresholding technique for MRI image brain tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI; Median filter; Otsu's thresholding; BRATS
AB MRI image segmentation is very challenging area in medical image processing. It is implemented with the low contract of MRI scan. In terms of certain input features or expert information, the major objective of medical image segmentation is to isolate and describe anatomical constitutions. In MRI image segmentation, brain tumor segmentation is more difficult because of its complex structure. The Otsu's thresholding method is well-known method in image segmentation. In this paper, choosing the classes or bins of Otsu's thresholding are analyzed on MRI image brain tumor segmentation. As a preprocessing, the 2D MRI images are convert the grayscale image and resized to the same size. And then, median filter is utilized to eliminate the noise from MRI image. In MRI image segmentation, the varieties of classes or bins of Otsu's thresholding are utilized to segment the brain tumor from MRI images. Then, the morphological operation is used to achieve the accurate tumor regions. All of the experiments are tested on 2015 BRATS dataset. As segmentation quality validation metric, Jaccard similarity index, true positive rate (Sensitivity), true negative rate (Specificity) and accuracy are used to validate the segmented results and their ground truth. According to the results, level 4 or class 4 got 68.7955% in true positive and 95.5593% in accuracy. Class 4 is the best or suitable for MRI image segmentation according to experiments.
C1 [Nyo, Myat Thet] Univ Comp Studies, Fac Comp Sci, Pakokku, Myanmar.
   [Mebarek-Oudina, F.] Univ 20 Aout 1955 Skikda, Fac Sci, Dept Phys, Skikda, Algeria.
   [Hlaing, Su Su] Myanmar Inst Informat Technol, Fac Informat Sci, Mandalay, Myanmar.
   [Khan, Nadeem A.] Jamia Millia Islamia, Dept Civil Engn, New Delhi 110025, India.
C3 Universite de Skikda; Jamia Millia Islamia
RP Mebarek-Oudina, F (corresponding author), Univ 20 Aout 1955 Skikda, Fac Sci, Dept Phys, Skikda, Algeria.
EM f.mebarek_oudina@univ-slcikda.dz
RI Mebarek-Oudina, Fateh/Y-8148-2019
OI Mebarek-Oudina, Fateh/0000-0001-6145-8195
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Ali A. H., 2014, IOSR J RES METHOD ED, V4, P58
   Anandgaonkar G, 2014, Int J Sci Res, V3, P814
   Bindu Ch Hima, 2009, International Journal of Recent Trends in Engineering, V2, P88
   Bindu ChHima., 2012, INT J ADV SCI TECHNO, V38, P67
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Gaikwad DP., 2011, 2011 MUMB P INT C WO, P63
   Gao Q, 2009, CLIN CANCER RES, V15, P971, DOI 10.1158/1078-0432.CCR-08-1608
   Ghosh KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114485
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Kazi IM., 2017, INT J COMPR APPL, V167, P11, DOI DOI 10.5120/IJCA2017914330
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Min A, 2019, P 17 INT C COMPUTER, P287
   Mishra A., 2014, J BIOSCIENCE BIOTECH, V6, P187, DOI DOI 10.14257/IJBSBT.2014.6.2.19
   Ozols RF, 2007, J CLIN ONCOL, V25, P146, DOI 10.1200/JCO.2006.09.7030
   Patil S. B., 2016, INT J ENG INNOVATION, V5, P173
   Prince J. L., 2006, Medical Imaging Signals and Systems
   Sasilatha T., 2017, INT J PHARM TECHNOLO, V9, P30688
   Sheeba A, 2014, 2014 INT C EL COMM S, P1
   Srikanth R., 2019, INT J ENG ADV TECH I, V9, P7306, DOI [10.35940/ijeat.A2025.109119, DOI 10.35940/IJEAT.A2025.109119]
   Sujan M., 2016, Int. J. Comput. Appl., V153, P41, DOI DOI 10.5120/IJCA2016912177
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Vijayarangan V., 2014, INT J ENG COMP SCI, V3, P7525
   Xuan X, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P421, DOI 10.1109/ICIG.2007.181
NR 27
TC 47
Z9 47
U1 8
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43837
EP 43849
DI 10.1007/s11042-022-13215-1
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802892700004
DA 2024-07-18
ER

PT J
AU Barzi, FK
   Nezamabadi-pour, H
AF Barzi, Fatemeh Kargar
   Nezamabadi-pour, Hossein
TI Automatic objects' depth estimation based on integral imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth estimation; Image processing; Integral imaging; 3D reconstruction;
   SURF features
ID RECONSTRUCTION; STEREO
AB A new approach for depth estimation based on integral imaging is proposed. In this method, multiple viewpoint images captured from a three-dimensional scene are used to extract the range information of the scene. These elemental images are captured through an array of lenses over a high-resolution camera or an array of cameras. Then the scene is computationally reconstructed in different depths using integral imaging reconstruction algorithm. Finally, by processing the reconstructed images and finding objects of the scene in these images using a matching technique with speeded-up robust features (SURF), the depth information of the objects will be acquired. Experimental results show that the proposed method has high accuracy and does not have many limitations of standard image processing, including sensitivity to the surface type and size of the objects.
C1 [Barzi, Fatemeh Kargar; Nezamabadi-pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, Intelligent Data Proc Lab IDPL, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Nezamabadi-pour, H (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, Intelligent Data Proc Lab IDPL, Kerman, Iran.
EM f.kargar@eng.uk.ac.ir; nezam@uk.ac.ir
RI Nezamabadi-pour, Hossein/I-9578-2014
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348
CR Aloni D, 2011, OPT EXPRESS, V19, P19681, DOI 10.1364/OE.19.019681
   Aslantas V, 2007, OPT EXPRESS, V15, P5024, DOI 10.1364/OE.15.005024
   Axelsson PE, 1999, ISPRS J PHOTOGRAMM, V54, P138, DOI 10.1016/S0924-2716(99)00008-8
   Badenko V, 2018, LECT NOTES COMPUT SC, V10961, P397, DOI 10.1007/978-3-319-95165-2_28
   Bae J., 2019, INT J APPL ENG RES, V14, P250
   Baek E., 2017, ELECT IMAGING, V5, P118, DOI [10.2352/ISSN.2470-1173.2017.5.SDA-367, DOI 10.2352/ISSN.2470-1173.2017.5.SDA-367]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cho M, 2009, J DISP TECHNOL, V5, P61, DOI 10.1109/JDT.2008.2004857
   Cruz-Mota J, 2012, INT J COMPUT VISION, V98, P217, DOI 10.1007/s11263-011-0505-4
   DaneshPanah M, 2009, OPT LETT, V34, P1105, DOI 10.1364/OL.34.001105
   Diebel J., 2005, P 18 INT C NEURAL IN, P291
   ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Ghaneizad M, 2016, ICDSC 2016: 10TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERA, P1, DOI 10.1145/2967413.2967417
   Ghaneizad M, 2017, OPT LASER ENG, V95, P69, DOI 10.1016/j.optlaseng.2017.03.012
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Greengard A, 2006, OPT LETT, V31, P181, DOI 10.1364/OL.31.000181
   Gur S, 2019, PROC CVPR IEEE, P7675, DOI 10.1109/CVPR.2019.00787
   Hazirbas C, 2019, LECT NOTES COMPUT SC, V11363, P525, DOI 10.1007/978-3-030-20893-6_33
   He WJ, 2018, PROC SPIE, V10792, DOI 10.1117/12.2500718
   Hong SH, 2004, OPT EXPRESS, V12, P483, DOI 10.1364/OPEX.12.000483
   Hong SP, 2012, OPT EXPRESS, V20, P23044, DOI 10.1364/OE.20.023044
   Inoue K, 2019, OPT LASER ENG, V115, P1, DOI 10.1016/j.optlaseng.2018.11.011
   Izzat I, 2015, U.S. Patent, Patent No. [9:030-530, 9030530]
   Javidi B, 2006, OPT EXPRESS, V14, P12096, DOI 10.1364/OE.14.012096
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Karami E, 2017, CORR ARXIV 171002726
   Komatsu S, 2018, OPT LETT, V43, P3261, DOI 10.1364/OL.43.003261
   Lee MC, 2016, CHIN OPT LETT, V14, DOI 10.3788/COL201614.121101
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li XW, 2019, OPT LASER ENG, V112, P162, DOI 10.1016/j.optlaseng.2018.09.015
   Lippmann G., 1908, J. Phys. Theor. Appl, V7, P821, DOI [DOI 10.1051/JPHYSTAP:019080070082100, 10.1051/jphystap:019080070082100]
   Martínez-Corral M, 2018, ADV OPT PHOTONICS, V10, P512, DOI 10.1364/AOP.10.000512
   Martínez-Usó A, 2016, J DISP TECHNOL, V12, P1715, DOI 10.1109/JDT.2016.2615565
   Matoba O, 2001, APPL OPTICS, V40, P3318, DOI 10.1364/AO.40.003318
   Moon I, 2008, OPT EXPRESS, V16, P13080, DOI 10.1364/OE.16.013080
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Poozesh P, 2017, J SOUND VIB, V407, P350, DOI 10.1016/j.jsv.2017.06.003
   Qu H., 2017, APPL OPTICS, V56, P151, DOI [10.1364/AO.56.00D151, DOI 10.1364/AO.56.00D151]
   Ren H, 2020, J SOC INF DISPLAY, V28, P75, DOI 10.1002/jsid.829
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saadat, 1998, SCI IRAN, V4, P183
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Son JY, 2013, P IEEE, V101, P190, DOI 10.1109/JPROC.2011.2178052
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Um GM, 2005, PROC SPIE, V5664, P271, DOI 10.1117/12.586764
   Venkataraman, 2016, U.S. Patent, Patent No. [9:438,888, 9438888]
   Zhang L, 2006, ACM T GRAPHIC, V25, P907, DOI 10.1145/1141911.1141974
   Zhou CY, 2011, INT J COMPUT VISION, V93, P53, DOI 10.1007/s11263-010-0409-8
NR 49
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43531
EP 43549
DI 10.1007/s11042-022-13221-3
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000801074700001
DA 2024-07-18
ER

PT J
AU Antoniadis, P
   Tsardoulias, E
   Symeonidis, A
AF Antoniadis, Panagiotis
   Tsardoulias, Emmanouil
   Symeonidis, Andreas
TI A mechanism for personalized Automatic Speech Recognition for less
   frequently spoken languages: the Greek case
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Speech recognition; Dictation; Personalization; Clustering
ID MODELS
AB Automatic Speech Recognition (ASR) has become increasingly popular since it significantly simplifies human-computer interaction, providing a more intuitive way of communication. Building an accurate, general-purpose ASR system is a challenging task that requires a lot of data and computing power. Especially for languages not widely spoken, such as Greek, the lack of adequately large speech datasets leads to the development of ASR systems adapted to a restricted corpus and/or for specific topics. When used in specific domains, these systems can be both accurate and fast, without the need for large datasets and extended training. An interesting application domain of such narrow-scope ASR systems is the development of personalized models that can be used for dictation. In the current work we present three personalization-via-adaptation modules, that can be integrated into any ASR/dictation system and increase its accuracy. The adaptation can be applied both on the language model (based on past text samples of the user) as well as on the acoustic model (using a set of user's narrations). To provide more precise recommendations, clustering algorithms are applied and topic-specific language models are created. Also, heterogeneous adaptation methods are combined to provide recommendations to the user. Evaluation performed on a self-created database containing 746 corpora included in messaging applications and e-mails from the same user, demonstrates that the proposed approach can achieve better results than the vanilla existing Greek models.
C1 [Antoniadis, Panagiotis] Natl Tech Univ Athens NTUA, Sch Elect & Comp Engn, Athens, Greece.
   [Tsardoulias, Emmanouil; Symeonidis, Andreas] Aristotle Univ Thessaloniki AUTh, Fac Engn, Sch Elect & Comp Engn, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Antoniadis, P (corresponding author), Natl Tech Univ Athens NTUA, Sch Elect & Comp Engn, Athens, Greece.
EM pantoniadis97@gmail.com; etsardou@ece.auth.gr; asymeon@eng.auth.gr
RI Tsardoulias, Emmanouil/JFK-4700-2023
OI Tsardoulias, Emmanouil/0000-0001-9034-4832; Antoniadis,
   Panagiotis/0000-0001-5647-641X
FU Google Summer of Code as an open source project11
FX Part of this work was supported by Google Summer of Code as an open
   source project11.
CR Arora S. J., 2012, INT J COMPUT APPL, V60
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Cephei A, 2021, VOSK OFFLINE SPEECH
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   CMU, SPHINX TRAIN AC MOD
   CMU, SPHINX AC MOD TYP
   CMU, SPHINX AD DEF AC MOD
   Dahl GE, 2011, INT CONF ACOUST SPEE, P4688
   Digalakis V, 2003, P EUROSPEECH
   Gaida C., 2014, COMPARING OPEN SOURC
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Google, CLOUD SPEECH TO TEXT
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Huggins-Daines D, 2006, INT CONF ACOUST SPEE, P185
   JACOB RJK, 1993, BEHAV INFORM TECHNOL, V12, P69, DOI 10.1080/01449299308924369
   Jaitly N, 2016, P ADV NIPS, V29
   Kunze J, 2017, P REPL4NLP
   Macskassy SA, 2003, ARTIF INTELL, V143, P51, DOI 10.1016/S0004-3702(02)00359-4
   Martincic-Ipsic S, 2011, AUTOMATIKA-UK, V52, P147
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Militaru D, 2009, FROM SPEECH PROCESSING TO SPOKEN LANGUAGE TECHNOLOGY, P21
   Mohamed AR, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2850
   Morbini F, 2013, P SIGDIAL
   Morgan N., 1990, INT C AC SPEECH SIGN, P413, DOI DOI 10.1109/ICASSP.1990.115720
   Mulbregt Pv, 1998, P ICSLP
   Oikonomidis D, 2003, P EUROSPEECH
   Pantazoglou F, 2017, P ERA 12
   Pleva M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1709
   RABINER LR, 1985, AT&T TECH J, V64, P1211, DOI 10.1002/j.1538-7305.1985.tb00272.x
   Raffel C, 2017, PR MACH LEARN RES, V70
   Rusko M, 2014, LECT NOTES ARTIF INT, V8387, P16, DOI 10.1007/978-3-319-08958-4_2
   Sak H, 2017, INTERSPEECH, P1298, DOI 10.21437/Interspeech.2017-1705
   Schlippe T, 2013, P IEEE ICASSP
   Stolcke A, 2002, P 7 INT C SPOK LANG
   Tamura M, 2001, INT CONF ACOUST SPEE, P805, DOI 10.1109/ICASSP.2001.941037
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Tsardoulias EG, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814931
   Waibel A, 1988, P IEEE ICASSP
   Young S, 2002, HTK BOOK, V3, P12
   Zgank A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2644
   Zhang L, 2006, P INTERSPEECH
   Ziólko B, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1062
NR 45
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40635
EP 40652
DI 10.1007/s11042-022-12953-6
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000799082800002
DA 2024-07-18
ER

PT J
AU Zhang, R
   Zhang, W
   Liu, YY
   Li, P
   Zhao, JH
AF Zhang, Rong
   Zhang, Wei
   Liu, Yanyan
   Li, Pu
   Zhao, Jianhan
TI An efficient deep neural network with color-weighted loss for fire
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fire detection; Deep learning; Anchor-free; Conditional convolution;
   Color-weighted loss
ID FLAME DETECTION; SURVEILLANCE; MODEL
AB Fire is one of the most harmful hazards that affect daily life. Compared with sensor-based methods, vision-based methods have more advantages in fire detection. Existing approaches fail to achieve a good trade-off among fire locations, false alarms and model size. In this paper, we propose a fire detection method based on deep learning with anchor-free architecture. We apply a conditional convolution to boost the visual representation of fire and construct a lightweight backbone by using the proposed conditional ghost module. A color-weighted loss function is presented to obtain more valuable information by using the unique color of fire. Besides, we create an annotated dataset for fire detection. A series of experiments demonstrate that the proposed method outperforms other popular methods based on handcraft features and deep learning object detection. Furthermore, the model size of the proposed method is only 34.92 MB, 80.73% smaller than that of the suboptimal method.
C1 [Zhang, Rong; Zhang, Wei; Li, Pu; Zhao, Jianhan] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
   [Liu, Yanyan] Nankai Univ, Coll Elect Informat & Opt Engn, Tianjin 300071, Peoples R China.
C3 Tianjin University; Nankai University
RP Zhang, W (corresponding author), Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
EM tjuzhangwei@tju.edu.cn
RI LI, WEI/ISS-1208-2023; liu, yan/HCI-5542-2022; Yang, Ying/ABD-2481-2022;
   liu, yan/HGV-1365-2022; Liu, Ying/ISU-1216-2023; Li, Ly/JCD-4746-2023;
   liu, liu/JEO-6900-2023; Liu, Yiming/ISU-3780-2023; li, wei/IUQ-2973-2023
CR Barmpoutis P, 2019, INT CONF ACOUST SPEE, P8301, DOI [10.1109/ICASSP.2019.8682647, 10.1109/icassp.2019.8682647]
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Changwoo Ha, 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P526, DOI 10.1109/CISIS.2012.25
   Chaoxia CY, 2020, IEEE ACCESS, V8, P58923, DOI 10.1109/ACCESS.2020.2982994
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Dunnings Andrew J., 2018, 2018 25th IEEE International Conference on Image Processing (ICIP), P1558, DOI 10.1109/ICIP.2018.8451657
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Gunay O, 2012, IEEE T IMAGE PROCESS, V21, P2853, DOI 10.1109/TIP.2012.2183141
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hashemzadeh M, 2019, EXPERT SYST APPL, V130, P60, DOI 10.1016/j.eswa.2019.04.019
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Kim B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142862
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Ko B, 2010, FIRE SAFETY J, V45, P262, DOI 10.1016/j.firesaf.2010.04.001
   Kong SG, 2016, FIRE SAFETY J, V79, P37, DOI 10.1016/j.firesaf.2015.11.015
   Li P, 2020, CASE STUD THERM ENG, V19, DOI 10.1016/j.csite.2020.100625
   Li SB, 2020, IEEE T IMAGE PROCESS, V29, P8467, DOI 10.1109/TIP.2020.3016431
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   Mueller M, 2013, IEEE T IMAGE PROCESS, V22, P2786, DOI 10.1109/TIP.2013.2258353
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Pengcheng Liu, 2016, 2016 22nd International Conference on Automation and Computing (ICAC), P395, DOI 10.1109/IConAC.2016.7604952
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Saeed F, 2020, MULTIMED TOOLS APPL, V79, P9083, DOI 10.1007/s11042-019-07785-w
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shahmohammadi MA, 2022, MECH BASED DES STRUC, V50, P3796, DOI 10.1080/15397734.2020.1822182
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Truong TX, 2012, ENG APPL ARTIF INTEL, V25, P1365, DOI 10.1016/j.engappai.2012.05.007
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu H, 2019, PROCESS SAF ENVIRON, V127, P245, DOI 10.1016/j.psep.2019.05.016
   Yang B, 2019, ADV NEUR IN, V32
NR 46
TC 4
Z9 5
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39695
EP 39713
DI 10.1007/s11042-022-12861-9
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789768900001
DA 2024-07-18
ER

PT J
AU Liu, T
   Yan, B
   Yang, HM
   Chu, SC
   Pan, JS
AF Liu, Tao
   Yan, Bin
   Yang, Hong-Mei
   Chu, Shu-Chuan
   Pan, Jeng-Shyang
TI A fake threshold visual cryptography of QR code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Safe transmission; Error correction code; QR code; Visual cryptography
ID SECRET SHARING SCHEME
AB Visual cryptography (VC) is a technique that can encrypt images without complicated calculation. As the image, the quick response (QR) code can also be encrypted by VC to ensure its safe transmission on the network. In recent years, VC has developed rapidly. The original VC has been developed into many forms, such as (n, n)-VC, (k, n)-VC. These new VC schemes can be applied to the QR code to make it more secure in the network. This paper proposes a new VC scheme for the QR code by using the mechanism of the error correction code (ECC). ECC is used to control the number of shares to recover whether the secret QR code can be decoded correctly. The codewords in the same block of the QR code are evenly distributed to each share. If the number of shares is less than the threshold, the restored QR code will not be decoded correctly. The number of wrong codewords exceeds its error correction capability. The theoretical analysis shows that the proposed scheme is secure when the standard decoder is used. The experimental results also prove the feasibility of the proposed scheme.
C1 [Liu, Tao; Yang, Hong-Mei; Chu, Shu-Chuan; Pan, Jeng-Shyang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Yan, Bin] Shandong Univ Sci & Technol, Coll Elect & Informat Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Pan, JS (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM taoliu0201@163.com; yanbinhit@hotmail.com; yhm1998@163.com;
   scchu0803@gmail.com; jspan@cc.kuas.edu.tw
RI Pan, Jeng-Shyang/AEO-3450-2022; Chu, Shu-Chuan/AFQ-6798-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025; Chu, Shu-Chuan/0000-0003-2117-0618
FU National Natural Science Foundation of China [61872085]; Natural Science
   Foundation of Fujian Province [2018J01638]; Fujian Provincial Department
   of Science and Technology [2018Y3001]
FX This work is supported by the National Natural Science Foundation of
   China (61872085), the Natural Science Foundation of Fujian Province
   (2018J01638) and the Fujian Provincial Department of Science and
   Technology (2018Y3001).
CR Abdulla A. A., 2015, Ph.D. dissertation
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Chiu PL, 2019, SIGNAL PROCESS, V165, P233, DOI 10.1016/j.sigpro.2019.06.038
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Hao LY, 2019, IEEE ACCESS, V7, P162366, DOI 10.1109/ACCESS.2019.2952058
   Huang BY, 2020, MULTIMED TOOLS APPL, V79, P7705, DOI 10.1007/s11042-019-08436-w
   Huang PC, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102719
   Huang PC, 2020, IEEE ACCESS, V8, P86706, DOI 10.1109/ACCESS.2020.2992694
   Huang PC, 2019, MULTIMED TOOLS APPL, V78, P26023, DOI 10.1007/s11042-019-07795-8
   Huang PC, 2018, MULTIMED TOOLS APPL, V77, P25275, DOI 10.1007/s11042-018-5784-0
   Information technology, 2006, 18004126 ISOIEC
   Kannojia SP, 2021, MULTIMED TOOLS APPL, V80, P14609, DOI 10.1007/s11042-020-10352-3
   Katzenbeisser S, 2000, DIGITAL WATERMARKING, P2
   Li LD, 2010, INFORM SCIENCES, V180, P2875, DOI 10.1016/j.ins.2010.04.009
   Liu T, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214670
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Sun Y, 2019, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.01178
   Tian AQ, 2020, PROCESSES, V8, DOI 10.3390/pr8030356
   Tian AQ, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12030767
   Wang DS, 2008, LECT NOTES COMPUT SC, V4990, P192
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang FH, 2007, INFORM SCIENCES, V177, P2522, DOI 10.1016/j.ins.2006.12.025
   Wen-Pinn Fang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P89, DOI 10.1109/IIHMSP.2011.10
   Weng SW, 2007, IEEE IMAGE PROC, P1369
   Wu TY, 2020, IEEE ACCESS, V8, P28096, DOI 10.1109/ACCESS.2020.2969986
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   Yan B, 2016, MULTIMED TOOLS APPL, V75, P11157, DOI 10.1007/s11042-015-2838-4
   Yan X, 2020, CRYPTOGRAPHY BREAKTH, P416
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
NR 35
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39635
EP 39653
DI 10.1007/s11042-022-13011-x
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789073100001
DA 2024-07-18
ER

PT J
AU Bharath, KP
   Kumar, MR
AF Bharath, K. P.
   Kumar, M. Rajesh
TI Replay spoof detection for speaker verification system using
   magnitude-phase-instantaneous frequency and energy features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Empirical mode decomposition; Hilbert spectrum; RFCC; CQCC; APGDF
ID EMPIRICAL MODE DECOMPOSITION; GROUP DELAY FUNCTIONS; LINEAR-PREDICTION;
   HILBERT SPECTRUM; SPEECH; EXTRACTION
AB Spoofing attack detection is one of the essential components in automatic speaker verification (ASV) systems. The success of ASV-2015 shows a great perspective by detecting the voice conversion and speech synthesis spoofs. However, the researchers address fewer replay attack spoof detection systems, and non-professional impersonators most likely use the replay attacks. This paper detects replay attacks on the ASV system using the ASVspoof-2017-v2.0 corpus. This work is mainly partitioned into two parts. The first part shows the significance of Empirical Mode Decomposition (EMD) and Hilbert Spectrum (HS) to detect the replay attack detection by extracting the instantaneous frequency (IF) and instantaneous energies (IE) from frequency components of the speech signal to differentiate the characteristics of genuine and spoof speech, then it given to rectangular filter cepstral coefficients (RFCC) to obtain the desired set of features to detect whether the given speech sample is genuine or spoof. In the second part, a new score-level fusion system is proposed to increase the system performance. Along with the proposed stand-alone method, Constant-Q cepstral coefficients (CQCC) and All-Pole Group Delay Function (APGDF) methods are used to extract the magnitude and phase features set, respectively. The proposed stand-alone and score-level fusion method improves performance accuracy than other state-of-art techniques.
C1 [Bharath, K. P.; Kumar, M. Rajesh] VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Kumar, MR (corresponding author), VIT Univ, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM bharathkp25@gmail.com; mrajeshkumar@vit.ac.in
OI M, Dr. Rajesh Kumar/0000-0003-0350-4397
FU Council of Scientific & Industrial Research (CSIR) Human Resource
   Development Group (HRDG), Govt of India [143672/2 k18/1,
   09/844(0084)/2019 EMR-I]
FX First author Bharath K P, (CSIR-Senior Research Fellow) would like to
   thank the Council of Scientific & Industrial Research (CSIR) Human
   Resource Development Group (HRDG), Govt of India, for financial
   assistance (CSIR-SRF, Ack. No.: 143672/2 k18/1, File No.:
   09/844(0084)/2019 EMR-I.)
CR Alam MJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P249
   [Anonymous], 2013, ARXIV13042865
   Bakar B, 2018, IEEE W SP LANG TECH, P132, DOI 10.1109/SLT.2018.8639511
   Banno H, 2003, ELECTRON COMM JPN 3, V86, P56, DOI 10.1002/ecjc.10120
   BROWN JC, 1991, J ACOUST SOC AM, V89, P425, DOI 10.1121/1.400476
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   Chen ZX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2052, DOI 10.1109/ICASSP.2018.8462644
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Eargle J., 2003, LOUDSPEAKER HDB
   Font R, 2017, INTERSPEECH, P7, DOI 10.21437/Interspeech.2017-450
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Hanilçi C, 2016, SPEECH COMMUN, V85, P83, DOI 10.1016/j.specom.2016.10.002
   Hanilçi C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2057
   Hautamäki RG, 2013, INTERSPEECH, P930
   Hegde RM, 2007, IEEE T AUDIO SPEECH, V15, P190, DOI 10.1109/TASL.2006.876858
   Huang H, 2006, SIGNAL PROCESS, V86, P792, DOI 10.1016/j.sigpro.2005.06.011
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jelil S, 2018, INTERSPEECH, P631, DOI 10.21437/Interspeech.2018-1297
   Jelil S, 2017, INTERSPEECH, P22, DOI 10.21437/Interspeech.2017-930
   Kamble MR, 2018, INTERSPEECH, P646, DOI 10.21437/Interspeech.2018-1687
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Lai CI, 2019, INT CONF ACOUST SPEE, P6316, DOI 10.1109/ICASSP.2019.8682640
   Larcher A, 2014, SPEECH COMMUN, V60, P56, DOI 10.1016/j.specom.2014.03.001
   Lavrentyeva G, 2017, INTERSPEECH, P82, DOI 10.21437/Interspeech.2017-360
   Liu Y, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2082
   Lukic Y, 2016, IEEE INT WORKS MACH
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Murthy HA, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P68
   Murthy HA, 2011, SADHANA-ACAD P ENG S, V36, P745, DOI 10.1007/s12046-011-0045-1
   Oo Z, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0151-2
   Pal M, 2015, APPL SOFT COMPUT, V30, P214, DOI 10.1016/j.asoc.2015.01.036
   Phapatanaburi K, 2019, IEEE ACCESS, V7, P183614, DOI 10.1109/ACCESS.2019.2960369
   Rajan P, 2013, INTERSPEECH, P2488
   Sailor HB, 2018, INTERSPEECH, P666, DOI 10.21437/Interspeech.2018-1651
   Schlotthauer G, 2010, IFMBE PROC, V25, P984
   Sharma R, 2018, SPEECH COMMUN, V96, P207, DOI 10.1016/j.specom.2017.12.001
   Sharma R, 2017, SPEECH COMMUN, V91, P1, DOI 10.1016/j.specom.2017.04.006
   Sharma R, 2017, SPEECH COMMUN, V88, P39, DOI 10.1016/j.specom.2016.12.004
   Sharma R, 2016, DIGIT SIGNAL PROCESS, V58, P26, DOI 10.1016/j.dsp.2016.07.012
   Shen JL, 2006, IEEE T MULTIMEDIA, V8, P1179, DOI 10.1109/TMM.2006.884618
   Shen JL, 2019, MULTIMEDIA SYST, V25, P639, DOI 10.1007/s00530-019-00613-z
   Suthokumar G, 2018, INTERSPEECH, P691, DOI 10.21437/Interspeech.2018-1846
   Sztaho D., 2019, ARXIV PREPRINT ARXIV
   Tapkir PA, 2018, ASIAPAC SIGN INFO PR, P1019, DOI 10.23919/APSIPA.2018.8659582
   Todisco M., 2016, P SPEAK LANG REC WOR, V25, P249, DOI DOI 10.21437/ODYSSEY.2016-41
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Wu Z., 2014, IEEE APSIPA ASC, P1, DOI 10.1109/APSIPA.2014.7041636
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   YEGNANARAYANA B, 1978, J ACOUST SOC AM, V63, P1638, DOI 10.1121/1.381864
   Yoshioka T, 2012, IEEE SIGNAL PROC MAG, V29, P114, DOI 10.1109/MSP.2012.2205029
NR 52
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39343
EP 39366
DI 10.1007/s11042-022-12380-7
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000006
DA 2024-07-18
ER

PT J
AU Tang, LL
   Xie, JL
   Wu, DR
AF Tang, Lili
   Xie, Jialiang
   Wu, Dongrui
TI An interval type-2 fuzzy edge detection and matrix coding approach for
   color image adaptive steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interval type-2 fuzzy similarity; Genetic algorithm; Chaotic method;
   Matrix coding
ID SEMI-TENSOR PRODUCT; DATA HIDING SCHEME; ENCRYPTION ALGORITHM; PAYLOAD
AB This paper proposes an adaptive color image steganography technique based on edge detection and matrix coding, by comprehensively considering the human eye sensitivity to edges and the RGB color components. First, non-edge and edge points are detected by computing interval type-2 fuzzy similarity on cover image after noise estimation and filtering. Then, a genetic algorithm is used to optimize the embedding bits (edge and non-edge in RGB channels) according to the capacity of the secret message. Next, a chaotic method and random sequence scrambling are used to prevent the secret message from attacks. Finally, three matrix coding schemes with different embedding efficiency (Least significant bit, Hamming code, and XOR coding) are used to embed the encrypted confidential information. The proposed method hides a large amount of data with good quality of stego image from the human visual system (HVS) and guarantees the confidentiality of communication. Experiments showed that it outperformed several state-of-the-art approaches in terms of payload, mean square error, peak signal-to-noise ratio, and structural similarity. The robustness of the method is also tested by RS steganalysis and pixel difference histogram (PDH) analysis.
C1 [Tang, Lili; Xie, Jialiang] Jimei Univ, Sch Sci, Xiamen 361021, Peoples R China.
   [Tang, Lili] Huaqiao Univ, Sch Mech Engn & Automat, Xiamen 361021, Peoples R China.
   [Wu, Dongrui] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
C3 Jimei University; Huaqiao University; Huazhong University of Science &
   Technology
RP Xie, JL (corresponding author), Jimei Univ, Sch Sci, Xiamen 361021, Peoples R China.
EM 1124870287@qq.com; xiejialiang@jmu.edu.cn; drwu@hust.edu.cn
OI , Tang Lili/0000-0003-0486-6322
FU National Natural Science Foundation of China [12071179, 61972168];
   National Natural Science Foundation of Fujian Province [2021J01861];
   Soft Science Research Program of Fujian Province [B19085]; Project of
   Education Department of Fujian Province [JT180263]; Youth Innovation
   Fund of Xiamen City [3502Z20206020]; Open Fund of Digital Fujian Big
   Data Modeling and Intelligent Computing Institute, Pre-Research Fund of
   Jimei University
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 12071179 and Nos. 61972168), the National
   Natural Science Foundation of Fujian Province (Nos. 2021J01861), Soft
   Science Research Program of Fujian Province (No. B19085), the Project of
   Education Department of Fujian Province (No. JT180263), the Youth
   Innovation Fund of Xiamen City (3502Z20206020), the Open Fund of Digital
   Fujian Big Data Modeling and Intelligent Computing Institute,
   Pre-Research Fund of Jimei University.
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bandyopadhyay D., 2014, FRAMEWORK SECURED BI
   Bassil Y., 2012, INT J COMPUTER APPL, V60, P35
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Crandall R., 1998, Steganography Mailing List, V1998, P1
   Dadgostar H, 2016, J INF SECUR APPL, V30, P94, DOI 10.1016/j.jisa.2016.07.001
   El-Emam NN, 2015, APPL SOFT COMPUT, V37, P830, DOI 10.1016/j.asoc.2015.08.057
   Eng HL, 2000, INT CONF ACOUST SPEE, P2175, DOI 10.1109/ICASSP.2000.859268
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gaurav K, 2018, J INF SECUR APPL, V41, P41, DOI 10.1016/j.jisa.2018.05.001
   Grover N, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P238, DOI 10.1109/ADCONS.2013.45
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kaur M., 2017, ADAPTIVE BLOCK BASED
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lili Tang, 2019, 2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings, P958, DOI 10.1109/EITCE47263.2019.9094841
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu XH, 2012, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2012.6466947
   Mendel JM, 2007, IEEE COMPUT INTELL M, V2, P20, DOI 10.1109/MCI.2007.380672
   Modi MR, 2013, LECT NOTES COMPUT SC, V7995, P593, DOI 10.1007/978-3-642-39479-9_69
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Nameer NEE., 2007, J COMPUTER SCI, V3, P223, DOI [10.3844/jcssp.2007.223.232, DOI 10.3844/JCSSP.2007.223.232]
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pradhan A, 2016, 2016 INTERNATIONAL CONFERENCE ON RESEARCH ADVANCES IN INTEGRATED NAVIGATION SYSTEMS (RAINS)
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Toony Zahra, 2009, 2009 14th International CSI Computer Conference (CSICC 2009) (Postponed from July 2009), P518, DOI 10.1109/CSICC.2009.5349632
   Vanmathi C, 2018, INT J FUZZY SYST, V20, P460, DOI 10.1007/s40815-017-0420-0
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang F.-Y., 2018, TYPE 2 FUZZY SETS LO
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yuan YH., 2016, THESIS U SHANDONG
   Zhang WM, 2008, DESIGN CODE CRYPTOGR, V46, P67, DOI 10.1007/S10623-007-9135-9
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 58
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39145
EP 39167
DI 10.1007/s11042-022-13127-0
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451400006
DA 2024-07-18
ER

PT J
AU Ahmed, I
   Khan, A
AF Ahmed, Irfan
   Khan, Aftab
TI Genetic algorithm based framework for optimized sensing matrix design in
   compressed sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Sensing matrix design; Compressive sensing; Learning
   based compressive subsampling; GA-LBCS
ID NETWORK
AB Sampling matrices used in compressed sensing framework are mostly randomly structured and thus inefficient in terms of memory utilization, reconstruction speed, and computational resources utilization. Recent use of learning based optimised sensing matrices are proven to be energy efficient and computationally feasible. However, such matrices are designed in isolation with reconstruction algorithm and thus could not facilitate efficient signal recovery. In this paper, a unique approach is devised to develop the optimized sampling matrix by using offline training mechanism of sparse matrix through Genetic Algorithm, Learning Based Compressive Subsampling, and combination of both strategies. The core idea of this paper lies in adopting GA for optimal sensing matrix design by using evolutionary mechanism. The designed matrices are evolved in number of iterations with respect to the desired accuracy. These matrices are of deterministic nature and aimed to provide computationally feasible and memory efficient solution by targeting maximal features of the training samples. In this work, we adopted two phase process for design and evaluation of the proposed framework which are called train and test phases. In first stage, the cumulative feature vector of all speech training samples is calculated and provided to the proposed techniques. In training phase, Genetic algorithm is tailored to be used as an optimization strategy to develop sensing matrix which supports faithful signal reconstruction. In test phase, the performance of the developed sampling matrices is evaluated by comparing signal-to-noise ratio and root mean squared error values obtained by sampling and reconstruction of test set through widely used modern signal reconstruction algorithms. The accuracy and precision analysis of acquired signal-to-noise ratio and root mean squared error values show that the GA based methods outperform the latest sampling matrix design method, when signal reconstruction is carried out with convex relaxation algorithm, greedy method, and linear reconstruction technique.
C1 [Ahmed, Irfan; Khan, Aftab] Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
C3 University of Engineering & Technology Peshawar
RP Ahmed, I (corresponding author), Univ Engn & Technol, Dept Comp Syst Engn, Peshawar, Pakistan.
EM irfanahmed@uetpeshawar.edu.pk; aftab.khan@uetpeshawar.edu.pk
RI Ahmed, Irfan/CAF-8126-2022
OI Ahmed, Irfan/0000-0002-3489-3519
CR Ahmed I, ARAB J SCI ENG, P1
   Ahmed I, 2012, INT CONF ROBOT ARTIF, P139, DOI 10.1109/ICRAI.2012.6413380
   Ahmed Irfan., 2012, AUTOMATION COMPUTING, P1
   [Anonymous], 2012, P INT S SUST HLTH BU
   Arjoune Y, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Arjoune Y, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3576
   Ayat S, 2006, COMPUT ELECTR ENG, V32, P411, DOI 10.1016/j.compeleceng.2006.05.002
   Bala S, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P81, DOI 10.1109/ISPCC.2015.7375002
   Bala S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P632, DOI 10.1109/CICT.2015.136
   Baldassarre L, 2016, IEEE J-STSP, V10, P809, DOI 10.1109/JSTSP.2016.2548442
   Beran J., 1992, J R STAT SOC B, V54, P749
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Conde MH, 2017, IEEE INT SYMP SIGNAL, P106, DOI 10.1109/ISSPIT.2017.8388625
   Cui WX, 2018, IEEE IMAGE PROC, P3883, DOI 10.1109/ICIP.2018.8451841
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Holland I.H., 1975, ADAPTATION NATURAL A
   Hong T, 2019, SIGNAL PROCESS, V159, P119, DOI 10.1016/j.sigpro.2019.02.004
   Kim K, 2019, J ELECTR ENG TECHNOL, V14, P2567, DOI 10.1007/s42835-019-00278-8
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Luo K, 2014, ELECTRON LETT, V50, P1271, DOI 10.1049/el.2014.1749
   Mahabadi RK, 2018, EUR SIGNAL PR CONF, P1925, DOI 10.23919/EUSIPCO.2018.8553402
   Osterland S, 2019, INT J HYDROMECHATRON, V2, P32
   Polikar R., 1996, The Wavelet Tutorial
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Ravelomanantsoa A, 2015, IEEE T INSTRUM MEAS, V64, P3405, DOI 10.1109/TIM.2015.2459471
   Shah J., 2014, RES J RECENT SCI, V3, P86
   Shah J, 2017, J SIGNAL PROCESS SYS, V88, P333, DOI 10.1007/s11265-016-1168-8
   Shokri M, 2019, INT J HYDROMECHATRON, V2, P178
   Susan S, 2019, CAAI T INTELL TECHNO, V4, P101, DOI 10.1049/trit.2019.0002
   Wiens T, 2019, INT J HYDROMECHATRON, V2, P16
   Yu TT, 2019, CAAI T INTELL TECHNO, V4, P122, DOI 10.1049/trit.2019.0017
   Zhang Lin, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P346
   Zhu CM, 2019, CAAI T INTELL TECHNO, V4, P255, DOI 10.1049/trit.2019.0036
NR 34
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39077
EP 39102
DI 10.1007/s11042-022-12894-0
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000794850900001
DA 2024-07-18
ER

PT J
AU Xu, MC
   Yang, CK
AF Xu, Meng-Chen
   Yang, Chuan-Kai
TI Realistic video generation for american sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE American sign language; Sign language video generation; Pose transition
   estimation; Two-stage video generation
AB There are many ways to generate sign language videos, but most of them are based on 3D character modeling. These methods are time-consuming and labor-intensive, and are hard to compare with the videos of real person sign language in terms of realness and naturalness. To address this, we propose a novel approach using the recently popular generative adversarial network to synthesize sentence-level videos from word-level videos. A pose transition estimation is used to measure the distance between sign language clips and synthesize the corresponding transition skeletons. In particular, we propose an interpolation approach, as it is faster than a graphics approach and does not require additional datasets. In addition, we also propose an stacked based approach for the Vid2Vid model. Two Vid2Vid models are stacked together to generate videos via two stages. The first stage is to generate IUV images (3 channels images composed by the index I and the UV texture coordinates) from the skeleton images, and the second stage is to generate realistic video from the skeleton images and the IUV images. We use American Sign Language Lexicon Video Dataset (ASLLVD) in our experiment, and we found that when the skeletons are generated by our proposed pose transition estimation method, the quality of the video is better than that of the direct generation using only the skeletons. Finally, we also develop a graphical user interface that allows users to drag and drop the clips to the video track and generate a realistic sign language video.
C1 [Xu, Meng-Chen; Yang, Chuan-Kai] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM B10509017@gapps.ntust.edu.tw; ckyang@cs.ntust.edu.tw
RI Xu, Meng/HJY-7139-2023
FU Ministry of Science and Technology of Taiwan [MOST 109-2221-E-011-133,
   MOST 109-2228-E-011-007]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the grants MOST 109-2221-E-011-133 and MOST
   109-2228-E-011-007. Conflict of Interest: Both authors have received the
   aforementioned funding support and both authors have no conflict of
   interest.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Athitsos V, 2008, PROC CVPR IEEE, P1666
   Borg M, 2020, ECCV 2020 WORKSH SIG
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4651, DOI 10.1007/s11042-016-3284-7
   Elliott R, 2000, ANN ACM C ASS TECHN
   Forster J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785
   Gokce C, 2020, ECCV 2020 WORKSH SIG
   Goodfellow IJ, 2014, ADV NEURAL INFORM PR, V3
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Huang A, 2019, IEEE CONF IMAGING SY
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013
   Krapez S, 1999, ELEKTROTEH VESTN, V66
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Liang X, 2020, ECCV 2020 WORKSH SIG
   Lu PF, 2014, COMPUT SPEECH LANG, V28, P812, DOI 10.1016/j.csl.2013.10.004
   Martínez AM, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P167, DOI 10.1109/ICMI.2002.1166987
   Merkel D., 2014, LINUX J, V2014, P2, DOI DOI 10.5555/2600239.2600241
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   NVIDIA, 2015, NVIDIA CONT TOOLK
   of the Deaf W F, 2018, OUR WORK
   Organization W H, 2020, DEAFN HEAR LOSS
   Oszust M, 2013, C HUM SYST INTERACT, P219, DOI 10.1109/HSI.2013.6577826
   Papadogiorgaki M, 2005, 13 EUR SIGN PROC C E
   Parelli M, 2020, ECCV 2020 WORKSH SIG
   Quiroga F, 2020, SIGN LANGUAGE RECOGN
   Radford A., 2015, ARXIV
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Silva E P D, 2020, ECCV 2020 WORKSH SIG
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Stoll S, 2020, INT J COMPUT VISION, V128, P891, DOI 10.1007/s11263-019-01281-2
   Tavakoli M, 2016, ACTUATORS, V5, DOI 10.3390/act5010001
   Tomar S., 2006, LINUX J, V2006, P10
   Wang T., 2018, ARXIV
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yulia, 2019, THESIS NATL TAIWAN U
   Zwitserlood I., 2005, SYNTHETIC SIGNING DE
NR 41
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38849
EP 38886
DI 10.1007/s11042-022-12590-z
EA APR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500011
DA 2024-07-18
ER

PT J
AU Unay, D
AF Unay, Devrim
TI Deep learning based automatic grading of bi-colored apples using
   multispectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Fruit grading;
   Multispectral images; Classification; Apple
ID MACHINE-VISION SYSTEM; SURFACE-DEFECTS; QUALITY EVALUATION;
   NEURAL-NETWORKS; INSPECTION; FRUIT; BRUISES; DESIGN; STEM
AB Grading of apple fruits involves their inspection, assessment and sorting by quality. Machine vision has been the industry's choice as it is fast, reliable and tireless. Recently deep learning has brought revolutionary advances in computer vision and machine learning. Accordingly this study presents a deep learning based quality grading solution for apple fruits. A 2D convolutional neural network is trained on multispectral images of bi-colored apples to realize two-category and multi-category grading. For the multi-category grading, the performance of a novel cascaded CNNs based solution is further investigated. Experimental results show that the proposed deep learning solution achieves highly accurate and fast grading performance outperforming the state-of-the-art.
C1 [Unay, Devrim] Izmir Demokrasi Univ, Elect & Elect Engn, Izmir, Turkey.
C3 Izmir Democracy University
RP Unay, D (corresponding author), Izmir Demokrasi Univ, Elect & Elect Engn, Izmir, Turkey.
EM unaydevrim@gmail.com
RI Unay, Devrim/AAE-6908-2020
OI Unay, Devrim/0000-0003-3478-7318
FU General Directorate of Technology, Research and Energy of the Walloon
   Region of Belgium [9813783]
FX This work is funded by the General Directorate of Technology, Research
   and Energy of the Walloon Region of Belgium with Convention No 9813783.
CR Alam N., 2020, INT C SMART COMPUTIN, P127
   Ariana D, 2006, COMPUT ELECTRON AGR, V50, P148, DOI 10.1016/j.compag.2005.10.002
   Bhatt AK, 2015, AI SOC, V30, P45, DOI 10.1007/s00146-013-0516-5
   Cheng X, 2003, T ASAE, V46, P551, DOI 10.13031/2013.12944
   Crowe TG, 1996, T ASAE, V39, P2299, DOI 10.13031/2013.27740
   Cubero S, 2011, FOOD BIOPROCESS TECH, V4, P487, DOI 10.1007/s11947-010-0411-8
   DAVENEL A, 1988, J AGR ENG RES, V41, P1, DOI 10.1016/0021-8634(88)90198-9
   DIENER RG, 1970, AGR ENG, V51, P356
   ElMasry G, 2009, POSTHARVEST BIOL TEC, V52, P1, DOI 10.1016/j.postharvbio.2008.11.008
   Elzebroek T., 2008, Guide to cultivated plants, pvii, DOI 10.1079/9781845933562.0000
   European Commission, 2004, Off. J. Eur. Union L, V13, P3
   Fan SX, 2020, J FOOD ENG, V286, DOI 10.1016/j.jfoodeng.2020.110102
   GEOOLA F, 1994, J AGR ENG RES, V58, P47, DOI 10.1006/jaer.1994.1034
   Hu ZL, 2020, MECH SYST SIGNAL PR, V145, DOI 10.1016/j.ymssp.2020.106922
   Ismail N., 2021, INF PROCESS AGR, V110, P1, DOI [10.1016/j.inpa.2021.01.005, DOI 10.1016/J.INPA.2021.01.005]
   Kavdir I, 2004, BIOSYST ENG, V89, P331, DOI 10.1016/j.biosystemseng.2004.08.008
   Keresztes JC, 2016, FOOD CONTROL, V66, P215, DOI 10.1016/j.foodcont.2016.02.007
   Kingma D. P., 2014, arXiv
   Kleynen O, 2005, J FOOD ENG, V69, P41, DOI 10.1016/j.jfoodeng.2004.07.008
   Kleynen O, 2003, POSTHARVEST BIOL TEC, V30, P221, DOI 10.1016/S0925-5214(03)00112-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leemans V, 2004, J FOOD ENG, V61, P83, DOI 10.1016/S0260-8774(03)00189-4
   Leemans V, 2002, BIOSYST ENG, V83, P397, DOI 10.1006/bioe.2002.0131
   Li Yingjie, 2021, Scientific Reports
   Lorente D, 2012, FOOD BIOPROCESS TECH, V5, P1121, DOI 10.1007/s11947-011-0725-1
   Lu R, 2003, T ASAE, V46, P523
   Ma LY, 2019, INT C ADV MECH SYST, P326, DOI [10.1109/ICAMechS.2019.8861601, 10.1109/icamechs.2019.8861601]
   Mehl PM, 2004, J FOOD ENG, V61, P67, DOI 10.1016/S0260-8774(03)00188-2
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Peng YK, 2008, POSTHARVEST BIOL TEC, V48, P52, DOI 10.1016/j.postharvbio.2007.09.019
   Prem Kumar M. K., 2020, Advances in Communication Systems and Networks. Select Proceedings of ComNet 2019. Lecture Notes in Electrical Engineering (LNEE 656), P477, DOI 10.1007/978-981-15-3992-3_40
   Rehman TU, 2019, COMPUT ELECTRON AGR, V156, P585, DOI 10.1016/j.compag.2018.12.006
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saranya N, 2020, ADV INTELL SYST COMP, V1108, P79, DOI 10.1007/978-3-030-37218-7_10
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shahin MA, 2002, T ASAE, V45, P1619
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sofu MM, 2016, COMPUT ELECTRON AGR, V127, P395, DOI 10.1016/j.compag.2016.06.030
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun D.-W., 2010, Hyperspectral Imaging for Food Quality Analysis and Control
   Tan WX, 2016, MULTIMED TOOLS APPL, V75, P16741, DOI 10.1007/s11042-015-2940-7
   Tang Y, 2020, IEEE ACCESS, V8, P147494, DOI 10.1109/ACCESS.2020.3015808
   Throop JA, 2005, POSTHARVEST BIOL TEC, V36, P281, DOI 10.1016/j.postharvbio.2005.01.004
   Toylan H, 2014, SCI WORLD J, DOI 10.1155/2014/292681
   Unay D, 2007, J FOOD ENG, V78, P597, DOI 10.1016/j.jfoodeng.2005.10.038
   Unay D, 2018, CAPA APPL QUALITY GR
   Unay D, 2011, COMPUT ELECTRON AGR, V75, P204, DOI 10.1016/j.compag.2010.11.006
   UPCHURCH BL, 1991, T ASAE, V34, P1004, DOI 10.13031/2013.31763
   Valdez P., 2020, P ICLR 2020 WORKSH C
   Wen ZQ, 1999, EXPERT SYST APPL, V16, P307, DOI 10.1016/S0957-4174(98)00079-7
   Wu A, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106454
   Zhang BH, 2014, FOOD RES INT, V62, P326, DOI 10.1016/j.foodres.2014.03.012
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
   Zhu LL, 2021, CURR RES FOOD SCI, V4, P233, DOI 10.1016/j.crfs.2021.03.009
   Zou XB, 2010, COMPUT ELECTRON AGR, V70, P129, DOI 10.1016/j.compag.2009.09.014
NR 55
TC 7
Z9 8
U1 15
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38237
EP 38252
DI 10.1007/s11042-022-12230-6
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000785933700003
DA 2024-07-18
ER

PT J
AU Huang, JF
   Tang, SQ
   Teng, ZF
   Zhang, YC
   Zhou, X
AF Huang, Jianfei
   Tang, Suqiong
   Teng, Zhenfang
   Zhang, Yongchun
   Zhou, Xiao
TI Face tracking and recognition in video moving images based on
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video moving image; Adaptive multi feature fusion algorithm;
   Convolutional neural network; Face recognition
AB In order to accurately track and recognize faces in video moving images, a method for tracking and recognizing faces in video moving images based on convolutional neural networks is proposed. Establish feature maps through convolutional neural networks, extract deep convolutional features of face targets in video moving images, build a multi-feature fusion likelihood model of face targets in video moving images, determine the importance of features and update face targets State, according to the size of the weight, adaptively select a reasonable feature set to describe the current state of the target, so as to realize the tracking and recognition of the face target in the video moving image. The proposed method has good tracking results for face targets in video moving images, and can accurately track face targets in video moving images, and under occlusion conditions, the tracking results have low mean square error and average absolute error. Below 0.02, the tracking accuracy is higher and the recognition time is shorter, indicating that the convolutional neural network has a better application effect in face tracking and recognition in video moving images.
C1 [Huang, Jianfei; Tang, Suqiong; Teng, Zhenfang; Zhang, Yongchun; Zhou, Xiao] Wenzhou Univ, Informat Technol Ctr, Meiquan Big St Chashan, Wenzhou 325035, Zhejiang, Peoples R China.
C3 Wenzhou University
RP Zhou, X (corresponding author), Wenzhou Univ, Informat Technol Ctr, Meiquan Big St Chashan, Wenzhou 325035, Zhejiang, Peoples R China.
EM huangjf@wzu.edu.cn; tsq@wzu.edu.cn; 1852875@qq.com; 00802011@wzu.edu.cn;
   00802002@wzu.edu.cn
RI Zhang, Yongchun/Q-2364-2016
OI Zhou, Xiao/0000-0002-0032-4828
FU Wenzhou Association For Science and Technology [kjfw39]; Wenzhou
   Municipal Science and Technology Bureau [G20210043]; Department of
   Education of Zhejiang Province [Y202146494]
FX Partial financial support was received from Wenzhou Association For
   Science and Technology under [grant no. kjfw39], from Wenzhou Municipal
   Science and Technology Bureau under [grant no. G20210043], from
   Department of Education of Zhejiang Province under [grant no.
   Y202146494].
CR Ahmed A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P144, DOI 10.1109/ICAIBD.2018.8396183
   Bidelman GM, 2020, EAR HEARING, V41, P268, DOI 10.1097/AUD.0000000000000755
   Cevikalp H, 2020, INT J COMPUT VISION, V128, P3000, DOI 10.1007/s11263-020-01356-5
   Chen T, 2021, IET IMAGE PROCESS, V15, P3559, DOI 10.1049/ipr2.12192
   Choi JY, 2020, IEEE T IMAGE PROCESS, V29, P3270, DOI 10.1109/TIP.2019.2958404
   Deng ZY, 2019, IEEE T IMAGE PROCESS, V28, P3102, DOI 10.1109/TIP.2019.2894272
   Edmunds T, 2018, J VIS COMMUN IMAGE R, V50, P314, DOI 10.1016/j.jvcir.2017.12.004
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Han SS, 2020, JAMA DERMATOL, V156, P29, DOI 10.1001/jamadermatol.2019.3807
   Khammari M, 2019, IET IMAGE PROCESS, V13, P1880, DOI 10.1049/iet-ipr.2018.5560
   Li J, 2021, MULTIMED TOOLS APPL, V80, P17223, DOI 10.1007/s11042-020-09601-2
   Logashanmugam E., 2019, INDONESIAN J ELECT E, V13, P665, DOI [10.11591/ijeecs.v13.i2.pp665-670, DOI 10.11591/IJEECS.V13.I2.PP665-670]
   Ma LH, 2020, IET IMAGE PROCESS, V14, P2435, DOI 10.1049/iet-ipr.2019.0141
   Rodriguez AM, 2020, J FORENSIC SCI, V65, P1169, DOI 10.1111/1556-4029.14324
   Madhavan S, 2021, ARTIF INTELL REV, V54, P253, DOI 10.1007/s10462-019-09734-3
   Mao L, 2021, J INTELL FUZZY SYST, P1
   Müller D, 2021, J NONDESTRUCT EVAL, V40, DOI 10.1007/s10921-020-00740-y
   Qian LD, 2020, IEEE ACCESS, V8, P62830, DOI 10.1109/ACCESS.2020.2983774
   Tang FG, 2020, OPTIK, V205, DOI 10.1016/j.ijleo.2020.164238
   Thiruthuvanathan MM, 2022, MULTIMED TOOLS APPL, V81, P35535, DOI 10.1007/s11042-021-11010-y
   Trigueros DS, 2021, NEURAL NETWORKS, V134, P86, DOI 10.1016/j.neunet.2020.11.008
   Wang C, 2019, LASER OPTOELECTRON P, V56, DOI 10.3788/LOP56.201002
   Wang JZ, 2021, IEEE INSTRU MEAS MAG, V24, P78
   Wei Di, 2019, Computer Engineering and Applications, V55, P187, DOI 10.3778/j.issn.1002-8331.1803-0117
   Yang H, 2021, IEEE T IMAGE PROCESS, V30, P3858, DOI 10.1109/TIP.2021.3065843
   Zaman FHK, 2020, IET COMPUT VIS, V14, P122, DOI 10.1049/iet-cvi.2019.0531
NR 26
TC 0
Z9 0
U1 4
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33771
EP 33784
DI 10.1007/s11042-022-13025-5
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300007
DA 2024-07-18
ER

PT J
AU Khan, LS
   Khan, M
   Jamal, SS
   Amin, M
AF Khan, Lal Said
   Khan, Majid
   Jamal, Sajjad Shaukat
   Amin, Muhammad
TI An Efficient Digital Confidentiality Scheme Based on Commutative Chaotic
   Polynomial
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chebyshev polynomial; Chaotic scrambling matrix; Key sensitivity;
   Confusion; Diffusion
ID IMAGE; MAPS
AB One of the most critical aspects of this technologically progressive era is the propagation of information through an unsecured communication channel. The information is electronically transported as binary bits. One of the most important issues in the existing world is the secrecy of these digital contents. In this paper, we used Chebyshev's polynomial-based, chaotic maps to propose a new technique for encrypting images. The proposed encryption brings confusion as well as diffusion to the system presented, which is one of the utmost essential aspects of the encryption method. The confusion process is performed in two stages, XORing the original image with the Chebyshev polynomial generated matrices and scrambling, the chaotic scrambling matrix is also generated by the Chebyshev polynomial generated matrix, which increases the sensitivity of the cryptosystem to the key which initialize the parameters for Chebyshev polynomial. We checked our planned scheme against various performance analyses and contrasted them with established outcomes. The scheme is accomplished by offering excellent privacy to digital images.
C1 [Khan, Lal Said; Amin, Muhammad] Inst Space Technol, Dept Av Engn, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Jamal, Sajjad Shaukat] King Khalid Univ, Coll Sci, Dept Math, Abha, Saudi Arabia.
C3 King Khalid University
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019; Jamal, Sajjad/AHE-6498-2022
OI Khan, Majid/0000-0001-5454-3770; , LALSAID/0000-0002-5325-6443
FU Deanship of Scientific Research at King Khalid University
FX One of the author Dr. Sajjad Shaukat Jamal extends his gratitude to the
   Deanship of Scientific Research at King Khalid University for funding
   this work through research groups program under grant number R. G. P.
   1/399/42.
CR Abd El-Latif AA, 2020, IEEE T NETW SERV MAN, V17, P118, DOI 10.1109/TNSM.2020.2969863
   Abd-El-Atty B, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2386-3
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Brahim AH, 2023, INF SECUR J, V32, P59, DOI 10.1080/19393555.2021.1943572
   Chatterjee S, 2018, IEEE T DEPEND SECURE, V15, P824, DOI 10.1109/TDSC.2016.2616876
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   GEISEL T, 1984, PHYS LETT A, V105, P263, DOI 10.1016/0375-9601(84)90993-9
   Guesmi R, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Jarin I, 2018, 2018 4TH IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2018), P99, DOI 10.1109/WIECON-ECE.2018.8783074
   Kang XJ, 2019, IEEE ACCESS, V7, P114459, DOI 10.1109/ACCESS.2019.2930183
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2017, MULTIMED TOOLS APPL, V76, P24027, DOI 10.1007/s11042-016-4090-y
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Kocarev L., 2015, SYST SIGNAL PROCESS, V24
   Lai H, 2014, NONLINEAR DYNAM, V77, P1427, DOI 10.1007/s11071-014-1388-z
   Lei Z., 2011, INT C IMAGE SIGNAL P, V4, P741
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang WKS, 2011, STUD COMPUT INTELL, V354, P99
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhong YR., 2018, P S 2018 INT C WAV A
NR 30
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33591
EP 33611
DI 10.1007/s11042-022-13078-6
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200005
DA 2024-07-18
ER

PT J
AU Wu, DM
   Yuan, CZ
AF Wu, Dongmei
   Yuan, Chengzhi
TI Threshold image segmentation based on improved sparrow search algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Swarm optimization algorithm; Threshold image segmentation; 2-D
   histogram; Maximum entropy; Nonlinear weight; Levy flight
ID OPTIMIZATION ALGORITHM; ENTROPY
AB Threshold segmentation based on swarm intelligence optimization algorithm is a research hotspot in image processing, because of its good segmentation effect and easy implementation. This paper proposes an image threshold segmentation method based on an improved sparrow search algorithm and 2-D maximum entropy method. In the proposed algorithm, the nonlinear inertia weight is introduced into the entrants' update formula to improve the local exploration ability of the algorithm, and Levy flight is introduced into the vigilant sparrows' update formula to prevent the algorithm from falling into the local optimal solution in the later stage of iteration. In addition, improved sparrow search algorithm is tested on fifteen benchmark functions. The results represent the merit of the proposed algorithm with respect to other algorithms. Finally, the proposed algorithm is applied to entropy based image segmentation. Experiment results on classical images and medical images show that the proposed method improves the segmentation effect in terms of peak signal-to-noise ratio and feature similarity.
C1 [Wu, Dongmei; Yuan, Chengzhi] Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Jiangsu Engn Lab IOT Intelligent Robots, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Wu, DM (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat & Artificial Intelligence, Jiangsu Engn Lab IOT Intelligent Robots, Nanjing, Peoples R China.
EM wudm@njupt.edu.cn
RI Wu, Dongmei/AAS-6647-2020
OI Wu, Dongmei/0000-0001-9830-0527
FU National Natural Science Foundation of China [61873326]; Natural Science
   Foundation of Jiangsu Province [BK20130873]; Scientific Research
   Foundation for Returned Scholars of Ministry of Education [BJ213010];
   Scientific Research Funds of Nanjing University of Posts and
   Telecommunications [NY220216]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61873326, Natural Science Foundation of Jiangsu Province
   under Grant BK20130873, The Scientific Research Foundation for Returned
   Scholars of Ministry of Education under Grant BJ213010, The Scientific
   Research Funds of Nanjing University of Posts and Telecommunications
   under Grant NY220216.
CR Abutaleb A., 1988, 31 ANN TECHN S 1988, DOI 10.1117/12.942103
   Afshin S, 2020, ARXIV PREPRINT ARXIV
   Barron JT., 2020, COMPUTER VISION ECCV, DOI 10.1007/978-3-030-58558-7_27
   Bhandari AK, 2020, IEEE-CAA J AUTOMATIC, V7, P200, DOI 10.1109/JAS.2019.1911843
   Cao QJ, 2020, MULTIMED TOOLS APPL, V79, P27091, DOI 10.1007/s11042-020-09265-y
   Chakraborty R, 2021, J AMB INTEL HUM COMP, V12, P7793, DOI 10.1007/s12652-020-02506-w
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Duan LZ, 2021, J SUPERCOMPUT, V77, P6734, DOI 10.1007/s11227-020-03566-7
   Esmaeili L, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115106
   Gai JB, 2021, MEASUREMENT, V185, DOI 10.1016/j.measurement.2021.110079
   Huang CY, 2021, ALEX ENG J, V60, P183, DOI 10.1016/j.aej.2020.06.054
   Jena B, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104293
   Jia H., 2019, APPL SCI TECHNOLOGY, V46, P16, DOI [10.11991/yykj.201904022, DOI 10.11991/YYKJ.201904022]
   Jiang ZQ, 2021, ARAB J SCI ENG, V46, P8371, DOI 10.1007/s13369-021-05483-0
   Kalyani R, 2021, MULTIMED TOOLS APPL, V80, P27553, DOI 10.1007/s11042-021-10909-w
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kathiroli P., 2021, INT C COMM INF COMP, DOI 10.1109/ICCICT50803.2021.9510032
   Kennedy J., 2002, ICNN95 INT C NEURAL
   Khairuzzaman AKM, 2020, INT J SWARM INTELL R, V11, P123, DOI 10.4018/IJSIR.2020100106
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Lei B, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105687
   Li, COMPUT KNOWL TECHNOL, P232, DOI 10.14004/j.cnki.ckt.2021.0594
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li G, 2020, TSINGHUA SCI TECHNOL, V25, P149, DOI 10.26599/TST.2019.9010026
   Liang JH, 2018, MULTIMED TOOLS APPL, V77, P31787, DOI 10.1007/s11042-018-6119-x
   Liang QK, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/9915420
   Lin QQ, 2020, SENSOR MATER, V32, P2687, DOI 10.18494/SAM.2020.2798
   Liu GY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041224
   Liu J.Z., 1993, Acta Automatica Sin, V19, P101, DOI DOI 10.16383/J.AAS.1993.01.015
   Liu Y., 2010, MULT TECHN ICMT 2010, DOI 10.1109/ICMULT.2010.5631047
   Lv X, SYST ENG ELECT, P318, DOI 10.12305/j.issn.1001-506x.2021.02.05
   Mahajan S, 2021, MULTIMED TOOLS APPL, V80, P19335, DOI 10.1007/s11042-021-10641-5
   Mao QH., 2021, COMPUT SCI EXPLOR, V15, P1155, DOI [10.3778/j.issn.1673-9418.2010032, DOI 10.3778/J.ISSN.1673-9418.2010032]
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadi-Balani A, 2021, COMPUT IND ENG, V152, DOI 10.1016/j.cie.2020.107050
   Moussa M, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620502278
   Nejad MR, 2016, ADV SCI TECHNOL-RES, V10, P125, DOI 10.12913/22998624/61940
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1989, SIGNAL PROCESS, V16, P97, DOI 10.1016/0165-1684(89)90090-X
   PAL NR, 1989, IEE PROC-E, V136, P284, DOI 10.1049/ip-e.1989.0039
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Peng C, 2020, IEEE-ASME T MECH, V25, P762, DOI 10.1109/TMECH.2020.2975096
   Qais MH, 2020, APPL INTELL, V50, P3926, DOI 10.1007/s10489-020-01727-y
   Roy PC, 2019, PROC CVPR IEEE, P2581, DOI 10.1109/CVPR.2019.00269
   Shen Y., 2021, CONTROL DECIS, P1, DOI DOI 10.13195/J.KZYJC.2021.0513
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   SOLIS FJ, 1981, MATH OPER RES, V6, P19, DOI 10.1287/moor.6.1.19
   Takeda H., 2020, 2020 IEEE 9 GLOB C C, DOI 10.1109/GCCE50665.2020.9291873
   Taruna, 2021, International Journal of Information Technology, P1375, DOI 10.1007/s41870-021-00655-5
   Wumaier T, 2021, IEEE ACCESS, V9, P69307, DOI 10.1109/ACCESS.2021.3075547
   Wang P, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5556780
   Wu Dinghui, 2017, Journal of Central South University (Science and Technology), V48, P2105, DOI 10.11817/j.issn.1672-7207.2017.08.018
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Yan ZP, 2021, IEEE ACCESS, V9, P41294, DOI 10.1109/ACCESS.2020.3005452
   Yuan JH, 2021, IEEE ACCESS, V9, P16623, DOI 10.1109/ACCESS.2021.3052960
   Zhang JN, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6622935
   Zhou SH, 2021, OPTIK, V244, DOI 10.1016/j.ijleo.2021.167516
NR 60
TC 15
Z9 16
U1 10
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33513
EP 33546
DI 10.1007/s11042-022-13073-x
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784951200006
PM 35463221
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Rout, DK
   Subudhi, BN
   Veerakumar, T
   Chaudhury, S
   Soraghan, J
AF Rout, Deepak Kumar
   Subudhi, Badri Narayan
   Veerakumar, T.
   Chaudhury, Santanu
   Soraghan, John
TI Multiresolution visual enhancement of hazy underwater scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Dark channel prior; Discrete wavelet transform;
   Underwater image enhancement
ID DISCRETE WAVELET TRANSFORM; IMAGE-ENHANCEMENT; REFRACTIVE-INDEX;
   CONTRAST; SYSTEM; MODEL; COMPLEXITY; ALGORITHM; SALINITY; MEMORY
AB Haze is an obvious phenomenon in the underwater scenario. The scene visibility reduces to a great extent due to haze, which makes the underwater visual surveillance quite a challenging task. In this article, we have exploited the multi-resolution ability of discrete wavelet transform and applied dark channel prior based transmission map estimation scheme to dehaze the highly degraded underwater image and restored the color. A three-fold scheme for dehazing of underwater sequences is proposed. In the first stage, image details are extracted using discrete wavelet transform followed by image negative operation. In the second stage, the negative of detail images are enhanced by the help of dark channel prior. The third stage is used for reconstruction, where the enhanced image details are used along with the single level approximate of the input image to get the dehazed underwater image using inverse discrete wavelet transform. The proposed scheme is tested with numerous standard underwater images, as well as the excavation images of Dwaraka (Dvaraka) underwater ruins. The effectiveness of the proposed scheme is justified by comparing it with different stateof-the-art image dehazing techniques. The quantitative evaluation has been carried out using five well established general purpose non-reference image quality indices namely BIQI (blind image quality index), BLIINDS (BLind Image Integrity Notator using DCT Statistics), DIIVINE (Distortion Identification-based Image Verity and INtegrity Evaluation), BRISQUE (Blind/Referenceless Image Spatial Quality Evaluator), and SSEQ (SpatialSpectral Entropy-based Quality). Encouraging scores of 35.01, 30.105, 27.22, 30.10, and 27.8, are achieved for the BIQI, BRISQUE, SSEQ, DIIVINE, and BLIINDS, respectively. Four evaluation measures, exclusively designed for underwater scenarios (underwater image quality, contrast, sharpness, and colorfulness measures) are also used to test the performance of the proposed scheme.
C1 [Rout, Deepak Kumar; Veerakumar, T.] Natl Inst Technol Goa, Veling, Goa, India.
   [Subudhi, Badri Narayan] Indian Inst Technol Jammu, Jammu 181221, Jammu & Kashmir, India.
   [Chaudhury, Santanu] Indian Inst Technol Jodhpur, Jheepasani, Rajasthan, India.
   [Soraghan, John] Univ Strathclyde, Glasgow, Lanark, Scotland.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) Jammu; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Jodhpur; University of Strathclyde
RP Subudhi, BN (corresponding author), Indian Inst Technol Jammu, Jammu 181221, Jammu & Kashmir, India.
EM deepak.y.rout@gmail.com; subudhi.badri@iitjammu.ac.in;
   tveerakumar@nitgoa.ac.in; santanuc@ee.iitd.ac.in;
   j.soraghan@strath.ac.uk
RI Rout, Deepak/N-1550-2018; Thangaraj, Veerakumar/AAS-8625-2020
OI Rout, Deepak/0000-0001-5692-5385; Thangaraj,
   Veerakumar/0000-0001-9084-1847
CR Addison P., 2017, ILLUSTRATED WAVELET, DOI DOI 10.1201/9781315372556
   Agarwal S, 2017, IEEE T INTELL TRANSP, V18, P1907, DOI 10.1109/TITS.2016.2613982
   Ahn J, 2017, J MAR SCI TECH-JAPAN, V22, P758, DOI 10.1007/s00773-017-0442-1
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Bickford D, 2007, TRENDS ECOL EVOL, V22, P148, DOI 10.1016/j.tree.2006.11.004
   Boujelbene R, 2019, MULTIMED TOOLS APPL, V78, P1649, DOI 10.1007/s11042-018-6262-4
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen Z, 2014, OPTIK, V125, P2090, DOI 10.1016/j.ijleo.2013.10.038
   Cheng CY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P110, DOI 10.1109/ICSIPA.2015.7412173
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Gao YY, 2014, SIGNAL PROCESS, V103, P380, DOI 10.1016/j.sigpro.2014.02.016
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   Goh YZ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P421, DOI 10.1109/CISP.2008.335
   González-Rivero M, 2014, AQUAT CONSERV, V24, P184, DOI 10.1002/aqc.2505
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Harris S. E., 1986, OCEANS 86 Conference Record. Science-Engineering-Adventure (Cat. No.86CH2363-0), P6, DOI 10.1109/OCEANS.1986.1160528
   Hassan N, 2021, MULTIMED TOOLS APPL, V80, P1839, DOI 10.1007/s11042-020-09752-2
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hsia CH, 2013, IEEE T CIRC SYST VID, V23, P671, DOI 10.1109/TCSVT.2012.2211953
   Hsia CH, 2009, IEEE T CIRC SYST VID, V19, P1202, DOI 10.1109/TCSVT.2009.2020259
   Hussein R, 2015, IEEE T INSTRUM MEAS, V64, P3601, DOI 10.1109/TIM.2015.2454651
   J M., 2012, COMPUTER SCI ENG INT, V2, P41
   Jaffe JS, 2015, IEEE J OCEANIC ENG, V40, P683, DOI 10.1109/JOE.2014.2350751
   Ju MY, 2019, IEEE T CIRC SYST VID, V29, P2349, DOI 10.1109/TCSVT.2018.2869594
   Lee D, 2012, OCEAN ENG, V48, P59, DOI 10.1016/j.oceaneng.2012.04.006
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Lu HM, 2015, INT CONF ACOUST SPEE, P1623, DOI 10.1109/ICASSP.2015.7178245
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Naik DK, 2014, IEEE INT ADV COMPUT, P1081, DOI 10.1109/IAdCC.2014.6779476
   Nikan S, 2015, IET IMAGE PROCESS, V9, P12, DOI 10.1049/iet-ipr.2013.0792
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Olszewska Joanna Isabelle, 2013, Proceedings of the 6th International Conference on Bio-inspired Systems and Signal Processing. BIOSIGNALS 2013, P429
   Ortega A, 1999, PROC SPIE, V3813, P386, DOI 10.1117/12.366796
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Pereira DA, 2004, OPT ENG, V43, P299, DOI 10.1117/1.1637903
   Priyadharsini R, 2018, MULTIDIM SYST SIGN P, V29, P1845, DOI 10.1007/s11045-017-0533-5
   Raihan AJ, 2019, IET IMAGE PROCESS, V13, P1587, DOI 10.1049/iet-ipr.2019.0117
   Raj SMA, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761194
   Rout DK, 2018, EXPERT SYST APPL, V97, P117, DOI 10.1016/j.eswa.2017.12.009
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sahu G, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103008
   Salazar Colores S, 2019, IET IMAGE PROCESS, V13, P2877, DOI 10.1049/iet-ipr.2018.6403
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shahbahrami A, 2012, J SUPERCOMPUT, V62, P1045, DOI 10.1007/s11227-012-0790-x
   Singh H, 2000, J FIELD ARCHAEOL, V27, P319, DOI 10.1179/jfa.2000.27.3.319
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Souaidi M, 2019, IET IMAGE PROCESS, V13, P2233, DOI 10.1049/iet-ipr.2019.0415
   Srivastava, 2017, 5 LEVEL WAVELET DECO, V2017
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Temple SE, 2007, J FISH BIOL, V70, P1626, DOI 10.1111/j.1095-8649.2007.01432.x
   Twardowski MS, 2001, J GEOPHYS RES-OCEANS, V106, P14129, DOI 10.1029/2000JC000404
   Vasamsetti S, 2017, OCEAN ENG, V141, P88, DOI 10.1016/j.oceaneng.2017.06.012
   Wang, 2019, 12 INT C IM SIGN PRO, P1
   Wood R., 2012, Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSIGNALS 2012), P494
   Xi Qiao, 2017, Information Processing in Agriculture, V4, P206, DOI 10.1016/j.inpa.2017.06.001
   Yassin A.A., 2013, Int. J. Comput. Sci. Issues, P220
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Zervas ND, 2001, IEEE T CIRC SYST VID, V11, P1246, DOI 10.1109/76.974679
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 72
TC 3
Z9 3
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32907
EP 32936
DI 10.1007/s11042-022-12692-8
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782717900004
DA 2024-07-18
ER

PT J
AU Ustubioglu, B
   Küçükugurlu, B
   Ulutas, G
AF Ustubioglu, Beste
   Kucukugurlu, Busranur
   Ulutas, Guzin
TI Robust copy-move detection in digital audio forensics based on pitch and
   modified discrete cosine transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Audio forgery; Audio forensic; MDCT; Pitch
AB Copy-move forgery is one of the most widely used methods in the field of audio forensic because it is difficult to detect and convenient to apply. However, post-processing operations applied to forged speech to hide traces of forgery make detection of forensic more difficult. In this study, we propose a robust method for detection and localization of the audio copy-move forgery using modified discrete cosine transform (MDCT). For this purpose, we first divide the speech recording into voiced and unvoiced parts by extracting a pitch sequence from the speech recording. After the determination of voiced parts, we extract MDCT coefficients from them and take the mean of the transpose of the coefficient matrix as the feature. These MDCT features are very robust against commonly used post-processing operations (especially audio compressing). Euclidean distance (ED) is applied to compute the similarities between the features. The voiced parts, which give minimum ED are determined as copy-move audio parts. Also, two separate databases (Pitch-based and Voice Activity Detection (VAD-based) are created during the work to evaluate the performance of the proposed method because there is no common database in the field of audio forensic in the literature. Experiment results show that the proposed method gives better results for detection and localization of audio copy-move forgery on different databases compared to other studies in the literature. The proposed method is also robust against common post-processing operations such as noise addition, filtering operation, and especially compression operation.
C1 [Ustubioglu, Beste; Kucukugurlu, Busranur; Ulutas, Guzin] Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
   [Kucukugurlu, Busranur] Gumushane Univ, Dept Software Engn, Gumushane, Turkey.
C3 Karadeniz Technical University; Gumushane University
RP Ustubioglu, B (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
EM bustubioglu@ktu.edu.tr; busra.kueukugurlu@gumushane.edu.tr;
   gulutas@ktu.edu.tr
RI USTUBIOGLU, Beste/AAJ-8187-2021; Ulutas, Guzin/ABI-4484-2020
OI kucukugurlu, busranur/0000-0002-6034-6850
FU Scientific and Technological Research Council of Turkey (TuBTAK)
   [122E013]
FX This work is supported by The Scientific and Technological Research
   Council of Turkey (TuBTAK, Project No. 122E013).
CR [Anonymous], 1993, NASA STIRECON TECH R, V93, DOI DOI 10.6028/NIST.IR.4930
   [Anonymous], 2016, SPEAK OD WORKSH
   Campbell W.M., 2006, Speaker and Language Recognition Workshop, P1, DOI [10.1109/ODYSSEY.2006.248091, DOI 10.1109/ODYSSEY.2006.248091]
   Champod C, 2000, SPEECH COMMUN, V31, P193, DOI 10.1016/S0167-6393(99)00078-3
   Chen JR, 2016, MULTIMED TOOLS APPL, V75, P2303, DOI 10.1007/s11042-014-2406-3
   Cuccovillo L, 2013, IEEE INT WORKSH MULT, P177, DOI 10.1109/MMSP.2013.6659284
   Gupta V, 2010, INT CONF ACOUST SPEE, P261, DOI 10.1109/ICASSP.2010.5495963
   Huang XC, 2019, INT J DIGIT CRIME FO, V11, P47, DOI 10.4018/IJDCF.2019040104
   Imran M, 2017, IEEE ACCESS, V5, P12843, DOI 10.1109/ACCESS.2017.2717842
   Ji-nian Xiao, 2014, Journal of Shanghai Jiaotong University (Science), V19, P392, DOI 10.1007/s12204-014-1515-5
   Lin XD, 2017, INT CONF ACOUST SPEE, P2142, DOI 10.1109/ICASSP.2017.7952535
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Luo D, 2017, IEEE T INF FOREN SEC, V12, P432, DOI 10.1109/TIFS.2016.2622012
   Malik H, 2012, AUD ENG SOC C, P5
   Muhammad G., 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P11, DOI 10.1109/ICDT.2010.10
   Nordén F, 2005, IEEE T SPEECH AUDI P, V13, P163, DOI 10.1109/TSA.2004.838535
   Pan XY, 2012, INT CONF ACOUST SPEE, P1841, DOI 10.1109/ICASSP.2012.6288260
   Talkin D., 1995, Speech coding and synthesis, V495, P518
   Wang FY, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1652, DOI 10.1109/ICCT.2017.8359911
   Xie ZZ, 2018, J INF SECUR APPL, V43, P37, DOI 10.1016/j.jisa.2018.10.003
   Yan Q, 2019, IEEE T INF FOREN SEC, V14, P2331, DOI 10.1109/TIFS.2019.2895965
   Yan Q, 2015, INT CONF ACOUST SPEE, P1782, DOI 10.1109/ICASSP.2015.7178277
   Zahorian SA, 2008, J ACOUST SOC AM, V123, P4559, DOI 10.1121/1.2916590
   Zhang YJ, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010023
   Zhao H, 2017, MULTIMED TOOLS APPL, V76, P13897, DOI 10.1007/s11042-016-3758-7
NR 25
TC 5
Z9 5
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27149
EP 27185
DI 10.1007/s11042-022-13035-3
EA APR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000781124000020
DA 2024-07-18
ER

PT J
AU Vadhnani, S
   Singh, N
AF Vadhnani, Sonia
   Singh, Navjot
TI Brain tumor segmentation and classification in MRI using SVM and its
   variants: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Otsu thresholding; Discrete wavelet transform;
   Principal component analysis; Support vector machine
ID SUPPORT VECTOR MACHINE; OF-THE-ART; IMAGE CLASSIFICATION; TRANSFORM;
   SYSTEM
AB The process of separation of brain tumor from normal brain tissues is Brain tumor segmentation. Segmentation of tumor from the MR images is a very challenging task as brain tumors are of different shapes and sizes. There are multiple phases to achieve the segmentation and the phases are pre-processing, segmentation, feature extraction, feature reduction, and classification of the tumor into benign and malignant. In this paper, Otsu thresholding is used in segmentation phase, Discrete Wavelet Transform (DWT) in feature extraction phase, Principal Component Analysis (PCA) in feature reduction phase and Support Vector Machine (SVM), Least Squared-Support Vector Machine (LS-SVM), Proximal Support Vector Machine (PSVM) and Twin Support Vector Machine (TWSVM) in the classification phase. We have compared the performances of all these classifiers, where TWSVM outperformed all other classifiers with 100% accuracy.
C1 [Vadhnani, Sonia] MNNIT, Allahabad, Prayagraj, India.
   [Singh, Navjot] IIIT, Allahabad, Prayagraj, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology; Indian Institute of Information Technology
   Allahabad
RP Singh, N (corresponding author), IIIT, Allahabad, Prayagraj, India.
EM sv.mnnit.22@gmail.com; navjot@iiita.ac.in
RI Singh, Navjot/I-5444-2017
OI Singh, Navjot/0000-0003-0409-8482
CR Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4
   Anitha R, 2018, INT J IMAG SYST TECH, V28, P48, DOI 10.1002/ima.22255
   [Anonymous], 2015, 2015 INT C COMP COMM
   Balafar MA, 2014, ARTIF INTELL REV, V41, P441, DOI 10.1007/s10462-012-9318-2
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bernal J, 2019, ARTIF INTELL MED, V95, P64, DOI 10.1016/j.artmed.2018.08.008
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaplot S, 2006, BIOMED SIGNAL PROCES, V1, P86, DOI 10.1016/j.bspc.2006.05.002
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Demuth H, 1993, NEURAL NETWORK TOOLB, V3, P0
   Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341
   Ejaz K, 2018, INT J ADV COMPUT SC, V9, P394
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Gordillo N, 2013, MAGN RESON IMAGING, V31, P1426, DOI 10.1016/j.mri.2013.05.002
   Gurusamy R, 2017, CMC-COMPUT MATER CON, V53, P91
   Jayadeva, 2007, IEEE T PATTERN ANAL, V29, P905, DOI 10.1109/TPAMI.2007.1068
   Kannan S, 2005, ICGST GVIP J, V5, P2
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu JW, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.182
   Liu J, 2014, TSINGHUA SCI TECHNOL, V19, P578, DOI 10.1109/TST.2014.6961028
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Louis DN, 2016, ACTA NEUROPATHOL, V131, P803, DOI 10.1007/s00401-016-1545-1
   Maitra M, 2006, BIOMED SIGNAL PROCES, V1, P299, DOI 10.1016/j.bspc.2006.12.001
   Mangasarian O., 2001, Proceedings KDD-2001: Knowledge Discovery and Data Mining
   Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17
   Mathew AR, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P75, DOI 10.1109/CSPC.2017.8305810
   McClelland JL, 1986, PARALLEL DISTRIBUTED, V2, P216, DOI [DOI 10.7551/MITPRESS/5237.001.0001, 10.7551/mitpress/5237.003.0008, DOI 10.7551/MITPRESS/5237.003.0008]
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mohsen H, 2017, Annals Of "Dunarea De Jos"University Of Galati, Mathematics, Physics, Theoretical mechanics
   Mwangi B, 2014, NEUROINFORMATICS, V12, P229, DOI 10.1007/s12021-013-9204-3
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Polly FP, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P813, DOI 10.1109/ICOIN.2018.8343231
   Rathi VGP., 2012, NOVEL APPROACH FEATU
   Rudrapathy B., 2020, DETECTION BRAIN TUMO, V107
   Saman S, 2019, INT J MULTIMED INF R, V8, P79, DOI 10.1007/s13735-018-0162-2
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Shanthi KJ, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P422
   Shil SK, 2017, I C INF COMM TECH CO, P54, DOI 10.1109/ICTC.2017.8190941
   Song S., 2017, BIOMED ENG REV, V1, P2375, DOI 10.18103/bme.v3i1.1550
   Stadlbauer A, 2004, NEUROIMAGE, V23, P454, DOI 10.1016/j.neuroimage.2004.06.022
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tavara S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3280989
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Vaishnavee KB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING AND TECHNOLOGY (ICETECH), P69
   van Gestel T, 2004, MACH LEARN, V54, P5, DOI 10.1023/B:MACH.0000008082.80494.e0
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wang HF, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P279
   Weglinski T., 2011, 2011 VII-th International Conference on Perspective Technologies and Methods in MEMS Design (MEMSTECH), P185
   Yang XF, 2011, MED PHYS, V38, P2879, DOI 10.1118/1.3584199
   Zhan TM, 2018, IEEE ACCESS, V6, P57113, DOI 10.1109/ACCESS.2018.2873674
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2011, PROG ELECTROMAGN RES, V116, P65, DOI 10.2528/PIER11031709
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YD, 2017, J EXP THEOR ARTIF IN, V29, P299, DOI 10.1080/0952813X.2015.1132274
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zöllner FG, 2012, Z MED PHYS, V22, P205, DOI 10.1016/j.zemedi.2012.03.007
NR 62
TC 10
Z9 10
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31631
EP 31656
DI 10.1007/s11042-022-12240-4
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000001
DA 2024-07-18
ER

PT J
AU Rahmeni, R
   Ben Aicha, A
   Ben Ayed, Y
AF Rahmeni, Raoudha
   Ben Aicha, Anis
   Ben Ayed, Yassine
TI Voice spoofing detection based on acoustic and glottal flow features
   using conventional machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ASV spoof; Glottal flow; Features selection; Features engineering; SVM;
   XGBoost
ID SPEAKER VERIFICATION; COUNTERMEASURES; SPEECH
AB Automatic Speaker Verification (ASV) systems are vulnerable to spoofing attacks. Most existing spoofing detection systems rely on two main points; the feature extraction and the classification methodology. In this paper, we propose a new strategy to recognize the veritable discourse from the spoofed one. The thought depends on the investigation of the human voice to identify the relevant acoustic and glottal features. Those features will be utilized to separate between a veritable discourse and a spoofed one. We have tested numerous of speech acoustic and glottal flow features from all data sets of ASVspoof challenge 2015 and ASVspoof challenge 2017. Several features are extracted and analyzed to choose the most pertinent ones using feature engineering methodology. To detect the genuine speech from the spoofed one, conventional machine learning techniques are applied as classification techniques mainly Support Vector Machine (SVM) and eXtreme Gradient Boosting (XGBoost). Features exploration and analysis leads to pick up pertinent ones. These features are used then as input for the SVM with multiple kernel and for XGBoost classification techniques. The highest rate of achieving accuracy is about 98.80% obtained with the XGBoost classification technique. Experimental results show the validity and the robustness of the proposed method.
C1 [Rahmeni, Raoudha] Univ Sfax, Natl Sch Engineers Sfax ENIS MIRACL Multimedia, InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
   [Ben Aicha, Anis] Univ Carthage, Fac Sci Bizerte FSB COSIM Commun Signals & IMages, Carthage, Tunisia.
   [Ben Ayed, Yassine] Univ Sfax, Higher Inst Comp Sci & Multimedia ISIMS MIRACL Mu, InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Universite de Carthage; Universite de
   Sfax; Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL)
RP Rahmeni, R (corresponding author), Univ Sfax, Natl Sch Engineers Sfax ENIS MIRACL Multimedia, InfoRmat Syst & Adv Comp Lab, Sfax, Tunisia.
EM raoudha.rahmeni@gmail.com; anis.benaicha@supcom.tn;
   yassine.benayed@isims.usf.tn
CR Alam MJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2072
   [Anonymous], 2018, IEEE INT CON MULTI
   [Anonymous], 2016, NEW FEATURE AUTOMATI
   Ben Ayed Mezghani D., 2010, INT J HYBRID INF TEC, V3, P3
   Bhattacharyya D., 2009, SCI TECHNOL HUM VAL, V2, P3, DOI [10.1063/1.3183558, DOI 10.1063/1.3183558]
   Cemal H, 2011, ELECO 7 INT C EL EL, P157
   Chee LS, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P15
   Chen NX, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2097
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen ZX, 2017, INTERSPEECH, P102, DOI 10.21437/Interspeech.2017-1085
   Chennoukh S, 2001, INT CONF ACOUST SPEE, P665, DOI 10.1109/ICASSP.2001.940919
   CHILDERS DG, 1995, SPEECH COMMUN, V16, P127, DOI 10.1016/0167-6393(94)00050-K
   Chow D, 2004, LECT NOTES ARTIF INT, V3157, P901
   CUMMINGS KE, 1995, J ACOUST SOC AM, V98, P88, DOI 10.1121/1.413664
   Dave N., 2013, INT J ADV RES ENG TE
   De Leon PL, 2010, INT CONF ACOUST SPEE, P1798, DOI 10.1109/ICASSP.2010.5495413
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P994, DOI 10.1109/TASL.2011.2170835
   Duraibi S, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1845, DOI 10.1109/SSCI47803.2020.9308489
   Ebenuwa SH, 2019, IEEE ACCESS, V7, P24649, DOI 10.1109/ACCESS.2019.2899578
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Fazel A, 2011, IEEE CIRC SYST MAG, V11, P62, DOI 10.1109/MCAS.2011.941080
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Font R, 2017, INTERSPEECH, P7, DOI 10.21437/Interspeech.2017-450
   Ji Z, 2017, INTERSPEECH, P87, DOI 10.21437/Interspeech.2017-1246
   Kim On CH, 2006, INT C COMP INF
   Kinnunen T, 2007, LECT NOTES COMPUT SC, V4642, P58
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Lavrentyeva G, 2019, INTERSPEECH, P1033, DOI 10.21437/Interspeech.2019-1768
   Murty KR, 2006, IEEE SIGNAL PROC LET, V13, P52, DOI 10.1109/LSP.2005.860538
   Novoselov S, 2016, IEEE INT C AC SPEECH
   Novoselov S, 2016, INT CONF ACOUST SPEE, P5475, DOI 10.1109/ICASSP.2016.7472724
   Patel TB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2062
   Patil HA, 2017, INTERSPEECH, P12, DOI 10.21437/Interspeech.2017-1362
   Paul D, 2017, INT CONF ACOUST SPEE, P2047, DOI 10.1109/ICASSP.2017.7952516
   Rahman R U., 2020, Social media adoption and financial sustainability: learned lessons from developing countries, P1
   Rahmeni R, 2019, PROCEDIA COMPUT SCI, V159, P668, DOI 10.1016/j.procs.2019.09.222
   Rahmeni Raoudha, 2020, PROCEDIA COMPUTER SC, V176, P1073
   ROSENBERG AE, 1976, P IEEE, V64, P475, DOI 10.1109/PROC.1976.10156
   Satoh T., 2001, Proc. Eur. Conf. Speech Commun. Technol. (Eurospeech), P759
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Sheridan RP, 2016, J CHEM INF MODEL, V56, P2353, DOI 10.1021/acs.jcim.6b00591
   VISWANATHAN R, 1975, IEEE T ACOUST SPEECH, VAS23, P309, DOI 10.1109/TASSP.1975.1162675
   Williams C.K.I, 2003, Journal of the American Statistical Association, V98, P489, DOI [DOI 10.1198/JASA.2003.S269, 10.1198/jasa.2003.s, 10.1198/jasa.2003]
   Witkowski M, 2017, INTERSPEECH, P27, DOI 10.21437/Interspeech.2017-776
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Xiao X, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2052
   Yu B, 2020, BIOINFORMATICS, V36, P1074, DOI 10.1093/bioinformatics/btz734
   Yu H, 2017, IEEE ACCESS, V5, P4779, DOI 10.1109/ACCESS.2017.2687041
NR 48
TC 8
Z9 8
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31443
EP 31467
DI 10.1007/s11042-022-12606-8
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700009
DA 2024-07-18
ER

PT J
AU Revathi, A
   Nagakrishnan, R
   Sasikaladevi, N
AF Revathi, Arunachalam
   Nagakrishnan, R.
   Sasikaladevi, N.
TI Comparative analysis of Dysarthric speech recognition: multiple features
   and robust templates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamma tone energy features; Modified group delay Cepstrum; Stockwell
   cepstral features; Dysarthric speech recognition; Speech enhancement;
   Clusters
AB Research on recognizing the speeches of normal speakers is generally in practice for numerous years. Nevertheless, a complete system for recognizing the speeches of persons with a speech impairment is still under development. In this work, an isolated digit recognition system is developed to recognize the speeches of speech-impaired people affected with dysarthria. Since the speeches uttered by the dysarthric speakers are exhibiting erratic behavior, developing a robust speech recognition system would become more challenging. Even manual recognition of their speeches would become futile. This work analyzes the use of multiple features and speech enhancement techniques in implementing a cluster-based speech recognition system for dysarthric speakers. Speech enhancement techniques are used to improve speech intelligibility or reduce the distortion level of their speeches. The system is evaluated using Gamma-tone energy (GFE) features with filters calibrated in different non-linear frequency scales, stock well features, modified group delay cepstrum (MGDFC), speech enhancement techniques, and VQ based classifier. Decision level fusion of all features and speech enhancement techniques has yielded a 4% word error rate (WER) for the speaker with 6% speech intelligibility. Experimental evaluation has provided better results than the subjective assessment of the speeches uttered by dysarthric speakers. The system is also evaluated for the dysarthric speaker with 95% speech intelligibility. WER is 0% for all the digits for the decision level fusion of speech enhancement techniques and GFE features. This system can be utilized as an assistive tool by caretakers of people affected with dysarthria.
C1 [Revathi, Arunachalam; Nagakrishnan, R.] SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
   [Sasikaladevi, N.] SASTRA Deemed Univ, Dept CSE SoC, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
EM revathi@ece.sastra.edu
CR Aihara R, 2017, INTERSPEECH, P3374, DOI 10.21437/Interspeech.2017-664
   Aihara R, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-5
   Arunachalam R, 2019, MULTIMED TOOLS APPL, V78, P20787, DOI 10.1007/s11042-019-7329-6
   Doire CSJ, 2017, IEEE-ACM T AUDIO SPE, V25, P572, DOI 10.1109/TASLP.2016.2641904
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   España-Bonet C, 2016, LECT NOTES COMPUT SC, V10077, P97, DOI 10.1007/978-3-319-49169-1_10
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Hegde RM, 2007, IEEE T AUDIO SPEECH, V15, P190, DOI 10.1109/TASL.2006.876858
   Jiao YS, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6009, DOI 10.1109/ICASSP.2018.8462290
   Kim H, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1741
   Lallouani A., 2004, Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513), P315, DOI 10.1109/CCECE.2004.1345019
   Lee SH, 2019, J KOREAN MED SCI, V34, DOI 10.3346/jkms.2019.34.e108
   Lu Y, 2008, SPEECH COMMUN, V50, P453, DOI 10.1016/j.specom.2008.01.003
   Revathi A, 2019, INT J SPEECH TECHNOL, V22, P979, DOI 10.1007/s10772-019-09644-3
   Revathi A, 2018, INT J SPEECH TECHNOL, V21, P723, DOI 10.1007/s10772-018-9546-1
   Rudzicz F, 2013, COMPUT SPEECH LANG, V27, P1163, DOI 10.1016/j.csl.2012.11.001
   Rudzicz F, 2011, IEEE T AUDIO SPEECH, V19, P947, DOI 10.1109/TASL.2010.2072499
   Sattar J, 2018, ARXIV PREPRINT ARXIV
   Selouani SA, 2012, INT J SPEECH TECHNOL, V15, P57, DOI 10.1007/s10772-011-9104-6
   Stark AP, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P549
   Takashima Y, 2019, INT CONF ACOUST SPEE, P6395, DOI 10.1109/ICASSP.2019.8683803
   Takashima Y, 2015, EUR SIGNAL PR CONF, P1411, DOI 10.1109/EUSIPCO.2015.7362616
   Thoppilu MG, 2017, ANN INDIAN ACAD NEUR, V20, P352, DOI 10.4103/aian.AIAN_130_17
   Tu M, 2017, INTERSPEECH, P1849, DOI 10.21437/Interspeech.2017-1222
NR 25
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31245
EP 31259
DI 10.1007/s11042-022-12937-6
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781336500013
DA 2024-07-18
ER

PT J
AU Jiang, L
   Zheng, H
   Wang, HY
   Quan, Z
AF Jiang, Li
   Zheng, Hao
   Wang, Haoyuan
   Quan, Zhi
TI A multipermutation superposition coding-based fragile watermarking for
   probabilistic encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ciphertext domain operation; Fragile watermarking; Multimedia
   information security; Probabilistic encryption
ID POB NUMBER SYSTEM; TAMPERING DETECTION; IMAGES; SECURE; DOMAIN
AB Considering the requirements of comprehensive data security protection in the current distributed technology environment, this paper proposes a new fragile watermarking algorithm in the ciphertext domain, which takes advantage of multipermutation superposition coding and the single-plaintext-multiple-ciphertext characteristic of probabilistic encryption. Without decryption, the proposed algorithm realizes integrity verification and tamper localization in the ciphertext domain and also embeds a large-capacity meaningful watermark, which is rare for fragile watermarking. According to the experimental results, in addition to the basic function implementation, the proposed ciphertext domain fragile watermarking algorithm has little impact on the security of the cryptographic algorithm and does not affect the decryption. Meanwhile, the proposed algorithm is highly sensitive to data tampering, which can be located at the pixel level. More importantly, the proposed algorithm is easy to implement and does not require the original carrier data during watermark extraction; thus, it serves as a valuable reference for the implementation of ciphertext data integrity verification technology.
C1 [Jiang, Li; Zheng, Hao; Wang, Haoyuan; Quan, Zhi] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
C3 Zhengzhou University
RP Quan, Z (corresponding author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
EM ieljiang@zzu.edu.cn; zhenghzzu@163.com; wanghyzzu@163.com;
   iezquan@zzu.edu.cn
RI wang, haoyuan/GWR-3322-2022; wang, hao/HSE-7975-2023
FU National Natural Science Foundation of China [U1604160]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. U1604160.
CR [Anonymous], 1995, Advances in Cryptology-EUROCRYPT'94, DOI DOI 10.1007/BFB0053428
   Badr AM, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020171
   Ding WX, 2017, INFORM SCIENCES, V409, P35, DOI 10.1016/j.ins.2017.05.004
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Gao H, 2020, J FRANKLIN I, V357, P9107, DOI 10.1016/j.jfranklin.2020.07.026
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Gupta M, 2021, WIRELESS PERS COMMUN, V121, P1857, DOI 10.1007/s11277-021-08742-3
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Jiang L, 2018, MULTIMED TOOLS APPL, V77, P30575, DOI 10.1007/s11042-018-6142-y
   Jiang L, 2015, IEEE J-STARS, V8, P2232, DOI 10.1109/JSTARS.2015.2412691
   Li M, 2019, MULTIMED TOOLS APPL, V78, P22727, DOI 10.1007/s11042-019-7560-1
   Liu Q, 2012, J NETW COMPUT APPL, V35, P927, DOI 10.1016/j.jnca.2011.03.010
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Ning JT, 2021, IEEE T SERV COMPUT, V14, P111, DOI 10.1109/TSC.2018.2791538
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qiu H, 2021, IEEE T CLOUD COMPUT, V9, P1293, DOI 10.1109/TCC.2019.2911679
   Raj NRN, 2021, MULTIMED TOOLS APPL, V80, P19307, DOI 10.1007/s11042-021-10664-y
   Ren H, 2022, MULTIMED TOOLS APPL, V81, P2161, DOI 10.1007/s11042-021-11341-w
   Singh P, 2018, IEEE T CIRC SYST VID, V28, P2116, DOI 10.1109/TCSVT.2017.2716828
   [宋玉杰 Song Yujie], 2003, [中国图象图形学报. A, Journal of image and graphics], V8, P1
   Sun J, 2011, MULTIMED TOOLS APPL, V53, P75, DOI 10.1007/s11042-010-0491-5
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zheng PJ, 2018, IEEE T IMAGE PROCESS, V27, P2541, DOI 10.1109/TIP.2018.2802199
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 31
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30025
EP 30048
DI 10.1007/s11042-022-12949-2
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500019
DA 2024-07-18
ER

PT J
AU Qu, HZ
   Wang, YW
AF Qu, Hangzhou
   Wang, Yinwei
TI Application of Optimized Local Binary Pattern Algorithm in Small Pose
   Face Recognition under Machine Vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern algorithm; Face recognition; TGLBP; Robustness;
   Background set
ID LBP
AB With the development of information technology, face recognition technology is becoming more robust against the influence of illumination, pose, and noise. The purpose is to study the application of an optimized Local Binary Pattern (LBP) algorithm based on machine vision in small-pose face recognition, thereby promoting the application of face recognition technologies in various fields. An improved LBP algorithm is proposed, namely the Gradient Local Binary Pattern (GLBP). Multiple path lines are used for sampling, then the neighborhood of two scales in the collected face image is calculated by GLBP, and the two-scale GLBP coding values are fused to obtain Two Gradient Local Binary Pattern (TGLBP) algorithm. Finally, the face recognition performance of the TGLBP algorithm is analyzed under simulation.The recognition accuracy of the proposed system is verified under comparative analysis with different algorithms. The results suggest that the recognition accuracy of the proposed TGLBP algorithm has reached 99.31%, 96.84%, and 95.31%, respectively in background set, expression set, and ornament set, all of which are at least 2.5% higher than that of other algorithms; Under the noise robustness recognition analysis, the robustness recognition accuracy of the proposed TGLBP algorithm model is significantly better than other algorithms, which is always over 90%. Therefore, the proposed TGLBP algorithm has higher face recognition accuracy and better noise robustness. The results can provide an experimental reference for the later intellectual development of image recognition.
C1 [Qu, Hangzhou; Wang, Yinwei] Xijing Univ, Sch Mech Engn, Xian 710100, Peoples R China.
C3 Xijing University
RP Qu, HZ (corresponding author), Xijing Univ, Sch Mech Engn, Xian 710100, Peoples R China.
EM 1633036008@qq.com
OI qu, hangzhou/0000-0002-9706-3889
CR Abebe HB, 2019, IET CYBER PHYS SYST, V4, P189, DOI 10.1049/iet-cps.2018.5045
   AlMousawi KM., 2020, J. Educ. Pure Sci.-Univ. Thi-Qar, V10, P73
   [Anonymous], 2017, INT J COMPUTER APPL
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2001, ITE TECHNICAL REPORT, P65
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Elias S.J., 2019, B ELECT ENG INFORM, V8, P239, DOI DOI 10.11591/EEI.V8I1.1439
   Fang WJ, 2019, J COMPUT METHODS SCI, V19, pS19, DOI 10.3233/JCM-191003
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   Kukreja S, 2021, VISUAL COMPUT, V37, P1481, DOI 10.1007/s00371-020-01883-9
   Kumar A., 2018, INT J PURE APPL MATH, V118, P2665
   Low CC, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05107
   Ma ZJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113876
   Moujahid A, 2018, INT J DATA SCI ANAL, V5, P11, DOI 10.1007/s41060-017-0083-9
   Khanbebin SN, 2021, NEURAL COMPUT APPL, V33, P7691, DOI 10.1007/s00521-020-05512-3
   Niu D, 2019, VISUAL COMPUT, V2019, P1
   Omar, 2019, ACAD J NAWROZ U, V8, P33, DOI [10.25007/ajnu.v8n3a394, DOI 10.25007/AJNU.V8N3A394]
   Omer Y, 2019, PERCEPTION, V48, P437, DOI 10.1177/0301006619838734
   Priya T.S. V., 2018, Int. J. Pure Appl. Math, V119, P1895
   Shi LL, 2020, OPTIK, V220, DOI 10.1016/j.ijleo.2020.165157
   Silwal R, 2020, MULTIMED TOOLS APPL, V79, P31027, DOI 10.1007/s11042-020-09559-1
   Song XN, 2019, PATTERN RECOGN, V88, P127, DOI 10.1016/j.patcog.2018.11.008
   Suma SL, 2018, IJSRCSE, V6, P6
   Tabatabaei, 2019, VISUAL COMPUT, P1
   Tong SG, 2019, INT J AUTOM COMPUT, V16, DOI 10.1007/s11633-018-1153-8
   Ul Haq M, 2019, KSII T INTERNET INF, V13, P3144, DOI 10.3837/tiis.2019.06.021
   Wu L, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.3977
   Zhang Q, 2020, MATH BIOSCI ENG, V17, P1578, DOI 10.3934/mbe.2020082
NR 31
TC 1
Z9 1
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29367
EP 29381
DI 10.1007/s11042-021-11809-9
EA APR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384800001
DA 2024-07-18
ER

PT J
AU Ren, RY
   Niu, SZ
AF Ren, Ruyong
   Niu, Shaozhang
TI Improvement of image quality of digital holographic reconstruction and
   development of related systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital-holography; Speckle noise; Image segmentation; Guided filtering;
   Filter reconstruction
ID HISTOGRAM EQUALIZATION; SPECKLE NOISE; VARIATIONAL MODEL; ALGORITHM
AB The introduction of speckle noise in the process of digital holographic reconstruction is inevitable. Meanwhile, the quality of the reconstructed images are seriously lower than that of the original images, affecting the visual perception. The removal of speckle noise is an internationally recognized conundrum. Currently, scholars have not proposed a better method to remove speckle noise, which hinders the further development of digital holography technology. As a result, reducing speck noise in digital holographic reconstruction and enhancing the quality of reconstructed images have become important research topics. Based on the characteristics of speckle noise in reconstructed images, this paper proposes a new method for the first time by combining the concepts of image segmentation, guided filtering, and filter reconstruction, which can significantly improve the image quality within a reasonable time. By comparison with other state-of-the-art methods, the proposed method perform excellently in terms of detail preservation and background noise suppression of the target image. Finally, a holographic reconstruction image quality enhancement system is developed, integrating the physical experiment of digital holographic reconstruction with the image quality enhancement algorithm. The simple and convenient operation of the system provides great help for non-algorithm physics researchers. Additionally, it is also the first holographic reconstruction image enhancement system with a good effect and has considerable market application value.
C1 [Ren, Ruyong; Niu, Shaozhang] Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Niu, SZ (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM renruyong520@bupt.edu.cn; szniu@bupt.edu.cn
OI Niu, Shaozhang/0000-0002-9639-5910
FU National Natural Science Foundation of China [U1536121, 61370195]
FX This work is supported by The National Natural Science Foundation of
   China (No.61370195) and the Joint Funds of the National Natural Science
   Foundation of China (No. U1536121).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], INT C COMP VIS
   Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Bhadu R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1178, DOI 10.1109/CCAA.2017.8229976
   Bianco V, 2016, 3D IMAGE ACQUISITION
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   DONATH WE, 1973, IBM J RES DEV, V17, P420, DOI 10.1147/rd.175.0420
   Dyomin VV, 2012, J OPT TECHNOL+, V79, P344, DOI 10.1364/JOT.79.000344
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Gu ZH, 2019, APPL MATH MODEL, V68, P643, DOI 10.1016/j.apm.2018.11.052
   Haouat M, 2017, OPT LETT, V42, P1047, DOI 10.1364/OL.42.001047
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jang JH, 2011, IEEE GEOSCI REMOTE S, V8, P983, DOI 10.1109/LGRS.2011.2146227
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kemper B, 2006, J BIOMED OPT, V11, DOI 10.1117/1.2204609
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lan X, 2014, SIGNAL PROCESS, V101, P19, DOI 10.1016/j.sigpro.2014.01.017
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liu C.-G., 2017, ARXIV170206159
   Locatelli M, 2013, OPT EXPRESS, V21, P5379, DOI 10.1364/OE.21.005379
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma PF, 2018, J LIGHTWAVE TECHNOL, V36, P2069, DOI 10.1109/JLT.2018.2802324
   Memmolo P, 2012, OPT EXPRESS, V20, P17250, DOI 10.1364/OE.20.017250
   Palma-Amestoy R, 2009, IEEE T PATTERN ANAL, V31, P458, DOI 10.1109/TPAMI.2008.86
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Patnaik AK, 2016, ALEX ENG J, V55, P407, DOI 10.1016/j.aej.2015.11.003
   Paturzo M, 2010, OPT EXPRESS, V18, P8806, DOI 10.1364/OE.18.008806
   Rivenson Y, 2015, OPT LETT, V40, P5606, DOI 10.1364/OL.40.005606
   SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221
   Sharma A, 2008, OPT LASER ENG, V46, P42, DOI 10.1016/j.optlaseng.2007.07.004
   Tian L, 2010, APPL OPTICS, V49, P1549, DOI 10.1364/AO.49.001549
   Tiwari M, 2016, TIMES INDIA
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wiener N., 1949, Extrapolation, Interpolation, and Smoothing of Stationary Time Series: with Engineering Applications, V113
   Wu YM, 2018, APPL OPTICS, V57, P5364, DOI 10.1364/AO.57.005364
   Yu HC, 2016, OPT LETT, V41, P994, DOI 10.1364/OL.41.000994
   Zaki F, 2017, BIOMED OPT EXPRESS, V8, P2720, DOI 10.1364/BOE.8.002720
NR 42
TC 1
Z9 2
U1 7
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29229
EP 29252
DI 10.1007/s11042-022-12884-2
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241600004
DA 2024-07-18
ER

PT J
AU Etoom, W
   Al-Haj, A
AF Etoom, Wala
   Al-Haj, Ali
TI A robust and imperceptible watermarking method for 3D DIBR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth-Image-Based Rendering; Integer Wavelet Transform using Lifting
   Scheme; Singular Value Decomposition; Robustness; Imperceptibility;
   Blind Watermarking
AB A well-known representation method for 3D images is the Depth-Image-Based-Rendering method (DIBR). It operates on a monoscopic center view and an associated per-pixel depth map image to generate two virtual views; a left-eye view and a right-eye view. During transmission, the three views can be illegally copied and manipulated, and thus providing copyright protection for the different DIBR views is deemed necessary. In this paper, we propose a 3D DIBR image watermarking method that fulfills the robustness and imperceptibility requirements of effective watermarking. The robustness requirement is fulfilled since the proposed algorithm utilizes the properties of the Integer Wavelet Transform using Lifting Scheme (IWTLS) and the Singular Value Decomposition (SVD). The IWTLS-SVD hybrid transform provides the shift invariance property which gives robustness against the translation caused the rendering operation of the DIBR process. Moreover, the Speed Up Robust Features (SURF) technique is used to provide robustness to geometrical attacks. At the sending end, the stereoscopic center image is decomposed into multiple frequency sub-bands by the IWTLS transform, after which selected sub-bands go through SVD transformation. At the receiving end, the watermark bits are blindly extracted from the three DIBR views: the monoscopic center image, the left-eye view, and the right-eye view. Performance evaluation results show that the proposed method is imperceptible, and robust against signal processing operations such as additive noise, JPEG compression, affine transformation, median filtering, re-scaling, rotation, and cropping. Imperceptibility is demonstrated by the relatively high average PSNR and SSIM values: 46.712 and 0.998, respectively, and robustness by the low average bit error rates (BER) values ranging from 0% to 0.4%, for most signal processing and geometrical attacks.
C1 [Etoom, Wala; Al-Haj, Ali] Princess Sumaya Univ Technol, King Abdullah II Sch Engn, Dept Comp Engn, POB 1438, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology
RP Al-Haj, A (corresponding author), Princess Sumaya Univ Technol, King Abdullah II Sch Engn, Dept Comp Engn, POB 1438, Amman 11941, Jordan.
EM wala_3toom@hotmail.com; ali@psut.edu.jo
OI Al-Haj, Ali/0000-0002-4215-2286
CR Al-Haj A, 2017, MEASUREMENT, V95, P405, DOI 10.1016/j.measurement.2016.10.016
   Alatan AA, 2007, IEEE T CIRC SYST VID, V17, P1587, DOI 10.1109/TCSVT.2007.909974
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], 2015, 2 INT C COMPUTER SCI
   [Anonymous], 2012, INT J ENG RES TECHNO
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Balakrishnan P, 2014, CAN J ELECT COMPUT E, V37, P127, DOI 10.1109/CJECE.2014.2316227
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Ben Ftima S, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P510, DOI 10.1109/ICECA.2017.8203737
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cui C, 2016, MEASUREMENT, V92, P130, DOI 10.1016/j.measurement.2016.05.079
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   De Silva DVSX, 2011, IEEE J-STSP, V5, P335, DOI 10.1109/JSTSP.2011.2108113
   Etoom W, 2017, P 8 IEEE INT C INF T
   Feng Y, 2011, IEEE T BROADCAST, V57, P500, DOI 10.1109/TBC.2011.2131030
   Guan Y, 2014, I C CONT AUTOMAT ROB, P346, DOI 10.1109/ICARCV.2014.7064330
   Hernandez M.C., 2013, RADIO ENG, V22
   Hirschmuller H, 2007, IEEE C COMPUT VIS PA
   Jaipuria Smita Jagdishprasad, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P181, DOI 10.1109/ICCSP.2014.6949824
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Li M, 2013, ADV INTEL SYS RES, V84, P1309
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu R., 2016, International Journal of Hybrid Information Technology, V9, P145, DOI [10.14257/ijhit.2016.9.5.12, DOI 10.14257/IJHIT.2016.9.5.12]
   Loukhaoukha K, 2011, J INF HIDING MULTIME, V2
   Oliveira A, 2015, INT CONF ACOUST SPEE, P1186, DOI 10.1109/ICASSP.2015.7178157
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Redert A, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P313
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schmeing M., 2011, Pattern Recognition, Machine Intelligence and Biometrics, P279, DOI [10.1007/978-3-642-22407-212, DOI 10.1007/978-3-642-22407-212]
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Wang W., 2013, TELKOMNIKA, V11, P1560
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 38
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28165
EP 28182
DI 10.1007/s11042-022-12553-4
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644100007
DA 2024-07-18
ER

PT J
AU Kumar, R
   Arora, R
   Bansal, V
   Sahayasheela, VJ
   Buckchash, H
   Imran, J
   Narayanan, N
   Pandian, GN
   Raman, B
AF Kumar, Rahul
   Arora, Ridhi
   Bansal, Vipul
   Sahayasheela, Vinodh J.
   Buckchash, Himanshu
   Imran, Javed
   Narayanan, Narayanan
   Pandian, Ganesh N.
   Raman, Balasubramanian
TI Classification of COVID-19 from chest x-ray images using deep features
   and correlation coefficient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; X-ray images; Feature extraction; Deep learning; Feature
   selection; Pearson correlation coefficient; Machine learning
ID NETWORK
AB COVID-19 is a viral disease that in the form of a pandemic has spread in the entire world, causing a severe impact on people's well being. In fighting against this deadly disease, a pivotal step can prove to be an effective screening and diagnosing step to treat infected patients. This can be made possible through the use of chest X-ray images. Early detection using the chest X-ray images can prove to be a key solution in fighting COVID-19. Many computer-aided diagnostic (CAD) techniques have sprung up to aid radiologists and provide them a secondary suggestion for the same. In this study, we have proposed the notion of Pearson Correlation Coefficient (PCC) along with variance thresholding to optimally reduce the feature space of extracted features from the conventional deep learning architectures, ResNet152 and GoogLeNet. Further, these features are classified using machine learning (ML) predictive classifiers for multi-class classification among COVID-19, Pneumonia and Normal. The proposed model is validated and tested on publicly available COVID-19 and Pneumonia and Normal dataset containing an extensive set of 768 images of COVID-19 with 5216 training images of Pneumonia and Normal patients. Experimental results reveal that the proposed model outperforms other previous related works. While the achieved results are encouraging, further analysis on the COVID-19 images can prove to be more reliable for effective classification.
C1 [Kumar, Rahul; Arora, Ridhi; Buckchash, Himanshu; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
   [Bansal, Vipul] Indian Inst Technol Roorkee, Dept Mech & Ind Engn, Roorkee, Uttar Pradesh, India.
   [Sahayasheela, Vinodh J.; Pandian, Ganesh N.] Kyoto Univ Adv Study, Inst Integrated Cell Mat Sci WPI iCeMS, Kyoto, Japan.
   [Narayanan, Narayanan; Raman, Balasubramanian] Univ CyberJaya, Ctr Res & Grad Studies, Sepang, Malaysia.
   [Kumar, Rahul] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
   [Imran, Javed] Univ Petr & Energy Studies UPES, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee; GLA University;
   University of Petroleum & Energy Studies (UPES)
RP Arora, R (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.; Pandian, GN (corresponding author), Kyoto Univ Adv Study, Inst Integrated Cell Mat Sci WPI iCeMS, Kyoto, Japan.
EM rkumar9@cs.iitr.ac.in; rarora@cs.ntr.ac.in; vbansal@me.iitr.ac.in;
   vinodh@chemb.kuchem.kyoto-u.ac.jp; hbuckchash@cs.iitr.ac.in;
   javed.imran@ddn.upes.ac.in; nn@annalakshmi.net;
   ganesh@kuchem.kyoto-u.ac.jp; bala@cs.iitr.ac.in
RI Bansal, Vipul/KVC-2594-2024; Pandian, Ganesh/E-5091-2012
OI Bansal, Vipul/0000-0003-1663-2670; J S, Vinodh/0000-0001-8231-3286;
   Pandian, Ganesh/0000-0002-5531-1995; KUMAR, RAHUL/0000-0002-9266-9515
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Alimadadi A, 2020, PHYSIOL GENOMICS, V52, P200, DOI 10.1152/physiolgenomics.00029.2020
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arora R, 2020, AI BASED DIAGNOSIS C
   Barstugan M, 2020, ARXIV200309424
   Basu S, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P2521, DOI 10.1109/SSCI47803.2020.9308571
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bukhari S.U., 2020, medRziv
   Chandra TB, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113909
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Farooq M., 2020, arXiv preprint arXiv:2003.14395
   Ghassemi, 2020, ARXIV200611988
   Ghoshal B., 2020, ARXIV200310769
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   Gupta A, 2020, IEEE ACCESS, V8, P14659, DOI 10.1109/ACCESS.2019.2962755
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hammoudi K., 2020, ARXIV PREPRINT ARXIV
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosmer D. W., 2000, APPL LOGISTIC REGRES, DOI [10.1002/0471722146, https://doi.org/10.1002/0471722146, DOI 10.1002/0471722146]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang CL, 2020, LANCET, V395, P497, DOI [10.1016/S0140-6736(20)30183-5, 10.1016/S0140-6736(20)30211-7]
   Hui DS, 2020, INT J INFECT DIS, V91, P264, DOI 10.1016/j.ijid.2020.01.009
   Imran Ali, 2020, Inform Med Unlocked, V20, P100378, DOI 10.1016/j.imu.2020.100378
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2022, MECH TIME-DEPEND MAT, V26, P101, DOI 10.1007/s11043-020-09477-7
   Li L., 2020, ARXIV PREPRINT ARXIV
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Liu Huiqing, 2002, Genome Inform, V13, P51
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Oh Y, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371936
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rahimzadeh Mohammad, 2020, Inform Med Unlocked, V19, P100360, DOI 10.1016/j.imu.2020.100360
   Rahmatizadeh S., 2020, Journal of Cellular and Molecular Anesthesia, V5, P16
   Randhawa GS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232391
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Rodriguez-Lujan I, 2010, J MACH LEARN RES, V11, P1491
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   World Health Organization, COVID 19 WEEKL EP UP
   World Health Organization, 2020, NAM COR DIS COV 19 V
   World Health Organization (WHO), Q&A on coronaviruses (COVID-19)
   ZWEIG MH, 1993, CLIN CHEM, V39, P561
NR 63
TC 17
Z9 18
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27631
EP 27655
DI 10.1007/s11042-022-12500-3
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800009
PM 35368858
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Pham, TTT
   Nguyen, HQ
   Phan, H
   Do, TND
   Nguyen, TB
   Tran, TH
   Le, TL
AF Thi Thanh Thuy Pham
   Hong-Quan Nguyen
   Hoai Phan
   Thi-Ngoc-Diep Do
   Thuy-Binh Nguyen
   Thanh-Hai Tran
   Thi-Lan Le
TI Towards a large-scale person search by vietnamese natural language:
   dataset and methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text-based person search; Vietnamese language; Text-based person search
   dataset
ID IMAGE; ANNOTATION
AB Person search by natural language description is a challenging problem because of demands for modelling and learning visual-text semantic embedding. While several works have been dedicated to person search by English description, very few attempts have been made for other languages. This paper presents the first work towards person search by Vietnamese description. The contribution of the paper is threefold. First, the first and large-scale dataset for person search by Vietnamese natural language named 3000VnPersonSearch is built. Second, inspired by dual-path architecture (Zheng et al. ACM Trans Multimed Comput Commit) Appl (TOMM) 16(2):1-23, 2020), in which single loss for intra-modal and triple loss for cross-modal learning of text and image data distribution were considered, in this paper, we employ this architecture for Vietnamese description-based person search. However, as Vietnamese language is under-resource, the existing word embedding model is still modest compared to that of English. Therefore, instead of using word2vec model as in Zheng et al. (ACM Trans Multimed Comput Commit) Appl (TOMM) 16(2):1-23, 2020), we modify the initialization process of the first convolution layer of the text-CNN path. In addition, we investigate in detail two online triplet mining strategies that are batch all and batch hard triplet. Extensive experiments have been conducted on benchmark datasets as well as on 3000VnPersonSearch. Experimental results show that the proposed method obtains 2.42% of improvement over the baseline method on CUHK-PEDES dataset and achieved state of the art results on VnPersonSearch dataset with a significant margin in comparison with the method in Pham et al. (2020). Finally, in order to illustrate the practical usage of person search by Vietnamese description language, a web-based application of person search is implemented and deployed.
C1 [Thi Thanh Thuy Pham; Hoai Phan] Acad People Secur, Fac Cyber Secur, Hanoi, Vietnam.
   [Thi Thanh Thuy Pham; Thi-Ngoc-Diep Do; Thanh-Hai Tran; Thi-Lan Le] Hanoi Univ Sci & Technol, MICA Int Res Inst, Hanoi, Vietnam.
   [Hong-Quan Nguyen] Viet Hung Ind Univ, Fac Informat Technol, Hanoi, Vietnam.
   [Thuy-Binh Nguyen] Univ Transport & Commun, Fac Elect & Elect Engn, Hanoi, Vietnam.
   [Thanh-Hai Tran; Thi-Lan Le] Hanoi Univ Sci & Technol, Sch Elect & Telecommun, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); University of Transport
   & Communications (UTC); Hanoi University of Science & Technology (HUST)
RP Le, TL (corresponding author), Hanoi Univ Sci & Technol, MICA Int Res Inst, Hanoi, Vietnam.; Le, TL (corresponding author), Hanoi Univ Sci & Technol, Sch Elect & Telecommun, Hanoi, Vietnam.
EM Thi-Lan.Le@mica.edu.vn
OI Le, Thi-Lan/0000-0001-9541-3905; Nguyen Hong, Quan/0000-0002-2635-6449
FU Vietnam Ministry of Education and Training [CT2020.02.BKA.02]; Vietnam
   National Foundation for Science and Technology Development (NAFOSTED)
   [11/2020/STS01]
FX This research is funded by the Vietnam Ministry of Education and
   Training under grant number CT2020.02.BKA.02. Dr. Thanh-Thuy Pham is
   supported by Vietnam National Foundation for Science and Technology
   Development (NAFOSTED) under grant number 11/2020/STS01.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chen TL, 2018, IEEE WINT CONF APPL, P1879, DOI 10.1109/WACV.2018.00208
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Devlin J., 2018, BERT PRE TRAINING DE
   Di Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12612, DOI 10.1109/CVPR42600.2020.01263
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dubey S, 2021, ARXIV210907799
   Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516
   Guanglu Song, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11560, DOI 10.1109/CVPR42600.2020.01158
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Iyengar G., 2005, 13th Annual ACM International Conference on Multimedia, P21, DOI 10.1145/1101149.1101154
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jin L, 2023, IEEE T NEUR NET LEAR, V34, P1838, DOI 10.1109/TNNLS.2020.2997020
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Le T L, 2010, 3 INT C COMM EL ICCE
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Li ZC, 2020, INT J COMPUT VISION, V128, P2265, DOI 10.1007/s11263-020-01331-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340
   Lin X, 2021, ARXIV210501605 CORR
   Lu ZW, 2015, IEEE T IMAGE PROCESS, V24, P176, DOI 10.1109/TIP.2014.2375641
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Nguyen, 2020, AS C INT INF DAT SYS, P469
   Nguyen D Q, 2017, ARXIV170906307
   Nguyen H.Q., 2020, TRANSPORT COMMUN SCI, V71, P868
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Shree V, 2019, P 28 IEEE INT C ROB, P1
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Siddharth N, 2014, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2014.99
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   SOCHER R, 2010, PROC CVPR IEEE, P966, DOI DOI 10.1109/CVPR.2010.5540112
   Nguyen TB, 2019, MULTIMED TOOLS APPL, V78, P33939, DOI 10.1007/s11042-019-08183-y
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vu Thanh, 2018, ARXIV180101331
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiao T, 2016, ARXIV160401850 CORR
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yamaguchi M, 2017, IEEE I CONF COMP VIS, P1462, DOI 10.1109/ICCV.2017.162
   Yan Y, 2021, ARXIV210311617 CORR
   Yan YC, 2023, IEEE T PATTERN ANAL, V45, P7001, DOI 10.1109/TPAMI.2020.3032542
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Zheng DY, 2020, SIGNAL PROCESS-IMAGE, V86, DOI 10.1016/j.image.2020.115876
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
   Zhenzhi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P34, DOI 10.1007/978-3-030-58595-2_3
   Zhong YJ, 2020, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR42600.2020.00686
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhou T, 2017, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2017.10
NR 69
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27569
EP 27600
DI 10.1007/s11042-022-12138-1
EA MAR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464800002
DA 2024-07-18
ER

PT J
AU Pang, S
   Gao, LX
AF Pang, Shuai
   Gao, Lianxue
TI Multihead attention mechanism guided ConvLSTM for pixel-level
   segmentation of ocean remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ocean remote sensing; Deep learning; Multihead attention mechanism;
   Multiscale convolutional
AB Semantic segmentation of ocean remote sensing images classifies each pixel in the image according to the ocean background and island type, and is an important research direction in the field of remote sensing image processing. Due to large differences in the scale of islands in ocean remote sensing images and the complexity of island boundaries, it is difficult to accurately extract features of ocean remote sensing images, which makes it difficult to accurately segment ocean remote sensing images. Convolutional neural networks have gradually become the mainstream algorithm in the field of image processing due to their autonomous hierarchical extraction of image features. In this paper, the MAGC-Net neural network model, which is based on the multihead attention mechanism and ConvLSTM, is used to segment ocean remote sensing images to improve the accuracy of semantic segmentation. First, shallow features are obtained via multiscale convolution, and multiple weights are assigned to features by the multihead attention mechanism (global, local, maximum). Then, the semantic relationship between the features is described through the integrated ConvLSTM module, and deep features are generated. Finally, deep features are filtered through residual blocks, reducing redundant features and improving segmentation accuracy. Experimental results with the NWPU-RESISC45 dataset demonstrate the effectiveness and robustness of the proposed algorithm.
C1 [Pang, Shuai; Gao, Lianxue] Binzhou Univ, Binzhou 256600, Peoples R China.
C3 Shandong University of Aeronautics
RP Pang, S (corresponding author), Binzhou Univ, Binzhou 256600, Peoples R China.
EM psh1988@126.com
FU Project of Shandong Province Higher Educational Science and Technology
   Program [J18KA394]; Project of Binzhou University Doctoral Research
   [2016Y19]
FX This study was supported by the Project of Shandong Province Higher
   Educational Science and Technology Program under grant number J18KA394
   and the Project of Binzhou University Doctoral Research under grant
   number 2016Y19.
CR Cai WW, 2021, MULTIMED TOOLS APPL, V80, P11291, DOI 10.1007/s11042-020-10188-x
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Camarretta N, 2020, NEW FOREST, V51, P573, DOI 10.1007/s11056-019-09754-5
   Chang YP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202333
   Chen J, 2020, IEEE GEOSCI REMOTE S, V17, P681, DOI 10.1109/LGRS.2019.2930462
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao H, 2020, IEEE ACCESS, V8, P142483, DOI 10.1109/ACCESS.2020.3013898
   Hatfield JL, 2020, IT PROF, V22, P42, DOI 10.1109/MITP.2020.2986102
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jing R, 2020, INT J REMOTE SENS, V41, P6209, DOI 10.1080/01431161.2020.1734253
   Khanal S, 2017, COMPUT ELECTRON AGR, V139, P22, DOI 10.1016/j.compag.2017.05.001
   Kpienbaareh D, 2020, AFR GEOGR REV, V39, P189, DOI 10.1080/19376812.2019.1677482
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu X., 2020, ECCV 2020 16 EUROPEA, V661, P679
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Nhamo L, 2020, PHYS CHEM EARTH, V115, DOI 10.1016/j.pce.2019.102810
   Ning X., 2021, ASP T PATTERN RECOGN, V1, P9, DOI [10.52810/TPRIS.2021.100009, DOI 10.52810/TPRIS.2021.100009]
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Padmanaban R, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6120401
   Qi CH, 2020, IEEE ACCESS, V8, P188068, DOI 10.1109/ACCESS.2020.3030878
   Qi XQ, 2020, IEEE ACCESS, V8, P146627, DOI 10.1109/ACCESS.2020.3015587
   Rao Z, 2020, IEEE T GEOSCI ELECT
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rudke AP, 2020, J ENVIRON MANAGE, V263, DOI 10.1016/j.jenvman.2020.110392
   Sannigrahi S, 2020, SCI TOTAL ENVIRON, V725, DOI 10.1016/j.scitotenv.2020.138331
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun ST, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3041530
   Tong Y., 2021, ASP T PATTERN RECOGN, V1, P32, DOI [10.52810/TPRIS.2021.100019, DOI 10.52810/TPRIS.2021.100019]
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Weiss M, 2020, REMOTE SENS ENVIRON, V236, DOI 10.1016/j.rse.2019.111402
   Wellmann T, 2020, LANDSCAPE URBAN PLAN, V204, DOI 10.1016/j.landurbplan.2020.103921
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060612
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
   Zhu RX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171996
   Zhu Y, 2020, FORESTS, V11, DOI 10.3390/f11020163
NR 43
TC 7
Z9 6
U1 8
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24627
EP 24643
DI 10.1007/s11042-022-12849-5
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200004
DA 2024-07-18
ER

PT J
AU Deshmukh, S
   Abhyankar, A
   Kelkar, S
AF Deshmukh, Shubhangi
   Abhyankar, Aditya
   Kelkar, Shubhangi
TI DCCA and DMCCA framework for multimodal biometric system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fusion techniques; Deep learning; Canonical correlation analysis
ID CANONICAL CORRELATION-ANALYSIS; FEATURE FUSION; LEVEL FUSION;
   RECOGNITION; EIGENFACES; ECG
AB Deep networks have been successfully applied to unsupervised feature learning for single modalities such as Text, Image, or Audio. Here, we present the Deep Network that learns nonlinear transformations of two or more biometric modalities. The resultant representation is a combination of maximally correlated features of the input modalities. It can be viewed as a feature fusion technique with the nonlinear extension of the linear multiset canonical correlation analysis (MCCA). The Foundation of a multibiometric system is information fusion. Feature level fusion is an important area of research owing to the information richness of features. This Deep learning model outlines the integrated correlation among multiple feature vectors and forms a new fused feature vector. This paper presents the Deep Canonical Correlation Analysis (DCCA) for bimodal biometric system and Deep Multiset Canonical Correlation Analysis (DMCCA) framework for the multimodal biometric system outperforming the traditional CCA based fusion methods. Experiments are carried out with the SDUMLA-HMT multimodal dataset. Using the proposed DCCA method performance of a bi-modal biometric system with iris and fingerprint modalities in terms of EER (equal error rate) is 3.78% and 0.116% (single modality recognition). While for the multibiometric system with four modalities (iris, fingerprint, finger-vein, and face) with DMCCA, EER is 0.717%.
C1 [Deshmukh, Shubhangi; Abhyankar, Aditya] Savitribai Phule Pune Univ, Dept Technol, Pune, Maharashtra, India.
   [Kelkar, Shubhangi] Persistent Syst, Pune, Maharashtra, India.
C3 Savitribai Phule Pune University
RP Deshmukh, S (corresponding author), Savitribai Phule Pune Univ, Dept Technol, Pune, Maharashtra, India.
EM shubhangi.tamsekar@gmail.com; aditya1210@gmail.com;
   shubhangi_kelkar@persistent.co.in
RI Deshmukh, Shubhangi/JCE-7316-2023
CR Ammour B, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010085
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   Anderson T.W., 1958, An introduction to multivariate statistical analysis
   Andrew G., 2013, ICML, P1247
   Bach Francis R., 2005, PROBABILISTIC INTERP
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bilenko NY, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00049
   Borga M., 2001, REPORT LIU IMT EX006
   Chakraborty S, 2017, IET SCI MEAS TECHNOL, V11, P226, DOI 10.1049/iet-smt.2015.0308
   Correa NM, 2008, IEEE J-STSP, V2, P998, DOI 10.1109/JSTSP.2008.2008265
   Eskandari M, 2014, SIGNAL IMAGE VIDEO P, V8, P995, DOI 10.1007/s11760-012-0411-4
   Gao XZ, 2017, EXPERT SYST APPL, V84, P171, DOI 10.1016/j.eswa.2017.05.017
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hammad M, 2019, IEEE ACCESS, V7, P26527, DOI 10.1109/ACCESS.2018.2886573
   Hardoon DR, 2007, NEUROIMAGE, V37, P1250, DOI 10.1016/j.neuroimage.2007.06.017
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hel-Or Y, 2004, TECH REP HPL 2003 16
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hsieh WW, 2000, NEURAL NETWORKS, V13, P1095, DOI 10.1016/S0893-6080(00)00067-8
   HUO G, 2015, J ELECTRON IMAGING, V24, DOI DOI 10.1117/1.JEI.24.6.063020
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   KETTENRING JR, 1971, BIOMETRIKA, V58, P433, DOI 10.2307/2334380
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Lai PL, 2000, IEEE IJCNN, P614
   Li YO, 2009, IEEE T SIGNAL PROCES, V57, P3918, DOI 10.1109/TSP.2009.2021636
   Loog M, 2005, PATTERN RECOGN, V38, P2409, DOI 10.1016/j.patcog.2005.04.011
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Regouid M, 2019, MULTIMED TOOLS APPL, V78, P22509, DOI 10.1007/s11042-019-7467-x
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Ross A, 2009, ADV PATTERN RECOGNIT, P273, DOI 10.1007/978-1-84882-385-3_11
   Ross ArunA., 2006, HDB MULTIBIOMETRICS, V6
   Sun QS, 2004, I C CONT AUTOMAT ROB, P1547
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vía J, 2007, NEURAL NETWORKS, V20, P139, DOI 10.1016/j.neunet.2006.09.011
   Wang LQ, 2015, IET COMPUT VIS, V9, P903, DOI 10.1049/iet-cvi.2014.0324
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Yuan YH, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5476
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
NR 47
TC 2
Z9 2
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24477
EP 24491
DI 10.1007/s11042-022-12435-9
EA MAR 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770960100005
DA 2024-07-18
ER

PT J
AU Kumar, S
   Mukherjee, S
   Pal, AK
AF Kumar, Shubham
   Mukherjee, Soumya
   Pal, Arup Kumar
TI An improved reduced feature-based copy-move forgery detection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery; Image forensics; SWT; SVD planes
ID DIGITAL IMAGES; WAVELET; EFFICIENT
AB With Widespread malpractice of copy-move image forgery, enforcing image forensics becomes imperative. In this approach, objects can be added into or removed from the same image to hide the truth with malicious intention. In order to address this issue, passive copy move forgery localization and detection has been playing a crucial rule in image forensics arena. The paper proposed a reduced feature-based algorithm which is robust as well as highly accurate in terms of detecting forged area. In this proposed scheme, stationary wavelet transform is employed on subject image to obtain low approximation band, and then significant features are extracted from it using block-based Discrete Cosine Transformation (DCT) and singular value decomposition (SVD) accordingly. Traditional block-based approach suffers from computational overhead especially for large images. Proposed scheme, extracts only three feature vectors, one DC component applying DCT on LL bands and two singular value components extracted employing SVD from the remaining AC components of each transformed block. These reduced features are further utilized for analysing and matching to detect identical regions in an image. In spite of having a smaller number of features, experimental results exhibit, this proposed scheme detects the forged area precisely as well as exhibits quality robustness against different post- processing attacks.
C1 [Kumar, Shubham; Mukherjee, Soumya; Pal, Arup Kumar] Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Engn, ND-826004 Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Mukherjee, S (corresponding author), Indian Inst Technol, Indian Sch Mines, Dept Comp Sci & Engn, ND-826004 Dhanbad, Bihar, India.
EM kumarshub18@gmail.com; mukhsoumya@gmail.com; arupkrpal@gmail.com
RI Kumar, Shubham/JPY-3824-2023
OI mukherjee, soumya/0000-0002-5483-9368
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bovik Alan C, 2010, Handbook of image and video processing
   Cao L., 2006, Singular value decomposition applied to digital image processing,'' Division Comput. Stud., P1
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Coifman R. R., 1995, LECT NOTES STAT, V103, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1002/cpa.3160410705, DOI 10.1002/CPA.3160410705]
   Dixit R, 2017, IET IMAGE PROCESS, V11, P746, DOI 10.1049/iet-ipr.2016.0322
   Farid AP., 2004, EXPOSING DIGITAL FOR
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lin X, 2018, ENGINEERING-PRC, V4, P29, DOI 10.1016/j.eng.2018.02.008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Meena K.B., 2019, DATA ENG APPL, P163, DOI [DOI 10.1007/978-981-13-6351-1_14, 10.1007/978-981-13-6351-1_14]
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P152, DOI 10.1016/j.cag.2017.08.014
   Soni B, 2019, J INF SECUR APPL, V45, P44, DOI 10.1016/j.jisa.2019.01.007
   Starck JL, 2007, IEEE T IMAGE PROCESS, V16, P297, DOI 10.1109/TIP.2006.887733
   Tharwat A, 2020, APPL COMPUT INF, DOI DOI 10.1016/J.ACI.2018.08.003
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Zandi M, 2014, IEEE INT WORKS INFOR, P119, DOI 10.1109/WIFS.2014.7084314
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 30
TC 14
Z9 14
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1431
EP 1456
DI 10.1007/s11042-022-12391-4
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000770549800018
DA 2024-07-18
ER

PT J
AU Satheesh, KKSVA
   Sree, TK
AF Satheesh, Kavuri K. S. V. A.
   Sree, T. Krishna
TI AB-DAM: attribute-based data access model in blockchain for healthcare
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Data access; Healthcare systems; Attribute-based encryption;
   And interplanetary file system (IPFS)
AB This research introduces a novel attribute-based data access model in Blockchain (AB-DAM) Framework in Healthcare Systems to enhance the authentication of the users before data transmission. The proposed AB-DAM strategy and the smart contract assure secure communication. The Data requestor (DR) requests access using a unique ID and password to the Data holder (DH), who processes the request and authenticates the Data user. The information of the DH is embedded in the blockchain using an encrypted master key. The DH does the data encryption process through attribute-based Encryption (ABE), and the encrypted files are uploaded to the Interplanetary File System (IPFS). When the smart contract identifies the user as valid, the DH sends the requested data to the DR through the IPFS. The proposed model obtained the responsiveness and genuine user detection rate value of 24.1578 s and 43.38%, respectively.
C1 [Satheesh, Kavuri K. S. V. A.] SR Univ, Sch Comp Sci & Artificial Intelligence, Hanuma Konda 506371, Telangana, India.
   [Sree, T. Krishna] PVP Siddhartha Inst Technol, Freshman Engn, Vijayawada 520007, Andhra Pradesh, India.
C3 Prasad V. Potluri Siddhartha Institute of Technology
RP Satheesh, KKSVA (corresponding author), SR Univ, Sch Comp Sci & Artificial Intelligence, Hanuma Konda 506371, Telangana, India.
EM kavuris45740@gmail.com
RI kavuri, krishnasree/AEF-4293-2022
OI kavuri, krishnasree/0000-0003-2231-7159; kavuri,
   satheesh/0000-0003-1201-5210
CR Abou-Nassar EM, 2020, IEEE ACCESS
   Albanese G, 2020, J AMB INTEL HUM COMP, V11, P4909, DOI 10.1007/s12652-020-01761-1
   Esposito C, 2018, IEEE CLOUD COMPUT, V5, P31
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Gan C., 2020, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-020-09322-6
   Kumar R, 2021, J AMB INTEL HUM COMP, V12, P2321, DOI 10.1007/s12652-020-02346-8
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Mubarakali A, 2020, MOBILE NETW APPL, V25, P1330, DOI 10.1007/s11036-020-01551-1
   Nguyen DC, 2021, PROG PHOTOVOLTAICS, V29, P423, DOI 10.1002/pip.3383
   Nyame G, 2020, INFORMATION, V11, DOI 10.3390/info11020111
   Rajput AR, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020206
   Saha S., 2020, SpringerBriefs Appl. Sci. Technol., P1, DOI DOI 10.1007/978-3-030-20740-3_1
   Saini A, 2020, IEEE INT THINGS J
   SUN J, 2020, PLOS ONE, V15
   Tan L, 2020, IEEE ACCESS, V8, P77215, DOI 10.1109/ACCESS.2020.2988951
   Tariq Fatima, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P106, DOI 10.1007/978-3-030-44041-1_10
   Wang SP, 2018, IEEE ACCESS, V6, P38437, DOI 10.1109/ACCESS.2018.2851611
   Yu GS, 2020, IEEE T ENG MANAGE, V67, P1213, DOI 10.1109/TEM.2020.2966643
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
   Zhu QY, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359982
NR 20
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23567
EP 23588
DI 10.1007/s11042-022-12674-w
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770549800009
DA 2024-07-18
ER

PT J
AU Niu, PP
   Wang, F
   Tian, J
   Cai, J
   Wang, XY
AF Niu, Pan-pan
   Wang, Fei
   Tian, Jing
   Cai, Jing
   Wang, Xiang-yang
TI RDWT domain statistical watermark detector using FRHFMs magnitudes and
   bivariate Cauchy-Rayleigh distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Statistical watermark detector; RDWT-FRHFMs magnitudes; Bivariate
   Cauchy-Rayleigh distribution; Method of logarithmic cumulants (MoLC);
   Locally most powerful test
ID IMAGE WATERMARKING; DECODER
AB Imperceptibility, robustness and data payload, which are complimentary to each other, are widely considered as the three main properties vital for any image watermarking systems. It is a challenging work to design a statistical model-based multiplicative watermarking scheme for achieving the tradeoff among three main properties. In this paper, we propose a novel statistical image watermarking scheme by modeling local redundant discrete wavelet transform (RDWT) and fast Radial harmonic Fourier moments (FRHFMs) magnitudes with bivariate Cauchy-Rayleigh distribution. Our image watermarking scheme consists of two parts, namely, embedding and detection. In the embedding process, RDWT is firstly performed on the host image and RDWT highpass subbands are divided into non-overlapping blocks. Then FRHFMs are computed on RDWT coefficient blocks. And finally, the watermark signal is inserted into robust RDWT-FRHFMs magnitudes through a non-linear multiplicative approach. In the detection process, robust local RDWT-FRHFMs magnitudes are firstly modeled by employing bivariate Cauchy-Rayleigh distribution, which can capture accurately both marginal distributions and strong dependencies of local RDWT-FRHFMs magnitudes. Statistical model parameters are then estimated effectively by the method of logarithmic cumulants (MoLC) approach. And finally, an image watermark detector for multiplicative watermarking is developed using bivariate Cauchy-Rayleigh model and locally most powerful (LMP) test. Also, we utilize the bivariate Cauchy-Rayleigh model to derive the closed-form expressions for the watermark detector. After performance testing and comparison with the experimental results of existing methods, the proposed statistical image watermarking method has achieved relatively ideal results in terms of robustness, imperceptibility and data payload.
C1 [Niu, Pan-pan; Wang, Fei; Tian, Jing; Cai, Jing; Wang, Xiang-yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Cai, J (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM workprocess0003@126.com
RI Niu, Panpan/Q-9953-2017
OI Wang, Fei/0009-0002-4256-5360
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Key Scientific Research
   Project of Liaoning Provincial Education Department (LZ2019001), and
   Natural Science Foundation of Liaoning Province (2019-ZD-0468). Also,
   the author would like to thank the anonymous reviewers with their
   valuable comments to improve the quality of this manuscript and Yu-yang
   Zhang at Liaoning Normal University who helps to collect data and
   participate in writing of the manuscript.
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Aminanto M.E., 2017, PROC S CRYPTOGR INF, P1
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amirmazlaghani M, 2019, IET COMPUT VIS, V13, P249, DOI 10.1049/iet-cvi.2018.5254
   Amirmazlaghani M, 2017, LECT NOTES COMPUT SC, V10485, P547, DOI 10.1007/978-3-319-68548-9_50
   Amirmazlaghani M, 2016, INFORM SCIENCES, V370, P1, DOI 10.1016/j.ins.2016.06.037
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], 2015, P SPIE MEDIA WATER H
   Barazandeh Milad, 2016, 2016 2nd International Conference on Signal Processing and Intelligent Systems (ICSPIS), DOI 10.1109/ICSPIS.2016.7869886
   Barazandeh M, 2016, P 2016 2 INT C SIGN
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Bi HB, 2016, MATH PROBL ENG, V7, P1
   Deng S., 2016, MULTIMED TOOLS APPL, V76, P1
   Etemad S, 2016, P 2016 2 INT C SIGN
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Hill PR, 2014, SIGNAL PROCESS, V105, P464, DOI 10.1016/j.sigpro.2014.03.028
   Liu JH, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P668, DOI 10.1109/ICIVC.2018.8492868
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P33071, DOI 10.1007/s11042-020-09621-y
   Niu PP, 2020, IEEE ACCESS, V8, P46624, DOI 10.1109/ACCESS.2020.2978119
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Sadreazami H, 2015, IEEE INT SYMP CIRC S, P1050, DOI 10.1109/ISCAS.2015.7168817
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Vedovatto, 2017, J THEORETICAL APPL S
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115972
   Wang XY, 2020, INFORM SCIENCES, V535, P81, DOI 10.1016/j.ins.2020.05.034
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Yang HY, 2015, AEU-INT J ELECTRON C, V69, P389, DOI 10.1016/j.aeue.2014.10.012
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhang P, 2019, PROC CVPR IEEE, P12077, DOI 10.1109/CVPR.2019.01236
NR 37
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21241
EP 21278
DI 10.1007/s11042-022-12737-y
EA MAR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500013
DA 2024-07-18
ER

PT J
AU Wang, JJ
   Liu, ZH
   Zhang, KB
   Wu, QT
   Zhang, MC
AF Wang, Jingjing
   Liu, Zhonghua
   Zhang, Kaibing
   Wu, Qingtao
   Zhang, Mingchuan
TI Robust sparse manifold discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear discriminant analysis; Robust sparse manifold discriminant
   analysis; Manifold learning; Feature selection
ID CLASSIFICATION; RECOGNITION; PROJECTIONS
AB Classical linear discriminant analysis (LDA) has been applied to machine learning and pattern recognition successfully, and many variants based on LDA are proposed. However, the traditional LDA has several disadvantages as follows: Firstly, since the features selected by feature selection have good interpretability, LDA has poor performance in feature selection. Secondly, there are many redundant features or noisy data in the original data, but LDA has poor robustness to noisy data and outliers. Lastly, LDA only utilizes the global discriminant information, without consideration for the local discriminant structure. In order to overcome the above problems, we present a robust sparse manifold discriminant analysis (RSMDA) method. In RSMDA, by introducing the L-2,L-1 norm, the most discriminant features can be selected for discriminant analysis. Meanwhile, the local manifold structure is used to capture the local discriminant information of the original data. Due to the introduction of L-2,L-1 constraints and local discriminant information, the proposed method has excellent robustness to noisy data and has the potential to perform better than other methods. A large number of experiments on different data sets have proved the good effectiveness of RSMDA.
C1 [Wang, Jingjing; Liu, Zhonghua; Wu, Qingtao; Zhang, Mingchuan] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Peoples R China.
   [Zhang, Kaibing] Xian Polytech Univ, Coll Elect & Informat, Xian, Peoples R China.
C3 Henan University of Science & Technology; Xi'an Polytechnic University
RP Liu, ZH (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang, Peoples R China.
EM ZhonghuaLiu@haust.edu.cn
RI ZHOU, YUE/IZE-6277-2023; wang, jiajun/JRW-6032-2023; wang,
   juan/IUO-6218-2023; wang, jing/HJA-5384-2022; Wang, Jin/GYA-2019-2022;
   Zhang, Mingchuan/I-6902-2018; WANG, JINGYI/GSJ-1241-2022; wang,
   jie/HTQ-4920-2023; wang, jiahui/IXD-1197-2023; Wang, Jing/IQW-3496-2023;
   wang, jing/GVT-8700-2022; wang, jing/GRS-7509-2022; wang,
   dan/JEF-0836-2023; wang, jian/HRB-9588-2023; Zhang, Kai/HWQ-4396-2023;
   wang, xu/IAN-4886-2023
OI Wang, Jing/0000-0002-8296-2961; 
FU Natural Science Foundation of China [U1504610, 61971339, 61471161]; Key
   Project of the Natural Science Foundation of Shanxi Province
   [2018JZ6002]; Scientific and Technological Innovation Team of Colleges
   and Universities in Henan Province [20IRTSTHN018]; Doctoral Startup
   Foundation of Xi'an Polytechnic University [BS1616]; Natural Science
   Foundations of Henan Province [202300410148]
FX This work was supported by Natural Science Foundation of China
   (U1504610, 61971339, 61471161), the Key Project of the Natural Science
   Foundation of Shanxi Province (2018JZ6002), Scientific and Technological
   Innovation Team of Colleges and Universities in Henan Province
   (20IRTSTHN018), the Doctoral Startup Foundation of Xi'an Polytechnic
   University (BS1616). the Natural Science Foundations of Henan Province
   (202300410148).
CR Andekah ZA, 2017, IRAN CONF ELECTR ENG, P2229, DOI 10.1109/IranianCEE.2017.7985433
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Gao GW, 2020, INFORM SCIENCES, V506, P19, DOI 10.1016/j.ins.2019.08.004
   Guo J, 2020, ACM T KNOWL DISCOV D, V14, P5
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Lai ZL, 2021, IEEE T SYST MAN CY-S, V51, P797, DOI [10.1109/TSMC.2018.2883329, 10.1109/TCYB.2017.2740949]
   Li Y, 2018, IEEE T NEUR NET LEAR, V29, P1975, DOI 10.1109/TNNLS.2017.2690683
   Liu J, 2020, IEEE T INSTRUM MEAS, V69, P2621, DOI 10.1109/TIM.2019.2930157
   Liu TC, 2018, PATTERN RECOGN, V77, P126, DOI 10.1016/j.patcog.2017.12.001
   Liu ZH, 2018, INT J SYST SCI, V49, P847, DOI 10.1080/00207721.2018.1424964
   Liu ZH, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107907
   Liu ZH, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103758
   Liu ZH, 2017, KSII T INTERNET INF, V11, P2523, DOI 10.3837/tiis.2017.05.012
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Lu YW, 2016, IEEE T CYBERNETICS, V46, P1900, DOI 10.1109/TCYB.2015.2457611
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Mishra, 2020, OPT LASER TECHNOL, P1975
   Modava M, 2017, INT J REMOTE SENS, V38, P355, DOI 10.1080/01431161.2016.1266104
   Ning, 2018, IEEE T IMAGE PROCESS
   Ning X., 2020, IEEE SIGNAL PROCESSI
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Sellami A, 2019, EXPERT SYST APPL, V129, P246, DOI 10.1016/j.eswa.2019.04.006
   Sharifzadeh Foroogh, 2019, Journal of the Indian Society of Remote Sensing, V47, P551, DOI 10.1007/s12524-018-0891-y
   Taibi F, 2019, MULTIDIM SYST SIGN P, V30, P2113, DOI 10.1007/s11045-019-00645-8
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Ye J., 2006, P INT C MACHINE LEAR, P1073
   Ye JP, 2006, IEEE T KNOWL DATA EN, V18, P1312, DOI 10.1109/TKDE.2006.160
   Yu WB, 2019, SIGNAL PROCESS, V164, P20, DOI 10.1016/j.sigpro.2019.05.034
   Zeng ZQ, 2019, KNOWL-BASED SYST, V181, DOI 10.1016/j.knosys.2019.05.030
   Zhang A., 2020, IEEE T IMAGE PROCESS
   Zhang A., 2020, IEEE ACCESS
   Zhang AH, 2020, IET COMMUN, V14, P1384, DOI 10.1049/iet-com.2018.6186
   Zhang J, 2019, PATTERN RECOGN, V95, P136, DOI 10.1016/j.patcog.2019.06.003
   Zhang L, 2020, APPL INTELL, V50, P438, DOI 10.1007/s10489-019-01539-9
   Zhang XW, 2016, IEEE T NEUR NET LEAR, V27, P1469, DOI 10.1109/TNNLS.2015.2448637
   Zhang ZY, 2012, IEEE T PATTERN ANAL, V34, P253, DOI 10.1109/TPAMI.2011.115
   Zhihua Qiao, 2009, IAENG International Journal of Applied Mathematics, V39, P48
   Zhou T, 2020, COMPUT STRUCT, V241, DOI 10.1016/j.compstruc.2020.106358
   Zhou Y, 2017, IEEE T CYBERNETICS, V47, P830, DOI 10.1109/TCYB.2016.2529299
   Zhu F, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108422
   Zhu X., 2013, MACH LEARN P 20 INT, P21
NR 44
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20781
EP 20796
DI 10.1007/s11042-022-12708-3
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000009
DA 2024-07-18
ER

PT J
AU Yao, YB
   Wang, JJ
   Du, CJ
   Zhu, JH
   Xu, X
AF Yao, Yingbiao
   Wang, Jiaojiao
   Du, Chenjie
   Zhu, Jinghui
   Xu, Xin
TI A support vector machine based fast planar prediction mode decision
   algorithm for versatile video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding; Support vector machine; Mode decision; Intra
   prediction
ID PARTITION DECISION; INTRA; SVM
AB Versatile Video Coding (VVC/H.266) expands the intra-frame prediction modes from 35 of H.265 to 67, which not only improves the prediction accuracy and coding efficiency of the encoder but also increases its encoding complexity. In response to this problem, this paper proposes a support vector machine-based fast planar prediction mode decision algorithm for VVC/H.266, which is used to quickly determine the Planar or non-Planar prediction modes during intra coding, avoiding the rate-distortion optimization calculation of multiple intra prediction modes, and thus reducing the encoding time. The contributions of this paper are: 1) It proposes a novel feature based on Statistical Oriented Gradient (SOG) to extract the feature information of the coding block; 2) Based on the SOG feature, a support vector machine-based method is proposed to make the decision between the Planar and non-Planar modes for intra coding of VVC/H.266. The proposed algorithm has been integrated into the VVC/H.266 standard coder, VTM5.0. The experimental results show that, compared with VTM5.0, the encoding time of the proposed algorithm is reduced by 18.0% on average, while the Bjontegaard-Delta -Rate (BD-RATE) increased by only 1.3%.
C1 [Yao, Yingbiao; Wang, Jiaojiao; Du, Chenjie; Zhu, Jinghui; Xu, Xin] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Yao, YB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
EM yaoyb@hdu.edu.cn
RI yao, yao/HHZ-7438-2022
FU Public Welfare Technology Research Project Of Zhejiang [LGG19F020014];
   Scientific research projects of Zhejiang Provincial Department of
   Education [Y202044430]; General Project of Zhejiang Natural Science
   Foundation [LY19F010011]
FX This work was supported in part by Public Welfare Technology Research
   Project Of Zhejiang (LGG19F020014), Scientific research projects of
   Zhejiang Provincial Department of Education (Y202044430) and General
   Project of Zhejiang Natural Science Foundation (LY19F010011).
CR Bahri N, 2020, IET COMPUT DIGIT TEC, V14, P256, DOI 10.1049/iet-cdt.2019.0197
   Bouaafia S, 2020, J REAL-TIME IMAGE PR, V17, P185, DOI 10.1007/s11554-019-00936-0
   Bross B., 2018, Versatile video coding (draft 1), jvet-j1001
   Bross B, 2020, IEEE T CIRC SYST VID, V30, P1226, DOI 10.1109/TCSVT.2019.2949619
   Cao J, 2020, LECT NOTES COMPUT SC, V11961, P739, DOI 10.1007/978-3-030-37731-1_60
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Li, 2018, 2018 IEEE International Conference of Safety Produce Informatization (IICSPI). Proceedings, P723, DOI 10.1109/IICSPI.2018.8690465
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Farrugia RA, 2008, IEEE T CIRC SYST VID, V18, P1766, DOI 10.1109/TCSVT.2008.2004919
   Gender W, 2015, IEEE IMAGE PROC, P242, DOI 10.1109/ICIP.2015.7350796
   Ghaznavi-Youvalari R, 2018, IEEE INT SYM MULTIM, P127, DOI 10.1109/ISM.2018.00030
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang YY, 2020, MULTIMED TOOLS APPL, V79, P33957, DOI 10.1007/s11042-020-08882-x
   Kamath S, 2020, MULTIMED TOOLS APPL, V79, P11375, DOI 10.1007/s11042-019-08466-4
   Lei M, 2019, IEEE IMAGE PROC, P4120, DOI [10.1109/ICIP.2019.8803421, 10.1109/icip.2019.8803421]
   Li TS, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115668
   Liao W., 2016, VIS COMM IM PROC VCI, V2016, P1, DOI [10.1109/VCIP.2016.7805540, DOI 10.1109/VCIP.2016.7805540]
   Liu Y, 2007, IEEE T SIGNAL PROCES, V55, P3272, DOI 10.1109/TSP.2007.894403
   Mallikarachchi T, 2018, IEEE T CIRC SYST VID, V28, P693, DOI 10.1109/TCSVT.2016.2619499
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Pakdaman F, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116177
   Polat K, 2009, EXPERT SYST APPL, V36, P10367, DOI 10.1016/j.eswa.2009.01.041
   Ruiz D, 2019, J REAL-TIME IMAGE PR, V16, P1825, DOI 10.1007/s11554-017-0685-4
   Ruiz D, 2017, MULTIMED TOOLS APPL, V76, P861, DOI 10.1007/s11042-015-3014-6
   Ryu S, 2018, IEEE T IMAGE PROCESS, V27, P5525, DOI 10.1109/TIP.2018.2857404
   Sun XB, 2018, PROC SPIE, V10615, DOI 10.1117/12.2302920
   Wang SW, 2020, IEEE DATA COMPR CONF, P398, DOI 10.1109/DCC47342.2020.00076
   Wang Z, 2018, IEEE T IMAGE PROCESS, V27, P1475, DOI 10.1109/TIP.2017.2778564
   Wang ZX, 2021, MULTIMED TOOLS APPL, V80, P2441, DOI 10.1007/s11042-020-09231-8
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang H, 2017, IEEE IMAGE PROC, P2468, DOI 10.1109/ICIP.2017.8296726
   Yao YB, 2018, MULTIMED TOOLS APPL, V77, P1861, DOI 10.1007/s11042-017-4372-z
   Yoon YU, 2019, ELECTRON LETT, V55, P188, DOI 10.1049/el.2018.7452
   Zhang QW, 2021, MULTIMEDIA SYST, V27, P1, DOI 10.1007/s00530-020-00688-z
   Zhang QW, 2020, IEEE ACCESS, V8, P117539, DOI 10.1109/ACCESS.2020.3004580
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao ZM, 2021, MULTIMED TOOLS APPL, V80, P345, DOI 10.1007/s11042-020-09721-9
   Zhu W, 2020, J REAL-TIME IMAGE PR, V17, P275, DOI 10.1007/s11554-018-0766-z
NR 40
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17205
EP 17222
DI 10.1007/s11042-022-12582-z
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764599500001
DA 2024-07-18
ER

PT J
AU Chuttur, MY
   Nazurally, A
AF Chuttur, M. Y.
   Nazurally, A.
TI A multi-modal approach to detect inappropriate cartoon video contents
   using deep learning networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Children; YouTube; Deep learning; User comments; Closed captions;
   Disturbing contents
ID SHORT-TERM; CLASSIFICATION; AGGRESSION; VIOLENCE; MEDIA
AB Children are more than ever exposed to all kinds of video contents on the Internet. Consequently, several studies have proposed different techniques to detect videos that can be harmful for children. However, we note so far, that no attention has been given to the cartoon characters and the underlying language used. To address this gap, we propose to evaluate the effectiveness of using actual images of cartoon characters and the language used in cartoons in categorising videos as being appropriate or inappropriate for children. We do so through the development of a multi modal classifier, which makes use of the output from two deep learning networks: LSTM for text analysis and VGGNet for image analysis. More specifically, the LSTM network is used to process user comments and closed captions associated with a video and the VGGNet network is used to recognize cartoon image characters. The LSTM model was trained and tested on a dataset comprising about 290,000 labelled text records, while the VGGNet model was trained and tested on a manually annotated image dataset of 6000 cartoon characters. A testing accuracy of 94% was obtained for the LSTM network while a testing accuracy of 99% was obtained for the VGGNet network. Our proposed approach was further evaluated using 50 actual videos intended for children from YouTube. Here also, a good accuracy of 72% was obtained using LSTM alone, while a better accuracy of 78% was obtained using VGGNet alone and an accuracy of 76% was obtained using the combined output from the LSTM and VGGNet networks. We conclude that closed captions, user comments and images of cartoon characters are all useful in detecting unsafe videos for children and can be considered as essential parameters to include when developing multimedia filtering tools.
C1 [Chuttur, M. Y.; Nazurally, A.] Univ Mauritius, Reduit 80837, Moka, Mauritius.
C3 University of Mauritius
RP Chuttur, MY (corresponding author), Univ Mauritius, Reduit 80837, Moka, Mauritius.
EM y.chuttur@uom.ac.mu; azina.nazurally@umail.uom.ac.mu
OI Chuttur, Yasser/0000-0002-6049-8272
CR Afifi M, 2019, IEEE I CONF COMP VIS, P243, DOI 10.1109/ICCV.2019.00033
   Aggarwal N, 2014, ANN CONF PRIV SECUR, P84, DOI 10.1109/PST.2014.6890927
   Alghowinem S, 2019, ADV INTELL SYST COMP, V868, P294, DOI 10.1007/978-3-030-01054-6_21
   Ali A, 2017, ADV INTELL SYST, V549, P130, DOI 10.1007/978-3-319-51281-5_14
   [Anonymous], 2017, GITHUB T DAV HAT SPE
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Bisht A., 2020, Recent trends in image and signal processing in computer vision, V1124, P243, DOI 10.1007/978-981-15-2740-1_17
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Bridges AJ, 2010, VIOLENCE AGAINST WOM, V16, P1065, DOI 10.1177/1077801210382866
   Bushman BJ, 2006, ARCH PEDIAT ADOL MED, V160, P348, DOI 10.1001/archpedi.160.4.348
   Buzzi M., 2011, Proceedings of the 9th ACM SIGCHI Italian Chapter International Conference on Computer-Human Interaction: Facing Complexity, CHItaly, P125, DOI DOI 10.1145/2037296.2037328
   Cao X., 2018, ADV INTELLIGENT SYST, P283, DOI [10.1007/978-3-030-02116-0_33, DOI 10.1007/978-3-030-02116-0_33]
   Chang JH, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.4319
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Dara Suresh, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1795, DOI 10.1109/ICECA.2018.8474912
   Dillon KP, 2017, JAMA PEDIATR, V171, P1057, DOI 10.1001/jamapediatrics.2017.2229
   Drushel BE, 2019, J HOMOSEXUAL, V66, P1756, DOI [10.1080/00918369.2018.1528072, 10.1080/00918369.2018.1511132]
   Eickhoff C, 2010, 3 NETW EL MED SUMM
   Ekenel HK, 2013, MULTIMED TOOLS APPL, V63, P547, DOI 10.1007/s11042-011-0923-x
   Elgendy M., 2020, Deep Learning for Vision Systems
   Feng GCC, 2019, INT COMMUN GAZ, V81, P283, DOI 10.1177/1748048518767799
   Gentile D.A., 2008, HDB CHILDREN MEDIA D, P527, DOI DOI 10.1002/9781444302752.CH23
   Gentile DA, 2011, AGGRESSIVE BEHAV, V37, P193, DOI 10.1002/ab.20380
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochscherf T, 2019, FILM HIST, V31, P83, DOI 10.2979/filmhistory.31.3.04
   Holman EA, 2020, CLIN PSYCHOL SCI, V8, P111, DOI 10.1177/2167702619858300
   Huang CN, 2010, J AM SOC INF SCI TEC, V61, P891, DOI 10.1002/asi.21291
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Ibrahim Z. A. A., 2019, EUROPEAN J ELECT ENG, V3
   Ishikawa A., 2019, ARXIV PREPRINT ARXIV
   Ishizawa A., 2019, 2019 URSI Asia-Pacific Radio Science Conference (AP-RASC), DOI 10.23919/URSIAP-RASC.2019.8738185
   Izci B., 2019, Criancas, P81, DOI DOI 10.34629/IPL.ESELX.CAP.LIVROS.017
   Kasbekar A, 2020, ADV COMPUTING TECHNO, P645
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kaushal Rishabh, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P157, DOI 10.1109/PST.2016.7906950
   Kennedy M, 2020, EUR J CULT STUD, V23, P1069, DOI 10.1177/1367549420945341
   Khan M., 2018, P 21 INT MULT TOP C
   Khan ML, 2017, COMPUT HUM BEHAV, V66, P236, DOI 10.1016/j.chb.2016.09.024
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Lagunas M., 2017, SPANISH COMPUTER GRA, DOI 10.2312/ceig.20171213
   Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1
   Liu J, 2018, IEEE T CIRC SYST VID, V28, P1232, DOI 10.1109/TCSVT.2016.2643009
   Muhammad U, 2018, INT C PATT RECOG, P1622, DOI 10.1109/ICPR.2018.8545591
   Neumann MM, 2020, EDUC INF TECHNOL, V25, P4459, DOI 10.1007/s10639-020-10183-7
   Papadamou K., 2020, P INT AAAI C WEB SOC, V14, P522, DOI [https://doi.org/10.1609/icwsm.v14i1.7320, DOI 10.1609/ICWSM.V14I1.7320]
   Rani P., 2020, EAI ENDORSED T CREAT, V7
   Reddy S., 2021, Data Science and Security, P243
   Ries CX, 2014, MULTIMED TOOLS APPL, V69, P661, DOI 10.1007/s11042-012-1132-y
   Rosencrans, 1989, COLUM VLA J ARTS, V14, P451
   Shafaei M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1327
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2104, DOI 10.1145/3297280.3297487
   Skowron A, 2006, LECT NOTES COMPUT SC, V4100, P224
   Soleymani R, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107146
   Su Y. C., 2014, ARXIV PREPRINT ARXIV
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Tahir R, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P464, DOI 10.1145/3341161.3342913
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tariq Muhammad Uzair, 2019, Human-Computer Interaction. Design Practice in Contemporary Societies, P90
   Yin XR, 2019, IEEE T MED IMAGING, V38, P2903, DOI 10.1109/TMI.2019.2917258
   Zepernick, 2019, PALGRAVE HDB CHILDRE, P1, DOI DOI 10.1109/IEEECONF48524.2019.9102590
NR 63
TC 1
Z9 1
U1 5
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16881
EP 16900
DI 10.1007/s11042-022-12709-2
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100017
DA 2024-07-18
ER

PT J
AU El Madani, S
   Motahhir, S
   El Ghzizal, A
AF El Madani, Samira
   Motahhir, Saad
   El Ghzizal, Abdelaziz
TI Internet of vehicles: concept, process, security aspects and solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of vehicles; VANET; Cloud computing; Security; Communications'
   protocols
ID NETWORK MODEL; ARCHITECTURE; COMMUNICATION; CHALLENGES; TECHNOLOGIES;
   MANAGEMENT; PERCEPTION; LIDAR; DSRC
AB Internet of Vehicles (IoV) is a new concept, derived from combining VANET and Internet of Things (IoT), aiming at increasing road' user safety and reducing the number of accidents. In IoV, different types of communication are possible, namely, vehicle-to-sensor, as the car is considered as a powerful multisensory object, vehicle-to-pedestrian i.e. sharing data between vehicle and people, and vehicle-to-cloud communication in which cloud data centers and vehicles are the main actors. Indeed, the IoV's topology is very dynamic and non-uniform; it can be a target of several types of attacks that could menace people's lives. This paper is a detailed review of the internet of vehicles by presenting first of all the VANET networks including their different components, their possible communication, and their applications. The reasons behind the transition from VANET to IoV are also carried out in this review. After this, an in-depth study of IoV is being done by discussing its architecture and the different sensors and network protocols used in IoV. As it is not standardized, a comparison of the existing architecture is also elaborated in this review. Taking into account its importance, we devoted a part of this work to the security aspect for IoV by presenting the security requirements and the possible attacks, moreover, a study of the proposed security solutions will be done
C1 [El Madani, Samira; El Ghzizal, Abdelaziz] SMBA Univ, Innovat Technol Lab, EST, Fes, Morocco.
   [Motahhir, Saad] SMBA Univ, Engn Syst & Applicat Lab, ENSA, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP El Madani, S (corresponding author), SMBA Univ, Innovat Technol Lab, EST, Fes, Morocco.
EM samira.elmadani@usmba.ac.ma; saad.motahhir@usmba.ac.ma;
   abdelaziz.elghzizal@usmba.ac.ma
RI Motahhir, Saad/J-3585-2016
OI Motahhir, Saad/0000-0002-6846-8908
CR Abboud K, 2016, IEEE T VEH TECHNOL, V65, P9457, DOI 10.1109/TVT.2016.2591558
   Abu Talib M, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718815054
   Al Junaid Mohammed Ali Hezam, 2018, MATEC Web of Conferences, V150, DOI 10.1051/matecconf/201815006038
   Al-Absi MA, 2020, INT CONF ADV COMMUN, P1, DOI [10.23919/icact48636.2020.9061543, 10.23919/ICACT48636.2020.9061543]
   Al-ani R, 2018, SURVEY SECURE SAFETY
   Alam KM, 2015, IEEE ACCESS, V3, P343, DOI 10.1109/ACCESS.2015.2416657
   Alouache L, 2017, INTERNET OBJETS, V17, DOI 10.21494/iste.op.2017.0139
   [Anonymous], 2018, CAR PROD NUMB CARS P
   [Anonymous], Vehicular ad-hoc network
   Baofeng Ji, 2020, IEEE Communications Standards Magazine, V4, P34, DOI 10.1109/MCOMSTD.001.1900053
   Baruah JK, 2018, LECT NOTES ELECTR EN, V462, P563, DOI 10.1007/978-981-10-7901-6_61
   Bechler M, 2001, 8 WORLD C INT TRANSP, P1
   Bey T, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P1032, DOI 10.1109/CCWC.2019.8666563
   BORCOCI Eugen, 2018, INT J ADV INTERNET T, V11, P31
   Campbell S, 2018, 2018 29TH IRISH SIGNALS AND SYSTEMS CONFERENCE (ISSC)
   Castiglione A, 2020, PATTERN RECOGN LETT, V135, P264, DOI 10.1016/j.patrec.2020.04.038
   Chen YR, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/3013562
   Chhabra R, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P36, DOI 10.1109/CONFLUENCE.2017.7943120
   Choe C., 2020, 2020 IEEE 91 VEH TEC, P1, DOI [10.1109/VTC2020-Spring48590.2020.9128853, DOI 10.1109/VTC2020-SPRING48590.2020.9128853]
   Contreras-Castillo J, 2017, J INFORM TELECOMMUN, V1, P4, DOI 10.1080/24751839.2017.1295601
   Daniel A., 2014, Proceedings of the 29th Annual ACM Symposium on Applied Computing, P715, DOI DOI 10.1145/2554850.2555192
   Daud MM, 2018, PROCEEDINGS OF THE 2018 1ST IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE INNOVATION AND INVENTION (ICKII 2018), P1, DOI 10.1109/ICKII.2018.8569141
   Deshmukh M, 2014, CHALLENGES VEHICLE A
   Lopez HJD, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P211, DOI 10.1109/SOLI.2017.8120996
   Dey J, 2021, INTERNET VEHICLES IT, P149, DOI DOI 10.1007/978-3-030-46335-9_10
   Dey KC, 2016, TRANSPORT RES C-EMER, V68, P168, DOI 10.1016/j.trc.2016.03.008
   Dong W, 2019, IOV, V30, P1, DOI [10.3966/199115992019023001001, DOI 10.3966/199115992019023001001]
   Dua A, 2014, VEH COMMUN, V1, P33, DOI 10.1016/j.vehcom.2014.01.001
   Ganeshkumar N, COMPUTATIONAL METHOD, P191
   Gasmi R, 2019, VEHICULAR AD HOC NET, DOI 10.1109/ICNAS.2019.8807870
   Geetha VKN, INT J ENG RES TECHNO, P10
   Gupta N, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12040063
   Haddadou N, RESEAUX AD HOC VEHIC
   Han M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239043
   Hasrouny H, 2017, VEH COMMUN, V7, P7, DOI 10.1016/j.vehcom.2017.01.002
   Hecht J, 2018, OPT PHOTONICS NEWS, V29, P26
   Hosur P, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1154, DOI 10.1109/ICACCI.2016.7732200
   Hussain S.M., 2021, J COMMUN, V16, P155, DOI 10.12720/jcm.16.5.155-166
   Jabbar R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143928
   Jalali F, 2016, IEEE J SEL AREA COMM, V34, P1728, DOI 10.1109/JSAC.2016.2545559
   Jose JB, 2015, IEEE INT SYMP INFO, P2822, DOI 10.1109/ISIT.2015.7282971
   Joy J., 2017, 2017 26th International Conference on Computer Communication and Networks (ICCCN), P1
   Joy J, 2018, INTERNET TECHNOL LET, V1, DOI 10.1002/itl2.16
   Joy J, 2017, IEEE VEHIC NETW CONF, P147, DOI 10.1109/VNC.2017.8275634
   Kaiwartya O, 2016, IEEE ACCESS, V4, P5356, DOI 10.1109/ACCESS.2016.2603219
   Kakkasageri MS, 2014, J NETW COMPUT APPL, V39, P334, DOI 10.1016/j.jnca.2013.05.015
   Kaur Rajdeep., 2018, 2018 2 INT C TRENDS, P884, DOI DOI 10.1109/ICOEI.2018.8553852
   Kawser MT, 2019, PERSPECTIVE VEHICLE
   Kayarga T., 2018, INT J ENG TECHNOL, V7, P245, DOI [10.14419/ijet.v7i3.31.18234, DOI 10.14419/IJET.V7I3.31.18234]
   Kchaou A, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P88, DOI 10.1109/WAINA.2018.00068
   Khairnar VD, 2013, INT J NETW SECUR ITS, V5, DOI 10.5121/ijnsa.2013.5212
   Ksouri C, 2018, INT WIREL COMMUN, P904, DOI 10.1109/IWCMC.2018.8450498
   Kukkala VK, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2018.2828440
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Lee D, 2017, I S BIOMED IMAGING, P15, DOI 10.1109/ISBI.2017.7950457
   Li WX, 2020, IEEE ACCESS, V8, P181733, DOI 10.1109/ACCESS.2020.3028189
   Lim K, 2019, CONSUM COMM NETWORK, DOI 10.1109/ccnc.2019.8651684
   Lim T.-Y., 2019, Radar and Camera Early Fusion for Vehicle Detection in Advanced Driver Assistance Systems
   Liu K, 2019, IEEE COMMUN MAG, V57, P41, DOI 10.1109/MCOM.2019.1800772
   Liu SN, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277965
   Mahmood A, 2018, BIG DATA PRIVACY ISS, P1
   Mahmood Z., 2020, CONNECTED VEHICLES I, P3, DOI DOI 10.1007/978-3-030-36167-9_1
   Malebary, 2016, REAL TIME JAMMING DE, V3, P2313
   Mohamed Z, 2019, OVERVIEW MILLIMETER
   Niu Y, 2015, WIREL NETW, V21, P2657, DOI 10.1007/s11276-015-0942-z
   Oica, 2006, WORLD VEH US ALL VEH
   Ondrus J, 2020, TRANSP RES PROC, V44, P226, DOI 10.1016/j.trpro.2020.02.049
   Priyan MK., 2019, INT J ADV INTELLIGEN, V12, P98, DOI [10.1504/IJAIP.2019.096957, DOI 10.1504/IJAIP.2019.096957]
   Qureshi KN, 2021, IEEE T INTELL TRANSP, V22, P1777, DOI 10.1109/TITS.2020.2994972
   Raghavan V, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417864
   Ram V. Ravi, 2020, International Journal of Networking and Virtual Organisations, V22, P347
   Rathee G, 2020, IEEE ACCESS, V8, P157427, DOI 10.1109/ACCESS.2020.3019795
   Saini M, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2817552
   Sakiz F, 2017, AD HOC NETW, V61, P33, DOI 10.1016/j.adhoc.2017.03.006
   Sewalkar P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020358
   Sharifi A, 2019, CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P452, DOI [10.1109/ICCAR.2019.8813433, 10.1109/iccar.2019.8813433]
   Sharma N, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P203, DOI 10.1109/ICSCCC.2018.8703272
   Sheikh MS, 2019, WIREL COMMUN MOB COM, V2019, DOI 10.1155/2019/2423915
   Shen XM, 2020, P IEEE, V108, P242, DOI 10.1109/JPROC.2020.2964107
   Silva L, 2021, IEEE-CAA J AUTOMATIC, V8, P491, DOI 10.1109/JAS.2021.1003862
   Singh A, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P632, DOI [10.1109/AICAI.2019.8701312, 10.1109/aicai.2019.8701312]
   Sommer F, 2019, INFORMATION, V10, DOI 10.3390/info10040148
   Stiawan R, 2019, J PHYS CONF SER, V1204, DOI 10.1088/1742-6596/1204/1/012017
   Sun YC, 2017, ANN TELECOMMUN, V72, P283, DOI 10.1007/s12243-016-0551-6
   Taleb, 2018, CREATIVE COMMONS ATT, DOI 10.3844/jcssp.2018.423.434
   Thakur A, 2019, IEEE INTEL TRANSP SY, V11, P8, DOI 10.1109/MITS.2019.2903551
   Nguyen TV, 2017, IEEE VEHIC NETW CONF, P101, DOI 10.1109/VNC.2017.8275618
   Tufail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113785
   Ukarande V.V., 2018, 2018 4 INT C ADV EL, P1, DOI [10.1109/AEEICB.2018.8480946, DOI 10.1109/AEEICB.2018.8480946]
   Va V, 2015, FOUND TRENDS NETW, V10, P1, DOI 10.1561/1300000054
   Velasco-Hernandez G, 2020, INT C INTELL COMP CO, P315, DOI [10.1109/ICCP51029.2020.9266268, 10.1109/iccp51029.2020.9266268]
   Villarreal-Vasquez M, 2017, 2017 IEEE 2ND INTERNATIONAL CONGRESS ON INTERNET OF THINGS (IEEE ICIOT), P17, DOI 10.1109/IEEE.ICIOT.2017.12
   Wang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020334
   Wang X, 2018, IEEE COMMUN SURV TUT, V20, P1616, DOI 10.1109/COMST.2018.2844322
   Warren ME, 2019, SYMP VLSI CIRCUITS, pC254, DOI [10.23919/VLSIC.2019.8777993, 10.23919/vlsic.2019.8777993]
   Wu W., 2016, Internet of Things, P299
   Xu W, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBER SITUATIONAL AWARENESS, DATA ANALYTICS AND ASSESSMENT (CYBER SA)
   Xu WC, 2018, IEEE-CAA J AUTOMATIC, V5, P19, DOI 10.1109/JAS.2017.7510736
   XU Z, 2017, J ADV TRANSPORT, V2017, DOI [10.1155/2017/2750452, DOI 10.1155/2017/2750452]
   Yalin Li, 2021, Journal of Physics: Conference Series, V1757, DOI 10.1088/1742-6596/1757/1/012149
   Yan GJ, 2017, AD HOC NETW, V58, P25, DOI 10.1016/j.adhoc.2016.11.017
   Yang FC, 2014, CHINA COMMUN, V11, P1, DOI 10.1109/CC.2014.6969789
   Yang W, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/5172305
   Yu L., 2015, AUTOMOBILE ECU DESIG, DOI 10.1145/2746266.2746276
   Zhang J, 2020, P IEEE, V108, P246, DOI 10.1109/JPROC.2019.2947490
   Zhong Z, 2018, CAMERA RADAR FUSION
   Zhu H, 2017, IEEE T INTELL TRANSP, V18, P2584, DOI 10.1109/TITS.2017.2658662
   Ziebinski A, 2017, AIP CONF PROC, V1906, DOI 10.1063/1.5012394
   Ziebinski A, 2016, LECT NOTES ARTIF INT, V9876, P135, DOI 10.1007/978-3-319-45246-3_13
   Zlomislic V, 2017, CLUSTER COMPUT, V20, P661, DOI 10.1007/s10586-017-0730-x
   Ghafoor KZ, 2020, IEEE INTERNET THINGS, V7, P8525, DOI 10.1109/JIOT.2020.2992449
NR 111
TC 17
Z9 17
U1 5
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16563
EP 16587
DI 10.1007/s11042-022-12386-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300009
DA 2024-07-18
ER

PT J
AU Moura, RS
   Sanches, SRR
   Bugatti, PH
   Saito, PTM
AF Moura, Ronaldo S.
   Sanches, Silvio R. R.
   Bugatti, Pedro H.
   Saito, Priscila T. M.
TI Pedestrian traffic lights and crosswalk identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reduced mobility; Object identification; Convolutional neural network;
   Deep learning
ID WHEELCHAIR
AB People who experience physical or visual impairments depend on family members or caregivers to accomplish their activities. For the physically impaired, the adoption of electric-powered wheelchairs remedies the effects of lost mobility, providing more independence to users. Thus, the research for autonomous wheelchairs becomes relevant. The detection of the location and the best time to cross the streets is a problem that concerns both the visually impaired and the autonomous navigation systems of these wheelchairs. Therefore, this work aims to develop a method for real-time pedestrian traffic lights (PTLs) and zebra crosswalks identification. To accomplish this, we built a new and challenging dataset, composed of 5180 images from five countries, and used it in the training, validation, and testing of five state-of-the-art convolutional neural networks (CNNs) architectures that we modified to be suitable for our task. The results found attest that our approach is capable of performing the simultaneous identification of crosswalks and PTLs with up to 95% accuracy, which makes it suitable for challenging scenarios.
C1 [Moura, Ronaldo S.; Sanches, Silvio R. R.; Bugatti, Pedro H.; Saito, Priscila T. M.] Univ Tecnol Fed Parana, Dept Acad Comp, Av Alberto Carazzai 1640, BR-86300000 Cornelio Procopio, PR, Brazil.
C3 Universidade Tecnologica Federal do Parana
RP Moura, RS (corresponding author), Univ Tecnol Fed Parana, Dept Acad Comp, Av Alberto Carazzai 1640, BR-86300000 Cornelio Procopio, PR, Brazil.
EM ronaldomoura@alunos.utfpr.edu.br; silviosanches@utfpr.edu.br;
   pbugatti@utfpr.edu.br; psaito@utfpr.edu.br
RI Bugatti, Pedro/T-5178-2017; Sanches, Silvio RR/J-6357-2013; Saito,
   Priscila/E-8159-2013
OI Bugatti, Pedro/0000-0001-9421-9254; Saito, Priscila/0000-0002-4870-4766;
   Moura, Ronaldo/0000-0001-8730-9948; Sanches, Silvio/0000-0003-3635-7477
CR Adapt-Project, 2019, AD PROJ QUELQ MOTS
   ADVOCATE, 2021, WORK PACK
   [Anonymous], 2018, ACM INT C PROCEEDING, DOI DOI 10.1145/3278229.3278231
   Ash R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING IN ISRAEL (ICSEE)
   Brézin AP, 2005, ARCH OPHTHALMOL-CHIC, V123, P1117, DOI 10.1001/archopht.123.8.1117
   Cheng R, 2018, IMAGE DATA SETS
   Cheng RQ, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053025
   Cheng RQ, 2018, MULTIMED TOOLS APPL, V77, P20651, DOI 10.1007/s11042-017-5472-5
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Edwards K, 2010, DISABIL REHABIL-ASSI, V5, P411, DOI 10.3109/17483101003793412
   Fehr L, 2000, J REHABIL RES DEV, V37, P353
   Finlayson M, 2003, DISABIL REHABIL, V25, P1168, DOI 10.1080/09638280310001596180
   Ghilardi M C., 2018, 2018 INT JOINT C NEU, DOI [DOI 10.1109/IJCNN.2018.8489516, 10.1109/ijcnn.2018.8489516]
   Grewal H, 2017, 2017 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Hartman A, 2017, THESIS CALIFORNIA ST
   Hartman A, 2019, J ROBOT, V2019, DOI 10.1155/2019/4837058
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huh Minyoung, 2016, ABS160808614 CORR
   IrisVision, 2021, IR RED WHAT LIV LOW
   Khan Zainab, 2016, Adv Med, V2016, P4683427, DOI 10.1155/2016/4683427
   Lankenau A., 2000, Zeitschrift Kunstliche Intellgenz, V14, P37
   Ma XS, 2021, PHYS COMMUN-AMST, V47, DOI 10.1016/j.phycom.2021.101375
   Niijima S, 2019, ADV ROBOTICS, V33, P1006, DOI 10.1080/01691864.2019.1642240
   NuEyes, 2021, WHAT IS NUEYES PRO
   O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Roters J, 2019, DATABASES
   Sakai Y, 2019, INT C CONTR AUTOMAT, P816, DOI [10.23919/iccas47443.2019.8971608, 10.23919/ICCAS47443.2019.8971608]
   Silva ET, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103086
   Tan MX, 2019, PR MACH LEARN RES, V97
   Valenta P, 2018, AMPEL PILOT DATASET
   Yu S, 2019, ARXIV190709706
   Yu S, 2019, IEEE INT CONF COMP V, P2593, DOI 10.1109/ICCVW.2019.00317
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
NR 34
TC 2
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16497
EP 16513
DI 10.1007/s11042-022-12222-6
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100010
DA 2024-07-18
ER

PT J
AU Kanwal, M
   Riaz, MM
   Ali, SS
   Ghafoor, A
AF Kanwal, Maria
   Riaz, M. Mohsin
   Ali, Syed Sohaib
   Ghafoor, Abdul
TI Fusing color, depth and histogram maps for saliency detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Histrogram based saliency; Visual attention; Image
   processing
ID OBJECT DETECTION; MODEL
AB A noval scheme is presented to identify image's saliency. The proposed scheme formalizes the saliency map using color, depth along with input histogram. The color saliency map assumes that the salient objects in an image are usually more colorful than objetcs that are not salient. Likewise the salient objects are usually found closer to the camera during acquisition, therefore the transmission map is also utilized for saliency detection. The third map is estimated from histogram. The observation of this histogram that the salient intensities appear less frequently compared with the background intensity levels. These three maps are then fused and filtered in order to yield a smooth saliency map. Experiments prove that proposed scheme attains state of the art performance on different images.
C1 [Kanwal, Maria; Riaz, M. Mohsin; Ali, Syed Sohaib; Ghafoor, Abdul] COMSATS Univ, Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); National University of Sciences &
   Technology - Pakistan
RP Ghafoor, A (corresponding author), COMSATS Univ, Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM maria.phd@students.mcs.edu.pk; mohsin.riaz@comsats.edu.pk;
   sohaib.ali@comsats.edu.pk; abdulghafoor-mcs@nust.edu.pk
RI Imran, Muhammad/AAS-9984-2021
OI Imran, Muhammad/0000-0002-7122-8454; Ghafoor, Abdul/0000-0002-6117-3656;
   Syed, Sohaib Ali/0000-0003-4795-7275; Kanwal, Maria/0000-0002-0504-0488
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2015, FAST GUIDED FILTER
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348
   FU HZ, 2015, PROC CVPR IEEE, P4428, DOI DOI 10.1109/CVPR.2015
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hu WM, 2014, IEEE T IMAGE PROCESS, V23, P1513, DOI 10.1109/TIP.2014.2303639
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang JJ, 2014, 2014 IEEE INTERNATIONAL CONFERENCE (ITHINGS) - 2014 IEEE INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) - 2014 IEEE INTERNATIONAL CONFERENCE ON CYBER-PHYSICAL-SOCIAL COMPUTING (CPS), P1, DOI 10.1109/iThings.2014.10
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Lau CP, 2018, IEEE T IMAGE PROCESS, V27, P5787, DOI 10.1109/TIP.2018.2858146
   Lei JJ, 2015, IEEE T BROADCAST, V61, P416, DOI 10.1109/TBC.2015.2437197
   Li WP, 2020, IET IMAGE PROCESS, V14, P4039, DOI 10.1049/iet-ipr.2020.0773
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Liu X, 2016, IET IMAGE PROCESS, V10, P877, DOI 10.1049/iet-ipr.2016.0138
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng H., 2013, PROC AAAI C ARTIF IN, P796
   Polakovic A, 2018, ELMAR PROC, P169, DOI 10.23919/ELMAR.2018.8534631
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Tang RD, 2015, ACSR ADV COMPUT, V18, P663
   Wang AZ, 2017, IEEE SIGNAL PROC LET, V24, P663, DOI 10.1109/LSP.2017.2688136
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang J., 2019, VISUAL SALIENCY PIXE
NR 35
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16243
EP 16253
DI 10.1007/s11042-022-12165-y
EA MAR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600002
DA 2024-07-18
ER

PT J
AU Kang, PP
   Lin, ZH
   Yang, ZG
   Bronstein, AM
   Li, Q
   Liu, WY
AF Kang, Peipei
   Lin, Zehang
   Yang, Zhenguo
   Bronstein, Alexander M.
   Li, Qing
   Liu, Wenyin
TI Deep fused two-step cross-modal hashing with multiple semantic
   supervision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal hashing; Deep fusion network; Semantic reconstruction;
   Two-step learning; Supervised learning
AB Existing cross-modal hashing methods ignore the informative multimodal joint information and cannot fully exploit the semantic labels. In this paper, we propose a deep fused two-step cross-modal hashing (DFTH) framework with multiple semantic supervision. In the first step, DFTH learns unified hash codes for instances by a fusion network. Semantic label and similarity reconstruction have been introduced to acquire binary codes that are informative, discriminative and semantic similarity preserving. In the second step, two modality-specific hash networks are learned under the supervision of common hash codes reconstruction, label reconstruction, and intra-modal and inter-modal semantic similarity reconstruction. The modality-specific hash networks can generate semantic preserving binary codes for out-of-sample queries. To deal with the vanishing gradients of binarization, continuous differentiable tanh is introduced to approximate the discrete sign function, making the networks able to back-propagate by automatic gradient computation. Extensive experiments on MIRFlickr25K and NUS-WIDE show the superiority of DFTH over state-of-the-art methods.
C1 [Kang, Peipei; Yang, Zhenguo; Liu, Wenyin] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou, Peoples R China.
   [Kang, Peipei; Bronstein, Alexander M.] Technion Israel Inst Technol, Comp Sci Dept, Haifa, Israel.
   [Lin, Zehang; Li, Qing] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Guangdong University of Technology; Technion Israel Institute of
   Technology; Hong Kong Polytechnic University
RP Yang, ZG; Liu, WY (corresponding author), Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou, Peoples R China.
EM ppkanggdut@126.com; cszhlin@outlook.com; zhengyang5-c@my.cityu.edu.hk;
   bron@cs.technion.ac.il; csqli@comp.polyu.edu.hk; liuwy@gdut.edu.cn
RI zheng, yi/JOZ-7204-2023; Yang, Zhenguo/X-9205-2019; Li,
   Qing/JMH-1365-2023; lin, zehang/ABD-1029-2020
OI Yang, Zhenguo/0000-0001-7674-977X; Li, Qing/0000-0003-3370-471X; 
FU National Natural Science Foundation of China [62076073, 61902077,
   62006048, 61772141, 61972102]; Guangdong Basic and Applied Basic
   Research Foundation [2020A1515010616]; Science and Technology Program of
   Guangzhou [202102020524, 201903010107, 201802010042]; Guangdong
   Innovative Research Team Program [2014ZT05G157]; Special Funds for the
   Cultivation of Guangdong College Students' Scientific and Technological
   Innovation [pdjh2020a0173]; Key-Area Research and Development Program of
   Guangdong Province [2019B010136001]; Science and Technology Planning
   Project of Guangdong Province [2019B020208001, 2019B110210002, LZC0023]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62076073, No.61902077, No.62006048, No.61772141, and
   No.61972102), the Guangdong Basic and Applied Basic Research Foundation
   (No. 2020A1515010616), Science and Technology Program of Guangzhou
   (No.202102020524, No.201903010107, No.201802010042), the Guangdong
   Innovative Research Team Program (No.2014ZT05G157), Special Funds for
   the Cultivation of Guangdong College Students' Scientific and
   Technological Innovation (pdjh2020a0173), and the Key-Area Research and
   Development Program of Guangdong Province (2019B010136001), and the
   Science and Technology Planning Project of Guangdong Province
   (No.LZC0023, No.2019B020208001 and No.2019B110210002).
CR Cao Y, 2018, LECT NOTES COMPUT SC, V11205, P207, DOI 10.1007/978-3-030-01246-5_13
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Chen ZD, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1694, DOI 10.1145/3343031.3350862
   Chen ZD, 2018, AAAI CONF ARTIF INTE, P274
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dejie Yang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P44, DOI 10.1145/3372278.3390673
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Hu D, 2019, IEEE T MULTIMEDIA, V21, P973, DOI 10.1109/TMM.2018.2866771
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Kang PP, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P226, DOI 10.1145/3323873.3325029
   Li C, 2018, PROC CVPR IEEE, P4242, DOI 10.1109/CVPR.2018.00446
   Li C, 2018, DES AUT CON, DOI 10.1145/3195970.3196091
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liong VE, 2017, IEEE I CONF COMP VIS, P4097, DOI 10.1109/ICCV.2017.439
   Liu H, 2017, PROC CVPR IEEE, P6345, DOI 10.1109/CVPR.2017.672
   Liu X, 2021, IEEE T PATTERN ANAL, V43, P964, DOI 10.1109/TPAMI.2019.2940446
   Liu XB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1662, DOI 10.1145/3240508.3240683
   Liu XW, 2019, AAAI CONF ARTIF INTE, P4400
   Luo X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2518
   Peng YX, 2018, IEEE T CIRC SYST VID, V28, P2372, DOI 10.1109/TCSVT.2017.2705068
   Shen HT, 2021, IEEE T KNOWL DATA EN, V33, P3351, DOI [10.1109/TKDE.2020.2970050, 10.1109/TNNLS.2020.2995708]
   Su SP, 2019, IEEE I CONF COMP VIS, P3027, DOI 10.1109/ICCV.2019.00312
   Wang D, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1409, DOI 10.1145/3397271.3401132
   Wang HT, 2019, IEEE INT CON MULTI, P1012, DOI 10.1109/ICME.2019.00178
   Wang K., 2016, A comprehensive survey on cross-modal retrieval
   Wang L, 2019, IEEE INT CON MULTI, P37, DOI 10.1109/ICME.2019.00015
   Wang Q, 2020, IEEE T GEOSCI REMOTE
   Wang Q, 2014, COMPUT VIS IMAGE UND, V124, P22, DOI 10.1016/j.cviu.2014.03.002
   Wang XZ, 2019, IEEE INT CON MULTI, P1006, DOI 10.1109/ICME.2019.00177
   Wang Y, 2020, BATCH SCALABLE ASYMM
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yang Z, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1349, DOI 10.1145/3397271.3401152
   Yang ZG, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3374754
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhen L, 2019, CVPR, P403
NR 38
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15653
EP 15670
DI 10.1007/s11042-022-12187-6
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600003
DA 2024-07-18
ER

PT J
AU Bathla, G
   Rani, R
   Aggarwal, H
AF Bathla, Gourav
   Rani, Rinkle
   Aggarwal, Himanshu
TI Stocks of year 2020: prediction of high variations in stock prices using
   LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stock Price prediction; Deep learning; LSTM; RNN; MAPE
ID TERM-MEMORY NETWORKS; VOLATILITY; INDEX
AB Stock Market movement is highly volatile, complex, and non-linear. Several researchers have proposed innovative approaches to predict stock price movement using traditional data analytics, machine learning, or deep learning. Data scientists have proved that if effective mathematical models are deployed, stock prices can be predicted with very high accuracy. Deep learning is the most popular technique used for stock price prediction due to its effective results in time-series based and non-linear patterns. In the Year 2020, stock prices variations are too high to be analyzed by traditional approaches. Very few research works have been carried out to predict high variations in stock prices during this time. The main motive of this research is to investigate whether deep learning can predict so high variations in stock prices in the Year 2020 and build proposed neural network model. In this paper, Long Short-Term Memory (LSTM) is used with adam optimizer and sigmoid activation function to train and test the model. Various stock indexes data are extracted using Yahoo Finance API. Window size of 60 days is used as stock prices are dependent on the previous day's prices. Experiment analysis has proved that LSTM using our layers set up was able to predict stock prices with adequate accuracy. Mean Absolute Percentage Error (MAPE) values are better than traditional data analytics techniques. The values of MAPE score calculated using our proposed approach are 3.89, 1.21, 3.01, 1.19, 2.03, and 0.86 for NSE, BSE, NASDAQ, NYSE, Dow Jones, and Nikkei 225 respectively for duration Jan 2010 to March 2020.
C1 [Bathla, Gourav] Univ Petr & Energy Studies, Dehra Dun, Uttarakhand, India.
   [Rani, Rinkle] Thapar Inst Engg & Tech, Patiala, Punjab, India.
   [Aggarwal, Himanshu] Punjabi Univ, Patiala, Punjab, India.
C3 University of Petroleum & Energy Studies (UPES); Thapar Institute of
   Engineering & Technology; Punjabi University
RP Bathla, G (corresponding author), Univ Petr & Energy Studies, Dehra Dun, Uttarakhand, India.
EM gouravbathla@gmail.com
RI Aggarwal, Rinkle/AAT-4740-2020; Aggarwal, Himanshu/GOE-5647-2022;
   Bathla, Gourav/HQZ-2734-2023
OI Bathla, Gourav/0000-0003-4198-9647; AGGARWAL,
   HIMANSHU/0000-0003-1782-8376
CR Abe M, P 2020 AS SERV SCI S, P9
   [Anonymous], 2014, J. Comput. Inform. Syst
   Bao W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180944
   Bathla G, 2020, INT C PAR DISTR GRID
   Borovkova S, 2019, J FORECASTING, V38, P600, DOI 10.1002/for.2585
   Cakra YE, 2015, INT C ADV COMP SCI I, P147, DOI 10.1109/ICACSIS.2015.7415179
   Chong E, 2017, EXPERT SYST APPL, V83, P187, DOI 10.1016/j.eswa.2017.04.030
   Eapen J, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P264, DOI [10.1109/ccwc.2019.8666592, 10.1109/CCWC.2019.8666592]
   Feng FL, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3309547
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gunduz H, 2017, KNOWL-BASED SYST, V137, P138, DOI 10.1016/j.knosys.2017.09.023
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Hao YP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113961
   Hiransha M., 2018, Procedia Computer Science, V132, P1351, DOI 10.1016/j.procs.2018.05.050
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Hoseinzade E, 2019, EXPERT SYST APPL, V129, P273, DOI 10.1016/j.eswa.2019.03.029
   Hu G, IEEE INT C AC SPEECH
   Huang JY, 2020, J FORECASTING, V39, P104, DOI 10.1002/for.2616
   Huang W, 2005, COMPUT OPER RES, V32, P2513, DOI 10.1016/j.cor.2004.03.016
   Idrees SM, 2019, IEEE ACCESS, V7, P17287, DOI 10.1109/ACCESS.2019.2895252
   Jiang WW, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115537
   Khare K, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P482, DOI 10.1109/RTEICT.2017.8256643
   Kim HY, 2018, EXPERT SYST APPL, V103, P25, DOI 10.1016/j.eswa.2018.03.002
   Kusuma RMI, 2019, ARXIV PREPRINT ARXIV
   Li X, 2021, MAGN RESON MED, V85, P3463, DOI 10.1002/mrm.28672
   Liu G, 2019, IEEE ACCESS, V7, P7357, DOI 10.1109/ACCESS.2018.2886367
   Long W, 2019, KNOWL-BASED SYST, V164, P163, DOI 10.1016/j.knosys.2018.10.034
   Lu WJ, 2021, NEURAL COMPUT APPL, V33, P4741, DOI 10.1007/s00521-020-05532-z
   Mehtab S, ARXIV PREPRINT ARXIV, P2020
   Nikou M, 2019, INTELL SYST ACCOUNT, V26, P164, DOI 10.1002/isaf.1459
   Palangi H, 2016, IEEE T SIGNAL PROCES, V64, P4504, DOI 10.1109/TSP.2016.2557301
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Patel J, 2015, EXPERT SYST APPL, V42, P2162, DOI 10.1016/j.eswa.2014.10.031
   Rezaei H, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114332
   Sak H, 2014, INTERSPEECH, P338
   Selvin S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1643, DOI 10.1109/ICACCI.2017.8126078
   Shah D, 2019, INT J FINANC STUD, V7, DOI 10.3390/ijfs7020026
   Sharaf M, 2021, MULTIMED TOOLS APPL, V80, P17923, DOI 10.1007/s11042-021-10579-8
   Sharma A, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P506, DOI 10.1109/ICECA.2017.8212715
   Shen S., 2012, Department of Electrical Engineering, Stanford University, Stanford, CA, P1
   Shui-Ling YU, 2017, DESTECH T SOCIAL SCI
   Siami-Namini S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1394, DOI 10.1109/ICMLA.2018.00227
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P18569, DOI 10.1007/s11042-016-4159-7
   Zhong X, 2017, EXPERT SYST APPL, V67, P126, DOI 10.1016/j.eswa.2016.09.027
   Zhou ZB, 2020, PHYSICA A, V542, DOI 10.1016/j.physa.2019.123389
NR 47
TC 12
Z9 12
U1 10
U2 83
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9727
EP 9743
DI 10.1007/s11042-022-12390-5
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000761886300004
DA 2024-07-18
ER

PT J
AU Soui, M
   Haddad, Z
   Trabelsi, R
   Srinivasan, K
AF Soui, Makram
   Haddad, Zainab
   Trabelsi, Rim
   Srinivasan, Karthik
TI Deep features extraction to assess mobile user interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile User Interface evaluation; Convolutional Neural Networks;
   Features extraction; Deep Learning; Deep features; Classification
ID BORDERLINE-SMOTE; MODEL
AB Recently, the quality of user interface design has become a major factor in the success of mobile applications. To this end, the evaluation of Mobile User Interface (MUIs) is a mandatory step. Generally, there exist two main categories of user interface evaluation methods: manual and automatic. The manual evaluation is conducted by users or experts to assess the MUIs and verify whether it works as intended. However, it is more time-consuming task. Automatic evaluation is based on an automatic tool, which needs preconfiguration in the source code. But, this manual configuration is a tedious task for non-programmer evaluators. To address this issue, we propose an evaluation approach based on the analysis of graphical MUI as screenshot without using the source code and user involvement. The proposed approach combines the GoogleNet architecture and K-Nearest Neighbours (KNN) classifier to evaluate the MUIs. First, we apply the Borderline-SMOTE method to obtain a balanced dataset. Then, the GoogleNet is used to extract automatically the features of MUI. Finally, we apply the KNN classifier to classify the MUIs as good or bad. We evaluate this approach based on publicly available large-scale datasets having more number of good ratings than bad ratings which may have an impact on the proposed model during the learning step. To this end, the Borderline-SMOTE method (BSM) is used to obtain a balanced class distribution. The obtained results are very promising.
C1 [Soui, Makram; Srinivasan, Karthik] Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
   [Haddad, Zainab] Univ Manouba, Natl Sch Comp Sci, Artificial Intelligence Res Unit, Manouba, Tunisia.
   [Trabelsi, Rim] Univ Gabes, Natl Engn Sch Gabes, Hatem Bettaher ResCoMath Res Unit, Gabes 6029, Tunisia.
C3 Saudi Electronic University; Universite de la Manouba; Universite de
   Gabes
RP Soui, M (corresponding author), Saudi Elect Univ, Coll Comp & Informat, Riyadh, Saudi Arabia.
EM m.soui@seu.edu.sa; zainab-haddad@hotmail.com; rim.trabelsi@enit.rnu.tn;
   k.parimala@seu.edu.sa
CR Akiki PA, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2597999
   Alemerien K., 2014, SEKE, P13
   Alharbi K, 2015, P 17 INT C HUM COMP, P515, DOI DOI 10.1145/2785830.2785892
   Allamanis M, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P472, DOI 10.1145/2635868.2635901
   [Anonymous], 2013, Int J P2P Netw Trends Technol (IJPTT)
   Bessghaier N, 2017, I C COMP SYST APPLIC, P895, DOI 10.1109/AICCSA.2017.10
   Buse RPL, 2012, PROC INT CONF SOFTW, P782, DOI 10.1109/ICSE.2012.6227140
   Dadi H.S., 2016, IOSR J. Electron. Commun.Eng., V11, P34, DOI 10.9790/2834-1104013444
   Deka B, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P845, DOI 10.1145/3126594.3126651
   Doosti B, 2018, ARXIV180704191
   Emam A, 2015, INFORM SYST FRONT, V17, P947, DOI 10.1007/s10796-013-9481-2
   Eskonen J, 2019, DEEP REINFORCEMENT L
   Fast E, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2491, DOI 10.1145/2556288.2556998
   Ferguson Max, 2017, 2017 IEEE International Conference on Big Data (Big Data), P1726
   Fontao AD, 2019, INFORM SYST FRONT, V21, P143, DOI 10.1007/s10796-018-9861-8
   Fu B, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1276
   Gaudioso M, 2017, COMPUT OPER RES, V87, P137, DOI 10.1016/j.cor.2017.06.001
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   Harrison R., 2013, Usability of Mobile applications: literature review and rationale for a new usability model
   Hasan M., 2019, COMP ANAL SVM ANN CN
   Heinerud J, 2020, AUTOMATIC TESTING GR
   Ines G, 2017, PROCEDIA COMPUT SCI, V112, P235, DOI 10.1016/j.procs.2017.08.234
   Khumsi A. F., 2019, INT C THEOR APPL SOF, P573
   Kowall J., 2012, MAGIC QUADRANT APPL
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D, 2015, INFORM MANAGE-AMSTER, V52, P295, DOI 10.1016/j.im.2014.12.001
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Liu Q, 2018, INFORM SYST FRONT, V20, P401, DOI 10.1007/s10796-016-9690-6
   Mohamed A. E., 2017, International Journal of Applied Science and Technology, V7, P5, DOI DOI 10.15546/AEEI-2014-0021
   Nayebi F, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Osman H, 2014, 2014 SOFTWARE EVOLUTION WEEK - IEEE CONFERENCE ON SOFTWARE MAINTENANCE, REENGINEERING, AND REVERSE ENGINEERING (CSMR-WCRE), P343, DOI 10.1109/CSMR-WCRE.2014.6747191
   Palomba F, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P487, DOI 10.1109/SANER.2017.7884659
   Park J, 2013, HUM FACTOR ERGON MAN, V23, P279, DOI 10.1002/hfm.20316
   Sahami Shirazi A., 2013, PROC 5 ACM SIGCHI S, P275
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soui Makram, 2015, International Journal of Adaptive, Resilient and Autonomic Systems, V6, P1, DOI 10.4018/IJARAS.2015010101
   Soui M., 2019, ASSESSING QUALITY MO, P1
   Soui M, 2022, INFORM SYST FRONT, V24, P659, DOI 10.1007/s10796-020-10100-w
   Soui M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 1, P127, DOI 10.5220/0006171201270136
   Sudha KK, 2020, QUALITATIVE ANAL GOO
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Topcu Be, 2018, METHODOLOGY CLASSIFI
   Toribio P, 2012, FRONT ARTIF INTEL AP, V248, P29, DOI 10.3233/978-1-61499-139-7-29
   Wang XD, 2016, ANAL CHEM, V88, P203, DOI 10.1021/acs.analchem.5b04298
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   ZHANG P, 1993, ANN STAT, V21, P299, DOI 10.1214/aos/1176349027
   Zhou LJ, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/3792805
NR 50
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12945
EP 12960
DI 10.1007/s11042-022-11978-1
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000759366800003
DA 2024-07-18
ER

PT J
AU Paul, NR
   Sahoo, D
   Balabantaray, RC
AF Paul, Nayan Ranjan
   Sahoo, Deepak
   Balabantaray, Rakesh Chandra
TI Classification of crisis-related data on Twitter using a deep
   learning-based framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; SkipCNN; Classification; Deep learning; Crisis event
ID SOCIAL MEDIA; TESTS
AB In recent years, many citizens use social media platforms like Twitter to share and get the most up-to-date information regarding crisis events such as natural and man-made crisis. Automatically identifying this crisis-related information from social media data is a challenging task because of the sheer amount of data is being communicated between users during such crisis situations. The general public, response groups, and relief agencies can increase situational awareness by identifying and assessing crisis-related information from these massive amounts of social media data in real-time. Many studies have been published, that employ traditional machine learning approaches to detect crisis events, as well as others that use a deep neural network. In recent years, the models based on the deep neural network have outperformed traditional machine learning models for a variety of tasks. Two popularly used deep neural network models are Convolutional Neural Network (CNN) and the Gated Recurrent Unit (GRU). The local features can be detected by CNN in a multidimensional field, while the GRU network can learn sequential data because it can remember previously read data. In this paper, we propose two novel hybrid deep neural network models. The first model combines CNN and GRU and the second one combines CNN with SkipCNN. We evaluate our proposed models on 4 different datasets provided by CrisisNLP to show their effectiveness in detecting crisis-related information as well as identifying different types of information required for humanitarian aid. We find that from our proposed models CNN-SkipCNN is the best performing model and achieving better results than the state-of-the-art methods with an improvement of up to 16.55 absolute points for detecting crisis-related events and with an improvement of up to 21.71 absolute points in detecting different types of crisis information.
C1 [Paul, Nayan Ranjan; Balabantaray, Rakesh Chandra] IIIT Bhubaneswar, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
   [Sahoo, Deepak] Sri Sri Univ, Dept Fac Emerging Technol, Cuttack, Odisha, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Paul, NR (corresponding author), IIIT Bhubaneswar, Dept Comp Sci & Engn, Bhubaneswar, Odisha, India.
EM c116008@iiit-bh.ac.in; deepsahoo@gmail.com; rakesh@iiit-bh.ac.in
OI PAUL, NAYAN RANJAN/0000-0002-7421-3805
CR Aivazoglou M, 2019, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-019-0621-7
   Alam F., 2018, P INT AAAI C WEB SOC, P556
   Andrews S, 2016, J INTELL INF SYST, V47, P287, DOI 10.1007/s10844-016-0404-9
   [Anonymous], 2016, ARXIV161003750
   [Anonymous], 2016, INT C INF SYST CRIS
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bhoi A, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00692-1
   Burel E, 2017, LECT NOTES COMPUT SC, V10587, P138, DOI 10.1007/978-3-319-68288-4_9
   Burel G, 2018, Crisis event extraction service (crees)-automatic detection and classification of crisis-related content on social media
   Burel G., 2017, On semantics and deep learning for event detection in crisis situations
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Chung J, 2014, DEEP LEARNING REPRES
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhiman A, 2020, IEEE ACCESS, V8, P122168, DOI 10.1109/ACCESS.2020.3007004
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Gao H, 2011, IEEE INTELL SYST, V26, P10, DOI 10.1109/MIS.2011.52
   Imran M, 2013, P 10 INT ISCRAM C GE
   Imran M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1638
   Imran M, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1021
   Interdonato R, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0608-4
   Karimi S, 2013, PROCEEDINGS OF THE 18TH AUSTRALASIAN DOCUMENT COMPUTING SYMPOSIUM (ADCS 2013), P26
   Kaufhold MA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102132
   Kejriwal M, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00670-7
   Kersten J., 2019, ISCRAM 2019 C P 16 I, P814
   Khare P., 2017, Statistical semantic classification of crisis information
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma D. P., 2014, arXiv
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Lee H, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P957, DOI 10.1145/2911451.2914734
   Li HM, 2018, J CONTING CRISIS MAN, V26, P16, DOI 10.1111/1468-5973.12194
   Madichetty S, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0579-5
   Martin J., 2011, P INT AAAI C WEB SOC, P5
   Mendon S, 2021, INFORM SYST FRONT, V23, P1145, DOI 10.1007/s10796-021-10107-x
   Olteanu A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P994, DOI 10.1145/2675133.2675242
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Power R, 2014, LECT NOTES BUS INF P, V196, P218
   Qu Y., 2011, P ACM 2011 C COMP SU, P25
   Resch B, 2018, CARTOGR GEOGR INF SC, V45, P362, DOI 10.1080/15230406.2017.1356242
   Sahin C, 2019, LECT NOTES SOC NETW, P149, DOI 10.1007/978-3-319-78256-0_9
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.05.009
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Schempp T, 2019, INT J DISAST RISK RE, V39, DOI 10.1016/j.ijdrr.2019.101143
   Sinnappan S, 2010, ACIS 2010 P, P39
   Stowe K., 2016, P 4 INT WORKSHOP NAT, P1, DOI DOI 10.18653/V1/W16-6201
   Sultana T, 2020, ADV DECISION SCI IMA, P579
   Thompson Richard J., 2012, Crystal Clear: The Struggle for Reliable Communications Technology in World War II, P1
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   Wang JN, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105842
   Wang Y, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: CONSTRUCTION PROJECT MANAGEMENT, P250
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Yan W, 2016, ASIA COMMUN PHOTON
   Zhang ZQ, 2019, SEMANT WEB, V10, P925, DOI 10.3233/SW-180338
NR 55
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8921
EP 8941
DI 10.1007/s11042-022-12183-w
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000756332700012
DA 2024-07-18
ER

PT J
AU Yadav, N
   Dass, R
   Virmani, J
AF Yadav, Niranjan
   Dass, Rajeshwar
   Virmani, Jitendra
TI Despeckling filters applied to thyroid ultrasound images: a comparative
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Despeckling filters; Image quality assessment metrics; SEPI metric;
   Speckle noise; Digital database of thyroid ultrasound images (DDTI)
ID SPECKLE REDUCTION; NOISE; MODEL; ENHANCEMENT
AB The speckle noise is an intrinsic artefact present in ultrasound images that masks the diagnostically important information, thus makes it hard for the radiologists to analyze them. Therefore, a suitable despeckling algorithm, which will retain the diagnostically important features such as structure, edges and margins are required. In this study the performance of 64 despeckling filters algorithms used for the analysis of thyroid nodule ultrasound images is compared. These 64 filters are divided into 9 categories namely Linear, Non-linear, Total Variation, Fuzzy, Fourier, Multiscale, Nonlocal Mean, Edge Preserving, and Hybrid filters. A total of 820 thyroid US images have been taken from two different benchmark datasets. Out of these 820 thyroid US images, 200 are benign and 620 are malignant. The performance analysis of despeckling filters has been carried out by calculating structure and edge preservation index metric. It has been observed that fast bilateral filter and edge-preserving smoothing filter yields optimal performance with respect to the preservation of image structures like edges and margins of benign and malignant thyroid tumors. Based on the criterion followed in real time clinical practice for differential diagnosis between benign and malignant thyroid ultrasound tumors, it is observed that the images filtered by DsF_EPSF filter yields better diagnostic quality images in terms of preservation and enhancement of important diagnostic information.
C1 [Yadav, Niranjan; Dass, Rajeshwar] Deenbandhu Chhotu Ram Univ Sci & Technol Murhal, Dept Elect & Commun Engn, Sonepat 131039, India.
   [Virmani, Jitendra] CSIR, Cent Sci Instruments Org, Chandigarh 160030, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Scientific Instruments Organisation (CSIO)
RP Yadav, N (corresponding author), Deenbandhu Chhotu Ram Univ Sci & Technol Murhal, Dept Elect & Commun Engn, Sonepat 131039, India.
EM niranjanyadav97@gmail.com; rajeshwardas10@gmail.com;
   jitendra.vinnani@gmail.com
RI yadav, niranjan/AFJ-1422-2022; Dass, Rajeshwar/AAC-3610-2022;
   Muralikrishnan, Niranjan/AAW-8171-2021
OI yadav, niranjan/0000-0002-1023-0438; Dass,
   Rajeshwar/0000-0002-5462-0817; Muralikrishnan,
   Niranjan/0000-0001-9552-2626
FU National Project Implementation Unit (NPIU), a unit of Ministry of Human
   Resource Development, Government of India
FX The authors would like to thanks Dr. Jyotsna Sen, Sr. Professor,
   department of radiodiagnosis, Pt. B. D. Sharma Postgraduate Institute of
   Medical Sciences, Rohtak for stimulating discussions regarding different
   sonographic characteristics exhibited by various types of benign and
   malignant thyroid tumors. The first author acknowledge "National Project
   Implementation Unit (NPIU), a unit of Ministry of Human Resource
   Development, Government of India" for the financial assistantship
   through TEQIP-III project as Deenbandhu Chhotu Ram University of Science
   and Technology, Murthal, Haryana, India.
CR Afrose Z., 2012, INT J COMPUT SCI ENG, V4, P1376
   Ahila A, 2017, REV TEC FAC ING UNIV, V40, P1
   Ahmed J, 2016, IEEE INT CONF INTELL, P44, DOI 10.1109/INTELSE.2016.7475160
   Ardakani AA, 2019, J ULTRAS MED, V38, P629, DOI 10.1002/jum.14731
   Augustin S, 2013, INT J COMPUT SCI MOB, P134
   Bama S, 2014, SIGNAL PROCESS, V103, P230, DOI 10.1016/j.sigpro.2013.12.020
   BAMA S, 2012, RES J APPL SCI ENG T, V4, P5443
   Bin Saeedan M, 2016, INSIGHTS IMAGING, V7, P601, DOI 10.1007/s13244-016-0506-5
   Biradar N, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/3636017
   Biradar N, 2015, IETE TECH REV, V32, P435, DOI 10.1080/02564602.2015.1031714
   Carson PL, 2009, MED PHYS, V36, P411, DOI 10.1118/1.2992048
   Chang CY, 2010, BIOMED ENG-APP BAS C, V22, P81, DOI 10.4015/S1016237210001803
   Chang Y, 2016, MED PHYS, V43, P554, DOI 10.1118/1.4939060
   Christos P., 2014, INT J MONITORING SUR, V1, P61, DOI [10.4018/ijmstr.2013100106, DOI 10.4018/IJMSTR.2013100106]
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Dass Rajeshwar, 2018, Procedia Computer Science, V132, P1543, DOI 10.1016/j.procs.2018.05.118
   Dass R., 2012, INT J COMPUT SCI ISS, V9, P372
   DENG G, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1615, DOI 10.1109/NSSMIC.1993.373563
   Eland A., 2016, International Students and Scholar Services, University of Minnesota, P1, DOI DOI 10.1109/ICETETS.2016.7603066
   Elyasi I, 2016, OPTIK, V127, P11732, DOI 10.1016/j.ijleo.2016.09.054
   Eu J. K. T., 1973, Optics Communications, V9, P257, DOI 10.1016/0030-4018(73)90300-3
   Feng XF, 2017, APPL SCI-BASEL, V7, DOI [10.3390/app7010037, 10.3390/atmos7030037]
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gayathri M., 2010, INT J ENG TECHNOL, V2, P514, DOI DOI 10.7763/IJET.2010.V2.174
   Gesing A, 2012, THYROID RES, V5, DOI 10.1186/1756-6614-5-16
   Gireesha HM., 2014, INT J ENG RES TECHNO, V3, P2252
   Flores WG, 2014, ULTRASOUND MED BIOL, V40, P2609, DOI 10.1016/j.ultrasmedbio.2014.06.005
   He K, 2015, ARXIV15050099612
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hiremath PS., 2013, Advancements and Breakthroughs in Ultrasound Imaging, DOI DOI 10.5772/56519
   Jabarulla MY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8060903
   Kamalaveni V, 2015, PROCEDIA COMPUT SCI, V58, P673, DOI 10.1016/j.procs.2015.08.087
   Kaplan MM., 1999, CLIN CHEM, V45, P8
   Khan AH, 2018, IET IMAGE PROCESS, V12, P307, DOI 10.1049/iet-ipr.2017.0411
   Khusna DA, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P76, DOI 10.1109/ICITACEE.2015.7437774
   Khvostikov A, 2017, SIGNAL PROCESS-IMAGE, V59, P3, DOI 10.1016/j.image.2017.09.005
   Khvostikov A, 2015, INT CONF IMAG PROC, P440, DOI 10.1109/IPTA.2015.7367183
   Kollorz ENK, 2008, IEEE T MED IMAGING, V27, P457, DOI 10.1109/TMI.2007.907328
   Kongburan W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P150, DOI 10.1109/ICACI.2016.7449819
   Koprowski R, 2012, BIOMED ENG ONLINE, V11, DOI 10.1186/1475-925X-11-91
   Koundal D, 2018, BIOMED SIGNAL PROCES, V40, P117, DOI 10.1016/j.bspc.2017.08.025
   Koundal D, 2016, IET IMAGE PROCESS, V10, P167, DOI 10.1049/iet-ipr.2015.0231
   Kozegar E, 2017, ULTRASONICS, V79, P68, DOI 10.1016/j.ultras.2017.04.008
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P536, DOI 10.1016/j.bbe.2019.02.004
   Kriti, 2019, BIOCYBERN BIOMED ENG, V39, P100, DOI 10.1016/j.bbe.2018.10.002
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Kushwaha S., 2017, BIOMED PHARMACOL J, V10, P837, DOI DOI 10.13005/bpj/1175
   Lal M., 2016, INT J IMAGE GRAPH SI, V9, P60, DOI [10.5815/ijigsp.2016.09.08, DOI 10.5815/IJIGSP.2016.09.08]
   Latha S, 2019, CURR MED IMAGING REV, V15, P414, DOI 10.2174/1573405614666180402124438
   Lee JS, 2009, IEEE T GEOSCI REMOTE, V47, P202, DOI 10.1109/TGRS.2008.2002881
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   LEE JS, 1983, IEEE T SYST MAN CYB, V13, P85, DOI 10.1109/TSMC.1983.6313036
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liang SJ, 2017, BMC MED IMAGING, V17, DOI 10.1186/s12880-017-0231-7
   Loganayagi T., 2016, ASIAN J INF TECHNOL, V15, P5084, DOI [10.36478/ajit.2016.5084.5092, DOI 10.36478/AJIT.2016.5084.5092]
   Loizou CP, 2014, INT J BIOMED IMAGING, V2014, DOI 10.1155/2014/518414
   Loizou CP, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.018
   Loizou CP, 2012, IEEE INT C BIOINF BI, P721, DOI 10.1109/BIBE.2012.6399756
   Loizou CP, 2005, IEEE T ULTRASON FERR, V52, P1653, DOI 10.1109/TUFFC.2005.1561621
   MAILLOUX GE, 1984, ULTRASONIC IMAGING, V6, P262, DOI 10.1016/0161-7346(84)90012-9
   Michailovich OV, 2006, IEEE T ULTRASON FERR, V53, P64, DOI 10.1109/TUFFC.2006.1588392
   NAGAO M, 1979, COMPUT VISION GRAPH, V9, P394, DOI 10.1016/0146-664X(79)90102-3
   Nieniewski M, 2017, IMAGE ANAL STEREOL, V36, P79, DOI 10.5566/ias.1639
   Nikolaou N, 2009, INT J IMAG SYST TECH, V19, P14, DOI 10.1002/ima.20174
   Njeh I., 2011, 8 INT MULTICONFERENC, P1
   Nugroho A., 2016, COMMUN SCI TECHNOL, V1, P61, DOI [10.21924/cst.1.2.2016.25, DOI 10.21924/CST.1.2.2016.25]
   Nugroho HA, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P47, DOI 10.1109/IC3INA.2017.8251738
   Nugroho HA, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P41, DOI 10.1109/IC3INA.2017.8251737
   Nugroho HA, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P476, DOI 10.1109/ELECSYM.2016.7861053
   Nugroho HA, 2015, 2015 INTERNATIONAL CONFERENCE QUALITY IN RESEARCH (QIR), P43, DOI 10.1109/QiR.2015.7374892
   OJEDACASTANEDA J, 1986, APPL OPTICS, V25, P4035, DOI 10.1364/AO.25.004035
   Pedraza L, 2015, PROC SPIE, V9287, DOI 10.1117/12.2073532
   Prabusankarlal K. M., 2018, Applied Computing and Informatics, V14, P48, DOI 10.1016/j.aci.2017.01.002
   Prabusankarlal KM, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0029-y
   Qi XF, 2019, MED IMAGE ANAL, V52, P185, DOI 10.1016/j.media.2018.12.006
   Rafati M, 2015, IRAN RED CRESCENT ME, V17, DOI 10.5812/ircmj.25013
   RAJ KH, 2012, BULL ENVIRON PHARMAC, V1, P81
   Ramesh J., 2018, ICTACT Journal on Image and Video Processing, V8, P1776, DOI 10.21917/ijivp.2018.0249
   Sahu S., 2013, INT J EMERG TRENDS T, V2, P161
   Seabra J, 2012, ULTRASOUND IMAGING: ADVANCES AND APPLICATIONS, P73, DOI 10.1007/978-1-4614-1180-2_4
   Selvathi D., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P836, DOI 10.1109/ICSCCN.2011.6024666
   Singh BK, 2015, IETE TECH REV, V32, P384, DOI 10.1080/02564602.2015.1019943
   Snekhalatha U, 2018, ADV INTELL SYST, V563, P89, DOI 10.1007/978-981-10-6872-0_9
   Song GS, 2015, J ULTRAS MED, V34, P1753, DOI 10.7863/ultra.15.14.10045
   Srivastava A, 2000, IEEE T SIGNAL PROCES, P1
   Talukder MH, 2018, P INT MULT ENG COMP, P1
   Tasnim T, 2017, INT CONF ADV ELECTR, P229, DOI 10.1109/ICAEE.2017.8255358
   Toufique Y, 2014, MID EAST CONF BIO, P1, DOI 10.1109/MECBME.2014.6783193
   Tsantis S, 2007, COMPUT MED IMAG GRAP, V31, P117, DOI 10.1016/j.compmedimag.2006.11.006
   Ueng SK, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/758439
   Umamaheswari G, 2014, J SCI IND RES INDIA, V73, P100
   Vanithamani R, 2018, ADV INTELL SYST, V614, P509, DOI 10.1007/978-3-319-60618-7_50
   Viswanath K, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P407, DOI 10.1109/ICACCI.2014.6968485
   Wong A, 2012, DIGIT SIGNAL PROCESS, V22, P768, DOI 10.1016/j.dsp.2012.04.006
   Zhang J, 2015, CIRC SYST SIGNAL PR, V34, P185, DOI 10.1007/s00034-014-9829-y
   Zulfanahri Nugroho HA, 2017, 10 BIOM ENG INT C BM, P1, DOI [10.1109/BMEiCON.2017.8229106, DOI 10.1109/BMEICON.2017.8229106]
NR 97
TC 12
Z9 12
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8905
EP 8937
DI 10.1007/s11042-022-11965-6
EA FEB 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000753241100005
DA 2024-07-18
ER

PT J
AU Sohrabinejad, A
   Hafshajani, KF
   Sobhani, FM
AF Sohrabinejad, Azadeh
   Hafshajani, Kiamars Fathi
   Sobhani, Farzad Movahdi
TI Futures studies in Iran broadcasting, a system dynamic modeling approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media; Broadcasting; Modeling; System dynamics; Future; Futures studies;
   Scenario
ID BENEFIT
AB If anything, our modern life, especially since the turn of the twenty-first century, is characterized by new forms of entertainment. One such entertainment is the radio and TV, which not only provides viewers with the latest news but also entertains them with all kinds of programs and shows. It is not for nothing that broadcasting is considered an essential aspect of any society. On the other hand, the advent of the internet and subsequently social media platforms has caused broadcasters to lose their monopoly and have to jockey for a place in people's leisure time. The situation has been exacerbated by the evolution of broadcasting from relatively simple systems to incredibly complex, interdependent, and policy-heavy structures that must explore and discern the future to remain competitive. Against this backdrop, futures studies which is the scientific, systematic, and formal investigation of likely, desirable, and possible future developments, - can help cushion the blow against stronger competitors. The main tools of futures studies are modeling and simulation. Therefore, this study aims to anticipate the possible alternative scenarios to describe plans for the future of the Islamic Republic of Iran Broadcasting (IRIB) by using system dynamics modeling to identify and develop alternative futures.
C1 [Sohrabinejad, Azadeh; Sobhani, Farzad Movahdi] Islamic Azad Univ, Tehran Sci & Res Branch, Sci & Res Branch, Daneshgah Blvd,Simon Bulivar Blvd, Tehran, Iran.
   [Hafshajani, Kiamars Fathi] 223 Headquarter Islamic Azad Univ, Islamic Azadeh Univ South Tehran Branch, South Tehran Branch, ZIP Area 11 Azarshahr St,North Iranshahr St, Tehran, Iran.
C3 Islamic Azad University
RP Sohrabinejad, A (corresponding author), Islamic Azad Univ, Tehran Sci & Res Branch, Sci & Res Branch, Daneshgah Blvd,Simon Bulivar Blvd, Tehran, Iran.
EM azadeh.sohrabinejad@gmail.com; Fathi@azad.ac.ir; f-movahedi@srbiau.ac.ir
RI sohrabinejad, azadeh/AEF-7105-2022
OI sohrabinejad, azadeh/0000-0002-7064-3461
CR Ahmad S, 2016, RENEW SUST ENERG REV, V56, P29, DOI 10.1016/j.rser.2015.11.034
   Akbarzade Jahromi, 2017, NEW MEDIA STUDIES, P41
   Alavivafa S, 2017, COMMUN RES, P31
   Alstyne, 2011, 2020 MEDIA FUTURES
   Aparicio S, 2016, FUTURES, V81, P130, DOI 10.1016/j.futures.2016.02.004
   Brose A., 2013, SYSTEM DYNAMIC ENHAN
   Brown D., 2015, FUTURE FILM TELEVISI
   Chen H, 2016, MECH IND ENG GENERAT
   Daymon C, 2003, MED TRANS 3 C MIT BO
   Eghbal Doust M., 2014, 2014 TEHR C FUT STUD
   Forrest, 1998, INT C SYST DYN SOC
   Forrester J., 1991, SYSTEM DYNAMICS LESS
   Groff JS, 2013, J NEW APPROACHES EDU, V2, P72, DOI 10.7821/naer.2.2.72-81
   Hirsch GB, 2007, AM J COMMUN PSYCHOL, V39, P239, DOI 10.1007/s10464-007-9114-3
   Horton, 2005, VISION 20 20 FUTURE
   Khojasteh M, 2017, SYSTEM DYNAMIC MODEL
   Kim N, 2019, KSII T INTERNET INF, V13, P2544, DOI 10.3837/tiis.2019.05.017
   Markakis E, 2011, GLOBAL TELECOMMUNICA
   Markakis E, 2018, INT C TEL MULT TEMU2, P16
   Markakis E, 2012, INT C COMP NETW COMM
   Moezzi-Madani N, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1814
   Olson, 2003, ENCY INFORM SYSTEMS
   Pepic-Bach M, 2007, J INF ORGAN SCI, V31, P171
   Randall R, 1997, LEARNING FUTURE COMP
   Rasooli M., 2002, MEDIA Q, V52, P114
   Richardson GP, 2008, J BUS RES, V61, P1099, DOI 10.1016/j.jbusres.2007.11.003
   Richmond B., 2001, An introduction to systems thinking
   Sadeghi F., 2013, FAILURE MONOPOLY
   Sahay, 2015, STRATEGIC APPROACH T
   Schmitt Olabisi Laura K., 2010, Sustainability, V2, P2686, DOI 10.3390/su2082686
   Shahabi M, 2008, IRANIAN J CULTURAL R, P23
   Sharifi S, 2019, CORPORATE MEDIA ENTR, P101
   Shi L, 2014, IEEE T BROADCAST, V60, P73, DOI 10.1109/TBC.2013.2295255
   Swanson J, 2002, J OPER RES SOC, V53, P472, DOI 10.1057/palgrave.jors.2601336
   Talebian, 2017, FUTURE BROADCASTING
   Wang X, 2010, EVALUATION RES COORD
   Yuan HP, 2011, RESOUR CONSERV RECY, V55, P604, DOI 10.1016/j.resconrec.2010.06.004
   Zhang Z, 2014, ECOL MODEL, V275, P9, DOI 10.1016/j.ecolmodel.2013.11.031
NR 38
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1
EP 29
DI 10.1007/s11042-022-12047-3
EA FEB 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000749966800016
DA 2024-07-18
ER

PT J
AU Mishra, P
   Kumar, S
   Chaube, MK
AF Mishra, Prerna
   Kumar, Santosh
   Chaube, Mithilesh Kumar
TI Graph Interpretation, Summarization and Visualization Techniques: A
   Review and Open Research Issues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Graph interpretation; Graph-Based learning methods; Graph mining; Graph
   summarization; Graph visualization
ID INFORMATION VISUALIZATION; NETWORK; EXPLORATION; EXTRACTION;
   CONSTRUCTION; RECOGNITION; FRAMEWORK; SYSTEM; IMAGES; CHARTS
AB Graphs has been a ubiquitous way of representing heterogeneous data. There are many studies focused on graph learning highlighting the approaches for graph data extraction, interpretation and graph summarization. Graph data summarization is achieving more expansion due to the broader length of sizeable applications and interpretation of proper understanding about the hidden details of the data using deep learning-based graph representation. Graph interpretation and summarization have come up as an interdisciplinary room that has vividly broader influence over multiple parallel areas and real-world applications. In other words, extraction of relevant data from massive and complex graph structure, enables the data to be used by many application area. However, it is found that recognizing the discriminatory and hidden properties from massive heterogeneous data is not easy in case of both nodal graph and graph image (also known as chart image). Hence, deep learning based approaches eventuated as a satisfactory solution. This paper presents an outline of the quantitative and statistical approaches used for learning and understanding different integrant of nodal graph and information graph, such as data extraction and processing, interpretation, summarization and visualization, by using graph-based learning methods. These integrant are broadly considered under (or as) SIV Model in this paper. Paper also discusses the influence of summarization techniques on the visualization of large data graphs and upcoming research areas of summarization. Lastly, paper provides with brief overview of challenges, application area, benefits of graph interpretation, summarization, and visualization, while providing existing tools and datasets available for graph processing and learning.
C1 [Mishra, Prerna; Kumar, Santosh] DSPM IIITNR, Dept CSE, Raipur, Madhya Pradesh, India.
   [Chaube, Mithilesh Kumar] DSPM IIITNR, Dept Math, Raipur, Madhya Pradesh, India.
RP Mishra, P (corresponding author), DSPM IIITNR, Dept CSE, Raipur, Madhya Pradesh, India.
EM prerna@iiitnr.edu.in; santosh@iiitnr.edu.in; mithilesh@iiitnr.edu.in
RI mishra, prerna/GPW-6915-2022; Chaube, Mithilesh/AAV-7844-2020
OI Chaube, Mithilesh/0000-0001-7086-1277; mishra,
   prerna/0000-0003-2895-6146; Kumar, Dr. Santosh/0000-0003-2264-9014
CR Agarwal M, 2021, INT C PATT RECOG, P9491, DOI 10.1109/ICPR48806.2021.9411922
   Ahn K.J., 2012, P 31 ACM SIGMOD SIGA, P5
   Akiba H, 2010, IEEE COMPUT GRAPH, V30, P61, DOI 10.1109/MCG.2009.107
   Akoglu L, 2015, DATA MIN KNOWL DISC, V29, P626, DOI 10.1007/s10618-014-0365-y
   Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Al-Zaidy Rabah A, 2016, WORKSH 30 AAAI C ART
   Amara JH, 2017, COMPUT SCI RES NOTES, V2701, P83
   Anderson, 1988, Neural Information Processing Systems, P31
   [Anonymous], Int. Conf. Natural Lang. Gener, DOI [DOI 10.3115/V1/W14-4413, 10.3115/v1/W14-4413]
   [Anonymous], 2011, P 24 ANN ACM S US IN
   [Anonymous], 2008, P 2008 ACM SIGMOD IN, DOI DOI 10.1145/1376616.1376661
   [Anonymous], 2012, P 2012 ACM SIGMOD IN
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Arleo A, 2017, INFORM SCIENCES, V381, P124, DOI 10.1016/j.ins.2016.11.012
   Atkinson A., 2017, Figureqa: An annotated figure dataset for visual reasoning
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Balaji Abhijit, 2018, ARXIV181210636
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   Battaglia, 2018, ARXIV180601261
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Bhagat S, 2011, SOCIAL NETWORK DATA ANALYTICS, P115
   Bharadwaj A, 2017, BIOINFORMATICS, V33, P3134, DOI 10.1093/bioinformatics/btx382
   Bhatia S, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2094072.2094075
   Bojchevski A, 2018, GRAPHGAN GENERATING
   Bojchevski A, ARXIV PREPRINT ARXIV, P2
   Bresson, EXPT STUDY NEURAL NE
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Browuer William, 2008, Joint Conference on Digital Libraries (JCDL 2008), P276, DOI 10.1145/1378889.1378936
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Burns R, 2013, UMAP WORKSH
   Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227
   Burns R, 2016, LECT NOTES COMPUT SC, V9781, P265, DOI 10.1007/978-3-319-42333-3_22
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Cai HY, 2018, IEEE T KNOWL DATA EN, V30, P1616, DOI 10.1109/TKDE.2018.2807452
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Carberry S., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P581, DOI 10.1145/1148170.1148270
   Cavallari S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P377, DOI 10.1145/3132847.3132925
   Cebiric S, 2019, VLDB J, V28, P295, DOI 10.1007/s00778-018-0528-3
   Chakrabarti D, 2006, ACM COMPUT SURV, V38, pA1, DOI 10.1145/1132952.1132954
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen C, 2020, IEEE WINT CONF APPL, P1526, DOI 10.1109/WACV45572.2020.9093592
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chester D, 2005, LECT NOTES COMPUT SC, V3488, P660
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Choudhury SR, 2016, ACM-IEEE J CONF DIG, P277, DOI 10.1145/2910896.2925469
   Choudhury SR, 2016, P INT WORKSH SEM BIG, P1, DOI DOI 10.1145/2928294.2928305
   Cliche M, 2017, LECT NOTES ARTIF INT, V10534, P135, DOI 10.1007/978-3-319-71249-9_9
   Constantin MG, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301299
   Cspedes-Hernandez D, 2017, RES COMPUT SCI, V145
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005
   Davila Kenny, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1594, DOI 10.1109/ICDAR.2019.00203
   De P, 2018, IEEE INT ADV COMPUT, P20, DOI 10.1109/IADCC.2018.8692104
   Demir Seniz, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P501, DOI 10.1007/978-3-642-37247-6_40
   Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091
   Demir S, 2010, NEW REV HYPERMEDIA M, V16, P245, DOI 10.1080/13614568.2010.534186
   Demir Seniz, 2008, Proceedings of the Fifth International Natural Language Generation Conference, INLG '08
   Demir Seniz., 2007, P RECENT ADV NATURAL, P150
   Di Sorbo A, 2017, PROC IEEE ACM INT C, P55, DOI 10.1109/ICSE-C.2017.5
   Ding WC, 2017, IEEE T SIGNAL INF PR, V3, P539, DOI 10.1109/TSIPN.2017.2731163
   Dong XW, 2019, IEEE SIGNAL PROC MAG, V36, P44, DOI 10.1109/MSP.2018.2887284
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Ebiri Goasdou F, 2018, COMPACT SUMMARIES RI
   Ehrig H, 1999, ACM COMPUT SURV, V31, pG1
   Elzer S, 2006, LECT NOTES COMPUT SC, V4045, P25
   Elzer S, 2011, ARTIF INTELL, V175, P526, DOI 10.1016/j.artint.2010.10.003
   Faerman E, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P246, DOI 10.1109/WI.2018.00-83
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gambhir M, 2017, ARTIF INTELL REV, V47, P1, DOI 10.1007/s10462-016-9475-9
   Gao JL, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P265
   Gao LC, 2017, PROC INT CONF DOC, P1417, DOI 10.1109/ICDAR.2017.231
   Gilani A, 2017, PROC INT CONF DOC, P771, DOI 10.1109/ICDAR.2017.131
   Göbel M, 2013, PROC INT CONF DOC, P1449, DOI 10.1109/ICDAR.2013.292
   Gonçalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Goonetilleke O, 2017, SSDBM 2017: 29TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, DOI 10.1145/3085504.3085516
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Greenbacker C, P WORKSH AUT SUMM DI, P41
   Hadlak S, 2011, IEEE T VIS COMPUT GR, V17, P2334, DOI 10.1109/TVCG.2011.213
   Hamilton WL, 2017, ADV NEUR IN, V30
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, P 27 ANN ACM S USER, V14, P253, DOI [10.1145/2642918.2647411, DOI 10.1145/2642918.26474112, DOI 10.1145/2642918.2647411]
   Henaff M., 2015, ARXIV150605163
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu YF, 2015, WIRES COMPUT STAT, V7, P115, DOI 10.1002/wics.1343
   Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9
   Jankun-Kelly TJ, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P323, DOI 10.1109/VISUAL.2002.1183791
   Jankun-Kelly TJ, 2001, IEEE T VIS COMPUT GR, V7, P275, DOI 10.1109/2945.942695
   Jiang WJ, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906151
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kafle K, 2020, IEEE WINT CONF APPL, P1487, DOI 10.1109/WACV45572.2020.9093494
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kallimani JS, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P382, DOI 10.1109/ICACCI.2013.6637202
   Kanapala A, 2019, ARTIF INTELL REV, V51, P371, DOI 10.1007/s10462-017-9566-2
   Karthikeyani V., 2012, INT J COMPUT APPL, V39, P1, DOI DOI 10.5120/4789-6997
   Khan A, 2017, PROC VLDB ENDOW, V10, P1981, DOI 10.14778/3137765.3137825
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kipf T. N., 2016, ARXIV161107308, V1050, P21
   Kipf TN, 2016, ARXIV
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Koutra D, 2015, STAT ANAL DATA MIN, V8, P183, DOI 10.1002/sam.11267
   Koutra Danai, 2014, P SIAM INT C DAT MIN, P91, DOI DOI 10.1137/1.9781611973440.11
   Kwan-Liu Ma, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P81, DOI 10.1109/VISUAL.1999.809871
   Latouche P., 2015, P EUR S ART NEUR NET, P207
   Lee A, 2020, ARXIV PREPRINT ARXIV
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038
   LeFevre Kristen, 2010, P 2010 SIAM INT C DA, P454, DOI DOI 10.1137/1.9781611972801.40
   Leppanen L., 2017, P 10 INT C NAT LANG, P188
   Li CZ, 2017, LECT NOTES COMPUT SC, V10177, P163, DOI 10.1007/978-3-319-55753-3_11
   Li M, 2022, ARCH PHYSIOL BIOCHEM, V128, P1259, DOI 10.1080/13813455.2020.1764051
   Li Y., 2016, P 4 INT C LEARNING R
   Li Z, 2015, DATA KNOWL ENG, V100, P191, DOI 10.1016/j.datak.2015.05.005
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Liu X, 2019, ARXIV190611906
   Liu X, P 23 ACM INT C C INF, P799
   Liu Y, 2013, PROC SPIE, V8654, DOI 10.1117/12.2008467
   Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727
   Livadas PE, 2000, INFORM SCIENCES, V125, P99, DOI 10.1016/S0020-0255(99)00030-4
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Mahmood A, 2014, INT C INTEL HUM MACH, P376, DOI 10.1109/IHMSC.2014.192
   Mao Q, 2017, IEEE T PATTERN ANAL, V39, P2227, DOI 10.1109/TPAMI.2016.2635657
   Marcheggiani Diego, 2017, EMNLP, DOI DOI 10.18653/V1/D17-1159
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Methani N, 2020, IEEE WINT CONF APPL, P1516, DOI 10.1109/WACV45572.2020.9093523
   Mishchenko A., 2011, 2011 Sixth International Conference on Digital Information Management, P115, DOI 10.1109/ICDIM.2011.6093320
   Mishra P, 2020 JOINT 9 INT C I, V26, P1
   Molla MKI, 2003, LECT NOTES COMPUT SC, V2690, P865
   Monti F, 2017, ADV NEUR IN, V30
   Nair RR, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P108, DOI 10.1109/DAS.2016.73
   Nair RR, 2015, PROC INT CONF DOC, P796, DOI 10.1109/ICDAR.2015.7333871
   Nie F, 31 AAAI C ART INT, P13
   Niepert M, 2016, PR MACH LEARN RES, V48
   Pan SR, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2609
   Pan SR, 2017, IEEE T CYBERNETICS, V47, P744, DOI 10.1109/TCYB.2016.2526058
   Pan SR, 2016, IEEE T KNOWL DATA EN, V28, P715, DOI 10.1109/TKDE.2015.2492567
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Tran PV, 2018, PR INT CONF DATA SC, P237, DOI 10.1109/DSAA.2018.00034
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Praczyk PA, 2013, INFORM TECHNOL LIBR, V32, P25, DOI 10.6017/ital.v32i4.3670
   Purchase HC, 2014, J VISUAL LANG COMPUT, V25, P57, DOI 10.1016/j.jvlc.2013.11.004
   Reddy VK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P190, DOI 10.1109/CGVIS.2015.7449920
   Riondato M, 2014, IEEE DATA MINING, P947, DOI 10.1109/ICDM.2014.56
   Rodrigues JF, 2006, IEEE INT SYM MULTIM, P227
   Rossi R. A., 2017, ARXIV170408829
   Rudinac S, 2018, LECT NOTES COMPUT SC, V10704, P632, DOI 10.1007/978-3-319-73603-7_51
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saha Ranajit, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P51, DOI 10.1109/ICDAR.2019.00018
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schreiber S, 2017, PROC INT CONF DOC, P1162, DOI 10.1109/ICDAR.2017.192
   Schulz HJ, 2006, INFORMATION VISUALIZATION-BOOK, P166
   Seo Y, 2018, LECT NOTES COMPUT SC, V11301, P362, DOI 10.1007/978-3-030-04167-0_33
   Shen XB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3549
   Shi L, 2015, IEEE T KNOWL DATA EN, V27, P3417, DOI 10.1109/TKDE.2015.2453957
   Shin K, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1679, DOI 10.1145/3308558.3313402
   Siddiqui SA, 2018, IEEE ACCESS, V6, P74151, DOI 10.1109/ACCESS.2018.2880211
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonovsky M, 2018, LECT NOTES COMPUT SC, V11139, P412, DOI 10.1007/978-3-030-01418-6_41
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sukhbaatar S, 2016, NeurIPS, P2244
   Svendsen, THESIS
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tarawaneh R.M., 2012, VISUALIZATION LARGE
   Tixier A. J.-P., 2017, ARXIV PREPRINT ARXIV
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   Vanetik N, 2020, INFORM SCIENCES, V509, P22, DOI 10.1016/j.ins.2019.08.079
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201
   Vo ND, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INFORMATION MANAGEMENT AND COMMUNICATION (IMCOM 2018), DOI 10.1145/3164541.3164644
   Wan XL, 2019, INFORM SCIENCES, V505, P306, DOI 10.1016/j.ins.2019.07.087
   Wang C, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P889, DOI 10.1145/3132847.3132967
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   WANG Hua-Qin, THESIS
   Wang HQ, 2018, 2018 14TH IEEE/ASME INTERNATIONAL CONFERENCE ON MECHATRONIC AND EMBEDDED SYSTEMS AND APPLICATIONS (MESA), DOI 10.1145/3204493.3204584
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wohlfart, P JOINT EUR IEEE VGT, P91
   Woodring J, 2006, IEEE T VIS COMPUT GR, V12, P909, DOI 10.1109/TVCG.2006.164
   Woodsend K, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P565
   Wu F, 2019, PR MACH LEARN RES, V97
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie Y, 2019, INFORM SCIENCES, V504, P20, DOI 10.1016/j.ins.2019.07.035
   Xu BW, 2017, IEEE INT CONF AUTOM, P706, DOI 10.1109/ASE.2017.8115681
   Xu H, ARXIV PREPRINT ARXIV, P17
   Xu Zhong, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1015, DOI 10.1109/ICDAR.2019.00166
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang H, 2018, IEEE DATA MINING, P1476, DOI [10.1109/ICDM.2018.00207, 10.1109/ICDM.2018.8626170]
   Ye Wu, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P503, DOI 10.1109/InfoSEEE.2014.6948163
   Ying R, 2018, ADV NEUR IN, V31
   Younas J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186460
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438
   Zhang N, 2010, PROC INT CONF DATA, P880, DOI 10.1109/ICDE.2010.5447830
   Zhang Zechen., 2018, ACM Trans. Graph, P11
   Zheng WG, 2014, INFORM SCIENCES, V261, P116, DOI 10.1016/j.ins.2013.10.003
   Zhou F, 2017, J EXP THEOR ARTIF IN, V29, P1023, DOI 10.1080/0952813X.2017.1280089
   Zhou FF, 2021, J VISUAL-JAPAN, V24, P419, DOI 10.1007/s12650-020-00702-6
   Zhou YP., 2001, 4th IAPR International Workshop on Graphics Recognition, GREC, P482
   Zuo Y, 2018, INT J COMPUT INTEG M, V31, P337, DOI 10.1080/0951192X.2017.1285429
NR 209
TC 1
Z9 1
U1 8
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8729
EP 8771
DI 10.1007/s11042-021-11582-9
EA JAN 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000740429700015
DA 2024-07-18
ER

PT J
AU Roy, A
   Bandopadhaya, S
   Chandra, S
   Suhag, A
AF Roy, Amarjit
   Bandopadhaya, Shuvabrata
   Chandra, Snehal
   Suhag, Ashok
TI Removal of impulse noise for multimedia-IoT applications at gateway
   level
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia IoT; Impulse noise; Hybrid detection; Fuzzy filter; PSNR;
   Computational complexity
ID FUZZY FILTER; DETECTOR
AB In last decade, most of the multimedia IoT (M-IoT) applications are gaining popularity where the real-time still and streaming images are captured, and corresponding data is transported to cloud servers via communication networks. In such applications, the image sources are low-cost sensors that introduce impulse noises in the images making it unreliable for any computer vision algorithms running on the cloud. Though many powerful impulse noise removal techniques present in literature, their computational complexities are much higher to carry out the data cleaning operation at the constrained IoT gateways. This paper has proposed an impulse removal technique with lower computational complexity than other well-established techniques best suited to be implemented at IoT gateway level. In this paper, a hybrid detection algorithm is proposed to detect the pixels corrupted by impulse noise followed by a fuzzy filter to restore the detected pixels. It has been observed that HDFF provides an improvement of 3% in comparison to state-of-the-art-filters in terms PSNR. The simulation results also suggest the noise-filtration performance of the proposed technique matches to that of some well-established techniques with lesser computational complexity making it suitable for gateway level implementation in M-IoT applications.
C1 [Roy, Amarjit] Ghani Khan Choudhury Inst Engn & Technol, Malda 732141, W Bengal, India.
   [Bandopadhaya, Shuvabrata] Banasthali Vidhyapith, Tonk 304022, Rajasthan, India.
   [Chandra, Snehal] IIM Ranchi, Ranchi 834008, Jharkhand, India.
   [Suhag, Ashok] BML Munjal Univ, Gurgaon 122413, Haryana, India.
C3 Banasthali Vidyapith; Indian Institute of Management (IIM System);
   Indian Institute of Management Ranchi; BML Munjal University
RP Roy, A (corresponding author), Ghani Khan Choudhury Inst Engn & Technol, Malda 732141, W Bengal, India.
EM royamarjit90@gmail.com; shuva_bandopadhaya@rediffmail.com;
   snehalchandra31@gmail.com; ashoksihag@gmail.com
RI Roy, Amarjit/ABD-1033-2020
OI Chandra, Snehal/0000-0003-2617-2057
CR Abdiansah A., 2015, INT J COMPUT APPL, V128, P28
   Cao Y, 2016, IEEE INTERNET THINGS, V3, P1246, DOI 10.1109/JIOT.2016.2582540
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jung-Hua Wang, 1999, Proceedings of the National Science Council, Republic of China, Part A (Physical Science and Engineering), V23, P630
   Kaliraj G, 2010, IMAGE VISION COMPUT, V28, P458, DOI 10.1016/j.imavis.2009.07.007
   KO S, 1999, IEEE T CIRCUITS SYST, V38
   Leal B, 2010, INTERNET OF THINGS-BOOK, P3, DOI 10.1007/978-1-4419-1674-7_1
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Masood S, 2014, APPL SOFT COMPUT, V21, P107, DOI 10.1016/j.asoc.2014.03.006
   Nauman A, 2020, IEEE ACCESS, V8, P8202, DOI 10.1109/ACCESS.2020.2964280
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Roy A, 2020, MULTIMED TOOLS APPL, V79, P34851, DOI 10.1007/s11042-020-09107-x
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Schulte S, 2007, IMAGE VISION COMPUT, V25, P1377, DOI 10.1016/j.imavis.2006.10.002
   Singh KM, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P396
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 23
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34463
EP 34480
DI 10.1007/s11042-021-11832-w
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000740419000006
DA 2024-07-18
ER

PT J
AU Zhao, YK
   Fu, FW
AF Zhao, Yongkang
   Fu, Fang-Wei
TI A cheating immune (<i>k</i>, <i>n</i>) visual cryptography scheme by
   using the rotation of shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cheating immune; Visual cryptography scheme; Random grid; Threshold;
   Rotation; Secret sharing
ID PREVENTION; ENCRYPTION
AB Since Noar and Shamir introduced visual cryptography scheme (VCS), the cheating problem of VCS has absorbed much attention of scholars. The current researches on cheating immune have one or more of these serious disadvantages: (1) each share has extra pixel expansion, (2) some methods need extra verification shares to determine the share is genuine or not, (3) some schemes require a higher encryption/decryption overhead, and (4) the authentication procedure needs a trusted third party. In order to establish a novel cheating immune visual cryptography scheme (CIVCS) without pixel expansion, this paper generates n original shares by using random grid based visual cryptography scheme (RG-based VCS) and stamps authentication patterns on original shares to obtain verifiable shares, where the authentication patterns are three adjacent and non-intersect concentric solid black rings. In authentication phase, the authentication patterns can be revealed respectively by stacking any two verifiable shares in several ways, including rotating one of the two shares by 90 degrees, 180 degrees, and 270 degrees counterclockwise. The main contribution of this paper is that we propose a novel CIVCS without the above deficiencies. Furthermore, experimental results and theoretical proofs are provided for illustrating the effectiveness of the proposed CIVCS.
C1 [Zhao, Yongkang; Fu, Fang-Wei] Nankai Univ, Chern Inst Math, Tianjin 300071, Peoples R China.
   [Zhao, Yongkang; Fu, Fang-Wei] Nankai Univ, LPMC, Tianjin 300071, Peoples R China.
C3 Nankai University; Nankai University
RP Zhao, YK (corresponding author), Nankai Univ, Chern Inst Math, Tianjin 300071, Peoples R China.; Zhao, YK (corresponding author), Nankai Univ, LPMC, Tianjin 300071, Peoples R China.
EM zhaoyk@mail.nankai.edu.cn; fwfu@nankai.edu.cn
RI Fu, Fang-Wei/L-8164-2015
FU National Key Research and Development Program of China [2018YFA0704703];
   National Natural Science Foundation of China [61971243]; Natural Science
   Foundation of Tianjin [20JCZDJC00610]; Fundamental Research Funds for
   the Central Universities of China (Nankai University); Candidate
   Research Innovation Fund of Nankai University
FX This research is supported by the National Key Research and Development
   Program of China (Grant No. 2018YFA0704703), the National Natural
   Science Foundation of China (Grant No. 61971243), the Natural Science
   Foundation of Tianjin (20JCZDJC00610), the Fundamental Research Funds
   for the Central Universities of China (Nankai University), and by the
   Ph.D. Candidate Research Innovation Fund of Nankai University.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   De Prisco R, 2006, LECT NOTES COMPUT SC, V4116, P216
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Hu H, 2018, KSII T INTERNET INF, V12, P3401, DOI 10.3837/tiis.2018.07.022
   Hwa-Ching Hsu, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P996
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lin PY, 2015, INFORM SCIENCES, V301, P61, DOI 10.1016/j.ins.2014.12.046
   Liu ZQ, 2021, SIGNAL PROCESS-IMAGE, V92, DOI 10.1016/j.image.2020.116129
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Wu CC, 1998, THESIS NATL CHIAO TU
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V75, P100, DOI 10.1016/j.image.2019.03.017
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yadav Mainejar, 2020, Ingenierie des systemes d'information, P453
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P13, DOI 10.1007/s11554-016-0639-2
   Yang C.-N., 1999, NATL COMPUTER S, V3, P260
   Yang CN, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102660
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 26
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6235
EP 6257
DI 10.1007/s11042-021-11692-4
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740429700037
DA 2024-07-18
ER

PT J
AU Singh, RK
   Tiwari, A
   Gupta, RK
AF Singh, Rajeev Kumar
   Tiwari, Akhilesh
   Gupta, Rajendra Kumar
TI Deep transfer modeling for classification of Maize Plant Leaf Disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Feature extraction; Convolution layer; Max pooling; Maize
   Plant Disease identification
ID ARTIFICIAL-INTELLIGENCE; IDENTIFICATION; VISION
AB Currently, Deep Learning is playing an influential role for Image analysis and object classification. Maize's diseases reduce production that subsequently becomes prominent factor for the economic losses in the agricultural industry worldwide. Previously, researchers have used hand-crafted-features for image classification and detection of leaf diseases in Maize plant. Nowadays, the development of the Deep Learning has allowed researchers to drastically improve the accuracy of object identification and classification. Therefore, this paper explores AlexNet model for fast and accurate detection of leaf disease in maize plant. For validating the result, we have used PlantVillage dataset. This dataset contains two categories of maize diseases namely leaf-spot based diseases (Cercospora and Gray) and the Common rust based diseases. The former category contains 1363 images and the latter category contains 929 images. One of the biggest advantages of CNN is to automatically extract the features by processing the raw images directly. By using various iteration such as 25, 50, 75 and 100, our model has obtained an accuracy of 99.16%. In future, the proposed work can be used as a practical tool to help farmer in detecting the aforementioned diseases and protect the maize crops.
C1 [Singh, Rajeev Kumar; Tiwari, Akhilesh] Madhav Inst Sci & Technol, Dept IT, Gwalior, India.
   [Gupta, Rajendra Kumar] Madhav Inst Sci & Technol, Dept CSE, Gwalior, India.
C3 Madhav Institute of Technology & Science; Madhav Institute of Technology
   & Science
RP Singh, RK (corresponding author), Madhav Inst Sci & Technol, Dept IT, Gwalior, India.
EM rajeev.mits1@gmail.com; atiwari@gmail.com; rkg@mitsgwalor.in
RI Singh, Rajeev Kumar/HKN-4005-2023; Gupta, Rajendra Kumar/GSD-3789-2022;
   Tiwari, Akhilesh/AAE-5437-2021
OI Singh, Rajeev Kumar/0000-0003-1009-3637; 
CR Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   An Y, 2021, AUTOMAT CONSTR, V131, DOI 10.1016/j.autcon.2021.103883
   [Anonymous], 2020, SCI REP-UK, DOI DOI 10.1038/S41598-019-53999-1
   Arivazhagan S., 2018, INT J PURE APPL MATH, V120, P11067
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Boonsirisumpun N, 2018, 2018 22 INT COMP SCI, P1, DOI DOI 10.1109/ICSEC.2018.8712778
   Chauhan P, 2021, AGR INFORMATICS AUTO, P131
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Darbari A, 2021, CARDIOTHORAC SURG, V29, DOI 10.1186/s43057-021-00053-4
   Gonzalez Teofilo F, 2007, Handbook of approximation algorithms and metaheuristics
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Guyer D, 2000, COMPUT ELECTRON AGR, V29, P179, DOI 10.1016/S0168-1699(00)00146-0
   Hughes D., 2015, ABS151108060 CORR
   Kaushal M, 2018, APPL SOFT COMPUT, V70, P423, DOI 10.1016/j.asoc.2018.05.023
   Kazerouni MF, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0785-9
   Kermany Daniel, 2018, Mendeley Data, V3
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Marsola TC, 2019, METEOR DETECTION USI, V8, P380, DOI [10.17648/sbai-2019-112456, DOI 10.17648/SBAI-2019-112456]
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nazki H, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105117
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Prasad S, 2016, SIGNAL IMAGE VIDEO P, V10, P379, DOI 10.1007/s11760-015-0751-y
   Sachar S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114181
   Shams SR, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-81455-6
   Shrivastava S, 2015, MULTIMED TOOLS APPL, V74, P11467, DOI 10.1007/s11042-014-2239-0
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
NR 29
TC 23
Z9 23
U1 6
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6051
EP 6067
DI 10.1007/s11042-021-11763-6
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739252400001
DA 2024-07-18
ER

PT J
AU Shah, TR
   ul Haq, T
AF Shah, Tariq
   ul Haq, Tanveer
TI Design of 24-by-24-replacement-matrix: a functionality to astronomical
   visual
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commutative chain ring; 24-by-24-replacement-matrix; Color astronomical
   image encryption; Analysis
ID BCH CODES; IMAGE; CONSTRUCTION; BOX
AB Typically, an 8 x 8 substitution box (S-box) is a square matrix of order 16 designed over Galois field GF(2(8)) having binary field F-2 algebra. A 24 by 24 S-box over GF(2(24)) is not effective as it covers a large computer memory. The finite commutative chain ring is primarily an algebra over F-2. In this work, we take the benefit and establish a new scheme of 24-by-24-replacement-matrix (Customarily known as an S-box (the only non-linear component of block ciphers)) design over commutative chain ring of the form F-2[u]/<u(24)>. The designed S-box shows high confusion ability than any customarily S-boxes. To gauge this effect, various digital astronomical RGB images are encrypted and compared with some existing S-box based encrypted images. In the planed ciphering scheme, firstly, we extract different layers of a color astronomical image and then concatenate the layers to form a 256 x 256 matrix having each entry of 24-bits. Thus, a novel method of RGB image ciphering scheme is functionalized that use 24 binary bits instead of 8 bits. Diffusion is attained by applying the linear permutation P = (i x 32) mod 257 and finally, an operation of bitwise Exclusive-or is performed. Results of analysis guarantees that the suggested encryption scheme approach to the peak values and may replace many S-box based image encryption techniques.
C1 [Shah, Tariq; ul Haq, Tanveer] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Shah, TR (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM stariqshah@gmail.com; tanveer_ulhaqqau@hotmail.com
OI Haq, Tanveer ul/0000-0003-0417-019X
CR Attaullah, 2020, WIRELESS PERS COMMUN, V110, P1429, DOI 10.1007/s11277-019-06793-1
   de Andrade AA, 1999, LINEAR ALGEBRA APPL, V286, P69, DOI 10.1016/S0024-3795(98)10163-5
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Mishra DC, 2016, INF SECUR J, V25, P213, DOI 10.1080/19393555.2016.1241323
   Omoruyi O., 2019, TELKOMNIKA (Telecommunication Computing Electronics and Control), V17, P2968, DOI [10.12928/telkomnika.v17i6.10488, DOI 10.12928/TELKOMNIKA.V17I6.10488]
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   Shah DW, 2020, MULTIMEDIA SYST, V26, P235, DOI 10.1007/s00530-019-00640-w
   Shah T, 2020, WIRELESS PERS COMMUN, V113, P1201, DOI 10.1007/s11277-020-07274-6
   Shah T, 2020, IEEE ACCESS, V8, P52609, DOI 10.1109/ACCESS.2020.2978083
   Shah T, 2017, COMPUT APPL MATH, V36, P1273, DOI 10.1007/s40314-015-0281-9
   Shah T, 2017, COMPUT APPL MATH, V36, P843, DOI 10.1007/s40314-015-0265-9
   Shah T, 2012, MATH SCI, V6, DOI 10.1186/2251-7456-6-51
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   SHANKAR P, 1979, IEEE T INFORM THEORY, V25, P480, DOI 10.1109/TIT.1979.1056063
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   ul Haq T, 2020, OPTIK, V217, DOI 10.1016/j.ijleo.2020.164922
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yadav AK, 2008, IC3 INTC CONT COMP, P115
NR 24
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5929
EP 5955
DI 10.1007/s11042-021-11682-6
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000737741900015
DA 2024-07-18
ER

PT J
AU Ren, YJ
   Tang, LM
   Zhang, HL
   Zheng, J
AF Ren, Yanjun
   Tang, Liming
   Zhang, Honglu
   Zheng, Jie
TI A variational level set model combining with local Gaussian fitting and
   Markov random field regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational level set; Markov random field; Image segmentation;
   Regularization
ID ACTIVE CONTOURS DRIVEN; IMAGE SEGMENTATION; STATISTICAL INTERPRETATION;
   CLUSTERING-ALGORITHM; REGION; MUMFORD
AB To effectively and accurately segment images in the presence of intensity inhomogeneity and noise, a variational level set model based on maximum a posteriori (MAP) criterion is proposed in this paper. In the Bayesian framework, the posterior probability of the corrected smooth image under the observation condition is described by a likelihood function of the observation multiplied by a prior probability of the corrected smooth image. In the model, the likelihood function of the observation is computed under the assumption that the observed image obeys the local Gaussian distribution with both varying means and variances; and based on Markov random field (MRF) model, the prior probability of the corrected smooth image is defined as a Gibbs energy function that is related to the total variation. Maximizing the likelihood function can effectively capture the local change of image intensity, and maximizing the prior probability can restrain the influence of noise. An alternating direction iterative algorithm combining with fixed point iteration and gradient descent is introduced to solve the proposed model. The experiments for both synthetic and real images validate the proposed model. In addition, compared with several state-of-the-art variational level set models, the proposed model show the best segmentation performance.
C1 [Ren, Yanjun; Tang, Liming; Zheng, Jie] Hubei Minzu Univ, Sch Math & Stat, Enshi 445000, Hubei, Peoples R China.
   [Zhang, Honglu] Enshi Polytech, Enshi 445000, Hubei, Peoples R China.
C3 Hubei Minzu University
RP Tang, LM (corresponding author), Hubei Minzu Univ, Sch Math & Stat, Enshi 445000, Hubei, Peoples R China.
EM tlmcs78@foxmail.com
RI Tang, Liming/AAE-6606-2022; Ren, Yanjun/GXW-1802-2022
OI Tang, Liming/0000-0001-9140-4745; 
FU Natural Science Foundation of China [62061016, 61561019]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant No. 62061016, 61561019.
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P203
   Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5
   Cai Q, 2018, PATTERN RECOGN, V82, P79, DOI 10.1016/j.patcog.2018.05.008
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang HH, 2009, NEUROIMAGE, V47, P122, DOI 10.1016/j.neuroimage.2009.03.068
   Chen SY, 2018, COMPUT GEOSCI-UK, V112, P38, DOI 10.1016/j.cageo.2017.12.003
   Chen X, 2019, PROC CVPR IEEE, P11624, DOI 10.1109/CVPR.2019.01190
   Dai LZ, 2015, PATTERN RECOGN, V48, P2513, DOI 10.1016/j.patcog.2015.03.001
   Darolti C, 2008, IEEE T IMAGE PROCESS, V17, P2275, DOI 10.1109/TIP.2008.2006443
   Deng C, 2018, PATTERN RECOGN, V77, P306, DOI 10.1016/j.patcog.2017.10.007
   Dong B, 2019, SIGNAL PROCESS-IMAGE, V78, P187, DOI 10.1016/j.image.2019.07.001
   Gao S, 2005, IEEE T IMAGE PROCESS, V14, P1537, DOI 10.1109/TIP.2005.852200
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gu Y, 2017, IEEE T IMAGE PROCESS, V26, P942, DOI 10.1109/TIP.2016.2636450
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hatamizadeh A., 2019, ARXIV PREPRINT ARXIV
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Lankton S, 2007, PROC SPIE, V6510, DOI 10.1117/12.709700
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li C, 2007, IEEE C COMPUT VISION, V3, P339
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liu C, 2019, J VIS COMMUN IMAGE R, V59, P89, DOI 10.1016/j.jvcir.2019.01.001
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu WF, 2017, IEEE GEOSCI REMOTE S, V14, P2330, DOI 10.1109/LGRS.2017.2764042
   Liu Y, 2018, DIGIT SIGNAL PROCESS, V78, P42, DOI 10.1016/j.dsp.2018.01.017
   Lu SY, 2017, COMPUT METH PROG BIO, V141, P1, DOI 10.1016/j.cmpb.2017.01.014
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Piovano J, 2007, LECT NOTES COMPUT SC, V4485, P709
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Tang Liming, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P1707
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang L, 2018, PATTERN RECOGN, V74, P145, DOI 10.1016/j.patcog.2017.08.031
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang LF, 2014, PATTERN RECOGN, V47, P1917, DOI 10.1016/j.patcog.2013.11.014
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wu CM, 2020, DIGIT SIGNAL PROCESS, V97, DOI 10.1016/j.dsp.2019.102615
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang HL, 2019, INFORM SCIENCES, V493, P152, DOI 10.1016/j.ins.2019.04.048
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
NR 51
TC 0
Z9 0
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4511
EP 4534
DI 10.1007/s11042-021-11783-2
EA DEC 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000729661100002
DA 2024-07-18
ER

PT J
AU Yu, JC
   Jin, L
   Chen, JY
   Xiao, YZ
   Tian, ZQ
   Lan, XG
AF Yu, Jiachen
   Jin, Li
   Chen, Jiayi
   Xiao, Youzi
   Tian, Zhiqiang
   Lan, Xuguang
TI Deep semantic space guided multi-scale neural style transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural style transfer; Image segmentation; Illumination estimation;
   Patch matching
AB This paper mainly studies the Neural Style Transfer (NST) problem based on convolutional neural networks (CNN). Existing deep style migration algorithms do not mimic the styles to a reasonable position. To solve the problem, this paper proposes a multi-scale style transfer algorithm based on deep semantic matching. For purpose of guiding the correct migration of the style, we use the priori spatial segmentation and illumination information of the input image to integrate the deep semantic information. First, we find that spatial division and illumination analysis are two important visual understanding approaches for artists to make each painting decision. In order to simulate these two visual understanding approaches, this paper defines the DSS (deep semantic space), which contains spatial segmentation and contextual illumination information. The semantic exists in the form of CNN (convolution neural network) characteristic graph. Second, we propose a deep semantic loss function based on DSS matching and nearest neighbor search to optimize the effect of deep style migration. Third, we propose a multi-scale optimization strategy for improving the speed of our method. The experiments show that our method can reasonably synthesize images in spatial structures. The placement of each style is more reasonable and has a good visual aesthetic.
C1 [Yu, Jiachen; Jin, Li; Xiao, Youzi; Tian, Zhiqiang] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
   [Chen, Jiayi; Lan, Xuguang] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Jin, L (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Peoples R China.
EM 19138682@qq.com
RI wang, yitian/JFA-6804-2023; Chen, Jiayi/GZM-5106-2022; chen,
   jiayi/IAP-9353-2023; chen, jia/JLM-4733-2023; Chen, Jia/HQZ-3908-2023;
   chen, jia/JDW-7660-2023
OI chen, jiayi/0009-0009-0528-5475; 
FU NSFC [91748208]; key project of Shaanxi province [2018ZDCXL-GY-0607];
   Fundamental Research Funds for the Central Universities [XJJ2018254];
   China Postdoctoral Science Foundation [2018M631164]
FX This work was also supported in part by the key project of Trico-Robot
   plan of NSFC under grant No. 91748208, key project of Shaanxi province
   No.2018ZDCXL-GY-0607, the Fundamental Research Funds for the Central
   Universities No. XJJ2018254, and China Postdoctoral Science Foundation
   No. 2018M631164.
CR [Anonymous], 2017, ARXIV170108893
   Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Baxter William., 2010, I3D, P135
   Champandard A. J., 2015, DEEP FORGER PAINT PH
   Champandard AJ, ARXIV160301768
   Chen ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818066
   Collomosse J, 2012, IMAGE VIDEO BASED AR, V42
   Drori I, 2003, PROC CVPR IEEE, P143
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Elad M, 2017, IEEE T IMAGE PROCESS, V26, P2338, DOI 10.1109/TIP.2017.2678168
   Fiser J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925948
   Frigo O, 2016, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2016.66
   Gatys L., 2015, NIPS
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gooch B., 2001, Non-photorealistic rendering
   He K., 2010, Eccv, P1
   Heckbert P. S., 1990, Computer Graphics, V24, P145, DOI 10.1145/97880.97895
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lee H., 2010, Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering, P43
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li SH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1716, DOI 10.1145/3123266.3123425
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu X.C., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, page, P1
   Prisma L, 2016, TURN MEMORIES ART US
   Sanakoyeu A, 2018, ARXIV180710201V2 ECC
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Wang CM, 2007, IEEE T VIS COMPUT GR, V13, P235, DOI 10.1109/TVCG.2007.41
   Wang MY, 2014, IEEE T VIS COMPUT GR, V20, P1451, DOI 10.1109/TVCG.2014.2303984
   Yosinski J., 2015, ARXIV150606579, V2015, P12
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
NR 39
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3915
EP 3938
DI 10.1007/s11042-021-11694-2
EA NOV 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722484100002
DA 2024-07-18
ER

PT J
AU Fazliani, Y
   Andrade, E
   Shirani, S
AF Fazliani, Yasamin
   Andrade, Ernesto
   Shirani, Shahram
TI Neural network solution fora real-time no-reference video quality
   assessment of H.264/AVC video bitstreams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; No-reference; Video quality assessment; VQA; H.264/AVC
ID DISTORTIONS; PREDICTION
AB The ever-growing video streaming services require accurate quality assessment with often no reference to the original media. One primary challenge in developing no-reference (NR) video quality metrics is achieving real-timeliness while retaining the accuracy. A real-time no-reference video quality assessment (VQA) method is proposed for videos encoded by H.264/AVC codec. Temporal and spatial features are extracted from the encoded bit-stream and pixel values to train and validate a fully connected neural network. The hand-crafted features and network dynamics are designed in a manner to ensure a high correlation with human judgment of quality as well as minimizing the computational complexities. Proof-of-concept experiments are conducted via comparison with: 1) video sequences rated by a full-reference quality metric, and 2) H.264-encoded sequences from the LIVE video dataset which are subjectively evaluated through differential mean opinion scores (DMOS). The performance of the proposed method is verified by correlation measurements with the aforementioned objective and subjective scores. The framework achieves real-time execution while outperforming state-of-art full-reference and no-reference video quality assessment methods.
C1 [Fazliani, Yasamin; Shirani, Shahram] McMaster Univ, Hamilton, ON, Canada.
   [Fazliani, Yasamin; Andrade, Ernesto; Shirani, Shahram] Evertz Microsyst, Burlington, ON, Canada.
C3 McMaster University
RP Fazliani, Y (corresponding author), McMaster Univ, Hamilton, ON, Canada.; Fazliani, Y (corresponding author), Evertz Microsyst, Burlington, ON, Canada.
EM fazliay@mcmaster.ca; eandrade@evertz.com
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahn S, 2018, ASIAPAC SIGN INFO PR, P1513, DOI 10.23919/APSIPA.2018.8659706
   [Anonymous], 2015, INT WORKSHOP QUALITY
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], 2014, PORC IEEE NETW OPER
   Born RT, 2005, ANNU REV NEUROSCI, V28, P157, DOI 10.1146/annurev.neuro.26.041002.131052
   Caruana R, 2001, ADV NEUR IN, V13, P402
   Fang RG, 2017, IEEE T CIRC SYST VID, V27, P1381, DOI 10.1109/TCSVT.2016.2539658
   Fazliani Y, 2019, 2019 IEEE INT S CIRC, P1, DOI DOI 10.1109/IS-CAS.2019.8702584
   Gu J, 2018, IEEE T MULTIMEDIA, V20, P1140, DOI 10.1109/TMM.2017.2761993
   Gunawan IP, 2008, IEEE T CIRC SYST VID, V18, P71, DOI 10.1109/TCSVT.2007.913755
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Keimel C, 2011, IEEE IMAGE PROC
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lay D.C., 2012, Linear Algebra and Its Applications
   Liu WT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P546, DOI 10.1145/3240508.3240643
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moghaddam B, 2007, IEEE I CONF COMP VIS, P2073, DOI 10.1109/cvpr.2007.383092
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   Pechard S, 2006, IEEE IMAGE PROC, P409, DOI 10.1109/ICIP.2006.312480
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Pitrey Y, 2010, EURO ITV
   Pitrey Y, 2012, PROC SPIE, V8291, DOI 10.1117/12.912180
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sogaard J, 2015, IEEE T CIRC SYST VID, V25, P1637, DOI 10.1109/TCSVT.2015.2397207
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Usman MA, 2017, IETE TECH REV, V34, P309, DOI 10.1080/02564602.2016.1185975
   Vega MT, 2017, IEEE SIGNAL PROC LET, V24, P736, DOI 10.1109/LSP.2017.2691160
   Vega MT, 2016, LIMP VIDEO QUALITY D
   Vink JP, 2011, IEEE J-STSP, V5, P297, DOI 10.1109/JSTSP.2010.2055832
   VQEG, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Vu PV, 2011, IEEE IMAGE PROC
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Xu B, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Xu JT, 2014, IEEE IMAGE PROC, P491, DOI 10.1109/ICIP.2014.7025098
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zeng K, 2010, INT CONF ACOUST SPEE, P1010, DOI 10.1109/ICASSP.2010.5495316
   Zhu KF, 2013, IEEE IMAGE PROC, P49, DOI 10.1109/ICIP.2013.6738011
NR 46
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2409
EP 2427
DI 10.1007/s11042-021-10654-0
EA OCT 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712480900002
DA 2024-07-18
ER

PT J
AU Rehman, IU
   Ullah, S
AF Rehman, Inam Ur
   Ullah, Sehat
TI Gestures and marker based low-cost interactive writing board for primary
   education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Gesture-based interaction; Human-computer
   interaction; Interactive writing boards; Fiducial marker; Primary
   education; Virtual reality
ID RECOGNITION; SYSTEM; WHITEBOARD; TRACKING
AB Provision of information simply and interactively has a vital role in any stage of the teaching-learning process especially at primary level, not only guarantees self-motivation of the students but also improves their learning and performance. Virtual and Augmented reality techniques are the most attractive candidates in this regard, render synthetic information, and allow realistic interaction. This paper proposes a low-cost interactive writing board for the teaching of Urdu alphabets in primary education. The proposed writing board allows visualization and interaction of all alphabets, 3D models, and other information realistically and simply. Interaction with writing board is made using: 1) simple mid-air hand gestures and 2) a new touchpad like multi-layered marker. Leap Motion sensor is used for gesture recognition while ARToolKit is used for marker recognition. Experimental results showed that the proposed system has significant improvement in student's motivation and learning skills. System Usability Scale (SUS) was used to measure usability of the system. The results found gesture-based interaction with high usability, learnability, and more user friendly while the marker with less physical fatigue. A comparison of the proposed writing board with state-of-the-art writing boards resulted in realistic visualization of information (audio, text, and 3D models) and natural interaction of the proposed writing board.
C1 [Rehman, Inam Ur; Ullah, Sehat] Univ Malakand, Dept CS & IT, Chakdara, Pakistan.
C3 University of Malakand
RP Rehman, IU (corresponding author), Univ Malakand, Dept CS & IT, Chakdara, Pakistan.
EM inam.btk@gmail.com
RI ullah, sehat/HTT-4581-2023; Rehman, Inam Ur/Q-3254-2019
OI ullah, sehat/0000-0002-1193-9350; Rehman, Inam Ur/0000-0001-6625-6680
CR Ahsan A, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P90, DOI 10.1109/ICEEOT.2016.7754805
   Amma C, 2014, PERS UBIQUIT COMPUT, V18, P191, DOI 10.1007/s00779-013-0637-3
   Bassily D., 2014, ISR ROBOTIK 2014, P1
   Bested M, 2017, MULTIMED TOOLS APPL, V76, P5367, DOI 10.1007/s11042-016-3922-0
   Bhalla M.R., 2010, International Journal of Computer Applications, V6, P12, DOI [10.5120/1097-1433, DOI 10.5120/1097-1433]
   Blaha J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P163, DOI 10.1109/VR.2014.6802102
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Chen MY, 2016, IEEE T HUM-MACH SYST, V46, P403, DOI 10.1109/THMS.2015.2492598
   Chien YH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11164415
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Gaeta E, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153251
   Hartono M, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND TECHNOLOGY (ICIMTECH), P93, DOI 10.1109/ICIMTech.2016.7930309
   Horii H, 2013, PROCD SOC BEHV, V103, P174, DOI 10.1016/j.sbspro.2013.10.323
   Kane L, 2017, IEEE T HUM-MACH SYST, V47, P1077, DOI 10.1109/THMS.2017.2706695
   Kato H., 2000, ARToolKit Version 2.33
   Khan D, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11205720
   Lech M, 2012, INTELL DECIS TECHNOL, V6, P161, DOI 10.3233/IDT-2012-0132
   Lee KR, 2017, IEEE T NEUR SYS REH, V25, P37, DOI 10.1109/TNSRE.2016.2542524
   Li QC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SYSTEM AND SOFTWARE RELIABILITY (ISSSR), P68, DOI [10.1109/ISSSR.2016.020, 10.1109/ISSSR.2016.14]
   Liang JM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153260
   MAGORI V, 1994, ULTRASON, P471, DOI 10.1109/ULTSYM.1994.401632
   MALLICOAT S, 1995, P SOC PHOTO-OPT INS, V2383, P419, DOI 10.1117/12.209044
   Mohammadi M, 2015, SAGE OPEN, V5, DOI [10.1109/PLASMA.2015.7179880, 10.1177/2158244015579726]
   Monzo C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020222
   Rabbi I, 2015, ADV ELECTR COMPUT EN, V15, P59, DOI 10.4316/AECE.2015.02008
   Rahim M A, 2020, MULTIMED TOOLS APPL, P1
   Rautaray S. S., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P244, DOI 10.1109/MSPCT.2011.6150485
   Rehman I, 2019, INT J INTERACT MULTI, V5, P128, DOI 10.9781/ijimai.2018.07.001
   Rehman IU, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9121986
   Sabir K, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P49, DOI 10.1109/BioVis.2013.6664346
   Schaub M, 2012, EFFECTS PROMETHEAN B
   Soares C, 2013, LOCOBOARD LOW COST I
   Tateno K, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P259
   Ullah S., 2016, Pakistan Journal of Science, V68, P366
   Vergara D, 2019, EDUC SCI, V9, DOI 10.3390/educsci9020083
   Wang RY., 2009, ACM transactions on graphics (TOG), V28, P1, DOI DOI 10.1145/1531326.1531369
   Xu DY, 2006, INT C PATT RECOG, P519
   Zhang Q, 2013, CHIN J ELECT DEV, V1
NR 38
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1337
EP 1356
DI 10.1007/s11042-021-11366-1
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701393200002
DA 2024-07-18
ER

PT J
AU Mondal, S
   Barman, AD
AF Mondal, Sujoy
   Barman, Abhirup Das
TI Human auditory model based real-time smart home acoustic event
   monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic event detection; Cochleagram; Deep neural network; Gammatone
   filter bank; Smart home
ID NEURAL-NETWORKS; RECOGNITION; NOISE; IMAGE
AB In this work Gammatone (GT) filter bank energy features are used with a deep neural network (GT-DNN) to model robust acoustic event detection (AED) in the smart home environment for monitoring human activities. The Gammatone filter bank is modelled for the human auditory system which decomposes the environmental sound events into multiple frequency bands energy features. These features are learned during the training phase of DNN which is similar to the AED task by a human brain. Gammatone filter bank energy features are found superior over popular Mel-scale filter bank features and Gammatone filter bank output provides smooth spectrogram patterns that help to identify the dominant characteristic features of the target events. Moreover, the auditory feature-based Gammatone filter bank approach showed its robustness against the noise compared to Mel-scale filter bank features. In this work, the proposed GT-DNN model is tested on a single board computer (SBC) prototype developed on a popular Raspberry Pi 4 Model B. Experimental F-score results show impressive real-time AED performance. Furthermore, different parameters of the model are optimised and it is used to classify the various acoustic events from Freiburg-106 event dataset. NOISEX-92 dataset is combined with the clean event dataset which is used to train the model. Comparison of AED performance in terms of F-score at different signal to noise ratios (SNRs) is carried out between GT-DNN and baseline Mel-scale filter bank energy features, and improved results are obtained with the GT-DNN method. Moreover, the confidence scores for 10 different classes of events are evaluated in presence of worst category babble noise at 0 dB SNR and excellent classification results are obtained using the proposed method. Detailed analysis and results are given in support of each claim.
C1 [Mondal, Sujoy] RCC Inst Informat Technol, Dept ECE, Kolkata, India.
   [Barman, Abhirup Das] Univ Calcutta, Inst Radio Phys & Elect, Kolkata, India.
C3 RCC Institute of Information Technology (RCCIIT); University of Calcutta
RP Mondal, S (corresponding author), RCC Inst Informat Technol, Dept ECE, Kolkata, India.
EM sujoymondal@gmail.com; abhirup1.rpe@gmail.com
OI MONDAL, SUJOY/0000-0002-3533-2991
CR Akhtar Z, 2017, IEEE ACCESS, V5, P21090, DOI 10.1109/ACCESS.2017.2750918
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   [Anonymous], 2006, Computational auditory scene analysis: Principles, algorithms, and applications
   [Anonymous], 1999, A wavelet tour of signal processing
   [Anonymous], 2016, P WORKSH DET CLASS A
   Baker M. R., 1998, Reliable Computing, V4, P235, DOI 10.1023/A:1009951412412
   Boddapati V, 2017, PROCEDIA COMPUT SCI, V112, P2048, DOI 10.1016/j.procs.2017.08.250
   Casasanta G, 2018, IEEE GEOSCI REMOTE S, V15, P1692, DOI 10.1109/LGRS.2018.2858930
   Chandrakala S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3322240
   Derczynski L, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P261
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Er PV, 2018, MEASUREMENT, V124, P91, DOI 10.1016/j.measurement.2018.04.009
   Foggia P, 2015, PATTERN RECOGN LETT, V65, P22, DOI 10.1016/j.patrec.2015.06.026
   Greco A, 2020, IEEE T INF FOREN SEC, V15, P3610, DOI 10.1109/TIFS.2020.2994740
   Imoto K, 2018, ACOUST SCI TECHNOL, V39, P182, DOI 10.1250/ast.39.182
   Khattree R, 2002, J STAT PLAN INFER, V100, P411, DOI 10.1016/S0378-3758(01)00150-1
   Kiktova-Vozarikova E, 2015, MULTIMED TOOLS APPL, V74, P4213, DOI 10.1007/s11042-013-1529-2
   King DB, 2015, ACS SYM SER, V1214, P1
   Krishnamurthy N, 2009, IEEE T AUDIO SPEECH, V17, P1394, DOI 10.1109/TASL.2009.2015084
   Lee Donmoon, 2017, P DCASE
   Li E, 2018, MECOMM'18: PROCEEDINGS OF THE 2018 WORKSHOP ON MOBILE EDGE COMMUNICATIONS, P31, DOI 10.1145/3229556.3229562
   Lozano-Diez A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182580
   Ma JB, 2019, MULTIMED TOOLS APPL, V78, P29509, DOI 10.1007/s11042-018-7142-7
   McLoughlin I, 2015, IEEE-ACM T AUDIO SPE, V23, P540, DOI 10.1109/TASLP.2015.2389618
   Mondal S, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107403
   MOORE BCJ, 1983, J ACOUST SOC AM, V74, P750, DOI 10.1121/1.389861
   Mqtt, STAND IOT MESS
   Mulimani M, 2019, EXPERT SYST APPL, V120, P413, DOI 10.1016/j.eswa.2018.12.004
   Patterson RD, 1987, M IOC SPEECH GROUP A, V2
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Proakis J. G., 2004, Digital signal processing
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Sharan RV, 2019, APPL ACOUST, V148, P62, DOI 10.1016/j.apacoust.2018.12.006
   Slaney M., 1993, An efficient implementation of the patterson-holdsworth auditory filterbank, V35
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stork J. A., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P509, DOI 10.1109/ROMAN.2012.6343802
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang CY, 2018, IEEE-ACM T AUDIO SPE, V26, P1336, DOI 10.1109/TASLP.2017.2738443
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Xia XJ, 2019, CIRC SYST SIGNAL PR, V38, P3433, DOI 10.1007/s00034-019-01094-1
   Yegnanarayana B., 2009, ARTIFICIAL NEURAL NE
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
NR 43
TC 7
Z9 7
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 887
EP 906
DI 10.1007/s11042-021-11455-1
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000696768600001
DA 2024-07-18
ER

PT J
AU Yan, N
   Chen, AB
   Zhou, GX
   Zhang, ZQ
   Liu, XY
   Wang, JW
   Liu, ZH
   Chen, WJ
AF Yan, Na
   Chen, Aibin
   Zhou, Guoxiong
   Zhang, Zhiqiang
   Liu, Xiangyong
   Wang, Jianwu
   Liu, Zhihua
   Chen, Wenjie
TI Birdsong classification based on multi-feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Birdsong classification; Acoustic feature; Feature fusion; 3DCNN-LSTM
ID NEURAL-NETWORKS; RECOGNITION; SOUNDS; MFCC
AB The classification of birdsong has very important signification to monitor the bird population in the habitats. Aiming at the birdsong dataset with complex and diverse audio background, this paper attempts to introduce an acoustic feature for voice and music analysis: Chroma. It is spliced and fused with the commonly used birdsong features, Log-Mel Spectrogram (LM) and Mel Frequency Cepstrum Coefficient (MFCC), to enrich the representational capacity of single feature; At the same time, in view of the characteristic that birdsong has continuous and dynamic changes in time, a 3DCNN-LSTM combined model is proposed as a classifier to make the network more sensitive to the birdsong information that changes with time. In this paper, we selected four bird audio data from the Xeno-Canto website to evaluate how LM, MFCC and Chroma were fused to maximize the birdsong audio information. The experimental results show that the LM-MFCC-C feature combination achieves the best result of 97.9% mean average precision (mAP) in the experiment.
C1 [Yan, Na; Chen, Aibin; Zhou, Guoxiong; Liu, Zhihua; Chen, Wenjie] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha, Peoples R China.
   [Zhang, Zhiqiang] Cent South Univ Forestry & Technol, Coll Forestry, Wildlife Conservat & Utilizat Lab, Changsha, Peoples R China.
   [Chen, Aibin] Cent South Univ Forestry & Technol, Coll Life Sci & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha, Peoples R China.
   [Liu, Xiangyong] Hunan Zixing Artificial Intelligence Res Acad, Hunan Zixing, Peoples R China.
   [Wang, Jianwu] HuangFengQiao State Owned Forest Farm, Youxian Cty, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology; Central South
   University of Forestry & Technology; Central South University of
   Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Inst Artificial Intelligence Applicat, Changsha, Peoples R China.; Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Coll Life Sci & Technol, Hunan Prov Key Lab Urban Forest Ecol, Changsha, Peoples R China.
EM hotaibin@163.com
RI 刘, 志华/HOF-8314-2023; zhang, zhi/HPH-4905-2023; wang,
   jianwu/KBB-3546-2024; LI, WEI/ISS-1208-2023; yan, na/HDM-3747-2022; yan,
   na/JAC-6056-2023
OI 刘, 志华/0000-0003-3980-2927; Zhou, Guoxiong/0000-0002-5142-4845
FU Scientific Innovation Fund for Post-graduates of Central South
   University of Forestry and Technology [CX20192014]; Hunan Key Laboratory
   of intelligent logistics technology [2019TP1015]
FX This work supported in part by Scientific Innovation Fund for
   Post-graduates of Central South University of Forestry and Technology
   CX20192014; Hunan Key Laboratory of intelligent logistics technology
   2019TP1015.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   [Anonymous], 2018, INT J MANAGE TECH EN
   Bai S., 2018, CoRR
   Bardeli R, 2010, PATTERN RECOGN LETT, V31, P1524, DOI 10.1016/j.patrec.2009.09.014
   Boddapati V, 2017, PROCEDIA COMPUT SCI, V112, P2048, DOI 10.1016/j.procs.2017.08.250
   Chachada S, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.12
   Ellis D., 2007, Chroma Feature Analysis and Synthesis. Resources of Laboratory for the Recognition and Organization of Speech and Audio-LabROSA
   Fagerlund S, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/38637
   Ganchev T., 2005, 10th International Conference on Speech and Computer (SPECOM 2005), V1, P191
   Ghosal D, 2018, INTERSPEECH, P2087
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Himawan I, 2018, 3D CONVOLUTION RECUR
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Izonin I, 2019, LECT NOTES COMPUT SC, V11506, P467, DOI 10.1007/978-3-030-20521-8_39
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Joly Alexis, 2017, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 8th International Conference of the CLEF Association, CLEF 2017. Proceedings: LNCS 10456, P255, DOI 10.1007/978-3-319-65813-1_24
   Kahl S., 2017, CLEF WORKING NOTES
   Kalan AK, 2015, ECOL INDIC, V54, P217, DOI 10.1016/j.ecolind.2015.02.023
   Koops HV, 2014, CLEF2014 WORKING NOT, V1180, P634
   Lee CH, 2006, PATTERN RECOGN LETT, V27, P93, DOI 10.1016/j.patrec.2005.07.004
   Lee CH, 2013, IEEE T MULTIMEDIA, V15, P454, DOI 10.1109/TMM.2012.2229969
   Leng YR, 2014, ASIAPAC SIGN INFO PR
   Li SB, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071152
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Muller M., 2007, INFORM RETRIEVAL MUS, V2, P59
   Muller M, 2005, P 6 INT C MUSIC INFO, P288
   NIROSHA P, 2018, J AVIAN BIOL, V49
   Paulus J., 2010, Ismir, P625
   Pereira HM, 2006, TRENDS ECOL EVOL, V21, P123, DOI 10.1016/j.tree.2005.10.015
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sangiorgio M, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110045
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Sprengel E., 2016, CLEF, P547
   Stowell D, 2019, METHODS ECOL EVOL, V10, P368, DOI 10.1111/2041-210X.13103
   Stowell D, 2014, PEERJ, V2, DOI 10.7717/peerj.488
   Su Y, 2020, APPL ACOUST, V158, DOI 10.1016/j.apacoust.2019.107050
   Su Y, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071733
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P112, DOI 10.1007/978-3-319-91008-6_12
   Tkachenko Roman, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P578, DOI 10.1007/978-3-319-91008-6_58
   Torfi A., 2018, 2018 IEEE INT C MULT, P1, DOI [DOI 10.1109/ICME.2018.8486441, 10.1109/ICME.2018.8486441]
   Torfi A, 2017, IEEE ACCESS, V5, P22081, DOI 10.1109/ACCESS.2017.2761539
   Walther GR, 2002, NATURE, V416, P389, DOI 10.1038/416389a
   Xie J, 2016, ECOL INFORM, V32, P134, DOI 10.1016/j.ecoinf.2016.01.007
   Xing Z, 2017, ARXIV PREPRINT ARXIV
   Yang GP, 2019, INTERSPEECH, P1363, DOI 10.21437/Interspeech.2019-2181
   Yin W., 2017, CoRR
   Zhang X, 2019, ECOL INFORM, V54, DOI 10.1016/j.ecoinf.2019.101009
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
NR 55
TC 12
Z9 14
U1 11
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36529
EP 36547
DI 10.1007/s11042-021-11396-9
EA SEP 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000695537100001
DA 2024-07-18
ER

PT J
AU Cuzzocrea, A
   Fadda, E
   Mumolo, E
AF Cuzzocrea, Alfredo
   Fadda, Edoardo
   Mumolo, Enzo
TI Cyber-attack detection via non-linear prediction of IP addresses: an
   innovative big data analytics approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber-attack; Distributed Denial of Service; Hammerstein models
ID FRAMEWORK
AB Computer network systems are often subject to several types of attacks. For example, an excessive traffic load sent to a web server for making it unusable is the main technique introduced by the Distributed Denial of Service (DDoS) attack. A well-known method for detecting attacks consists in analyzing the sequence of source IP addresses for detecting possible anomalies. With the aim of predicting the next IP address, the Probability Density Function of the IP address sequence is estimated. Anomalous requests are detected via predicting source's IP addresses in future accesses to the server. Thus, when an access to the server occurs, the server accepts only the requests from the predicted IP addresses and it blocks all the others. The approaches used to estimate the Probability Density Function of IP addresses range from the sequence of IP addresses seen previously and stored in a database to address clustering, for instance via the K-Means algorithm. Instead, the sequence of IP addresses is considered as a numerical sequence in this paper, and non-linear analysis of this numerical sequence is applied. In particular, we exploited non-linear analysis based on Volterra Kernels and Hammerstein models. The experiments carried out with datasets of source IP address sequences show that the prediction errors obtained with Hammerstein models are smaller than those obtained both with the Volterra Kernels and with the sequence clustering based on the K-Means algorithm.
C1 [Cuzzocrea, Alfredo] Univ Calabria, Arcavacata Di Rende, Italy.
   [Cuzzocrea, Alfredo] LORIA, Nancy, France.
   [Fadda, Edoardo] Politecn Torino, Turin, Italy.
   [Fadda, Edoardo] ISIRES, Turin, Italy.
   [Mumolo, Enzo] Univ Trieste, Trieste, Italy.
C3 University of Calabria; Universite de Lorraine; Polytechnic University
   of Turin; University of Trieste
RP Cuzzocrea, A (corresponding author), Univ Calabria, Arcavacata Di Rende, Italy.; Cuzzocrea, A (corresponding author), LORIA, Nancy, France.
EM alfredo.cuzzocrea@unical.it; edoardo.fadda@polito.it; mumolo@units.it
RI Cuzzocrea, Alfredo/B-6374-2015; Fadda, Edoardo/N-7120-2018
OI Fadda, Edoardo/0000-0002-5599-6349
FU Universita della Calabria within the CRUI-CARE Agreement; French PIA
   project "Lorraine Universite d'Excellence" [ANR-15-IDEX-04-LUE]
FX Open access funding provided by Universita della Calabria within the
   CRUI-CARE Agreement. This research has been partially supported by the
   French PIA project "Lorraine Universite d'Excellence", reference
   ANR-15-IDEX-04-LUE.
CR Abid Ahlem, 2020, Procedia Computer Science, V176, P572, DOI 10.1016/j.procs.2020.08.059
   Agrawal A, 2003, CCGRID 2003: 3RD IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P367, DOI 10.1109/CCGRID.2003.1199389
   Amen B, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1177, DOI 10.1109/HPCC/SmartCity/DSS.2018.00198
   Bonifati A, 2006, DATA KNOWL ENG, V59, P247, DOI 10.1016/j.datak.2006.01.011
   Cannataro M., 2002, P 14 INT C SOFTWARE, P627
   Casas P, 2013, 2013 25TH INTERNATIONAL TELETRAFFIC CONGRESS (ITC)
   Cerone V, 2017, P AMER CONTR CONF, P831, DOI 10.23919/ACC.2017.7963056
   Chatzimilioudis G, 2013, J COMPUT SYST SCI, V79, P349, DOI 10.1016/j.jcss.2012.09.013
   Cuzzocrea A., 2006, Web Intelligence and Agent Systems, V4, P289
   Cuzzocrea A., 2009, ENCY DATA WAREHOUSIN, V2e, P1575
   Cuzzocrea A., 2016, P 31 ANN ACM S APPL, P992, DOI DOI 10.1145/2851613.2851662
   Cuzzocrea A., 2014, P 17 INT WORKSHOP DA, P99
   Cuzzocrea A, 2013, LECT NOTES COMPUT SC, V8216, P38, DOI 10.1007/978-3-642-41366-7_4
   Cuzzocrea A, 2011, J COMPUT SYST SCI, V77, P965, DOI 10.1016/j.jcss.2011.02.004
   Dehghani R, 2015, J KNOWL MANAG, V19, P682, DOI 10.1108/JKM-10-2014-0438
   Dietrich S, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE FOURTEENTH SYSTEMS ADMINISTRATION CONFERENCE (LISA XIV), P329
   Fadda E, 2019, EUR J OPER RES, V277, P643, DOI 10.1016/j.ejor.2019.02.052
   Fadda E, 2017, LECT NOTES COMPUT SC, V10199, P329, DOI 10.1007/978-3-319-55849-3_22
   Goldstein M, 2008, ICN 2008: SEVENTH INTERNATIONAL CONFERENCE ON NETWORKING, PROCEEDINGS, P174, DOI 10.1109/ICN.2008.64
   Jung J., 2002, Proceedings of the 11th international conference on World Wide Web, P293, DOI DOI 10.1145/511446.511485
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Pack G., 2006, FILTERING DDOS ATTAC, P1, DOI [10.1109/SECCOMW.2006.359537, DOI 10.1109/SECCOMW.2006.359537]
   Park S, 2008, DATA KNOWL ENG, V65, P512, DOI 10.1016/j.datak.2008.01.002
   Peng T, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-5, P482
   [彭志科 Peng Zhike], 2015, [科学通报, Chinese Science Bulletin], V60, P1874
   Phan TV, 2019, IEEE ACCESS, V7, P18701, DOI 10.1109/ACCESS.2019.2896783
   Praveena V, 2020, WIRELESS PERS COMMUN, V113, P669, DOI 10.1007/s11277-020-07183-8
   Sarker IH, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00318-5
   Seah, 2006, FRAMEWORK STAT FILTE, DOI [10.1109/ICESS.2005.57, DOI 10.1109/ICESS.2005.57]
   Tóth P, 2013, 2013 IEEE 8TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI 2013), P61, DOI 10.1109/SACI.2013.6608939
   Wang LD, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P105, DOI 10.1109/UEMCON47517.2019.8993037
   Yang YK, 2005, IEEE ICC, P224
   Zhao HQ, 2009, IEEE T NEURAL NETWOR, V20, P665, DOI 10.1109/TNN.2008.2011481
NR 33
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 171
EP 189
DI 10.1007/s11042-021-11390-1
EA SEP 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000692489400005
OA hybrid
DA 2024-07-18
ER

PT J
AU Mao, QY
   Yang, XM
   Zhang, RZ
   Jeon, G
   Hussain, F
   Liu, K
AF Mao, Qingyu
   Yang, Xiaomin
   Zhang, Rongzhu
   Jeon, Gwanggil
   Hussain, Farhan
   Liu, Kai
TI Multi-focus images fusion via residual generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Multi-focus image fusion; End-to-end
   model; Multiple input images
ID INFORMATION MEASURE; PERFORMANCE; FRAMEWORK
AB Recently, most existing learning-based fusion methods are not fully end-to-end, which still predict the decision map and recover the fused image by the refined decision map. However, in practice, these methods are hard to predict the decision map precisely. Inaccurate prediction further degrades the performance of fusing, resulting in edge blurring and artefacts. This paper proposes an end-to-end multi-focus image fusion model based on conditional generative adversarial network (MFFGAN). In MFFGAN, we introduce a pioneering use of the conditional generative adversarial network to the field of image fusion. Moreover, we introduce the simple and efficient relativistic discriminator to our network, so the network converges faster. More importantly, MFFGAN is fully trained in this adversarial relationship to produce visually perceptive images that contain rich texture information and avoid the post-processing phase. Considering the detailed information of source images, we introduce the widely used perceptual loss to improve fused image performance. Thanks to the element-wise fusion criterion, our model can conveniently and efficiently fuse multiple images. Additionally, extensive experimental results show that the proposed model achieves excellent performance in subjective and objective evaluations.
C1 [Mao, Qingyu; Yang, Xiaomin; Zhang, Rongzhu] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.
   [Mao, Qingyu; Yang, Xiaomin] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610064, Sichuan, Peoples R China.
   [Jeon, Gwanggil] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Jeon, Gwanggil] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon 22012, South Korea.
   [Hussain, Farhan] Natl Univ Sci & Informat Technol, Coll Elect & Mech Engn, Islamabad 44000, Pakistan.
   [Liu, Kai] Sichuan Univ, Coll Elect Engn, Chengdu 610064, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University; Xidian University; Incheon
   National University; Sichuan University
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Sichuan, Peoples R China.; Yang, XM (corresponding author), Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610064, Sichuan, Peoples R China.
EM arielyang@scu.edu.cn
RI chen, yanhong/JVE-0289-2024; Huang, Yu/KDM-9182-2024; Liu,
   Kai/IST-6808-2023; yang, xiao/HJI-7815-2023
OI Mao, Qingyu/0000-0003-2473-4976; Hussain, Farhan/0000-0001-9073-5892
FU Sichuan University [2020SCUNG205]
FX This work was supported in part by the Sichuan University under grant
   2020SCUNG205.
CR Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Chen J, 2020, MULTIMED TOOLS APPL, V79, P27615, DOI 10.1007/s11042-020-09387-3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Kingma D. P., 2014, arXiv
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li HF, 2012, OPT COMMUN, V285, P91, DOI 10.1016/j.optcom.2011.08.078
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li Q, 2019, IEEE SENS J
   Li QL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072143
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Paszke A, 2019, ADV NEUR IN, V32
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Saeedi J, 2013, PATTERN ANAL APPL, V16, P365, DOI 10.1007/s10044-011-0235-9
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Teichmann M. T. T., 2018, COMPUT VIS PATTERN R
   Vakaimalar E, 2019, MULTIMED TOOLS APPL, V78, P17573, DOI 10.1007/s11042-018-7124-9
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wen Y, 2020, MULTIMED TOOLS APPL, V79, P34531, DOI 10.1007/s11042-020-08945-z
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan H, 2019, IEEE T CIRC SYST VID, V29, P80, DOI 10.1109/TCSVT.2017.2772892
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zheng Z, 2020, MULTIMED TOOLS APPL, P1
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 50
TC 3
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12305
EP 12323
DI 10.1007/s11042-021-11278-0
EA AUG 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000686512700002
DA 2024-07-18
ER

PT J
AU Tan, CB
   Hijazi, MHA
   Khamis, N
   Nohuddin, PNEB
   Zainol, Z
   Coenen, F
   Gani, A
AF Tan, Choon Beng
   Hijazi, Mohd Hanafi Ahmad
   Khamis, Norazlina
   Nohuddin, Puteri Nor Ellyza Binti
   Zainol, Zuraini
   Coenen, Frans
   Gani, Abdullah
TI A survey on presentation attack detection for automatic speaker
   verification systems: State-of-the-art, taxonomy, issues and future
   direction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker identification; Speaker verification; Anti-spoofing voice
   recognition; Voice presentation attack detection; Voice PAD
ID REPLAY SPOOF DETECTION; SYNTHETIC SPEECH; SCORE NORMALIZATION; FEATURE
   FUSION; I-VECTOR; ASVSPOOF; COUNTERMEASURES; REPRESENTATION; FEATURES;
   CLASSIFICATION
AB The emergence of biometric technology provides enhanced security compared to the traditional identification and authentication techniques that were less efficient and secure. Despite the advantages brought by biometric technology, the existing biometric systems such as Automatic Speaker Verification (ASV) systems are weak against presentation attacks. A presentation attack is a spoofing attack launched to subvert an ASV system to gain access to the system. Though numerous Presentation Attack Detection (PAD) systems were reported in the literature, a systematic survey that describes the current state of research and application is unavailable. This paper presents a systematic analysis of the state-of-the-art voice PAD systems to promote further advancement in this area. The objectives of this paper are two folds: (i) to understand the nature of recent work on PAD systems, and (ii) to identify areas that require additional research. From the survey, a taxonomy of voice PAD and the trend analysis of recent work on PAD systems were built and presented, whereby the recent and relevant articles including articles from Interspeech and ICASSP Conferences, mostly indexed by Scopus, published between 2015 and 2021 were considered. A total of 172 articles were surveyed in this work. The findings of this survey present the limitation of recent works, which include spoof-type dependent PAD. Consequently, the future direction of work on voice PAD for interested researchers is established. The findings of this survey present the limitation of recent works, which include spoof-type dependent PAD. Consequently, the future direction of work on voice PAD for interested researchers is established.
C1 [Tan, Choon Beng; Hijazi, Mohd Hanafi Ahmad; Khamis, Norazlina; Gani, Abdullah] Univ Malaysia Sabah, Fac Comp & Informat, Jalan UMS, Sabah, Malaysia.
   [Nohuddin, Puteri Nor Ellyza Binti] Univ Kebangsaan Malaysia, Inst IR4 0, Bangi, Malaysia.
   [Zainol, Zuraini] Univ Pertahan Nas Malaysia, Fac Sci & Def Technol, Dept Comp Sci, Kuala Lumpur, Malaysia.
   [Coenen, Frans] Univ Liverpool, Dept Comp Sci, Liverpool, Merseyside, England.
C3 Universiti Malaysia Sabah; Universiti Kebangsaan Malaysia; University of
   Liverpool
RP Hijazi, MHA (corresponding author), Univ Malaysia Sabah, Fac Comp & Informat, Jalan UMS, Sabah, Malaysia.
EM hanafi@ums.edu.my
RI Tan, Choon Beng/ABE-4041-2021; Nohuddin, Puteri Nor
   Ellyza/GWV-2366-2022; Ahmad Hijazi, Mohd Hanafi/I-5702-2015; Gani,
   Abdullah/C-2888-2009
OI Tan, Choon Beng/0000-0002-7204-7305; Coenen, Frans/0000-0003-1026-6649;
   Ahmad Hijazi, Mohd Hanafi/0000-0003-0431-8967; Nohuddin, Puteri Nor
   Ellyza/0000-0003-0627-5630; Zainol, Zuraini/0000-0002-6881-7039; Gani,
   Abdullah/0000-0002-4388-020X
CR ABOZAID A, 2018, MULTIMED TOOLS APPL
   Abu Mallouh A, 2018, NEURAL COMPUT APPL, V30, P2581, DOI 10.1007/s00521-017-2848-4
   Adel M, 2018, IEEE W SP LANG TECH, P1001, DOI 10.1109/SLT.2018.8639574
   Adiban M, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101105
   Admuthe SS, 2015, INT C MULT COMP GRAP, V4, P10895
   Al-Ali AKH, 2017, IEEE I C SIGNAL IMAG, P174, DOI 10.1109/ICSIPA.2017.8120601
   [Anonymous], 2006, HDB MULTIBIOMETRICS
   [Anonymous], 2015, IEEE AFRICON C IEEE, DOI DOI 10.1109/AFRCON.2015.7331916
   [Anonymous], 2017, 2017 INT C BIOM SPEC
   ASVspoof, 2019, ASVSPOOF 2019 AUT SP
   ASVspoof consortium, 2019, P ANN C INT SPEECH C, P1
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   Baumann R, 2021, COMPUT SPEECH LANG, V65, DOI 10.1016/j.csl.2020.101132
   Billal K, 2017, 2017 5 INT C EL ENG, P1, DOI [10.1109/ICEE-B.2017.8192139, DOI 10.1109/ICEE-B.2017.8192139]
   Biometrics Institute, 2017, TYP BIOM
   Biometrics TF, 2008, BIOM GLOSS BG
   Bonifaco H, 2017, I C HUMANOID NANOTEC
   Cai WC, 2017, INTERSPEECH, P17, DOI 10.21437/Interspeeeh.2017-906
   Chen ZX, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2052, DOI 10.1109/ICASSP.2018.8462644
   Chen ZX, 2017, INTERSPEECH, P102, DOI 10.21437/Interspeech.2017-1085
   Chettri B, 2020, IEEE-ACM T AUDIO SPE, V28, P3018, DOI 10.1109/TASLP.2020.3036777
   Chettri B, 2018, IEEE W SP LANG TECH, P92, DOI 10.1109/SLT.2018.8639666
   Chettri B, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5159, DOI 10.1109/ICASSP.2018.8461467
   Das RK, 2019, INTERSPEECH, P1058, DOI 10.21437/Interspeech.2019-1887
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Demiroglu C, 2017, IEEE J-STSP, V11, P671, DOI 10.1109/JSTSP.2017.2673807
   Dey S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5344, DOI 10.1109/ICASSP.2018.8461389
   Dinkel H, 2017, INT CONF ACOUST SPEE, P4860, DOI 10.1109/ICASSP.2017.7953080
   DUA M, J AMB INTEL HUM COMP
   Evans N., 2009, ENCY BIOMETRICS
   Evans N, 2014, ADV COMPUT VIS PATT, P125, DOI 10.1007/978-1-4471-6524-8_7
   Gomez-Alanis A, 2021, IEEE T INF FOREN SEC, V16, P1579, DOI 10.1109/TIFS.2020.3039045
   Gomez-Alanis A, 2020, IEEE ACCESS, V8, P108530, DOI 10.1109/ACCESS.2020.3000641
   Gomez-Alanis A, 2018, INTERSPEECH, P676, DOI 10.21437/Interspeech.2018-1909
   Gong Y, 2019, INTERSPEECH, P2355, DOI 10.21437/Interspeech.2019-1541
   Gong Y, 2020, IEEE SIGNAL PROC LET, V27, P920, DOI 10.1109/LSP.2020.2996908
   Hanilçi C, 2017, 2017 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P1187
   Hanilçi C, 2018, DIGIT SIGNAL PROCESS, V72, P171, DOI 10.1016/j.dsp.2017.10.010
   Hanilçi C, 2017, EUR SIGNAL PR CONF, P96, DOI 10.23919/EUSIPCO.2017.8081176
   Hanilçi C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2057
   Haviluddin, 2015, ADV SCI LETT, V21, P3037, DOI 10.1166/asl.2015.6490
   Heigold G, 2018, ACOUSTICS SPEECH SIG, P3
   Hemavathi R, 2021, MULTIMED TOOLS APPL, V80, P23561, DOI 10.1007/s11042-020-10212-0
   Hijazi MHA, 2018, ADV SCI LETT, V24, P1172, DOI 10.1166/asl.2018.10710
   Himawan I, 2019, COMPUT SPEECH LANG, V58, P377, DOI 10.1016/j.csl.2019.05.007
   Idiap Dataset Distribution Portal, 2015, AVSPOOF DAT
   Jiang XW, 2017, ASIAPAC SIGN INFO PR, P1628, DOI 10.1109/APSIPA.2017.8282293
   Jin M, 2010, BEHAV BIOMETRICS HUM, P264, DOI DOI 10.4018/978-1-60566-725-6.CH013
   Kamble MR, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2019.21
   Kamble MR, 2017, 2017 NINTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P326
   Kinnunen T., 2018, P SPEAK LANG REC WOR, P312
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Kinnunen T, 2017, INT CONF ACOUST SPEE, P5395, DOI 10.1109/ICASSP.2017.7953187
   Korshunov P, 2017, PRESENTATION ATTACK
   Korshunov P, 2016, INTERSPEECH, P1705, DOI 10.21437/Interspeech.2016-1326
   Korshunov P, 2017, IEEE J-STSP, V11, P695, DOI 10.1109/JSTSP.2017.2692389
   Kotta H, 2020, ASIAPAC SIGN INFO PR, P538
   Kumar AK, 2021, INT J SPEECH TECHNOL, V24, P193, DOI 10.1007/s10772-020-09785-w
   Kumar SR, 2021, CIRC SYST SIGNAL PR, V40, P872, DOI 10.1007/s00034-020-01501-y
   Lai CI, 2019, INTERSPEECH, P1013, DOI 10.21437/Interspeech.2019-1794
   Lavrentyeva G, 2017, INTERSPEECH, P82, DOI 10.21437/Interspeech.2017-360
   Lee KA, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2996
   Lei ZC, 2020, INTERSPEECH, P1116, DOI 10.21437/Interspeech.2020-2723
   Li JK, 2020, IEEE ACCESS, V8, P7907, DOI 10.1109/ACCESS.2020.2964048
   Li LT, 2017, INTERSPEECH, P1542, DOI 10.21437/Interspeech.2017-452
   Lin WY, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P1490, DOI 10.1109/ICCSNT.2015.7491011
   Malik KM, 2020, IEEE J-STSP, V14, P982, DOI 10.1109/JSTSP.2020.2999828
   Mariethoz J, 2006, TECH REP LIDIAP
   Markowitz J, 2008, TECH REP
   Matejka P, 2017, INTERSPEECH, P1567, DOI 10.21437/Interspeech.2017-803
   Mather Francis, 2017, Biometric Technology Today, V2017, P7, DOI 10.1016/S0969-4765(17)30055-3
   Matic M, 2017, IEEE I C CONS ELECT, P248, DOI 10.1109/ICCE-Berlin.2017.8210640
   Mayhew S., 2015, History of biometrics
   McGettigan C, 2013, J COGNITIVE NEUROSCI, V25, P1875, DOI 10.1162/jocn_a_00427
   Mehta N, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103311
   Mishra J, 2018, INT CO SIG PROC COMM, P95, DOI 10.1109/SPCOM.2018.8724390
   Monteiro J, 2020, INT CONF ACOUST SPEE, P6599, DOI [10.1109/icassp40776.2020.9054558, 10.1109/ICASSP40776.2020.9054558]
   Monteiro J, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101096
   Muckenhirn H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P335, DOI 10.1109/BTAS.2017.8272715
   Muhammad G, 2018, IEEE COMMUN MAG, V56, P60, DOI 10.1109/MCOM.2018.1700790
   Nagarsheth P, 2017, INTERSPEECH, P97, DOI 10.21437/Interspeech.2017-1377
   Neelima Medikonda, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P314, DOI 10.1109/ICOSEC49089.2020.9215407
   Pal M, 2018, COMPUT SPEECH LANG, V48, P31, DOI 10.1016/j.csl.2017.10.001
   Pal M, 2015, APPL SOFT COMPUT, V30, P214, DOI 10.1016/j.asoc.2015.01.036
   Parasu P, 2020, INTERSPEECH, P1111, DOI 10.21437/Interspeech.2020-2039
   Patel TB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2062
   Patil HA, 2018, ASIAPAC SIGN INFO PR, P1047, DOI 10.23919/APSIPA.2018.8659666
   Paul D, 2017, INT CONF ACOUST SPEE, P2047, DOI 10.1109/ICASSP.2017.7952516
   Paul D, 2017, IEEE J-STSP, V11, P605, DOI 10.1109/JSTSP.2017.2684705
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Prajapati GP, 2021, EUR SIGNAL PR CONF, P386, DOI 10.23919/Eusipco47968.2020.9287577
   Rahmani R, 2020, FUTURE GENER COMP SY, V108, P742, DOI 10.1016/j.future.2020.03.013
   Ramgire J. B., 2016, International Research Journal of Engineering and Technology, V3, P709
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Sabhanayagam T., 2018, International Journal of Applied Engineering Research, V13, P2276, DOI [10.1016/j.matpr.2021.07.005, DOI 10.1016/J.MATPR.2021.07.005]
   Safavi S, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P219, DOI 10.1109/CSPA.2017.8064954
   Sahidullah M., 2019, INTRO VOICE PRESENTA, P321
   Sahidullah M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2087
   Sailor HB, 2017, INTERSPEECH, P2601, DOI 10.21437/Interspeech.2017-1393
   Sanchez J, 2015, IEEE T INF FOREN SEC, V10, P810, DOI 10.1109/TIFS.2015.2398812
   Saratxaga I, 2016, SPEECH COMMUN, V81, P30, DOI 10.1016/j.specom.2016.04.001
   Sarkar AK, 2016, INTERSPEECH, P425, DOI 10.21437/Interspeech.2016-362
   Sarria-Paja M, 2016, INT CONF ACOUST SPEE, P5480, DOI 10.1109/ICASSP.2016.7472725
   Sharma V., 2013, Int. J. Eng. Res. Technol. (IJERT), V2, P1581
   Shim HJ, 2020, INTERSPEECH, P1091, DOI 10.21437/Interspeech.2020-1345
   Simmons, 2017, BBC FOOLS HSBC VOICE
   Singh M, 2019, INT J SPEECH TECHNOL, V22, P313, DOI 10.1007/s10772-019-09604-x
   Singh R, 2017, IET BIOMETRICS, V6, P282, DOI 10.1049/iet-bmt.2016.0126
   Sinitca Aleksandr M., 2020, 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus). Proceedings, P505, DOI 10.1109/EIConRus49466.2020.9039393
   Snyder David, 2018, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   Stan Z., 2003, EUR C SPEECH COMM TE, P1677
   Sujiya S., 2017, Int. J. Eng. Technol., V9, P1592
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Suthokumar G, 2020, INT CONF ACOUST SPEE, P6609, DOI [10.1109/ICASSP40776.2020.9054322, 10.1109/icassp40776.2020.9054322]
   Suthokumar G, 2018, INT CONF INF AUTOMAT
   Ting Huang, 2020, Digital Forensics and Watermarking. 18th International Workshop, IWDW 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12022), P115, DOI 10.1007/978-3-030-43575-2_9
   Todisco M., 2016, P SPEAK LANG REC WOR, V25, P249, DOI DOI 10.21437/ODYSSEY.2016-41
   Todisco M, 2019, INTERSPEECH, P1008, DOI 10.21437/Interspeech.2019-2249
   Todisco M, 2017, COMPUT SPEECH LANG, V45, P516, DOI 10.1016/j.csl.2017.01.001
   Tsai WH, 2016, 2016 IEEE INT C CONS, P1, DOI [10.1109/ICCE-TW.2016.7521051, DOI 10.1109/ICCE-TW.2016.7521051]
   Valin JM, 2019, INT CONF ACOUST SPEE, P5891, DOI 10.1109/ICASSP.2019.8682804
   Villalba J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2067
   Vishi K, 2018, ARXIVABS180511111805
   Wang D, 2017, ASIAPAC SIGN INFO PR, P177, DOI 10.1109/APSIPA.2017.8282024
   Wang LB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2092
   Wang X, 2020, COMPUT SPEECH LANG, V64, DOI [10.1016/j.csl.2020.101114, 10.1016/j.csi.2020.101114]
   Wang Z, 2020, ASIAPAC SIGN INFO PR, P1352
   Wijethunga R. L. M. A. P., 2020, 2020 2nd International Conference on Advancements in Computing (ICAC), P192, DOI 10.1109/ICAC51239.2020.9357161
   Wu ZZ, 2020, INTERSPEECH, P1101, DOI 10.21437/Interspeech.2020-1810
   Wu ZZ, 2017, IEEE J-STSP, V11, P588, DOI 10.1109/JSTSP.2017.2671435
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037
   Wu ZZ, 2016, MULTIMED TOOLS APPL, V75, P5311, DOI 10.1007/s11042-015-3080-9
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang JC, 2018, ASIAPAC SIGN INFO PR, P1024, DOI 10.23919/APSIPA.2018.8659537
   Ye YC, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P407, DOI [10.1109/ICCCBDA.2019.8725688, 10.1109/icccbda.2019.8725688]
   Zeinali H, 2019, INTERSPEECH, P1073, DOI 10.21437/Interspeech.2019-2892
   Zhang C, 2020, INTERSPEECH, P4596, DOI 10.21437/Interspeech.2020-1044
   Zheng TR, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5354, DOI 10.1109/ICASSP.2018.8461344
NR 142
TC 10
Z9 10
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32725
EP 32762
DI 10.1007/s11042-021-11235-x
EA AUG 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000681210700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, H
   Baek, K
AF Lee, Hyunseung
   Baek, Kyungsoon
TI Developing a smart multifunctional outdoor jacket with wearable sensing
   technology for user health and safety
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Technological convergence; Engineering; Multifunctional fashion; Outdoor
   fashion; Smart fashion; Wearable technology
ID RISK
AB Over the decades, there has been a sustained effort to use fashion as a medium for delivering digital functionality. The goal is to integrate information technology (IT) into clothing to provide users with functions to assist them in their tasks. Regarding the direction of previous efforts, this study developed a multifunctional smart outdoor jacket prototype that senses, recognizes, responds, and manages various safety risks and potentially hazardous situations and identifies environmental factors that are difficult to predict. The prototype's research and development (R & D) was carried out through the following steps. First, to determine functions that can practically assist users in outdoor environments and help ensure their health and safety, a user requirement survey subject to expert evaluation was conducted. Six functions were selected: (1) Bluetooth hands-free calling and audio streaming, (2) heart rate monitoring for self-health care, (3) emergency calls to request assistance, (4) temperature-reactive heating to retain body heat for survival, (5) fall detection and automatic emergency calls, and (6) ultraviolet monitoring for self-health care. Next, a wearable system and its garment platform were developed, containing detachable device modules for washability and ease of maintenance. Lastly, a dedicated smartphone application was developed for extended functionality. By exploring the use of clothing in diversifying wearable health care and HAR systems, the study could be used to diversify wearable healthcare and safety platforms.
C1 [Lee, Hyunseung] Incheon Natl Univ, Dept Fash Ind, Incheon, South Korea.
   [Baek, Kyungsoon] Kookmin Univ, Modular Smart Fash Platform Res Ctr, Seoul, South Korea.
C3 Incheon National University; Kookmin University
RP Lee, H (corresponding author), Incheon Natl Univ, Dept Fash Ind, Incheon, South Korea.
EM hslalpha@daum.net
OI Lee, Hyunseung/0000-0003-0949-8207
FU National Research Foundation of Korea (NRF) - Korean Government (MSIP)
   [2015R1A5A7037615]
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean Government (MSIP) (Grant No.
   2015R1A5A7037615).
CR Android Developers, BLUET OV
   [Anonymous], 2010, FASHION PRACT, DOI DOI 10.2752/175693810X12640026716519
   [Anonymous], 2014, THESIS IOWA STATE U
   Backe S, 2009, SCAND J MED SCI SPOR, V19, P850, DOI 10.1111/j.1600-0838.2008.00851.x
   Becker K, 2020, DIGITAL TRENDS
   Becker K, 2018, DIGITAL TRENDS
   Bluetooth, LEARN BLUETOOTH RADI
   Burns N, 2013, DISABIL SOC, V28, P1059, DOI 10.1080/09687599.2012.749180
   Cho G, 2009, INT J HUM-COMPUT INT, V25, P582, DOI 10.1080/10447310902997744
   Choi J, 2016, COMPUT HUM BEHAV, V63, P777, DOI 10.1016/j.chb.2016.06.007
   Costanza E, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P819
   D'Orazio Dante., 2012, The Verge
   De Rossi D, 2006, P 1 IEEE RAS EMBS IN, P1189
   Dellinger AJ, 2020, DAILY DOT
   Dunne L., 2010, FASHION PRACT, V2, P41, DOI DOI 10.2752/175693810X12640026716393
   Dunne LE, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P299
   Ebling MR, 2016, IEEE PERVAS COMPUT, V15, P2
   Frango PMVL, 2018, 2018 INTERNATIONAL SYMPOSIUM IN SENSING AND INSTRUMENTATION IN IOT ERA (ISSI)
   Gellersen HW, 2002, MOBILE NETW APPL, V7, P341, DOI 10.1023/A:1016587515822
   Gepperth J, 2012, CITESEERX
   Goulev P, 2004, P INT WORKSH WEAR IM, P6
   Hegde N, 2016, IEEE ENG MED BIO, P1886, DOI 10.1109/EMBC.2016.7591089
   Horvat I, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P435, DOI 10.1109/ICCE-Berlin.2015.7391301
   Karras A, 2017, SUNDAY TIMES
   Lee H, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2019.e03130
   Lee Hyunseung, 2019, [Fashion & Textile Research Journal, 한국의류산업학회지], V21, P769, DOI 10.5805/SFTI.2019.21.2.133
   Lee Hyunseung, 2018, [Journal of the Korean Society of Costume, 복식], V68, P98, DOI 10.7233/jksc.2018.68.2.098
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P18, DOI 10.1109/MIC.2020.2969610
   Li YT, 2018, IET COMMUN, V12, P751, DOI 10.1049/iet-com.2017.0502
   Majeed A.A., 2017, Int. J. Supply Chain Manag, V6, P25
   Mann S., 1997, Personal Technologies, V1, P21, DOI [10.1007/BF01317885, DOI 10.1007/BF01317885]
   Mazzoldi A., 2002, AUTEX Research Journal, V2, P199
   McCrindle RJ., 2011, INT J DISABIL HUM DE, V10, P349, DOI [10.1515/IJDHD.2011.052, DOI 10.1515/IJDHD.2011.052]
   McDonald JW, 2017, WILD ENVIRON MED, V28, P185, DOI 10.1016/j.wem.2017.05.001
   Miller MC, 2020, TOURISM GEOGR, V22, P354, DOI 10.1080/14616688.2019.1654538
   Myint CZ, 2010, AIP CONF PROC, V1239, P213, DOI 10.1063/1.3459752
   Ortner SB, 1997, REPRESENTATIONS, P135
   Ortner SherryB., 1999, Life and Death on Mt. Everest: Sherpas and Himalayan Mountaineering
   Park JA, 2017, COMPUT ASSIST SURG, V22, P176, DOI 10.1080/24699322.2017.1389396
   Porjazoski M, 2019, IEEE EUROCON 2019 18, DOI 10.1109/EUROCON.2019.8861866
   Quinn B., 2002, TECHNO FASHION
   Sabine S., 2008, Fashionable technology: the intersection of design, fashion, science, and technology
   Sayeed TS, 2018, 2018 INT C COMP COMM, DOI 10.1109/IC4ME2.2018.8465645
   Seigneur V, 2006, HIST SOC RES, V31, P245
   Sportstechie, 2014, SPORTS TECHIE
   Statt N., 2016, The Verge
   Such O, 2006, 2006 3RD IEEE/EMBS INTERNATIONAL SUMMER SCHOOL ON MEDICAL DEVICES AND BIOSENSORS, P49, DOI 10.1109/ISSMDBS.2006.360094
   Suh Sung-Eun, 2015, [The Research Journal of the Costume Culture, 복식문화연구], V23, P1097, DOI 10.7741/rjcc.2015.23.6.1097
   Toney A, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P35, DOI 10.1109/ISWC.2003.1241391
   Van Laerhoven K, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P49, DOI 10.1109/ISWC.2002.1167218
   Wang ZH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020341
   Watson A, P 20 INT C INF PROC, P1
   Weir J, 2007, CRUNCHWEAR
   Weir J, 2012, CRUNCHWEAR
   Yang JS., 2014, J KOREAN SOC DES CUL, V20, P354
   Yoon SI., 2013, DESIGN FORUM SOC KOR, V38, P299
   Yung-Cheng Ma, 2013, 2013 IEEE Third International Conference on Consumer Electronics - Berlin (ICCE-Berlin). Proceedings, P60, DOI 10.1109/ICCE-Berlin.2013.6698063
NR 57
TC 7
Z9 7
U1 4
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32273
EP 32310
DI 10.1007/s11042-021-11166-7
EA JUL 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678480300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Dalai, R
   Das, P
AF Dalai, Radhamadhab
   Das, Pritishree
TI Effective fine-grained feature extraction and classification of solid
   materials using hybrid region convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature points; BigData; Convolutional neural networks; FASTER-region
   CNN; And fine-grained based deep learning; Scale invariant feature
   transform
ID RECOGNITION
AB Difference between similar feature points is presented in the fine-grained classification, which depends on discriminative in extremely localized regions. Hence, the accurate localization of discriminative regions is the major challenge found in the fine-grained feature extraction and classification. The patch-based framework has been described to address this issue. The accurate patch localization is enhanced by the triplet of patches with the logical constraints, it minimnized the feature set. Therefore, the object bounding boxes are the only need for the proposed approach. This paper presents an effective fine-grained feature extraction and classification schemes for solid materials. The Fuzzy logic-Scale Invariant Feature Transform (FL-SIFT) is introduced for feature extraction. FL-SIFT based key points are taken for the classification is performed by hybrid Multilayer Perceptron with Faster Region Convolutional Neural Networks (MLP-Faster RCNN). A key advantage of fine-grained based MLP-Faster RCNN approach is, on average better in identification with FL-SIFT key points. The model is retrained to play out the recognition of four sorts of metal articles with the whole procedure taking 4 h time to clarify and prepare the new model per strong piece. The simulation is implemented on Python platform and the results are evaluated by several evaluation measures like specificity, accuracy, precision, f-measure, and recall. The performance outcomes are compared with the existing approaches and existing works. It shows that the proposed model achieved maximum outcomes than existing schemes in terms of accuracy 98.3%, Precision 96%, specificity 97.87% and it takes very low execution time 1.46 s.
C1 [Dalai, Radhamadhab] BIT, Dept Comp Sci & Engn, Ranchi, Bihar, India.
   [Das, Pritishree] Utkal Univ, Vani Vihar, Dept Psychol, Bhubaneswar, India.
C3 Birla Institute of Technology Mesra; Utkal University
RP Dalai, R (corresponding author), BIT, Dept Comp Sci & Engn, Ranchi, Bihar, India.
EM rdalai.teqip@bitmesra.ac.in
CR Baddeley D, 2018, ANNU REV BIOCHEM, V87, P965, DOI 10.1146/annurev-biochem-060815-014801
   Bindu CH, 2019, J ENG RES-KUWAIT, V7, P142
   Chau NL, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106486
   Chen M, 2017, IEEE ACCESS, V5, P8869, DOI 10.1109/ACCESS.2017.2694446
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Fang J, 2017, IEEE T INTELL TRANSP, V18, P1782, DOI 10.1109/TITS.2016.2620495
   Ge C, 2020, COMPUT IND, V121, DOI 10.1016/j.compind.2020.103232
   Goswami A, 2019, ARXIV PREPRINT ARXIV
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI [10.1109/WACV45572.2020.9093358, 10.1109/wacv45572.2020.9093358]
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Li A, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329075
   Li JQ, 2020, IEEE ACM T COMPUT BI, V17, P1546, DOI 10.1109/TCBB.2020.2965919
   Lin ZQ, 2019, IEEE ACCESS, V7, P11570, DOI 10.1109/ACCESS.2019.2891739
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Moorthy U, 2018, HCI CHALLENGES PRIVA, P95
   Pashaei A, 2020, J REAL-TIME IMAGE PR, V17, P1051, DOI 10.1007/s11554-019-00852-3
   Qiu HQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4171, DOI 10.1145/3394171.3413850
   Shariati M., 2019, Geomechanics and Engineering, V19, P473
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tian GZ, 2019, NEUROCOMPUTING, V345, P3, DOI 10.1016/j.neucom.2019.01.088
   Wang C, 2017, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2017.7858304
   Wei J, 2020, IEEE T INTELL TRANSP, V21, P1572, DOI 10.1109/TITS.2019.2910643
   Yan JQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030286
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yao Y., 2020, ARXIV PREPRINT ARXIV
   Yuan Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0496-6
   Zhang JS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072327
   Zhang L, 2015, SENSORS-BASEL, V15, P19937, DOI 10.3390/s150819937
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
NR 33
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32171
EP 32196
DI 10.1007/s11042-021-11189-0
EA JUL 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678476200001
DA 2024-07-18
ER

PT J
AU Jia, MH
   Gao, YB
   Li, S
   Yue, J
   Ye, M
AF Jia, Menghu
   Gao, Yanbo
   Li, Shuai
   Yue, Jian
   Ye, Mao
TI An explicit self-attention-based multimodality CNN in-loop filter for
   versatile video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile video coding; VVC; in-loop filter; CNN; attention
AB The newest video coding standard, versatile video coding (VVC), has just been published recently. While it greatly improves the performance over the last High Efficiency Video Coding (HEVC) standard, there are still blocking artifacts under the more flexible block partitioning structures. In order to reduce the blocking artifact and improve the quality of the reconstructed video frame, an explicit self-attention-based multimodality convolutional neural network (CNN) is proposed in this paper. It adaptively adjusts the restoration of different coding units (CU) according to the CU partition structure and texture of the reconstructed video frame, considering that the loss scales of different CUs can be quite different. The proposed method takes advantage of the CU partition map by using it as a different modality and combined with the attention mechanism. Moreover, the unfiltered reconstructed image is also used to enhance the attention branch, which forms an explicit self-attention model. Then a densely integrated multi-stage fusion is developed where the attention branch is densely fused to the main filtering CNN to adaptively adjust the overall image recovery scale. Thorough analysis on the proposed method is provided with ablation study on each module. Experimental results show that the proposed method achieves the state-of-the-art performance under all intra (AI) configuration, with 7.24% BD-rate savings on average compared with the VVC reference software (VTM).
C1 [Jia, Menghu; Yue, Jian; Ye, Mao] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Gao, Yanbo; Li, Shuai] Shandong Univ, Shandong, Peoples R China.
C3 University of Electronic Science & Technology of China; Shandong
   University
RP Gao, YB (corresponding author), Shandong Univ, Shandong, Peoples R China.
EM ybgao@sdu.edu.cn
RI Ye, Mao/G-8559-2012
OI Li, Shuai/0000-0002-9938-0917
FU National Key RAMP;D Program of China [2018YFE0203900]; National Natural
   Science Foundation of China [61901083, 62001092]; Project of Quzhou
   Municipal Government [2020D011]; SDU QILU Young Scholars program
FX This work was partly supported by the National Key R&D Program of China
   (2018YFE0203900), the National Natural Science Foundation of China (No.
   61901083 and 62001092), Project of Quzhou Municipal Government
   (2020D011), and SDU QILU Young Scholars program.
CR [Anonymous], 2019, 14 JVET M GEN SWITZ
   Birman R, 2020, MULTIMED TOOLS APPL, V79, P11699, DOI 10.1007/s11042-019-08572-3
   Bossen F, 2018, 12 JVET M MIC CN, P3
   Bross B, 2018, JVETL1001, P3
   Cavigelli L, 2017, IEEE IJCNN, P752, DOI 10.1109/IJCNN.2017.7965927
   Dai Y, 2017, MMM
   Ding DD, 2020, IEEE T CIRC SYST VID, V30, P1871, DOI 10.1109/TCSVT.2019.2935508
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Elharrouss O, 2020, NEURAL PROCESS LETT, V51, P2007, DOI 10.1007/s11063-019-10163-0
   Fu CM, 2012, IEEE T CIRC SYST VID, V22, P1755, DOI 10.1109/TCSVT.2012.2221529
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He XY, 2018, IEEE IMAGE PROC, P216, DOI 10.1109/ICIP.2018.8451086
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang ZL, 2021, INT ARCH ALLERGY IMM, V182, P388, DOI 10.1159/000511612
   Jia CM, 2019, IEEE T IMAGE PROCESS, V28, P3343, DOI 10.1109/TIP.2019.2896489
   Kang J, 2017, IEEE IMAGE PROC, P26, DOI 10.1109/ICIP.2017.8296236
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai PR, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P173, DOI [10.1109/aicas48895.2020.9073980, 10.1109/AICAS48895.2020.9073980]
   Li C, 2017, IEEE IMAGE PROC, P4577, DOI 10.1109/ICIP.2017.8297149
   Li DW, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/iscas.2019.8702443
   Li S, 2019, FULLY TRAINABLE NETW
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Ma D, 2020, BVI DVC TRAINING DAT
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mishkin D, 2016, INT C LEARNING REPRE
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tsai CY, 2013, IEEE J-STSP, V7, P934, DOI 10.1109/JSTSP.2013.2271974
   Wang MZ, 2019, IEEE ACCESS, V7, P145214, DOI 10.1109/ACCESS.2019.2944473
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wang ZX, 2021, MULTIMED TOOLS APPL, V80, P2441, DOI 10.1007/s11042-020-09231-8
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang SF, 2020, IEEE T CIRC SYST VID, V30, P1888, DOI 10.1109/TCSVT.2019.2938192
   Zhang YB, 2018, IEEE T IMAGE PROCESS, V27, P3827, DOI 10.1109/TIP.2018.2815841
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 44
TC 5
Z9 5
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42497
EP 42511
DI 10.1007/s11042-021-11214-2
EA JUL 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000677229000002
DA 2024-07-18
ER

PT J
AU Niu, PP
   Tian, J
   Wu, QC
   Zhang, C
   Wang, XY
AF Niu, Pan-Pan
   Tian, Jing
   Wu, Qiu-Cheng
   Zhang, Can
   Wang, Xiang-Yang
TI Statistical texture image retrieval in DD-DTCWT domain using magnitudes
   and relative phases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Textured image retrieval; DD-DTCWT; Magnitude and relative phase; Cauchy
   and Vonn distributions; Kullback-Leibler divergences
ID MODEL; CLASSIFICATION; DESCRIPTOR; FEATURES
AB Statistical models of transform coefficients are an efficient way to discriminate between texture classes. Statistical-based approaches provide a natural way to solve texture retrieval problem. In this paper, we proposed a new framework for textured image retrieval in DD-DTCWT (Double-density dual-tree complex wavelet transform) domain, which is based on the mixture of Cauchy and Vonn statistical models. Firstly, the image is decomposed into frequency subbands using DD-DTCWT, and the amplitude and relative phase of DD-DTCWT coefficients are computed. Secondly, Cauchy and Vonn distributions are employed respectively to capture the statistical characteristics of the magnitude and relative phase of DD-DTCWT coefficients, and the Cauchy and Vonn model parameters are utilized to construct a compact texture image feature space. Finally, image similarity measurement is accomplished by using closed-form solutions for the Kullback-Leibler divergences between the Cauchy and Vonn statistical models. Experimental results demonstrate the high efficiency of our textured image retrieval scheme, which can provide better retrieval rates and lower computational cost, in comparison with the state-of-the-art approaches recently proposed in the literature.
C1 [Niu, Pan-Pan; Tian, Jing; Wu, Qiu-Cheng; Zhang, Can; Wang, Xiang-Yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Niu, PP (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM niupanpan3333@163.com
RI Niu, Panpan/Q-9953-2017
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Key Scientific Research
   Project of Liaoning Provincial Education Department (LZ2019001), and
   Natural Science Foundation of Liaoning Province (2019-ZD-0468).
CR Al-Marzouqi H, 2019, SIGNAL PROCESS-IMAGE, V76, P252, DOI 10.1016/j.image.2019.04.015
   [Anonymous], 2018, SALZBURG TEXTURES
   [Anonymous], 2018, VISION TEXTURE
   [Anonymous], 2018, BRODATZ TEXTURE DATA
   Baradarani A, 2013, PATTERN RECOGN, V46, P57, DOI 10.1016/j.patcog.2012.06.007
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Chaker A, 2018, MULTIMED TOOLS APPL, V77, P1, DOI 10.1007/s11042-016-4205-5
   de Ves E, 2014, PATTERN RECOGN, V47, P2925, DOI 10.1016/j.patcog.2014.03.004
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Engin MA, 2019, MULTIMED TOOLS APPL, V78, P6581, DOI 10.1007/s11042-018-6368-8
   Karine A, 2018, J VIS COMMUN IMAGE R, V50, P27, DOI 10.1016/j.jvcir.2017.11.006
   Kwitt R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P33, DOI 10.1145/1411328.1411337
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li CR, 2015, IEEE T IMAGE PROCESS, V24, P2344, DOI 10.1109/TIP.2015.2422575
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Majumdar I, 2019, STUD COMPUT INTELL, V776, P405, DOI 10.1007/978-3-662-57277-1_17
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Morand C, 2010, SIGNAL PROCESS-IMAGE, V25, P450, DOI 10.1016/j.image.2010.04.004
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Rallabandi VR, 2008, SIGNAL PROCESS, V88, P2593, DOI 10.1016/j.sigpro.2008.04.019
   Rami H, 2016, SIGNAL PROCESS-IMAGE, V42, P45, DOI 10.1016/j.image.2016.01.005
   Sana JK, 2018, IET IMAGE PROCESS, V12, P2065, DOI 10.1049/iet-ipr.2018.5604
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   Vasconcelos N, 1997, IEEE DATA COMPR CONF, P121, DOI 10.1109/DCC.1997.581989
   Vo A, 2011, SIGNAL PROCESS, V91, P114, DOI 10.1016/j.sigpro.2010.06.014
   Vo A, 2010, SIGNAL PROCESS-IMAGE, V25, P28, DOI 10.1016/j.image.2009.09.003
   Yang HY, 2019, SOFT COMPUT, V23, P4749, DOI 10.1007/s00500-018-3127-8
   [杨娟 Yang Juan], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P2856
   Yu LH, 2018, SIGNAL IMAGE VIDEO P, V12, P247, DOI 10.1007/s11760-017-1152-1
   Yuan H, 2010, IEEE T CIRC SYST VID, V20, P439, DOI 10.1109/TCSVT.2009.2031396
NR 34
TC 3
Z9 3
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29893
EP 29913
DI 10.1007/s11042-021-11124-3
EA JUL 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673928000004
DA 2024-07-18
ER

PT J
AU Wu, Q
   Guo, YJ
   Hou, JC
   Yuan, JJ
   Kong, F
   Lyu, WH
   Liu, Z
   Yang, WJ
   Liang, QQ
AF Wu, Qi
   Guo, YinJing
   Hou, JiaChen
   Yuan, JiaoJiao
   Kong, Fang
   Lyu, WenHong
   Liu, Zhen
   Yang, WenJian
   Liang, QuanQuan
TI Underwater optical image processing based on double threshold judgements
   and optimized red dark channel prior method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater images; Image restoration; Optimized red dark channel prior;
   Double threshold judgments; Contrast indicator
ID RESTORATION; ENHANCEMENT; DEPENDENCE; QUALITY; COLOR; MODEL
AB Underwater images are prone to suffer from color distortion and low visibility because of the strong light attenuation. The traditional dark channel prior (DCP) method tends to fail when used for underwater image restoration. By exploring the differences in light attenuation between atmosphere and water, we propose an innovative image restoration method-optimized red dark channel prior (ORDCP) which adds a valid contrast indicator. In addition, we set double threshold judgments to determine the main color tone and calculate red channel transmission map. After getting the two estimated parameters including transmission maps and background light, we can restore underwater images using conventional underwater imaging model. The subjective evaluations indicate that the algorithm we proposed has better performance in terms of saturation, contrast and images edge details. What's more, the results of objective evaluation metrics show that the performances maximally increase by 32.32% in underwater images such as the ship and stone. The conclusion can be drawn that the proposed method is able to remove the noise and blur caused by complicated underwater environment and performs favorably against the state-of-the-art algorithms.
C1 [Wu, Qi; Guo, YinJing; Hou, JiaChen; Yuan, JiaoJiao; Kong, Fang; Liu, Zhen; Yang, WenJian; Liang, QuanQuan] Shandong Univ Sci & Technol, Coll Elect Informat Engn, Qingdao, Peoples R China.
   [Lyu, WenHong] Shandong Univ Sci & Technol, Coll Transportat, Qingdao, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Guo, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Elect Informat Engn, Qingdao, Peoples R China.
EM gyjlwh004@126.com
RI Wu, Qi/ABD-6304-2021
OI Wu, Qi/0000-0003-3631-256X; kong, fang/0000-0003-2539-3181
FU National Natural Science Foundation of China [61471224]; Shandong
   Province Key R&D Program (Public Welfare Project) [2018GHY115022]
FX The research work is supported by the The National Natural Science
   Foundation of China(61801270), The National Natural Science Foundation
   of China (61471224) and Shandong Province Key R&D Program (Public
   Welfare Project) (2018GHY115022). Many thanks to the anonymous reviewers
   for their constructive comments and valuable suggestions.
CR Amer KO, 2019, OPT EXPRESS, V27, P621, DOI 10.1364/OE.27.000621
   [Anonymous], 2017, PROC C LASERS ELECTR
   Birk, 2018, IEEE OCEANS, V1, P1
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chang, 2020, IEEE ACCESS, V86, P50
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Cheng CY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P110, DOI 10.1109/ICSIPA.2015.7412173
   Dai CG, 2020, OPT LASER TECHNOL, V123, DOI 10.1016/j.optlastec.2019.105947
   Gaya JFD, 2019, IEEE COMPUT GRAPH, V39, P71, DOI 10.1109/MCG.2018.2881388
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gillis DB, 2020, IEEE J-STARS, V13, P1798, DOI 10.1109/JSTARS.2020.2969013
   GORDON HR, 1989, LIMNOL OCEANOGR, V34, P1484, DOI 10.4319/lo.1989.34.8.1484
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Guo QW, 2017, J OCEAN U CHINA, V16, P757, DOI 10.1007/s11802-017-3242-7
   Han PL, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106256
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hou G, 2019, J VIS COMMUN IMAGE R, P1
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Joel D.O, 2016, GEN PARTICIPATIVE ME
   Liu YZ, 2020, LASER OPTOELECTRON, P1, DOI DOI 10.1080/02678292.2020.1847333
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Ma XM, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053033
   Mathias A, 2019, OPTIK, V192, DOI 10.1016/j.ijleo.2019.06.025
   Nakatani T, 2013, 2013 OCEAN, P1
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Pérez J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164580
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   [汤忠强 Tang Zhongqiang], 2018, [机器人, Robot], V40, P222
   Xu H, 2020, J OCEAN U CHINA, V19, P551, DOI 10.1007/s11802-020-4003-6
   Yang AP, 2018, J ELECTRON INF TECHN, V40, P298, DOI 10.11999/JEIT170460
   Yang M, 2020, IEEE J OCEANIC ENG, V45, P521, DOI 10.1109/JOE.2018.2886093
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yang S., 2020, IEEE ACCESS, V1, P318
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
NR 38
TC 6
Z9 7
U1 0
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29985
EP 30002
DI 10.1007/s11042-021-11200-8
EA JUL 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673800700001
DA 2024-07-18
ER

PT J
AU Wongtanawijit, R
   Khaorapapong, T
AF Wongtanawijit, Rattachai
   Khaorapapong, Thanate
TI Nighttime rubber tapping line detection in near-range images Near-Range
   tapping line shadow acquisition technique with tapping line detection
   algorithm for automatic rubber tapping robot in nighttime
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hevea brasiliensis; Rubber tapping; Image acquisition; Image
   differencing; Image pssrocessing
ID APPLE DETECTION; SEGMENTATION
AB Despite many applications of computer vision for agricultural harvesting robots that focus on fruit detection, some agricultural applications are not well-developed, especially for natural rubber latex production. Tapping is a method to harvest rubber latex from the natural rubber trees (Hevea brasiliensis) which involves operating at night in Southern Thailand. This article presents a near range machine vision for the rubber tapping automation that detects the tapping line in the near-range images. Our acquisition tool integrates an RGB-D camera with assisting lights for capturing images under low light conditions. Our tapping line detection algorithm extracts the tapping path shadow regions by the image differencing with connected component labeling algorithm of two grayscale images from different lighting directions. We adopted the sub-array searching technique to detect the tapping line that agreed to the downward tapping system. Detection accuracy archived the highest at 90.1% using the intersection over union ratio of 0.5 evaluation criteria between the pre-defined ground truth and the detected bounding boxes. Distance errors of the detected tapping lines are also measured using the average discrete Hausdorff Distance. Our algorithm produces an error distance of 13 pixels or 5.5-7.8 millimeters by the camera working-geometry. Our techniques feasibly support the generation of a 3D tapping path in further development.
C1 [Wongtanawijit, Rattachai; Khaorapapong, Thanate] Prince Songkla Univ, Dept Comp Engn, POB 2 Kohong, Hat Yai 90112, Songkhla, Thailand.
C3 Prince of Songkla University
RP Wongtanawijit, R (corresponding author), Prince Songkla Univ, Dept Comp Engn, POB 2 Kohong, Hat Yai 90112, Songkhla, Thailand.
EM rattachai.gov@gmail.com; kthanate@coe.psu.ac.th
RI Wongtanawijit, Rattachai/GLT-5053-2022
OI Wongtanawijit, Rattachai/0000-0003-2214-0461
CR Abraham P, 1992, NATURAL RUBBER, V263
   Alt H, 2008, INT J COMPUT GEOM AP, V18, P307, DOI 10.1142/S0218195908002647
   An Feng LW, 2018, KIND INTEGRATED AUTO
   An Feng LW, 2018, AUTOMATIC INTEGRATED
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chambon B, 2014, ADV MATER RES-SWITZ, V844, P34, DOI 10.4028/www.scientific.net/AMR.844.34
   Chantuma P, 2011, FIELD CROP RES, V121, P416, DOI 10.1016/j.fcr.2011.01.013
   Czuni L, 2018, 2018 25 INT C SYST S, P1
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Davis JW, 2007, INT J COMPUT VISION, V71, P161, DOI [10.1007/s11263-006-4121-7, 10.1007/sl1263-006-4121-7]
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fernández R, 2018, IEEE ACCESS, V6, P35512, DOI 10.1109/ACCESS.2018.2851376
   Fu LS, 2015, INT J AGR BIOL ENG, V8, P52, DOI 10.3965/j.ijabe.20150804.1576
   Gongal A, 2016, COMPUT ELECTRON AGR, V120, P26, DOI 10.1016/j.compag.2015.10.022
   Grana C, 2009, LECT NOTES COMPUT SC, V5716, P816, DOI 10.1007/978-3-642-04146-4_87
   Guanyu Y, 2020, ROBOT STARTS ON SITE
   Hamuda E, 2016, COMPUT ELECTRON AGR, V125, P184, DOI 10.1016/j.compag.2016.04.024
   Häni N, 2020, IEEE ROBOT AUTOM LET, V5, P852, DOI 10.1109/LRA.2020.2965061
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huttenlocher D. P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P654, DOI 10.1109/CVPR.1992.223209
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Kunghun W, 2018, 2018 INT C ENG APPL, P1
   Leu A, 2017, IEEE-ASME T MECH, V22, P2401, DOI 10.1109/TMECH.2017.2735861
   Limin Wu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1550, DOI 10.1109/FSKD.2012.6234125
   Linker R, 2015, COMPUT ELECTRON AGR, V114, P154, DOI 10.1016/j.compag.2015.04.005
   Liu XY, 2016, COMPUT ELECTRON AGR, V122, P118, DOI 10.1016/j.compag.2016.01.023
   Nair KPP, 2010, ELSEV INSIGHT, P237, DOI 10.1016/B978-0-12-384677-8.00008-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rüfenacht D, 2014, IEEE T PATTERN ANAL, V36, P1672, DOI 10.1109/TPAMI.2013.229
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Silwal A, 2017, J FIELD ROBOT, V34, P1140, DOI 10.1002/rob.21715
   Soumya SJ, 2016, IEEE REG 10 HUMANIT
   Susanto H, 2019, IOP CONF SER-MAT SCI, V506, DOI 10.1088/1757-899X/506/1/012002
   Vijayakumar K, 2009, J RUBBER RES
   Wang CL, 2017, OPTIK, V131, P626, DOI 10.1016/j.ijleo.2016.11.177
   Wang DD, 2020, IEEE ACCESS, V8, P26911, DOI 10.1109/ACCESS.2020.2971524
   Wongtanawijit Rattachai, 2018, 2018 15th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P126, DOI 10.1109/ECTICon.2018.8619863
   Xiang R, 2018, COMPUT ELECTRON AGR, V154, P434, DOI 10.1016/j.compag.2018.09.034
   Yang CH, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P398, DOI 10.1109/ICRAE.2017.8291418
   Yatawara YAI, 2019, ENG-J INST ENG SRI L, V52, P27, DOI 10.4038/engineer.v52i2.7351
   Zhang BWX, 2017, ONE KIND RUBBER TAPP
   Zhang CL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092136
   Zhang ShunLu Zhang ShunLu, 2018, International Agricultural Engineering Journal, V27, P110
   Zhao YS, 2016, COMPUT ELECTRON AGR, V127, P311, DOI 10.1016/j.compag.2016.06.022
NR 48
TC 6
Z9 6
U1 8
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29401
EP 29422
DI 10.1007/s11042-021-11140-3
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000667012400001
DA 2024-07-18
ER

PT J
AU Gupta, SK
AF Gupta, Sanjay Kumar
TI Reduction of covariate factors from Silhouette image for robust gait
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Silhouette images; Covariate factor; Gait energy image (GEI); Pose
   energy image (PEI); Video surveillance
ID ENERGY IMAGE; IDENTIFICATION; REPRESENTATION; EXTRACTION
AB Humans can be identified through the way they walk, according to medical studies, each person has an almost unique way of walking. Over the past decade, numerous gait recognition approach has been presented by researchers through which human can be identified, but gait recognition can be affected by a variety of wearable objects such as clothes, carry bags, shoes and others. The silhouette-image with invariant features can be obtained if the wearer objects are removed from it. The Generator Advisory Network (GAN) model is used to remove covariate objects from the silhouette images. The main challenge of this approach to make input-output pairs of frames to train GAN model, for this silhouette image has to mapped with another silhouette image with same pose. Since pose analysis has been done in Pose Energy Image (PEI) approach so PEI is used to label the frames with a specific key pose. After labelling silhouette frames, pair them with the recognition of same pose and train the GAN model. The trained GAN model used to generate a new gait invariant feature which is named as Covariate Factors Omitted Silhouette Image (CFOSI). For cross-validation of the proposed approach, three publically available datasets are used, where proposed approach found 5.50, 4.71 and 17.88 percentage more accurate results with respect to CASIA B, CASIA C and TUM-GAID in case of Gait Energy Image (GEI). We can conclude that after the omission of covariate objects from silhouette images our approach performance is more accurate than others.
C1 [Gupta, Sanjay Kumar] Banaras Hindu Univ, Indian Inst Technol, Varanasi, India.
C3 Banaras Hindu University (BHU); Indian Institute of Technology System
   (IIT System); Indian Institute of Technology BHU Varanasi (IIT BHU
   Varanasi)
RP Gupta, SK (corresponding author), Banaras Hindu Univ, Indian Inst Technol, Varanasi, India.
EM sanjaykrgupta.rs.cse17@itbhu.ac.in
RI Gupta, Sanjay Kumar/AAS-6960-2020
OI Gupta, Sanjay Kumar/0000-0003-3171-9926
CR Aggarwal H, 2018, IEEE T COGN DEV SYST, V10, P397, DOI 10.1109/TCDS.2017.2658674
   Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   [Anonymous], 2019, DISCRIMINANT ANAL
   Ariyanto G., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117582
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bodor R, 2009, IMAGE VISION COMPUT, V27, P1194, DOI 10.1016/j.imavis.2008.11.008
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Castro FM, 2020, NEURAL COMPUT APPL, V32, P14173, DOI 10.1007/s00521-020-04811-z
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Chaurasia P, 2017, IEEE T HUM-MACH SYST, V47, P751, DOI 10.1109/THMS.2017.2706658
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   de Lima VC, 2019, LECT NOTES COMPUT SC, V11896, P719, DOI 10.1007/978-3-030-33904-3_68
   Deng MQ, 2019, IEEE T CIRC SYST VID, V29, P3636, DOI 10.1109/TCSVT.2018.2883449
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Gupta SK, 2021, NEUROCOMPUTING, V454, P76, DOI 10.1016/j.neucom.2021.04.113
   Gupta SK, 2021, MULTIMED TOOLS APPL, V80, P35903, DOI 10.1007/s11042-020-10071-9
   Gupta SK, 2020, ADV INTELLIGENT SYST, V937
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Khamsemanan N, 2018, IEEE T INF FOREN SEC, V13, P119, DOI 10.1109/TIFS.2017.2738611
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Lam THW, 2006, LECT NOTES COMPUT SC, V3832, P612
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee H, 2009, INT J CONTROL AUTOM, V7, P638, DOI [10.1007/S12555-009-0414-2, 10.1007/s12555-009-0414-2]
   Liu JY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P663
   Makihara Y, 2017, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR.2017.718
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Schott JR., 2002, J AM STAT ASSOC, V97, P657, DOI [10.1198/jasa.2002.s479, DOI 10.1198/JASA.2002.S479]
   Seber GA, 2009, BOOK SERIES WILEY SE, V252, DOI [10.1002/9780470316641, DOI 10.1002/9780470316641]
   Shiraga K, 2016, INT CONF BIOMETR
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Tan DL, 2006, INT C PATT RECOG, P1000
   Uddin Md Zasim, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0041-z
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Xue ZJ, 2010, PATTERN RECOGN, V43, P2904, DOI 10.1016/j.patcog.2010.03.011
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2019, PATTERN RECOGN, V87, P179, DOI 10.1016/j.patcog.2018.10.019
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang KH, 2019, PROC CVPR IEEE, P4695, DOI 10.1109/CVPR.2019.00483
NR 50
TC 3
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 36033
EP 36058
DI 10.1007/s11042-021-10941-w
EA JUN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000663494600001
DA 2024-07-18
ER

PT J
AU Pham, C
   Nguyen, L
   Nguyen, A
   Nguyen, N
   Nguyen, V
AF Pham, Cuong
   Nguyen, Linh
   Nguyen, Anh
   Nguyen, Ngon
   Nguyen, Van-Toi
TI Combining skeleton and accelerometer data for human fine-grained
   activity recognition and abnormal behaviour detection with deep temporal
   convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Multi-modal; Wearable sensor; Kinect;
   Skeleton; Acceleration; Data fusion; Temporal convolutional network
ID FUSION
AB Single sensing modality is widely adopted for human activity recognition (HAR) for decades and it has made a significant stride. However, it often suffers from challenges such as noises, obstacles, or dropped signals, which might negatively impact on the recognition performance. In this paper, we propose a multi-sensing modality framework for human fine-grained activity recognition and abnormal behaviour detection by combining skeleton and acceleration data at feature level (so-called feature-level fusion). Firstly, deep temporal convolutional networks (TCN), consisting of the dilated causal convolution components, are utilized for feature learning and handling temporal properties. The feature map learnt and represented with convolutional layers in TCN is fed into two fully connected layers for the prediction. Secondly, we conduct an empirical experiment to verify our proposed method. Experimental results have shown that the proposed method could achieve 83% F1-score and surpassed several single modality models as well as early and late fusion methods on the Continuous Multimodal Multi-view Dataset of Human Fall Dataset (CMDFALL), comprised of 20 fine-grained normal and abnormal activities collected from 50 subjects. Moreover, our proposed architecture achieves 96.98% accuracy on the UTD-MHAD dataset, which has 8 subjects and 27 activities. These results indicate the effectiveness of our proposed method for the classification of human fine-grained normal and abnormal activities as well as the potential for HAR-based situated service applications.
C1 [Pham, Cuong; Nguyen, Linh; Nguyen, Anh; Nguyen, Ngon] Posts & Telecommun Inst Technol, Hanoi, Vietnam.
   [Nguyen, Linh] Thai Nguyen Coll Econ & Finance, Thai Nguyen, Vietnam.
   [Nguyen, Van-Toi] AA Green Phoenix Grp JSC, PHENIKAA Res & Technol Inst PRATI, 167 Hoang Ngan, Hanoi 11313, Vietnam.
   [Nguyen, Van-Toi] PHENIKAA Univ, Fac Elect & Elect Engn, Hanoi 12116, Vietnam.
RP Nguyen, V (corresponding author), AA Green Phoenix Grp JSC, PHENIKAA Res & Technol Inst PRATI, 167 Hoang Ngan, Hanoi 11313, Vietnam.; Nguyen, V (corresponding author), PHENIKAA Univ, Fac Elect & Elect Engn, Hanoi 12116, Vietnam.
EM toi.nguyenvan@phenikaa-uni.edu.vn
RI Nguyen, Duc-Anh/JRX-4112-2023
OI Nguyen, Duc-Anh/0000-0001-8613-6854
FU Vietnam Ministry of Education and Training [CT2020.02, BKA.02]
FX This research was funded by the Vietnam Ministry of Education and
   Training under grant number CT2020.02.BKA.02.
CR Aguileta AA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173808
   Ahmad Z, 2020, IEEE SENS J, V20, P1445, DOI 10.1109/JSEN.2019.2947446
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Bai S., 2018, CoRR
   Chen CH, 2019, PROC CVPR IEEE, P10534, DOI 10.1109/CVPR.2019.01079
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Pham C, 2017, INT CONF KNOWL SYS, P269, DOI 10.1109/KSE.2017.8119470
   Dawar N, 2018, IEEE SENS J, V18, P9660, DOI 10.1109/JSEN.2018.2872862
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Gao Y, 2019, IEEE IMTC P, P177, DOI [10.1109/i2mtc.2019.8826970, 10.1145/3314399]
   HOANG VN, 2019, J CHEM INF MODEL
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoey J, 2011, PERVASIVE MOB COMPUT, V7, P299, DOI 10.1016/j.pmcj.2010.11.007
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Imran J, 2020, J AMB INTEL HUM COMP, V11, P189, DOI 10.1007/s12652-019-01239-9
   Jang E., 2016, ARXIV161101144
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Khan A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1155, DOI 10.1145/2750858.2807534
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Liang CW, 2020, IEEE ACCESS, V8, P39920, DOI 10.1109/ACCESS.2020.2976496
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu K, 2014, IEEE SENS J, V14, P1898, DOI 10.1109/JSEN.2014.2306094
   Liu L., 2019, ARXIV190803265
   Luo F, 2020, IEEE INTERNET THINGS, V7, P7432, DOI 10.1109/JIOT.2020.2984544
   Maddison Chris J, 2016, ARXIV161100712
   Mannini A, 2019, IEEE J BIOMED HEALTH, V23, P1585, DOI 10.1109/JBHI.2018.2869779
   Memmesheimer R, 2020, IEEE INT C INT ROBOT, P10394, DOI 10.1109/IROS45743.2020.9341699
   Münzner S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P158, DOI 10.1145/3123021.3123046
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Tran TH, 2018, INT C PATT RECOG, P1947, DOI 10.1109/ICPR.2018.8546308
   Nguyen TN, 2018, INT CONF KNOWL SYS, P50, DOI 10.1109/KSE.2018.8573421
   Um T. T., 2017, P 19 ACM INT C MULTI, P216, DOI DOI 10.1145/3136755.3136817
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Yu Guan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090076
NR 36
TC 10
Z9 10
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28919
EP 28940
DI 10.1007/s11042-021-11058-w
EA JUN 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000661366700001
DA 2024-07-18
ER

PT J
AU Kumar, N
   Chakravarti, AK
   Singh, Y
AF Kumar, Neeraj
   Chakravarti, Ashish Kumar
   Singh, Yashveer
TI Synthesis and analysis of prediction errors and error fusion based prior
   for prediction algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Error fusion; Maximum-a-posteriori; Prediction
   algorithm
ID QUALITY ASSESSMENT; IMAGE
AB In this paper, we propose a simple and efficient post-processing algorithm to improve the accuracy of prediction based, computationally simple image reconstruction algorithms. The proposed algorithm works where there is a need to restore the missing pixels (such as interpolation, deinterlacing, sub-pixel rendering, denoising, and demosaicing). In this work, we formulate the post-processing stage as a Maximum-a-Posteriori (MAP) estimation problem. Interestingly, we find that prediction errors of a missing pixel and its neighboring pixels are also correlated, which can be utilized to improve the prediction accuracy. Therefore, we propose an efficient way of calculating prior information by estimating synthetically created prediction errors from the four connected neighbors and fuse these prediction errors based on the corresponding activity levels. Experiments demonstrate that the proposed method can significantly improve the performance of existing computationally simple prediction algorithms in terms of both objective and subjective quality with a slight increment of the computational requirement.
C1 [Kumar, Neeraj] Nagarjuna Coll Engn & Technol, Dept Elect & Commun, Bengluru, Karnataka, India.
   [Chakravarti, Ashish Kumar] Pranveer Singh Inst Technol, Dept Informat Technol, Kanpur, UP, India.
   [Singh, Yashveer] ABES Engn Collage, Dept Informat Technol, Gzaziabad, UP, India.
RP Kumar, N (corresponding author), Nagarjuna Coll Engn & Technol, Dept Elect & Commun, Bengluru, Karnataka, India.
EM neeraj.mohiwal@gmail.com; ashish.me08@gmail.com;
   yashveersingh85@gmail.com
RI Kumar, Neeraj/L-3500-2016
OI Kumar, Neeraj/0000-0002-3020-3947; Jain, NeerajKumar/0000-0001-7010-4209
CR Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   Chen PY, 2007, IEICE T INF SYST, VE90D, P606, DOI 10.1093/ietisy/e90-d.2.606
   Chen PY, 2008, IEEE SIGNAL PROC LET, V15, P833, DOI 10.1109/LSP.2008.2005047
   Chen X, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.107402
   Dai JJ, 2013, IEEE T CIRC SYST VID, V23, P128, DOI 10.1109/TCSVT.2012.2203203
   Hu MH, 2020, IEEE T BROADCAST, V66, P140, DOI 10.1109/TBC.2019.2901388
   Hung KW, 2012, IET IMAGE PROCESS, V6, P877, DOI 10.1049/iet-ipr.2011.0050
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Jakhetiya Vinit, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5819, DOI 10.1109/ICASSP.2014.6854719
   Jakhetiya V, 2017, IEEE T IND INFORM
   Jakhetiya V, 2018, IEEE T IND INFORM, V14, P652, DOI 10.1109/TII.2017.2756666
   Jakhetiya V, 2017, IEEE T MULTIMEDIA, V19, P93, DOI 10.1109/TMM.2016.2609419
   Jakhetiya V, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P201, DOI 10.1109/ICDSP.2015.7251859
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Khan S, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.10.103108
   Kim W, 2007, IEEE T CONSUM ELECTR, V53, P1036, DOI 10.1109/TCE.2007.4341583
   Liu XM, 2014, IEEE T IMAGE PROCESS, V23, P1491, DOI 10.1109/TIP.2014.2303638
   Paudyal P, 2019, IEEE T BROADCAST, V65, P152, DOI 10.1109/TBC.2019.2892092
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Wang J, 2014, IEEE T CIRC SYST VID, V24, P39, DOI 10.1109/TCSVT.2013.2280068
   Wang J, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
NR 26
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19835
EP 19847
DI 10.1007/s11042-021-11144-z
EA JUN 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000661366900001
DA 2024-07-18
ER

PT J
AU Wang, J
   Lu, SY
   Wang, SH
   Zhang, YD
AF Wang, Jian
   Lu, Siyuan
   Wang, Shui-Hua
   Zhang, Yu-Dong
TI A review on extreme learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE extreme learning machine; neural network; medical imaging;
   classification; optimization; clustering; regression
ID RESTRICTED BOLTZMANN MACHINE; ARTIFICIAL NEURAL-NETWORK; FAULT-DIAGNOSIS
   METHOD; OBJECT RECOGNITION; FEATURE-SELECTION; TUMOR DETECTION; ELM;
   CLASSIFICATION; ALGORITHM; PREDICTION
AB Extreme learning machine (ELM) is a training algorithm for single hidden layer feedforward neural network (SLFN), which converges much faster than traditional methods and yields promising performance. In this paper, we hope to present a comprehensive review on ELM. Firstly, we will focus on the theoretical analysis including universal approximation theory and generalization. Then, the various improvements are listed, which help ELM works better in terms of stability, efficiency, and accuracy. Because of its outstanding performance, ELM has been successfully applied in many real-time learning tasks for classification, clustering, and regression. Besides, we report the applications of ELM in medical imaging: MRI, CT, and mammogram. The controversies of ELM were also discussed in this paper. We aim to report these advances and find some future perspectives.
C1 [Wang, Jian; Lu, Siyuan; Zhang, Yu-Dong] Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua; Zhang, Yu-Dong] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Wang, Shui-Hua] Univ Leicester, Dept Cardiovasc Sci, Leicester LE1 7RH, Leics, England.
   [Wang, Shui-Hua; Zhang, Yu-Dong] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.
   [Wang, Shui-Hua] Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
C3 University of Leicester; Henan Polytechnic University; University of
   Leicester; King Abdulaziz University; Loughborough University
RP Zhang, YD (corresponding author), Univ Leicester, Sch Informat, Leicester LE1 7RH, Leics, England.; Wang, SH; Zhang, YD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Wang, SH (corresponding author), Univ Leicester, Dept Cardiovasc Sci, Leicester LE1 7RH, Leics, England.; Wang, SH; Zhang, YD (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Syst, Jeddah 21589, Saudi Arabia.; Wang, SH (corresponding author), Loughborough Univ, Sch Architecture Bldg & Civil Engn, Loughborough LE11 3TU, Leics, England.
EM jw830@le.ac.uk; sl672@le.ac.uk; shuihuawang@ieee.org;
   yudongzhang@ieee.org
RI Wang, Shuihua/G-7326-2016; Lu, Siyuan/ABE-7949-2020; Zhang,
   Yudong/I-7633-2013
OI Lu, Siyuan/0000-0001-6720-1323; Zhang, Yudong/0000-0002-4870-1493
FU Henan Key Research and Development Project [182102310629]; National Key
   Research and Development Plan [2017YFB1103202]; Guangxi Key Laboratory
   of Trusted Software [kx201901]; International Exchanges Cost Share Royal
   Society [RP202G0230]; Hope Foundation for Cancer Research [RM60G0680];
   Medical Research Council Confidence in Concept Award, UK [MC_PC_17171];
   Fundamental Research Funds for the Central Universities [CDLS-2020-03];
   Key Laboratory of Child Development and Learning Science (Southeast
   University), Ministry of Education
FX This work was supported by Henan Key Research and Development Project
   (182102310629), National Key Research and Development Plan
   (2017YFB1103202), Guangxi Key Laboratory of Trusted Software (kx201901),
   International Exchanges Cost Share Royal Society (RP202G0230), Hope
   Foundation for Cancer Research (RM60G0680); Medical Research Council
   Confidence in Concept Award, UK (MC_PC_17171); Fundamental Research
   Funds for the Central Universities (CDLS-2020-03); Key Laboratory of
   Child Development and Learning Science (Southeast University), Ministry
   of Education.
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Alcin OF, 2016, 2016 21ST INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P1160, DOI 10.1109/MMAR.2016.7575302
   Alshamiri AK, 2016, SOFT COMPUT, V20, P3163, DOI 10.1007/s00500-015-1686-5
   Bai Z, 2015, PROCEDIA COMPUT SCI, V53, P391, DOI 10.1016/j.procs.2015.07.316
   Bhat AU, 2008, IND ENG CHEM RES, V47, P920, DOI 10.1021/ie0704647
   Bian YQ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/917139
   Broomhead D. S., 1988, Complex Systems, V2, P321
   Bu YD, 2015, ASTRON ASTROPHYS, V576, DOI 10.1051/0004-6361/201424194
   Cai ZN, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.031
   Cao JW, 2012, NEURAL PROCESS LETT, V36, P285, DOI 10.1007/s11063-012-9236-y
   Cao JW, 2012, INFORM SCIENCES, V185, P66, DOI 10.1016/j.ins.2011.09.015
   Cao LD, 2018, J HAZARD MATER, V352, P17, DOI 10.1016/j.jhazmat.2018.03.025
   Chacko BP, 2012, INT J MACH LEARN CYB, V3, P149, DOI 10.1007/s13042-011-0049-5
   Chen K, 2017, NEUROCOMPUTING, V230, P345, DOI 10.1016/j.neucom.2016.12.029
   Chen L, 2018, MOL GENET GENOMICS, V293, P137, DOI 10.1007/s00438-017-1372-7
   Chen L, 2017, CHIN CONT DECIS CONF, P2121, DOI 10.1109/CCDC.2017.7978866
   Chen ST, 2018, COMPLEXITY, DOI 10.1155/2018/6264124
   Chen YM, 2019, IEEE T CYBERNETICS, V49, P1909, DOI 10.1109/TCYB.2018.2816981
   Chen ZY, 2013, CONF CYBERN INTELL S, P78, DOI 10.1109/ICCIS.2013.6751582
   Cheng XY, 2017, MEMET COMPUT, V9, P199, DOI 10.1007/s12293-016-0185-2
   Chorowski J, 2014, NEUROCOMPUTING, V128, P507, DOI 10.1016/j.neucom.2013.08.009
   Cogoljevic D, 2018, PHYSICA A, V495, P211, DOI 10.1016/j.physa.2017.12.082
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   da Costa NL, 2018, MEASUREMENT, V120, P92, DOI 10.1016/j.measurement.2018.01.052
   Deng WY, 2016, NEURAL NETWORKS, V77, P14, DOI 10.1016/j.neunet.2015.09.003
   Deng WY, 2016, NEURAL NETWORKS, V76, P29, DOI 10.1016/j.neunet.2015.10.006
   Deng WY, 2014, NEURAL NETWORKS, V53, P1, DOI 10.1016/j.neunet.2014.01.008
   Deng WY, 2013, ADV INTELL SYST, V226, P63, DOI 10.1007/978-3-319-00969-8_6
   Ding SF, 2017, INT J MACH LEARN CYB, V8, P587, DOI 10.1007/s13042-015-0351-8
   Ding SF, 2014, NEURAL COMPUT APPL, V24, P1487, DOI 10.1007/s00521-013-1385-z
   Duan JH, 2019, IEEE T SYST MAN CY-S, V49, P1175, DOI 10.1109/TSMC.2017.2705279
   Nguyen DT, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212582
   Feng GR, 2012, NEUROCOMPUTING, V82, P62, DOI 10.1016/j.neucom.2011.10.028
   Feng GR, 2009, IEEE T NEURAL NETWOR, V20, P1352, DOI 10.1109/TNN.2009.2024147
   Fernández-Navarro F, 2011, NEUROCOMPUTING, V74, P2502, DOI 10.1016/j.neucom.2010.11.032
   Gao H, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/145156
   Gelenbe E, 1989, NEURAL COMPUT, V1, P502, DOI 10.1162/neco.1989.1.4.502
   Geng ZQ, 2017, ENG APPL ARTIF INTEL, V62, P38, DOI 10.1016/j.engappai.2017.03.011
   Geng ZQ, 2017, FOOD CONTROL, V78, P33, DOI 10.1016/j.foodcont.2017.02.045
   Ghiasi R, 2018, ADV ENG SOFTW, V125, P101, DOI 10.1016/j.advengsoft.2018.02.006
   Gumaei A, 2019, IEEE ACCESS, V7, P36266, DOI 10.1109/ACCESS.2019.2904145
   Guo M, 2019, BIOSYST ENG, V184, P37, DOI 10.1016/j.biosystemseng.2019.04.022
   Hao JH, 2016, COMPUT OPER RES, V66, P215, DOI 10.1016/j.cor.2015.08.005
   Hassan AR, 2015, 2015 INTERNATIONAL CONFERENCE ON ELECTRICAL & ELECTRONIC ENGINEERING (ICEEE), P45, DOI 10.1109/CEEE.2015.7428288
   He Q, 2014, NEUROCOMPUTING, V128, P88, DOI 10.1016/j.neucom.2012.12.063
   He XH, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/2957083
   Huynh HT, 2011, PATTERN RECOGN LETT, V32, P1930, DOI 10.1016/j.patrec.2011.07.016
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hu K, 2017, EXPERT SYST APPL, V86, P135, DOI 10.1016/j.eswa.2017.05.062
   Huang FM, 2017, ENG GEOL, V223, P11, DOI 10.1016/j.enggeo.2017.04.013
   Huang G-B., 2006, PROC INT JOINT CONFE, V2, p985 990
   Huang G, 2015, NEURAL NETWORKS, V70, P1, DOI 10.1016/j.neunet.2015.06.002
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, P232
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang GB, 2010, NEUROCOMPUTING, V74, P155, DOI 10.1016/j.neucom.2010.02.019
   Huang JH, 2018, NEUROCOMPUTING, V277, P108, DOI 10.1016/j.neucom.2017.02.100
   Huang W, 2012, IEEE ENG MED BIO, P3752, DOI 10.1109/EMBC.2012.6346783
   Huang WM, 2014, IEEE ENG MED BIO, P4675, DOI 10.1109/EMBC.2014.6944667
   Jayaweera CD, 2019, J WATER PROCESS ENG, V32, DOI 10.1016/j.jwpe.2019.100977
   Jiang YZ, 2021, IEEE T INTELL TRANSP, V22, P1752, DOI 10.1109/TITS.2020.2973673
   Jiang YZ, 2020, J SUPERCOMPUT, V76, P2929, DOI 10.1007/s11227-019-03080-5
   Jiang YZ, 2020, J MED IMAG HEALTH IN, V10, P502, DOI 10.1166/jmihi.2020.2695
   Jiang YZ, 2019, J MED IMAG HEALTH IN, V9, P1865, DOI 10.1166/jmihi.2019.2807
   Jiang YZ, 2017, J MED IMAG HEALTH IN, V7, P1772, DOI 10.1166/jmihi.2017.2261
   Jiang YZ, 2016, INFORM SCIENCES, V357, P39, DOI 10.1016/j.ins.2016.03.050
   Kaloop MR, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163221
   Kang F, 2017, EUR J ENVIRON CIV EN, V21, P1341, DOI 10.1080/19648189.2016.1169225
   Kang XJ, 2018, J MOL LIQ, V262, P139, DOI 10.1016/j.molliq.2018.04.026
   Kasun LLC, 2013, IEEE INTELL SYST, V28, P31
   Krishnasamy G, 2016, NEUROCOMPUTING, V207, P560, DOI 10.1016/j.neucom.2016.05.039
   Lam D, 2017, IEEE T CYBERNETICS, V47, P224, DOI 10.1109/TCYB.2015.2511149
   Lama RK, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/5485080
   Landa-Torres I, 2012, IEEE J-STSP, V6, P388, DOI 10.1109/JSTSP.2012.2199463
   Lei HJ, 2019, IEEE J BIOMED HEALTH, V23, P1290, DOI 10.1109/JBHI.2018.2845866
   Leung HC, 2019, IEEE ACCESS, V7, P155171, DOI 10.1109/ACCESS.2019.2948059
   Li HT, 2019, IEEE T CIRCUITS-I, V66, P4699, DOI 10.1109/TCSI.2019.2940642
   Li JQ, 2020, IEEE ACM T COMPUT BI, V17, P1546, DOI 10.1109/TCBB.2020.2965919
   Li MB, 2006, LECT NOTES COMPUT SC, V3973, P114
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li XL, 2019, IEEE ACCESS, V7, P124891, DOI 10.1109/ACCESS.2019.2938568
   Li XD, 2016, MEMET COMPUT, V8, P85, DOI 10.1007/s12293-016-0188-z
   Li XD, 2016, NEUROCOMPUTING, V174, P203, DOI 10.1016/j.neucom.2015.01.096
   Li ZS, 2019, 2019 IEEE 27TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2019), P144, DOI 10.1109/REW.2019.00031
   Liang HH, 2019, IEEE TETCI, V3, P15, DOI 10.1109/TETCI.2018.2849721
   Lima AR, 2015, ENVIRON MODELL SOFTW, V73, P175, DOI 10.1016/j.envsoft.2015.08.002
   Liu B, 2016, NEURAL COMPUT APPL, V27, P255, DOI 10.1007/s00521-014-1777-8
   Liu B, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P977, DOI 10.1109/ICMLA.2017.00-26
   Liu JW, 2019, IEEE T TRANSP ELECTR, V5, P271, DOI 10.1109/TTE.2018.2886153
   Liu JY, 2019, IEEE ACCESS, V7, P36866, DOI 10.1109/ACCESS.2019.2905077
   Liu MM, 2017, INT J MACH LEARN CYB, V8, P1039, DOI 10.1007/s13042-016-0592-1
   Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356
   Liu P, 2016, INT J MACH LEARN CYB, V7, P765, DOI 10.1007/s13042-014-0292-7
   Liu RJ, 2019, IEEE ACCESS, V7, P158025, DOI 10.1109/ACCESS.2019.2950327
   Liu TC, 2018, NEUROCOMPUTING, V277, P78, DOI 10.1016/j.neucom.2017.01.115
   Liu TC, 2016, IEEE T INTELL TRANSP, V17, P1108, DOI 10.1109/TITS.2015.2496157
   Liu X, 2015, NEUROCOMPUTING, V168, P1132, DOI 10.1016/j.neucom.2015.05.010
   Liu XL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183935
   Liu XW, 2015, NEUROCOMPUTING, V149, P253, DOI 10.1016/j.neucom.2013.09.072
   Liu Y, 2005, LECT NOTES ARTIF INT, V3533, P390
   Liu ZT, 2019, J ADV COMPUT INTELL, V23, P444, DOI 10.20965/jaciii.2019.p0444
   Lu F, 2020, IEEE T IND INFORM, V16, P959, DOI 10.1109/TII.2019.2921032
   Lu LB, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209083
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Malar E, 2012, COMPUT BIOL MED, V42, P898, DOI 10.1016/j.compbiomed.2012.07.001
   Marjanovic V, 2016, J CO2 UTIL, V16, P212, DOI 10.1016/j.jcou.2016.07.009
   Markovic D, 2017, PHYSICA A, V465, P217, DOI 10.1016/j.physa.2016.08.034
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Mehrizi A, 2016, INTELL DATA ANAL, V20, P1115, DOI 10.3233/IDA-160859
   Milacic L, 2017, PHYSICA A, V465, P285, DOI 10.1016/j.physa.2016.08.040
   Minemoto T, 2017, SIGNAL PROCESS, V136, P59, DOI 10.1016/j.sigpro.2016.11.008
   Mirza B, 2013, NEURAL PROCESS LETT, V38, P465, DOI 10.1007/s11063-013-9286-9
   Nana Zhang, 2015, 2015 7th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). Proceedings, P274, DOI 10.1109/IHMSC.2015.181
   Nayak DR, 2020, MULTIMED TOOLS APPL, V79, P15381, DOI 10.1007/s11042-019-7233-0
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P22705, DOI 10.1007/s11042-017-5281-x
   Naz A, 2019, ENERGIES, V12, DOI 10.3390/en12050866
   Niu MT, 2020, COMPUT STRUCT BIOTEC, V18, P834, DOI 10.1016/j.csbj.2020.03.028
   Niu WJ, 2019, WATER-SUI, V11, DOI 10.3390/w11010088
   Olatunji SO, 2017, CAN CON EL COMP EN
   Oneto L, 2017, IEEE T SYST MAN CY-S, V47, P2754, DOI 10.1109/TSMC.2017.2693209
   Ouyang CS, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P466, DOI 10.1109/ICInfA.2017.8078953
   Ouyang Q, 2013, FOOD BIOPROCESS TECH, V6, P2486, DOI 10.1007/s11947-012-0936-0
   Ouyang TH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3013129
   Pacheco AGC, 2018, EXPERT SYST APPL, V96, P77, DOI 10.1016/j.eswa.2017.11.054
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   Pavelski LM, 2016, NEUROCOMPUTING, V180, P55, DOI 10.1016/j.neucom.2015.09.111
   Pavelski LM, 2014, 2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P318, DOI 10.1109/BRACIS.2014.64
   Pei GS, 2019, IEEE ACCESS, V7, P112304, DOI 10.1109/ACCESS.2019.2934742
   Peng XL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079476
   Peng Y, 2016, NEUROCOMPUTING, V174, P250, DOI 10.1016/j.neucom.2014.11.097
   Prates MO, 2019, STAT METHODS MED RES, V28, P2583, DOI 10.1177/0962280218767985
   Qin YF, 2019, PROCESSES, V7, DOI 10.3390/pr7070474
   Qiu SS, 2015, J FOOD ENG, V166, P193, DOI 10.1016/j.jfoodeng.2015.06.007
   Qiu Y, 2019, IEEE ACCESS, V7, P121156, DOI 10.1109/ACCESS.2019.2937885
   Qureshi MNI, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00059
   Qureshi MNI, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160697
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Rakic G, 2019, PHYSICA A, V513, P418, DOI 10.1016/j.physa.2018.09.010
   Ramalho Geraldo Luis Bezerra, 2014, Rev. Bras. Eng. Bioméd., V30, P207
   Ramasamy S, 2017, TENCON IEEE REGION, P2313, DOI 10.1109/TENCON.2017.8228247
   Rathore S, 2018, APPL SOFT COMPUT, V72, P79, DOI 10.1016/j.asoc.2018.05.049
   Rodriguez N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060540
   Rong HJ, 2014, NEUROCOMPUTING, V128, P166, DOI 10.1016/j.neucom.2012.12.064
   Ronoud S, 2019, SOFT COMPUT, V23, P13139, DOI 10.1007/s00500-019-03856-0
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sánchez-Oro J, 2016, ENERG CONVERS MANAGE, V123, P445, DOI 10.1016/j.enconman.2016.06.050
   SCHMIDT WF, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P1, DOI 10.1109/ICPR.1992.201708
   Sharma J, 2019, EURASIP J INF SECUR, V2019, DOI 10.1186/s13635-019-0098-y
   She QS, 2018, IEEE ACCESS, V6, P49399, DOI 10.1109/ACCESS.2018.2868713
   She QS, 2019, MED BIOL ENG COMPUT, V57, P147, DOI 10.1007/s11517-018-1875-3
   Shen C, 2018, INT CONF MACH LEARN, P399, DOI 10.1109/ICMLC.2018.8526934
   Shen Y, 2019, IEEE ACCESS, V7, P132240, DOI 10.1109/ACCESS.2019.2940697
   Shoumo SZH, 2019, TENCON IEEE REGION, P2023, DOI [10.1109/TENCON.2019.8929527, 10.1109/tencon.2019.8929527]
   Shukla Ankita., 2018, Proceedings of the 11th Indian Conference on Computer Vision, Graphics and Image Processing, P1
   Singh S, 2020, P NATL ACAD SCI USA, V117, P1339, DOI 10.1073/pnas.1916392117
   Sokolov-Mladenovic S, 2016, COMPUT HUM BEHAV, V65, P43, DOI 10.1016/j.chb.2016.08.014
   Song JL, 2016, NEUROCOMPUTING, V175, P383, DOI 10.1016/j.neucom.2015.10.070
   Song TH, 2019, IEEE ACCESS, V7, P64533, DOI 10.1109/ACCESS.2019.2915970
   Song YD, 2012, J NEUROSCI METH, V210, P132, DOI 10.1016/j.jneumeth.2012.07.003
   Soria-Olivas E, 2011, IEEE T NEURAL NETWOR, V22, P505, DOI 10.1109/TNN.2010.2103956
   Sun CL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1115, DOI 10.1109/ROBIO.2015.7418921
   Sun K, 2017, NEUROCOMPUTING, V230, P374, DOI 10.1016/j.neucom.2016.12.027
   Sun W, 2019, ENERGIES, V12, DOI 10.3390/en12020277
   Sun W, 2018, APPL ENERG, V231, P1354, DOI 10.1016/j.apenergy.2018.09.118
   Sun W, 2017, J CLEAN PROD, V162, P1095, DOI 10.1016/j.jclepro.2017.06.016
   Sun ZL, 2011, IEEE T INTELL TRANSP, V12, P1484, DOI 10.1109/TITS.2011.2160053
   Tang XF, 2019, CLUSTER COMPUT, V22, pS6937, DOI 10.1007/s10586-018-1808-9
   Termenon M, 2013, NEURAL PROCESS LETT, V38, P375, DOI 10.1007/s11063-013-9277-x
   Termenon M, 2016, NEUROCOMPUTING, V174, P344, DOI 10.1016/j.neucom.2015.03.111
   Tian YM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163468
   Vani G, 2010, I C CONT AUTOMAT ROB, P2114, DOI 10.1109/ICARCV.2010.5707794
   Wang JN, 2013, J COMPUT CHEM, V34, P566, DOI 10.1002/jcc.23168
   Wang L, 2020, IEEE ACM T COMPUT BI, V17, P972, DOI 10.1109/TCBB.2018.2874267
   Wang MJ, 2017, ENG APPL ARTIF INTEL, V63, P54, DOI 10.1016/j.engappai.2017.05.003
   Wang R, 2018, IEEE T KNOWL DATA EN, V30, P585, DOI 10.1109/TKDE.2017.2772907
   Wang XZ, 2019, IEEE T SYST MAN CY-S, V49, P1299, DOI 10.1109/TSMC.2017.2701419
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795
   Wang ZQ, 2016, NEURAL COMPUT APPL, V27, P227, DOI 10.1007/s00521-014-1764-0
   Wang ZQ, 2014, NEUROCOMPUTING, V128, P175, DOI 10.1016/j.neucom.2013.05.053
   Wei XL, 2019, J MAR SCI ENG, V7, DOI 10.3390/jmse7090312
   Wen H, 2017, IEEE ACCESS, V5, P16539, DOI 10.1109/ACCESS.2017.2740420
   Werbos P. J., 1974, REGRESSION NEW TOOLS
   Wong PK, 2020, NEURAL COMPUT APPL, V32, P14399, DOI 10.1007/s00521-019-04482-5
   Wu D, 2019, IEEE ACCESS, V7, P118422, DOI 10.1109/ACCESS.2019.2936856
   Wu TQ, 2017, COGN COMPUT, V9, P275, DOI 10.1007/s12559-017-9451-y
   Xia JF, 2017, COMPUT METH PROG BIO, V147, P37, DOI 10.1016/j.cmpb.2017.06.005
   Xia M, 2020, NEURAL COMPUT APPL, V32, P7747, DOI 10.1007/s00521-019-04066-3
   Xianglong Wei, 2019, IOP Conference Series: Earth and Environmental Science, V304, DOI 10.1088/1755-1315/304/4/042006
   Xie WY, 2016, NEUROCOMPUTING, V173, P930, DOI 10.1016/j.neucom.2015.08.048
   Xin JC, 2015, NEUROCOMPUTING, V149, P464, DOI 10.1016/j.neucom.2013.09.075
   Xing YM, 2018, INT CONF BIG DATA, P533, DOI 10.1109/BigComp.2018.00089
   Xu XZ, 2019, NEUROCOMPUTING, V331, P213, DOI 10.1016/j.neucom.2018.11.018
   Xu ZX, 2016, NEUROCOMPUTING, V174, P134, DOI 10.1016/j.neucom.2015.01.097
   Yan JY, 2017, AGRO FOOD IND HI TEC, V28, P2321
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yang R, 2018, ALGORITHMS, V11, DOI 10.3390/a11070107
   Yang X.C., 2015, Math. Probl. Eng., V2015
   Yi YG, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9235042
   Yin Y, 2018, IEEE ACCESS, V6, P52713, DOI 10.1109/ACCESS.2018.2869306
   You ZH, 2017, IEEE T CYBERNETICS, V47, P731, DOI 10.1109/TCYB.2016.2524994
   Yousefi-Azar M, 2017, IEEE IJCNN, P1968, DOI 10.1109/IJCNN.2017.7966092
   Yu J, 2019, MULTIMED TOOLS APPL, V78, P8497, DOI 10.1007/s11042-018-6923-3
   Yu WC, 2015, NEUROCOMPUTING, V149, P308, DOI 10.1016/j.neucom.2014.03.077
   Yuan Q, 2011, EPILEPSY RES, V96, P29, DOI 10.1016/j.eplepsyres.2011.04.013
   Zeng NY, 2017, NEUROCOMPUTING, V240, P175, DOI 10.1016/j.neucom.2017.01.090
   Zeng YJ, 2017, IEEE T INTELL TRANSP, V18, P1647, DOI 10.1109/TITS.2016.2614916
   Zhang D., 2019, MATH PROBL ENG, V2019, P1
   Zhang D., 2015, DOMAIN ADAPTATION TR, P103
   Zhang J, 2016, INT J MACH LEARN CYB, V7, P111, DOI 10.1007/s13042-015-0419-5
   Zhang J, 2020, NEUROCOMPUTING, V396, P383, DOI 10.1016/j.neucom.2018.11.106
   Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P4959, DOI 10.1109/TIP.2016.2598679
   Zhang L, 2017, NEUROCOMPUTING, V239, P194, DOI 10.1016/j.neucom.2017.02.016
   Zhang L, 2016, PROC ADAPT LEARN OPT, V6, P249, DOI 10.1007/978-3-319-28397-5_20
   Zhang L, 2015, IEEE T INSTRUM MEAS, V64, P1790, DOI 10.1109/TIM.2014.2367775
   Zhang M, 2016, CHINESE J CHEM ENG, V24, P1013, DOI 10.1016/j.cjche.2016.05.030
   Zhang N, 2017, MEMET COMPUT, V9, P129, DOI 10.1007/s12293-016-0198-x
   Zhang PB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/260970
   Zhang Q, 2013, INT SYM COMPUT INTEL, P133, DOI 10.1109/ISCID.2013.147
   Zhang RF, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P448, DOI 10.1109/ICDSBA.2018.00090
   Zhang XF, 2019, ENERGIES, V12, DOI 10.3390/en12173241
   Zhang X, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11154138
   Zhang XM, 2017, I S INTELL SIG PROC, P149, DOI 10.1109/ISPACS.2017.8266463
   Zhang YS, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3340268
   Zhang YS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171983
   Zhang YS, 2017, PATTERN RECOGN, V68, P52, DOI 10.1016/j.patcog.2017.02.036
   Zhang YS, 2016, PATTERN RECOGN, V58, P135, DOI 10.1016/j.patcog.2016.04.003
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22629, DOI 10.1007/s11042-017-5023-0
   Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003
   Zhao J, 2019, IEEE ACCESS, V7, P119181, DOI 10.1109/ACCESS.2019.2924647
   Zheng, 2018, PATTERN DISCOVERY BI, P132
   Zheng DH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061706
   Zheng LK, 2019, IEEE ACCESS, V7, P89845, DOI 10.1109/ACCESS.2019.2926348
   Zhong HM, 2014, NEUROCOMPUTING, V128, P285, DOI 10.1016/j.neucom.2013.02.054
   Zhou T, 2018, J MED IMAG HEALTH IN, V8, P33, DOI 10.1166/jmihi.2018.2228
   Zhou ZY, 2019, FIBRES TEXT EAST EUR, V27, P67, DOI 10.5604/01.3001.0012.7510
   Zhu W., 2015, REPR LEARN INT JOINT, P12
   Zhu WZ, 2016, MULTIMED TOOLS APPL, V75, P2815, DOI 10.1007/s11042-015-2582-9
   Zhu WT, 2014, IEEE IJCNN, P800, DOI 10.1109/IJCNN.2014.6889761
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
   Zou WD, 2017, NEUROCOMPUTING, V249, P72, DOI 10.1016/j.neucom.2017.03.023
NR 246
TC 156
Z9 161
U1 37
U2 200
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41611
EP 41660
DI 10.1007/s11042-021-11007-7
EA MAY 2021
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000652938900001
OA hybrid
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Kazemi, M
AF Kazemi, Mohammad
TI Refinement of the recovered motion vectors for error concealment in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transmission; Error; loss concealment; Motion vector recovery;
   HEVC
ID VIDEO
AB For error concealment of the relatively large corrupted areas in High Efficiency Video Coding (HEVC), the available spatial information is far from the corrupted region and cannot be directly exploited for error concealment. In this paper, a method is proposed to use the spatial information in a new manner to refine the already recovered Motion Vectors (MVs). The refinement method works based on boundary matching and adaptively selection among three approaches for fine tuning of the temporal MVs. The experiments show that the refinement leads to a significant improvement, 2-7 dB in PSNR, for some frames, and the highest MS-SSIM against the state of the art methods. Another important feature of the proposed method is its generality; which can be added on top of other MV recovery methods.
C1 [Kazemi, Mohammad] Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
C3 University of Isfahan
RP Kazemi, M (corresponding author), Univ Isfahan, Dept Elect Engn, Esfahan 8174673441, Iran.
EM m.kazemi@eng.ui.ac.ir
RI Kazemi, Mohammad/G-7733-2017
CR Adeyemi-Ejeye AO, 2019, MULTIMED TOOLS APPL, V78, P31733, DOI 10.1007/s11042-019-07996-1
   Ahmed Ansari Vaqar, 2020, International Journal of Computer Vision and Image Processing, V10, P1, DOI 10.4018/IJCVIP.2020100101
   Akbari A, 2017, IEEE T MULTIMEDIA, V19, P1339, DOI 10.1109/TMM.2017.2662203
   Belfiore S, 2005, IEEE T MULTIMEDIA, V7, P316, DOI 10.1109/TMM.2005.843347
   Boussard V, 2020, IEEE IMAGE PROC, P1098, DOI 10.1109/ICIP40778.2020.9190650
   Byongsu H, 2019, MULTIMED TOOLS APPL, V78, P2587, DOI 10.1007/s11042-018-6362-1
   Chang YL, 2013, INT PACK VID WORKSH
   Chen C, 2008, IEEE T CONSUM ELECTR, V54, P1422, DOI 10.1109/TCE.2008.4637636
   Chien JT, 2010, IEEE T CONSUM ELECTR, V56, P1689, DOI 10.1109/TCE.2010.5606314
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Chung B, 2020, IEEE T CIRC SYST VID, V30, P1535, DOI 10.1109/TCSVT.2019.2909564
   Francisco, IEEE 9 INT C HUM NAN
   Ghanbari M., 2011, STANDARD CODECS IMAG, V3rd
   Hojati S, 2020, MULTIMED TOOLS APPL, V79, P7449, DOI 10.1007/s11042-019-08538-5
   Huang ZH, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P727, DOI 10.1109/ICCT.2018.8599966
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Kazemi M, 2021, MULTIMED TOOLS APPL, V80, P12685, DOI 10.1007/s11042-020-10333-6
   Kazemi M, 2020, IEEE T MULTIMEDIA, V22, P2193, DOI 10.1109/TMM.2019.2957991
   Kazemi M, 2021, SIGNAL IMAGE VIDEO P, V15, P165, DOI 10.1007/s11760-020-01735-y
   Kazemi M, 2020, IEEE T IMAGE PROCESS, V29, P5937, DOI 10.1109/TIP.2020.2984356
   Kim DH, 2018, ETRI J, V40, P266, DOI 10.4218/etrij.2017-0078
   Li YF, 2017, MULTIMED TOOLS APPL, V76, P14993, DOI 10.1007/s11042-017-4407-5
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Lin T., 2013, 2013 COMM COMP ICSP
   Lin TL, 2017, MULTIMED TOOLS APPL, V76, P397, DOI 10.1007/s11042-015-3056-9
   Lin TL, 2016, J DISP TECHNOL, V12, P1451, DOI 10.1109/JDT.2016.2595640
   Lin TL, 2013, IEEE T BROADCAST, V59, P705, DOI 10.1109/TBC.2013.2275056
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P782, DOI 10.1109/TIP.2016.2623481
   Moiron S., 2011, RECENT PATENTS SIGNA, V1, P1, DOI DOI 10.2174/2210686311101020124
   Nam C, 2020, MULTIMED TOOLS APPL, V79, P1221, DOI 10.1007/s11042-019-08176-x
   Peng, 2019, 2019 SPEECH SIGN PRO, DOI 10.1109/ICASSP.2019.8683622
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Peng YT, 2014, CONF REC ASILOMAR C, P921, DOI 10.1109/ACSSC.2014.7094587
   Pérez-Ibacache R, 2019, IEEE ACCESS, V7, P157318, DOI 10.1109/ACCESS.2019.2944898
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Sankisa A, 2020, SIGNAL IMAGE VIDEO P, V14, P1369, DOI 10.1007/s11760-020-01671-x
   Sankisa A, 2019, INT J MULTIMED DATA, V10, P27, DOI 10.4018/IJMDEM.2019070102
   Sankisa A, 2018, IEEE IMAGE PROC, P380, DOI 10.1109/ICIP.2018.8451090
   Suh JW, 2002, IEEE T BROADCAST, V48, P299, DOI 10.1109/TBC.2002.806797
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Usman M, 2016, IEEE T MULTIMEDIA, V18, P831, DOI 10.1109/TMM.2016.2537200
   Usman M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P233, DOI 10.1109/PCS.2015.7170081
   Usman MA, 2019, MULTIMED TOOLS APPL, V78, P22959, DOI 10.1007/s11042-019-7639-8
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Xu JJ, 2018, IEEE IMAGE PROC, P3294, DOI 10.1109/ICIP.2018.8451175
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang SH, 2015, MULTIMED TOOLS APPL, V74, P10785, DOI 10.1007/s11042-014-2206-9
   Yu W., 2017, INT S INT SIGN PROC
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
   Zhou ZH, 2017, MULTIMED TOOLS APPL, V76, P16045, DOI 10.1007/s11042-016-3894-0
NR 50
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27385
EP 27405
DI 10.1007/s11042-021-11005-9
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000651346500001
DA 2024-07-18
ER

PT J
AU Soni, PK
   Rajpal, N
   Mehta, R
   Mishra, VK
AF Soni, Pramod Kumar
   Rajpal, Navin
   Mehta, Rajesh
   Mishra, Vikash Kumar
TI Urban land cover and land use classification using multispectral
   sentinal-2 imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentinel-2; SVM; ANN; MLC; Urban land cover land use
ID ACCURACY; DYNAMICS; SVM
AB In recent years, remote sensing data contains ample information about landcover due to the advancements in remote sensing technology. Humans can utilize this data in agriculture, forestry, disaster management, urbanization, and many more applications. The European Space Agency's Sentinel -2 satellite delivers freely accessible multispectral remote sensing data of different high spatial resolutions, which can be used in various remote sensing fields to extract meaningful information. In this work, the multispectral imagery of 10 m spatial resolution of a densely populated urban area, obtained from sentinel-2, is classified using Support vector machine (SVM), artificial neural network (ANN) and maximum likelihood classifier (MLC). The results obtained using the classifiers SVM, ANN and MLC are compared in terms of the kappa coefficient, overall accuracy and accuracy of users and producers. An area of 14 x 14 km(2) of the South-West district of Delhi (India) is chosen for this study with five urban land-cover and land-use(ULCLU) classes, namely roads, water, buildings, vegetation, and barren land, with a training sample size of 150 pixels per class. The highly complex nature (high population density, urbanization) of the study area makes the classification task challenging and appealing. All the classification methods have more than 90% accuracy, but SVM obtains the best performance with 98.05% accuracy. The work presented in this paper can support policymakers in making better decisions and extracting meaningful information about ULCLU.
C1 [Soni, Pramod Kumar; Rajpal, Navin] Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
   [Mehta, Rajesh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
   [Mishra, Vikash Kumar] Indian Inst Informat Technol Allahabad, Prayagraj, India.
C3 GGS Indraprastha University; Thapar Institute of Engineering &
   Technology; Indian Institute of Information Technology Allahabad
RP Soni, PK (corresponding author), Guru Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, New Delhi, India.
EM pramod.soni0007@gmail.com
OI Mishra, Vikash Kumar/0000-0001-5481-1368; SONI,
   PRAMOD/0000-0003-0632-5044
CR Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697217224
   Chadchan J., 2012, INT J SUSTAIN BUILT, V1, P36, DOI [https://doi.org/10.1016/j.ijsbe.2012.05.001, DOI 10.1016/J.IJSBE.2012.05.001, 10.1016/j.ijsbe.2012.05.001]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DOBSON MC, 1995, REMOTE SENS ENVIRON, V51, P199, DOI 10.1016/0034-4257(94)00075-X
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Dutta D, 2020, ANN REGIONAL SCI, V65, P67, DOI 10.1007/s00168-020-00974-8
   Gasparovic M, 2018, INT J REMOTE SENS, V39, P822, DOI 10.1080/01431161.2017.1392640
   Goldblatt R, 2018, REMOTE SENS ENVIRON, V205, P253, DOI 10.1016/j.rse.2017.11.026
   Haas J, 2018, IEEE J-STARS, V11, P485, DOI 10.1109/JSTARS.2017.2786468
   Tran H, 2015, REMOTE SENS-BASEL, V7, P2899, DOI 10.3390/rs70302899
   Inglada J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010095
   Isaac E, 2017, REMOTE SENS LETT, V8, P350, DOI [10.1080/2150704X.2016.1274443, 10.1080/2150704x.2016.1274443]
   Jebur M.N., 2014, GEOCARTO INT, V29, P792, DOI DOI 10.1080/10106049.2013.848944
   Kavzoglu T, 2009, INT J APPL EARTH OBS, V11, P352, DOI 10.1016/j.jag.2009.06.002
   Lantzanakis G, 2021, IEEE T GEOSCI REMOTE, V59, P3805, DOI 10.1109/TGRS.2020.3017937
   Liou YA, 1999, IEEE T GEOSCI REMOTE, V37, P2718, DOI 10.1109/36.803419
   Liu KF, 2011, ISPRS J PHOTOGRAMM, V66, P103, DOI 10.1016/j.isprsjprs.2010.09.007
   Liu ZF, 2012, LANDSCAPE URBAN PLAN, V106, P62, DOI 10.1016/j.landurbplan.2012.02.013
   Louis J, 2018, INT GEOSCI REMOTE SE, P1894, DOI 10.1109/IGARSS.2018.8517562
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Main-Knorn M, 2015, INT ARCH PHOTOGRAMM, V47, P1249, DOI 10.5194/isprsarchives-XL-7-W3-1249-2015
   Mayer B, 2005, ATMOS CHEM PHYS, V5, P1855, DOI 10.5194/acp-5-1855-2005
   Mishra VN, 2017, ENVIRON EARTH SCI, V76, DOI 10.1007/s12665-016-6341-7
   Naikoo MW, 2020, J URBAN MANAG, V9, P347, DOI 10.1016/j.jum.2020.05.004
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Otukei JR, 2010, INT J APPL EARTH OBS, V12, pS27, DOI 10.1016/j.jag.2009.11.002
   Peters J, 2017, ADAPT COMPUT MACH LE
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Qiu CP, 2020, IEEE GEOSCI REMOTE S, V17, P1787, DOI 10.1109/LGRS.2019.2953497
   Rana VK, 2020, REMOTE SENS APPL, V19, DOI 10.1016/j.rsase.2020.100351
   Seto KC, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023777
   Spoto F, 2012, INT GEOSCI REMOTE SE, P1707, DOI 10.1109/IGARSS.2012.6351195
   Vohra R, 2020, SENS IMAGING, V21, DOI 10.1007/s11220-020-00280-9
   Wan B, 2015, REMOTE SENS-BASEL, V7, P10143, DOI 10.3390/rs70810143
   Zhang HKK, 2017, REMOTE SENS ENVIRON, V197, P15, DOI 10.1016/j.rse.2017.05.024
   Zhu Z, 2012, REMOTE SENS ENVIRON, V117, P72, DOI 10.1016/j.rse.2011.07.020
NR 36
TC 11
Z9 11
U1 4
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 36853
EP 36867
DI 10.1007/s11042-021-10991-0
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000650124300002
DA 2024-07-18
ER

PT J
AU Alzubaidi, L
   Fadhel, MA
   Al-Shamma, O
   Zhang, JL
   Santamaría, J
   Duan, Y
AF Alzubaidi, Laith
   Fadhel, Mohammed A.
   Al-Shamma, Omran
   Zhang, Jinglan
   Santamaria, J.
   Duan, Ye
TI Robust application of new deep learning tools: an experimental study in
   medical imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Diabetic foot ulcer; Wound; Deep learning; Deep
   convolutional neural network; Classification; Transfer learning; Medical
   imaging
ID CANCER STATISTICS; CLASSIFICATION; IMAGES; DIAGNOSIS
AB Nowadays medical imaging plays a vital role in diagnosing the various types of diseases among patients across the healthcare system. Robust and accurate analysis of medical data is crucial to achieving a successful diagnosis from physicians. Traditional diagnostic methods are highly time-consuming and prone to handmade errors. Cost is reduced and performance is improved by adopting computer-aided diagnosis methods. Usually, the performance of traditional machine learning (ML) classification methods much depends on both feature extraction and selection methods that are sensitive to colors, shapes, and sizes, which conveys a complex solution when facing classification tasks in medical imaging. Currently, deep learning (DL) tools have become an alternative solution to overcome the drawbacks of traditional methods that make use of handmade features. In this paper, a new DL approach based on a hybrid deep convolutional neural network model is proposed for the automatic classification of several different types of medical images. Specifically, gradient vanishing and over-fitting issues have been properly addressed in the proposed model in order to improve its robustness by means of different tested techniques involving residual links, global average pooling layers, dropout layers, and data augmentation. Additionally, we employed the idea of parallel convolutional layers with the aim of achieving better feature representation by adopting different filter sizes on the same input and then concatenated as a result. The proposed model is trained and tested on the ICIAR 2018 dataset to classify hematoxylin and eosin-stained breast biopsy images into four categories: invasive carcinoma, in situ carcinoma, benign tumors, and normal tissue. As the experimental results show, our proposed method outperforms several of the state-of-the-art methods by achieving rate values of 93.2% and 89.8% for both image- and patch-wise image classification tasks, respectively. Moreover, we fine-tuned our model to classify foot images into two classes in order to test its robustness by considering normal and abnormal diabetic foot ulcer (DFU) image datasets. In this case, the model achieved an F1 score value of 94.80% on the public DFU dataset and 97.3% on the private DFU dataset. Lastly, transfer learning (TL) has been adopted to validate the proposed model with multiple classes with the aim of classifying six different wound types. This approach significantly improves the accuracy rate from a rate of 76.92% when trained from scratch to 87.94% when TL was considered. Our proposed model has proven its suitability and robustness by addressing several medical imaging tasks dealing with complex and challenging scenarios.
C1 [Alzubaidi, Laith; Zhang, Jinglan] Queensland Univ Technol, Sch Comp Sci, Brisbane, Qld, Australia.
   [Alzubaidi, Laith; Al-Shamma, Omran] Univ Informat Technol & Commun, Baghdad, Iraq.
   [Fadhel, Mohammed A.] Univ Sumer, Coll Comp Sci & Informat Technol, Rifai, Thi Qar, Iraq.
   [Santamaria, J.] Univ Jaen, Dept Comp Sci, Jaen, Spain.
   [Duan, Ye] Univ Missouri, Fac Elect Engn & Comp Sci, Columbia, MO USA.
C3 Queensland University of Technology (QUT); University of Information
   Technology & Communication; University of Sumer; Universidad de Jaen;
   University of Missouri System; University of Missouri Columbia
RP Alzubaidi, L (corresponding author), Queensland Univ Technol, Sch Comp Sci, Brisbane, Qld, Australia.; Alzubaidi, L (corresponding author), Univ Informat Technol & Commun, Baghdad, Iraq.
EM laith.alzubaidi@hdr.qut.edu.au
RI Santamaria, Jose/A-6415-2011; Alzubaidi, Laith/AAC-9291-2020; Fadhel,
   Mohammed A./Q-3147-2019; Al-Shamma, Omran/Z-3351-2019
OI Santamaria, Jose/0000-0002-2022-6838; Alzubaidi,
   Laith/0000-0002-7296-5413; Fadhel, Mohammed A./0000-0001-9877-049X;
   Al-Shamma, Omran/0000-0001-5930-6176
FU Queensland University of Technology
FX We would like to express our gratitude to Dr.Sameer R. Oleiwi from
   Nursing College, Muthanna University, for his effort in confirming the
   labels of wound images. We would also like to thank the Queensland
   University of Technology for supporting us.
CR Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   Alzubaidi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134523
   Alzubaidi L, 2019, I C DEV ESYST ENG, P268, DOI 10.1109/DeSE.2019.00057
   Alzubaidi L, 2020, MULTIMED TOOLS APPL, V79, P15655, DOI 10.1007/s11042-019-07820-w
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030427
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030445
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.683
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Aresta G, 2019, MED IMAGE ANAL, V56, P122, DOI 10.1016/j.media.2019.05.010
   Awan R, 2018, LECT NOTES COMPUT SC, V10882, P788, DOI 10.1007/978-3-319-93000-8_89
   Bailing Zhang, 2011, 2011 4th International Conference on Biomedical Engineering and Informatics, P180, DOI 10.1109/BMEI.2011.6098229
   Barker J, 2016, MED IMAGE ANAL, V30, P60, DOI 10.1016/j.media.2015.12.002
   Belsare AD, 2015, TENCON IEEE REGION
   Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   DeSantis CE, 2017, CA-CANCER J CLIN, V67, P439, DOI 10.3322/caac.21412
   Doyle S, 2008, I S BIOMED IMAGING, P496, DOI 10.1109/ISBI.2008.4541041
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   Filipczuk P, 2013, IEEE T MED IMAGING, V32, P2169, DOI 10.1109/TMI.2013.2275151
   George YM, 2014, IEEE SYST J, V8, P949, DOI 10.1109/JSYST.2013.2279415
   Golatkar A, 2018, LECT NOTES COMPUT SC, V10882, P837, DOI 10.1007/978-3-319-93000-8_95
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Herent P, 2019, DIAGN INTERV IMAG, V100, P219, DOI 10.1016/j.diii.2019.02.008
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kassani SH, 2019, I C INF COMM TECH CO, P519, DOI 10.1109/ictc46691.2019.8939878
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kothari S, 2013, BMC MED IMAGING, V13, DOI 10.1186/1471-2342-13-9
   Kowal M, 2013, COMPUT BIOL MED, V43, P1563, DOI 10.1016/j.compbiomed.2013.08.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Li C, 2019, MED IMAGE ANAL, V53, P165, DOI 10.1016/j.media.2019.01.013
   Li Y, 2019, METHODS, V166, P4, DOI 10.1016/j.ymeth.2019.04.008
   Lu L, 2019, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-030-13969-8
   Lv EH, 2019, ARTIF INTELL REV, V52, P151, DOI 10.1007/s10462-019-09708-5
   Maier A, 2019, Z MED PHYS, V29, P86, DOI 10.1016/j.zemedi.2018.12.003
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Moore S, 2020, RADIOGRAPHY, V26, pE297, DOI 10.1016/j.radi.2020.04.005
   Nawaz W, 2018, LECT NOTES COMPUT SC, V10882, P869, DOI 10.1007/978-3-319-93000-8_99
   Raghu M, 2019, ADV NEUR IN, V32
   Roy K, 2019, COMPUT MED IMAG GRAP, V71, P90, DOI 10.1016/j.compmedimag.2018.11.003
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaranjini S, 2020, MULTIMED TOOLS APPL, V79, P15467, DOI 10.1007/s11042-019-7469-8
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Targ S., 2016, Resnet in Resnet: Generalizing Residual Architectures
   Vang YS, 2018, LECT NOTES COMPUT SC, V10882, P914, DOI 10.1007/978-3-319-93000-8_104
   Vedaldi A., 2015, Proceedings of the 23rd ACM international conference on Multimedia, P689, DOI DOI 10.1145/2733373.2807412
   Wang D., 2016, ARXIV PREPRINT ARXIV
   Wang ZY, 2018, LECT NOTES COMPUT SC, V10882, P745, DOI 10.1007/978-3-319-93000-8_84
   Ward EM, 2015, CA-CANCER J CLIN, V65, P481, DOI 10.3322/caac.21321
   Yao Guo, 2018, Image Analysis and Recognition. 15th International Conference, ICIAR 2018. Proceedings: LNCS 10882, P827, DOI 10.1007/978-3-319-93000-8_94
   Yap MH, 2018, PROC SPIE, V10578, DOI 10.1117/12.2293498
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
NR 64
TC 23
Z9 23
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13289
EP 13317
DI 10.1007/s11042-021-10942-9
EA MAY 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000648501200001
DA 2024-07-18
ER

PT J
AU Salim, I
   Ben Hamza, A
AF Salim, Ibrahim
   Ben Hamza, A.
TI Ridge regression neural network for pediatric bone age assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Bone age; Deep learning; Ridge regression; Instance
   segmentation
AB Bone age is an important measure for assessing the skeletal and biological maturity of children. Delayed or increased bone age is a serious concern for pediatricians, and needs to be accurately assessed in a bid to determine whether bone maturity is occurring at a rate consistent with chronological age. In this paper, we introduce a unified deep learning framework for bone age assessment using instance segmentation and ridge regression. The proposed approach consists of two integrated stages. In the first stage, we employ an image annotation and segmentation model to annotate and segment the hand from the radiographic image, followed by background removal. In the second stage, we design a regression neural network architecture composed of a pre-trained convolutional neural network for learning salient features from the segmented pediatric hand radiographs and a ridge regression output layer for predicting the bone age. Experimental evaluation on a dataset of hand radiographs demonstrates the competitive performance of our approach in comparison with existing deep learning based methods for bone age assessment.
C1 [Salim, Ibrahim; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ben Hamza, A (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM hamza@ciise.concordia.ca
RI Hamza, Abdessamad Ben/G-4571-2013
CR Alshamrani K, 2019, EUR RADIOL, V29, P2910, DOI 10.1007/s00330-018-5792-5
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Gilsanz V, 2012, HAND BONE AGE DIGITA
   Greulich W. W., 1959, AM J MED SCI, V238, P393, DOI DOI 10.1097/00000441-195909000-00030
   Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Liu, 2019, FUTURE GENER COMP SY, P1, DOI 10.13009/EUCASS2019-674
   Liu B, 2019, IEEE ACCESS, V7, P120976, DOI 10.1109/ACCESS.2019.2937341
   Martin DD, 2011, HORM RES PAEDIAT, V76, P1, DOI 10.1159/000329372
   Omeiza D., 2019, ABS190801224 CORR
   Pan XY, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8460493
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Satoh Mari, 2015, Clin Pediatr Endocrinol, V24, P143, DOI 10.1297/cpe.24.143
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smilkov D., 2017, ARXIV170603825
   Somkantha K, 2011, J DIGIT IMAGING, V24, P1044, DOI 10.1007/s10278-011-9372-3
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   Tanner JM, 1983, Assessment of Skeletal Maturity and Prediction of Adult Height (TW2 Method), V2nd
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   Tong C, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1091-6
   Van Steenkiste T, 2018, IEEE ENG MED BIO, P674, DOI 10.1109/EMBC.2018.8512334
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Wibisono A, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00347-0
   Wu ER, 2019, I S BIOMED IMAGING, P1158, DOI [10.1109/isbi.2019.8759332, 10.1109/ISBI.2019.8759332]
   Yang X, 2020, INT J BIOMED IMAGING
NR 31
TC 19
Z9 19
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30461
EP 30478
DI 10.1007/s11042-021-10935-8
EA MAY 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000648376700003
DA 2024-07-18
ER

PT J
AU Siam, AI
   Abou Elazm, A
   El-Bahnasawy, NA
   El Banby, GM
   Abd El-Samie, FE
AF Siam, Ali I.
   Elazm, Atef Abou
   El-Bahnasawy, Nirmeen A.
   El Banby, Ghada M.
   Abd El-Samie, Fathi E.
TI PPG-based human identification using Mel-frequency cepstral coefficients
   and neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PPG; Biometrics; Human identification; IoT; MFCCs; Neural network
AB One of the known problems in security systems is to identify persons based on certain signatures. Biometrics have been adopted in security systems to identify persons based on some physiological or behavioral characteristics that they own. Photoplethysmography (PPG) is a physiological signal that is used to describe the volumetric change of blood flow in peripherals with heartbeats. The PPG signals gained some interest of researchers in the last few years, because they are used non-invasively, and they are easily captured by the emerging IoT sensors from fingertips. This paper presents a PPG-based approach to identify persons using a neural network classifier. Firstly, PPG signals are captured from a number of persons using IoT sensors. Then, unique features are extracted from captured PPG signals by estimating the Mel-Frequency Cepstral Coefficients (MFCCs). These features are fed into an Artificial Neural Network (ANN) to be trained first and used for identification of persons. A dataset of PPG signals for 35 healthy persons was collected to test the performance of the proposed approach. Experimental results demonstrate 100% and 98.07% accuracy levels using the hold-out method and the 10-fold cross-validation method, respectively.
C1 [Siam, Ali I.] Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Embedded Network Syst Technol, Kafr Al Sheikh, Egypt.
   [Elazm, Atef Abou; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Engn Dept, Menoufia, Egypt.
   [El-Bahnasawy, Nirmeen A.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
   [El Banby, Ghada M.] Menoufia Univ, Fac Elect Engn, Ind Elect & Control Engn Dept, Menoufia, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Dept Informat Technol, Informat Sci, Riyadh 84428, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Kafrelsheikh University; Egyptian
   Knowledge Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB);
   Menofia University; Egyptian Knowledge Bank (EKB); Menofia University;
   Princess Nourah bint Abdulrahman University
RP Siam, AI (corresponding author), Kafrelsheikh Univ, Fac Artificial Intelligence, Dept Embedded Network Syst Technol, Kafr Al Sheikh, Egypt.
EM ali.siam@ai.kfs.edu.eg; abouelazm.atef@gmail.com;
   nirmeena.el-bahnasawy@el-eng.menofia.edu.eg;
   ghada.elbanby@el-eng.menofia.edu.eg; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; Siam, Ali/AAX-6797-2020; El-Bahnasawy,
   Nirmeen A./GNM-7138-2022; Siam, Ali/CAG-8270-2022
OI Sayed, Fathi/0000-0001-8749-9518; El-Bahnasawy, Nirmeen
   A./0000-0002-4542-323X; Siam, Ali/0000-0002-7242-5281
CR Abd El-Samie FE, 2011, SPRINGERBRIEF SPEECH, P1, DOI 10.1007/978-1-4419-9698-5_1
   Abou Elazm LA, 2020, MULTIMED TOOLS APPL, V79, P14053, DOI 10.1007/s11042-019-08462-8
   Allen J, 2007, PHYSIOL MEAS, V28, pR1, DOI 10.1088/0967-3334/28/3/R01
   [Anonymous], 2007, Neural networks theory
   Belgacem N, 2012, INT J COMPUT SCI ENG, V4
   Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Biswas D, 2019, IEEE SENS J, V19, P6560, DOI 10.1109/JSEN.2019.2914166
   Dessouky MM., 2014, Int J Intell Comput Medi Sci Image Process, V6, P65, DOI [10.1080/1931308X.2015.1004823, DOI 10.1080/1931308X.2015.1004823]
   Dreyfus G., 2005, NEURAL NETWORKS METH, DOI DOI 10.1007/3-540-28847-3
   Gu YY, 2003, ENG MED BIOL SOC ANN, P13
   Islam MS, 2017, MULTIMED TOOLS APPL, V76, P12709, DOI 10.1007/s11042-016-3694-6
   Ittichaichareon C., 2012, P INT C COMP GRAH SI, P28
   Jindal V, 2016, IEEE ENG MED BIO, P6401, DOI 10.1109/EMBC.2016.7592193
   Kavsaoglu AR, 2014, COMPUT BIOL MED, V49, P1, DOI 10.1016/j.compbiomed.2014.03.005
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Lim YG, 2006, IEEE T BIO-MED ENG, V53, P956, DOI 10.1109/TBME.2006.872823
   Moharnmadi G, 2006, PROC WRLD ACAD SCI E, V11, P281
   O'Gorman L, 2003, P IEEE, V91, P2021, DOI 10.1109/JPROC.2003.819611
   Panwar M, 2020, IEEE SENSORS J, V1
   Sancho J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051525
   Siam A. I., 2019, Menoufia J Electron Eng Res, P37, DOI DOI 10.21608/MJEER.2019.76711
   Siam AI, 2019, WIRELESS PERS COMMUN, V108, P1055, DOI 10.1007/s11277-019-06453-4
   Spachos P., 2011, 2011 17 INT C DIG SI, P1, DOI DOI 10.1109/ICDSP.2011.6004938
   Von Solms SH, 2005, EL P INF SEC S AFR I, P1
   Xiao J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235330
   Xu Huang, 2012, 2012 International Symposium on Communications and Information Technologies (ISCIT), P1021, DOI 10.1109/ISCIT.2012.6380841
   Yadav U, 2018, INT CONF BIOMETR, P277, DOI 10.1109/ICB2018.2018.00049
NR 28
TC 21
Z9 21
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26001
EP 26019
DI 10.1007/s11042-021-10781-8
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644268000002
DA 2024-07-18
ER

PT J
AU Sales, LF
   Pereira, A
   Vieira, T
   Costa, ED
AF Sales, Luiz Felipe
   Pereira, Artur
   Vieira, Thales
   de Barros Costa, Evandro
TI Multimodal deep neural networks for attribute prediction and
   applications to e-commerce catalogs enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; E-commerce; Attribute prediction; Natural language
   processing; Computer vision
AB Compiling and managing huge e-commerce catalogs is a hard and time-consuming task for a retailer. In particular, deriving standardized and structured descriptions from unstructured data modalities, such as texts and images, is crucial to the performance of search engines and the general organization of virtual store databases. In this paper, we propose methodologies and strategies based on Deep Learning classifiers to structure, update, and inspect large e-commerce catalogs. To this purpose, we exploit multimodal representations combining data from images and unstructured textual descriptions to identify relevant labels for e-commerce applications. Such modalities of data are employed to train deep neural network architectures, which are then able to automatically recognize attributes. Three classes of architecture were investigated: variations of the VGG architecture for recognition from images; architectures combining embedding, convolutional and recurrent layers for text recognition; and hybrid architectures that combine elements from each of the previous architectures. We also propose tools that allow the detection of insufficiently descriptive visual and textual data, which can be later manually improved; and automatic enhancement of attribute annotations through neural network predictions. Using a database that we collected through a Web Crawler from a large e-commerce site, we show in our experiments that hybrid architectures achieve a better result in the classification task by combining both types of data. Finally, we show results of a case study performed to demonstrate the potential of our strategy for insufficiently descriptive data detection. We conclude that the proposed tools are effective to rectify, enhance, and efficiently update e-commerce catalogs.
C1 [Sales, Luiz Felipe; Vieira, Thales; de Barros Costa, Evandro] Univ Fed Alagoas, Inst Comp, Maceio, AL, Brazil.
   [Pereira, Artur] Univ Fed Campina Grande, Syst & Comp Dept, Campina Grande, PB, Brazil.
C3 Universidade Federal de Alagoas; Universidade Federal de Campina Grande
RP Vieira, T (corresponding author), Univ Fed Alagoas, Inst Comp, Maceio, AL, Brazil.
EM lfsmb@ic.ufal.br; artur.pereira@copin.ufcg.edu.br; thales@ic.ufal.br;
   evandro@ic.ufal.br
RI Vieira, Thales/C-7689-2017
OI Vieira, Thales/0000-0001-7775-5258
FU Alagoas Research Foundation (FAPEAL) [60030001626/2018]
FX The authors would like to thank the Alagoas Research Foundation (FAPEAL)
   for the first author's scholarship #60030001626/2018.
CR Arslan HS, 2019, INFORMATION, V10, DOI 10.3390/info10100308
   Bracher C., 2016, ARXIV160902489 CORR
   Cardoso A, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P80, DOI 10.1145/3219819.3219888
   Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76
   Chollet F, 2015, KERAS
   Dai A.M., 2015, Document Embedding with Paragraph Vectors
   Dasgupta R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3550, DOI 10.1145/3394171.3413558
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, BERT PRE TRAINING DE
   Fensel D, 2001, SECOND INTERNATIONAL WORKSHOP ON USER INTERFACES TO DATA INTENSIVE SYSTEMS, PROCEEDINGS, P2, DOI 10.1109/UIDIS.2001.929920
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Inoue N, 2017, IEEE INT CONF COMP V, P2261, DOI 10.1109/ICCVW.2017.265
   JURASKY D, 2000, COMPUT LINGUIST
   Katarya R, 2020, MULTIMED TOOLS APPL, V79, P35927, DOI 10.1007/s11042-020-09199-5
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kingma D. P., 2014, arXiv
   Laenen K., 2017, PROC ACM KDD WORKSHO, P1
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Rubio A, 2017, IEEE INT CONF COMP V, P2236, DOI 10.1109/ICCVW.2017.261
   Ruder S., ARXIV160904747
   Schindler A, 2018, ARXIV181104374 CORR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun GL, 2018, MULTIMED TOOLS APPL, V77, P17731, DOI 10.1007/s11042-017-5245-1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu WH, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P649, DOI 10.1145/3178876.3186146
   Zahavy Tom, 2016, ARXIV161109534 CORR
NR 32
TC 2
Z9 2
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25851
EP 25873
DI 10.1007/s11042-021-10885-1
EA APR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000642836200001
DA 2024-07-18
ER

PT J
AU Li, L
   Fan, MY
   Liu, DF
AF Li, Lin
   Fan, Mingyu
   Liu, Defu
TI AdvSGAN: Adversarial image Steganography with adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Deep learning; GAN; Adversarial example;
   Adversarial learning
AB Steganalysers based on deep learning achieve state-of-the-art performance. However, due to the difficulty of capturing the distribution of the high-dimensional covers, traditional steganography schemes construct more complex artificial rules within expert knowledge, which is usually challenging to obtain to counter these powerful steganalysers. Adversarial learning is a valuable potential for steganography. There have some steganography schemes through playing an adversarial game within deep neural networks. However, there is a vast security margin needed to reduce. In this paper, we propose AdvSGAN, which learns an image steganography scheme represented by a restricted neural coder from scratch by playing an adversarial game between the restricted neural coder and adversaries in the adversary model, i.e., In-Training and Out-Training adversaries. The restricted neural coder is implemented by two neural networks named SE and SD are to perform encoding and decoding transformation respectively, and a flexible restriction model to constrain the covers' embedding space to improve the performance. The In-Training adversary is implemented by another network of discriminator named Eve in the GANs model. The Out-Training adversary is implemented by the targeted CNN based steganalyser. By playing adversarial game jointly with Eve, SE and SD are evolving to find the possible transformation. Meanwhile, by attacking the Out-Training adversary in a white-box setting, the obtained gradient provides instructive guidance for evolving to find the optimal steganographic scheme. Experiments demonstrate that the proposed steganographic scheme achieves better security performance even in high capacity against targeted steganalyser, and still has some transferability to other unaware steganalysers.
C1 [Li, Lin; Fan, Mingyu; Liu, Defu] Univ Elect Sci & Technol China UESTC, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Fan, MY (corresponding author), Univ Elect Sci & Technol China UESTC, Sch Comp Sci & Engn, Chengdu, Peoples R China.
EM flyatlin@163.com; ff98@163.com; gxdefu@gmail.com
RI liu, huan/JEO-4705-2023
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], The Prisoners' Problem and the Subliminal Channel, DOI 10.1007/978-1-4684-4730-95
   Baluja S, 2017, ADV NEUR IN, V30
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boehm Benedikt, 2014, ARXIV14106656
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chaumont M, 2019, ARXIV 190706956
   Chaumont M, 2019, ARXIV 190401444
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Cogranne R, 2015, IEEE INT WORKS INFOR
   Denemark T, 2014, PROC SPIE, V9028, DOI 10.1117/12.2044803
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2020, STEGANOGRAPHICALGORI
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Girod Bernd, 1993, P207
   Goodfellow I.J., 2014, ARXIV 14126572
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hayes Jamie, 2017, Advances in neural information processing systems, P1954
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Gulrajani I, 2017, ADV NEUR IN, V30
   King DB, 2015, ACS SYM SER, V1214, P1
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kouider S, 2013, IEEE INT CON MULTI
   Kurakin A., 2016, WORKSHOP TRACK P
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu P, 2018, LECT NOTES COMPUT SC, V11165, P792, DOI 10.1007/978-3-030-00767-6_73
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zhang Kevin Alex, 2019, ARXIV190103892
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 41
TC 8
Z9 10
U1 4
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25539
EP 25555
DI 10.1007/s11042-021-10904-1
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862500001
DA 2024-07-18
ER

PT J
AU Rana, S
   Mishra, D
AF Rana, Saurabh
   Mishra, Dheerendra
TI An authenticated access control framework for digital right management
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital right management; Access control; Authentication; Security;
   Privacy
AB With the growing development in digital content distribution, researchers focus on the construction of an access right enabled digital content distribution framework for the legal user. Digital rights management (DRM) is the system which tries to ensure authorized content distribution. Current, DRM systems either provide authentication or constrain access right, but access control with legal authentication in the digital content distribution has remained a challenging issue for public-key cryptography (PKC) or identity-based public-key cryptography (ID-PKC). PKC associates certificate management, which includes revocation, storage, distribution and verification of certificates. As a result, certificate authority becomes the bottleneck in a large network. On the other hand, ID-PKC has the drawback of key escrow. For secure and authorized content distribution, evacuation from these problems is needed. In this paper, we present an authenticated access control protocol, which maintains user's right with authorized content distribution for the digital right management system. Its security has been proved in the random oracle model. An analysis of performance shows enhancement in efficiency, which indicates that the proposed scheme presents a secure and authorized access control mechanisms for resource-constrained devices.
C1 [Rana, Saurabh] LNM Inst Informat Technol, Dept Math, Jaipur 302031, Rajasthan, India.
   [Mishra, Dheerendra] Maulana Azad Natl Inst Technol, Dept Math, Bhopal, India.
C3 LNM Institute of Information Technology; National Institute of
   Technology (NIT System); Maulana Azad National Institute of Technology
   Bhopal
RP Rana, S (corresponding author), LNM Inst Informat Technol, Dept Math, Jaipur 302031, Rajasthan, India.
EM saurabhranapsm@gmail.com
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397; Rana,
   Saurabh/0000-0003-1583-4510
CR Abbasi M, 2020, COMPUT COMMUN, V153, P217, DOI 10.1016/j.comcom.2020.02.017
   Baker T, 2020, SOFTWARE PRACT EXPER, V50, P503, DOI 10.1002/spe.2688
   Behrad S, 2020, FUTURE GENER COMP SY, V108, P46, DOI 10.1016/j.future.2020.02.014
   De SJ, 2020, IEEE T CLOUD COMPUT, V8, P124, DOI 10.1109/TCC.2017.2754255
   Diro A, 2020, IEEE ACCESS, V8, P60539, DOI 10.1109/ACCESS.2020.2983117
   Hu V.C., 2013, NIST special publication, V800, P1
   Hur J, 2011, IEEE T PARALL DISTR, V22, P1214, DOI 10.1109/TPDS.2010.203
   Imine Y, 2018, J NETW COMPUT APPL, V122, P61, DOI 10.1016/j.jnca.2018.08.008
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Kifayat K, 2013, SECURITY ENGINEERING FOR CLOUD COMPUTING: APPROACHES AND TOOLS, P123, DOI 10.4018/978-1-4666-2125-1.ch007
   Li L, 2017, IEEE ACCESS, V5, P1137, DOI 10.1109/ACCESS.2017.2651904
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Liang X., 2011, GLOB TELECOMM CONF, P1
   Meng SM, 2021, IEEE T IND INFORM, V17, P4219, DOI 10.1109/TII.2020.2995348
   Pussewalage HSG, 2017, J INF SECUR APPL, V37, P50, DOI 10.1016/j.jisa.2017.10.004
   Qian HL, 2015, INT J INF SECUR, V14, P487, DOI 10.1007/s10207-014-0270-9
   Rajesh S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020293
   Roy S, 2019, IEEE T IND INFORM, V15, P457, DOI 10.1109/TII.2018.2824815
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Srinath M., 2016, INT J ADV TECHNOL IN, V8, P1564
   Tan YL, 2011, COMM COM INF SC, V251, P238
   Xu XL, 2021, IEEE T IND INFORM, V17, P2910, DOI 10.1109/TII.2020.2987994
   Xu XL, 2020, IEEE INTERNET THINGS, V7, P7919, DOI [10.1109/TITS.2020.2995622, 10.1109/JIOT.2020.3000871]
   Xu XL, 2016, J SYST ENG ELECTRON, V27, P211, DOI 10.1109/JSEE.2016.00021
   Yang K, 2014, IEEE T PARALL DISTR, V25, P1735, DOI 10.1109/TPDS.2013.253
   Yang K, 2013, IEEE T INF FOREN SEC, V8, P1790, DOI 10.1109/TIFS.2013.2279531
   Yu ZX, 2018, FUTURE GENER COMP SY, V78, P763, DOI 10.1016/j.future.2017.01.025
NR 27
TC 7
Z9 7
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25255
EP 25270
DI 10.1007/s11042-021-10813-3
EA APR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640469900001
DA 2024-07-18
ER

PT J
AU Patra, S
   Middya, AI
   Roy, S
AF Patra, Susmita
   Middya, Asif Iqbal
   Roy, Sarbani
TI PotSpot: Participatory sensing based monitoring system for pothole
   detection using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Participatory sensing; Pothole detection; Convolutional neural network;
   Transfer learning; Cloud
ID ROAD; SMARTPHONES
AB Proper maintenance of roads is an extremely complex task and also an important issue all over the world. One of the most critical road monitoring and maintenance activities is the detection of road anomalies such as potholes. Identification of potholes is necessary to avoid road accidents, prevent damage of vehicles, enhance travelling comforts, etc. Although maintenance of roads is considered to be a serious issue by the authorities over the years, lack of proper detection and mapping of road potholes makes the issue more severe. To overcome this problem, an end-to-end system called PotSpot is built for real-time detection, monitoring, and spatial mapping of potholes across the city A Convolutional Neural Network (CNN) model is proposed and evaluated on real-world dataset for pothole detection. Additionally, real-time pothole-marked maps are generated with the help of Google Maps API (Application Programming Interface). To provide an end-to-end service through this system, both the pothole detection and pothole mapping are integrated through an android application. The proposed model is also compared with six baselines namely Artificial Neural Network (ANN), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and three pre-trained CNN models InceptionV3, VGG19 and VGG16 in terms of performance metrics to verify its effectiveness. The proposed model achieves better accuracy (approximate to 97.6 %) as compared to the above-mentioned baseline methods. It is also observed that the Area Under the Curve (AUC) value for the proposed pothole detection model (AUC= 0.97) is higher than the baseline methods.
C1 [Patra, Susmita; Middya, Asif Iqbal; Roy, Sarbani] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Roy, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM susmitapatra95@gmail.com; asifim.rs@jadavpuruniversity.in;
   sarbani.roy@jadavpuruniversity.in
RI MIDDYA, ASIF IQBAL/AAU-4012-2020; MIDDYA, ASIF IQBAL/HSH-9366-2023; Roy,
   Sarbani/J-1997-2018
OI MIDDYA, ASIF IQBAL/0000-0001-6558-4930; MIDDYA, ASIF
   IQBAL/0000-0001-6558-4930; Roy, Sarbani/0000-0002-7598-8266
FU project entitled- "Participatory and Realtime Pollution Monitoring
   System For Smart City" - Higher Education, Science & Technology and
   Biotechnology, Department of Science & Technology, Government of West
   Bengal, India
FX This research work is supported by the project entitled- "Participatory
   and Realtime Pollution Monitoring System For Smart City", funded by
   Higher Education, Science & Technology and Biotechnology, Department of
   Science & Technology, Government of West Bengal, India.
CR AI D, 2018, IEEE ACCESS, V6
   Albawi S, 2017, I C ENG TECHNOL
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Anaissi A, 2019, J CIV STRUCT HEALTH, V9, P91, DOI 10.1007/s13349-019-00323-0
   Anand Sukhad, 2018, 2018 Digital Image Computing: Techniques and Applications (DICTA), DOI 10.1109/DICTA.2018.8615819
   [Anonymous], 2020, Road Traffic Injuries
   Aparna Y, 2022, J KING SAUD UNIV-COM, V34, P578, DOI 10.1016/j.jksuci.2019.02.004
   Arya D., 2020, ARXIV200813101
   Bhatt U., 2017, ARXIV171002595
   Burke J., 2006, PARTICIPATORY SENSIN, DOI DOI 10.1109/MIC.2010.12
   Butt RA, 2019, OPT FIBER TECHNOL, V52, DOI 10.1016/j.yofte.2019.101964
   Cabral Frederico Soares, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P65, DOI 10.1109/SOLI.2018.8476788
   Chen HS, 2020, INT J MACH LEARN CYB, V11, P899, DOI 10.1007/s13042-020-01078-7
   Chen KY, 2011, 2011 6TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P1032, DOI 10.1109/ChinaCom.2011.6158308
   Chitale P. A., 2020, P 2020 35 INT C IMAG, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Detho A, 2018, ENG TECHNOL APPL SCI, V8, P2875
   Dhiman A, 2020, IEEE T INTELL TRANSP, V21, P3536, DOI 10.1109/TITS.2019.2931297
   Ghosh A, 2019, INT CONF COMMUN SYST, P486, DOI [10.1109/comsnets.2019.8711473, 10.1109/COMSNETS.2019.8711473]
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   Hameed H., 2018, Em: 2018 IEEE 87th Vehicular Technology Conference (VTC Spring), P1, DOI [10.1109/VTCSpring.2018.8417780, DOI 10.1109/VTCSPRING.2018.8417780]
   Hara K, 2015, IEEE IJCNN
   Hassan N, 2019, INT CONF PERVAS COMP, P645, DOI [10.1109/percomw.2019.8730713, 10.1109/PERCOMW.2019.8730713]
   Jokela M, 2009, INT C INTELL COMP CO, P423, DOI 10.1109/ICCP.2009.5284724
   Kanhere S.S., 2013, DISTRIB COMPUT, P19, DOI DOI 10.1007/978-3-642-36071-8
   Kar D, 2019, IEEE I C ADV NETW TE, DOI 10.1109/ants47819.2019.9118073
   Kwasigroch Arkadiusz, 2017, 2017 22nd International Conference on Methods and Models in Automation and Robotics (MMAR), P1069, DOI 10.1109/MMAR.2017.8046978
   Li K, 2007, P I MECH ENG K-J MUL, V221, P129, DOI 10.1243/1464419JMBD60
   Lin J, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P544, DOI 10.1109/DCABES.2010.115
   Liu CH, 2017, IEEE SYST J, V11, P2490, DOI 10.1109/JSYST.2016.2533538
   Middya AI, 2020, MOBILE NETW APPL, V25, P1249, DOI 10.1007/s11036-020-01539-x
   Nunes DE, 2019, J INTERNET SERV APPL, V10, DOI 10.1186/s13174-019-0111-1
   Pan Y, 2017, INT ARCH PHOTOGRAMM, V42-4, P209, DOI 10.5194/isprs-archives-XLII-4-W4-209-2017
   Pereira Vosco, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P279, DOI 10.1109/SOLI.2018.8476795
   Ranjbar S, 2021, INT J PAVEMENT RES T, V14, P437, DOI 10.1007/s42947-020-0098-9
   Raza B, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106216
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarma S., 2016, PROC INT C COMMUN SY, P1
   Sehgal A, 2019, MACH LEARN KNOW EXTR, V1, P450, DOI 10.3390/make1010027
   Sharma, 2020, INT J INNOV SCI RES, V5, P165
   Silvister S, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI 10.1109/punecon46936.2019.9105737
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Suong LK, 2018, J UNIVERS COMPUT SCI, V24, P1244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takahashi J, 2018, ELECTR COMMUN JPN, V101, P3, DOI 10.1002/ecj.12027
   Verster T, 2018, S AFR J SCI, V114, P63, DOI 10.17159/sajs.2018/20170427
   Wang H, 2020, ARXIV200811383
   Ye WL, 2021, ROAD MATER PAVEMENT, V22, P42, DOI 10.1080/14680629.2019.1615533
   Yeoh Keng Yik, 2021, Journal of Physics: Conference Series, V1828, DOI 10.1088/1742-6596/1828/1/012001
NR 51
TC 26
Z9 26
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25171
EP 25195
DI 10.1007/s11042-021-10874-4
EA APR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000640172500001
DA 2024-07-18
ER

PT J
AU Hashemi, AS
   Mozaffari, S
AF Hashemi, Atiye Sadat
   Mozaffari, Saeed
TI CNN adversarial attack mitigation using perturbed samples training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial example; Convolution neural network; Denoising autoencoder;
   Evasion attacks; Noisy training
AB Susceptibility to adversarial examples is one of the major concerns in convolutional neural networks (CNNs) applications. Training the model with adversarial examples, known as adversarial training, is a common countermeasure to tackle such attacks. In reality, however, defenders are uninformed about how adversarial examples are generated by the attacker. Therefore, it is pivotal to utilize more general alternatives to intrinsically improve the robustness of models. For this purpose, we train CNNs with perturbed samples manipulated by various transformations and contaminated by different noises to foster robustness of networks against adversarial attacks. This idea derived from the fact that both adversarial and noisy samples undermine the classifier accuracy. We propose combination of a convolutional denoising autoencoder with a classifier (CDAEC) as a defensive structure. The proposed method does not add to the computational cost. Experimental results on MNIST database demonstrate that the accuracy of CDAEC trained by perturbed samples against adversarial attacks was more than 71.29%.
C1 [Hashemi, Atiye Sadat; Mozaffari, Saeed] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Mozaffari, S (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM atiye.hashemi@semnan.ac.ir; mozaffari@semnan.ac.ir
RI Hashemi, Atiye Sadat/GWV-5973-2022
OI Hashemi, Atiye Sadat/0000-0001-5191-0424; zy, P/0009-0006-2820-8788
CR Ajay K.B., 2015, Signal & Image Processing, V6, P63, DOI [DOI 10.5121/SIPIJ.2015.6206, 10.5121/sipij.2015.6206]
   [Anonymous], 2019, arXiv preprint, arXiv:1902.07623
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P968, DOI 10.1109/TNNLS.2018.2852738
   Deng T, 2019, PATTERN RECOGN LETT, V125, P632, DOI 10.1016/j.patrec.2019.06.028
   Diale M, 2019, COMPUT ELECTR ENG, V74, P89, DOI 10.1016/j.compeleceng.2019.01.004
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Ford N., 2019, arXiv preprint arXiv:1901.10513
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Gu S, 2015, 3TH INT C LEARN REPR
   Hashemi AS, 2019, COMPUT SECUR, V86, P372, DOI 10.1016/j.cose.2019.06.012
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZZ, 2019, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2019.00068
   Hendrycks D., 2018, arXiv preprint arXiv:1812.04606
   Hu HB, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240835
   Jeong JH, 2019, MULTIMED TOOLS APPL, P1
   Karpathy, 2016, NEURAL NETWORKS, V1
   Khamparia A, 2020, MULTIMED TOOLS APPL, V79, P35425, DOI 10.1007/s11042-019-07839-z
   Kurakin A., 2016, WORKSHOP TRACK P
   Kurakin A, 2018, SPRING SER CHALLENGE, P195, DOI 10.1007/978-3-319-94042-7_11
   Kwon H, 2018, COMPUT SECUR, V78, P380, DOI 10.1016/j.cose.2018.07.015
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Li Y, ACM T SENSOR NETWORK
   Liu Y., 2016, ARXIV161102770
   Madry A., 2018, ARXIV
   Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894
   Song XN, 2018, COMPUT ELECTR ENG, V68, P381, DOI 10.1016/j.compeleceng.2018.04.003
   Spigler G, 2020, IEEE T PATTERN ANAL, V42, P998, DOI 10.1109/TPAMI.2019.2909876
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wei X, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107012
   Xiao Chaowei, 2018, 6 INT C LEARN REPR I
   Xie CH, 2019, PROC CVPR IEEE, P2725, DOI 10.1109/CVPR.2019.00284
NR 35
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22077
EP 22095
DI 10.1007/s11042-020-10379-6
EA MAR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790800006
DA 2024-07-18
ER

PT J
AU Haq, NU
   Khan, A
   Rehman, ZU
   Din, A
   Shao, L
   Shah, S
AF Haq, Nuhman Ui
   Khan, Ahmad
   Rehman, Zia Ur
   Din, Ahmad
   Shao, Ling
   Shah, Sajid
TI A novel weight initialization with adaptive hyper-parameters for deep
   semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Deep learning; Initialization; Adaptive layer
   learning rate
ID NEURAL-NETWORKS; ALGORITHM
AB The semantic segmentation process divides an image into its constituent objects and background by assigning a corresponding class label to each pixel in the image. Semantic segmentation is an important area in computer vision with wide practical applications. The contemporary semantic segmentation approaches are primarily based on two types of deep neural networks architectures i.e., symmetric and asymmetric networks. Both types of networks consist of several layers of neurons which are arranged in two sections called encoder and decoder. The encoder section receives the input image and the decoder section outputs the segmented image. However, both sections in symmetric networks have the same number of layers and the number of neurons in an encoder layer is the same as that of the corresponding layer in the decoder section but asymmetric networks do not strictly follow such one-one correspondence between encoder and decoder layers. At the moment, SegNet and ESNet are the two leading state-of-the-art symmetric encoder-decoder deep neural network architectures. However, both architectures require extensive training for good generalization and need several hundred epochs for convergence. This paper aims to improve the convergence and enhance network generalization by introducing two novelties into the network training process. The first novelty is a weight initialization method and the second contribution is an adaptive mechanism for dynamic layer learning rate adjustment in training loop. The proposed initialization technique uses transfer learning to initialize the encoder section of the network, but for initialization of decoder section, the weights of the encoder section layers are copied to the corresponding layers of the decoder section. The second contribution of the paper is an adaptive layer learning rate method, wherein the learning rates of the encoder layers are updated based on a metric representing the difference between the probability distributions of the input images and encoder weights. Likewise, the learning rates of the decoder layers are updated based on the difference between the probability distributions of the output labels and decoder weights. Intensive empirical validation of the proposed approach shows significant improvement in terms of faster convergence and generalization.
C1 [Haq, Nuhman Ui; Khan, Ahmad; Rehman, Zia Ur; Din, Ahmad; Shah, Sajid] COMSATS Univ Islamabad CUI, Abbottabad Campus Univ Rd Tobe Camp, Abbottabad, Pakistan.
   [Shao, Ling] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates.
C3 COMSATS University Islamabad (CUI)
RP Rehman, ZU (corresponding author), COMSATS Univ Islamabad CUI, Abbottabad Campus Univ Rd Tobe Camp, Abbottabad, Pakistan.
EM nuhman@cuiatd.edu.pk; ahmadkhan@cuiatd.edu.pk; ziarehman@cuiatd.edu.pk;
   ahmaddin@cuiatd.edu.pk; ling.shao@ieee.org; sajidshah@cuiatd.edu.pk
RI Shao, Ling/D-3535-2011; Din, Ahmad/W-1987-2019; Rehman, Zia
   ur/AAS-6171-2020; Ul Haq, Nuhman/AGY-8616-2022; Khan,
   Ahmad/AAG-1269-2020
OI Din, Ahmad/0000-0002-4135-0221; Rehman, Zia ur/0000-0001-5836-0488;
   Khan, Ahmad/0000-0002-6955-8876; Shah, Sajid/0000-0001-6334-4773; Ul
   Haq, Nuhman/0000-0002-0154-7011
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Afouras T, 2022, IEEE T PATTERN ANAL, V44, P8717, DOI 10.1109/TPAMI.2018.2889052
   Agarwal N, 2017, ACM S THEORY COMPUT, P1195, DOI 10.1145/3055399.3055464
   Andrew, 2013, ARXIV13126120
   [Anonymous], 2015, All you need is a good init
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Brox T, 2006, IEEE T IMAGE PROCESS, V15, P3213, DOI 10.1109/TIP.2006.877481
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Cheng Yu, 2017, ARXIV
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Chorowski J, 2015, ADV NEUR IN, V28
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Dai JF, 2016, ADV NEUR IN, V29
   Dauphin YN, 2014, ADV NEUR IN, V27
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   GAO Z, 2020, NEURAL NETWORKS
   Gao Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1879, DOI 10.1145/3343031.3350861
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hanin B, 2018, ADV NEUR IN, V31
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kawaguchi K., 2016, ADV NEURAL INFORM PR, V29, P586
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Khan A, 2015, APPL SOFT COMPUT, V32, P300, DOI 10.1016/j.asoc.2015.03.029
   Khan A, 2015, KNOWL INF SYST, V43, P583, DOI 10.1007/s10115-014-0741-3
   Khan A, 2014, SIGNAL IMAGE VIDEO P, V8, P1233, DOI 10.1007/s11760-012-0347-8
   Khan A, 2013, MULTIMED TOOLS APPL, V64, P331, DOI 10.1007/s11042-012-1003-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Lim, 2016, 2016 AS PAC SIGN INF, P1, DOI [DOI 10.1109/APSIPA.2016.7820699, 10.1109/APSIPA.2016.7820699]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00094
   Marquez ES, 2018, IEEE T NEUR NET LEAR, V29, P5475, DOI 10.1109/TNNLS.2018.2805098
   Mesnil G, 2015, IEEE-ACM T AUDIO SPE, V23, P530, DOI 10.1109/TASLP.2014.2383614
   Montufar G. F., 2014, ADV NEURAL INFORM PR, P2924
   Nwankpa C., 2018, ARXIV181103378
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   Omran MGH, 2006, PATTERN ANAL APPL, V8, P332, DOI 10.1007/s10044-005-0015-5
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Poole B, 2016, ADV NEURAL INFORM PR, P3360
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Ruder S., 2016, ARXIV
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SHALEVSHWARTZ S, 2017, P 34 INT C MACH LEAR, V70, P3076
   Shickel Benjamin, 2018, IEEE J Biomed Health Inform, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   Ullah J, 2018, MULTIMED TOOLS APPL, V77, P7429, DOI 10.1007/s11042-017-4655-4
   Wang Y, 2019, Pattern Recognition and Computer Vision, V11858, P41
   Wu JT, 2018, INT J MED INFORM, V112, P68, DOI 10.1016/j.ijmedinf.2017.12.003
   Wu Lei, 2017, ARXIV170610239
   Yang J, 2018, ALGORITHMS, V11, DOI 10.3390/a11030028
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang, 2018, ARXIV180309327
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
NR 74
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21771
EP 21787
DI 10.1007/s11042-021-10510-1
EA MAR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630848100002
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Li, XF
   Zhu, R
   Zhang, XL
   Wang, ZY
   Zhang, SH
AF Zhang, Siqi
   Li, Xiongfei
   Zhu, Rui
   Zhang, Xiaoli
   Wang, Zeyu
   Zhang, Shuhan
TI Medical image fusion algorithm based on <i>L</i><sub>0</sub> gradient
   minimization for CT and MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image fusion; L-0 Gradient Minimization; local energy; saliency
   detection
ID PERFORMANCE; DECOMPOSITION; TRANSFORM
AB In this paper, a novel medical image fusion method based on L-0 Gradient Minimization for CT and MRI is proposed. Compared with traditional algorithms, the proposed method performs well in preserving bones structures from CT and sustaining the soft tissue detail from MRI. It's worth mentioning that both the proposed low- and high-frequency fusion rules have the capability of generating appropriate weight maps according to the characteristics of CT and MRI images. The fusion algorithm using L-0 Gradient Minimization mainly comprises of four steps: First, source images are decomposed into multi-scale representations via L-0 Gradient Minimization. Second, we propose a low-frequency fusion rule based on local energy and Gaussian filters, which can generate the fused base layer in accord with the basic principle of human beings' visual system. Third, high-frequency sub-bands are fused by utilizing saliency detection rule based on texture extraction, which generates the satisfying maps according to the degree of significance. Finally, we get the fused result according to the image reconstruction. The proposed algorithm is compared with nine advanced fusion methods and shows superior performance in whether subjective or objective evaluations.
C1 [Zhang, Siqi; Li, Xiongfei; Zhu, Rui; Wang, Zeyu; Zhang, Shuhan] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Li, Xiongfei; Zhu, Rui; Zhang, Xiaoli; Wang, Zeyu; Zhang, Shuhan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Wang, Zeyu/AAF-3906-2022; Zhang, Xiaoli/ABC-2210-2021; Wang,
   Zeyu/AFI-7323-2022
FU National Science and Technology Pillar Program of China [2012BAH48F02];
   National Natural Science Foundation of China [61801190]; Nature Science
   Foundation of Jilin Province [20180101055JC]; Outstanding Young Talent
   Foundation of Jilin Province [20180520029JH]; China Postdoctoral Science
   Foundation [2017M611323]; Industrial Technology Research and Development
   Funds of Jilin Province [2019C054-3]; Graduate Innovation Fund of Jilin
   University; Fundamental Research Funds for the Central Universities, JLU
FX The work was supported in part by the National Science and Technology
   Pillar Program of China under Grant 2012BAH48F02, in part by the
   National Natural Science Foundation of China under Grant 61801190, in
   part by the Nature Science Foundation of Jilin Province under Grant
   20180101055JC, in part by the Outstanding Young Talent Foundation of
   Jilin Province under Grant 20180520029JH, in part by the China
   Postdoctoral Science Foundation under Grant 2017M611323, in part by the
   Industrial Technology Research and Development Funds of Jilin Province
   under Grant 2019C054-3, in part by Graduate Innovation Fund of Jilin
   University, and in part by the Fundamental Research Funds for the
   Central Universities, JLU.
CR Blum R.S., 2005, MULTISENSOR IMAGE FU
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   Dogra A, 2017, IEEE ACCESS, V5, P16040, DOI 10.1109/ACCESS.2017.2735865
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Ganasala P, 2014, J DIGIT IMAGING, V27, P407, DOI 10.1007/s10278-013-9664-x
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Ghoneim A, 2018, IEEE COMMUN MAG, V56, P33, DOI 10.1109/MCOM.2018.1700817
   Gutman I, 2006, LINEAR ALGEBRA APPL, V414, P29, DOI 10.1016/j.laa.2005.09.008
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Kumar G. R. Harish, 2010, Progress In Electromagnetics Research B, V24, P191, DOI 10.2528/PIERB10072101
   Kumar M, 2009, IEEE T IMAGE PROCESS, V18, P2137, DOI 10.1109/TIP.2009.2025006
   Li B, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107793
   Li H, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106182
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li TJ, 2011, INFORM FUSION, V12, P85, DOI 10.1016/j.inffus.2010.03.007
   Li XX, 2020, IEEE T INSTRUM MEAS, V69, P6880, DOI 10.1109/TIM.2020.2975405
   Liu H, 2019, MULTIMED TOOLS APPL, V78, P9033, DOI 10.1007/s11042-017-5277-6
   Liu Y, 2019, IEEE SIGNAL PROC LET, V26, P485, DOI 10.1109/LSP.2019.2895749
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Melkemi K, 2017, INT J HIGH PERFORM C, V1, P1, DOI [10.1504/IJHPCN.2017.10013846, DOI 10.1504/IJHPCN.2017.10013846]
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Peifang Guo, 2018, International Journal of Software Science and Computational Intelligence, V10, P36, DOI 10.4018/IJSSCI.2018040103
   Petrovic V, 2005, OPT ENG, V44, DOI 10.1117/1.2009764
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Portilla J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P37, DOI 10.1109/ICIP.2001.958418
   Pradhan PS, 2006, IEEE T GEOSCI REMOTE, V44, P3674, DOI 10.1109/TGRS.2006.881758
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-bo, 2009, Optics and Precision Engineering, V17, P1203
   Rockinger O, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P288, DOI 10.1109/ICIP.1997.632093
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Shen R, 2013, IEEE T BIO-MED ENG, V60, P1069, DOI 10.1109/TBME.2012.2211017
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706
   SUBR K, 2009, ACM T GRAPHIC, V28
   Toet A, 1996, OPT ENG, V35, P650, DOI 10.1117/1.600657
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wald L, 1999, IEEE T GEOSCI REMOTE, V37, P1190, DOI 10.1109/36.763269
   Wang MN, 2020, IEEE SIGNAL PROC LET, V27, P990, DOI 10.1109/LSP.2020.2999788
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2019, MULTIMED TOOLS APPL, V78, P34483, DOI 10.1007/s11042-019-08070-6
   Xu J, 2010, J VIS COMMUN IMAGE R, V21, P627, DOI 10.1016/j.jvcir.2010.04.002
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang Bo, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P6, DOI 10.1007/s12204-010-7186-y
   Ye FJ, 2019, MULTIMED TOOLS APPL, V78, P14683, DOI 10.1007/s11042-018-6850-3
   Zhang XL, 2017, MULTIMED TOOLS APPL, V76, P8175, DOI 10.1007/s11042-016-3453-8
   Zhang XL, 2014, SIGNAL PROCESS, V102, P64, DOI 10.1016/j.sigpro.2014.02.024
NR 53
TC 6
Z9 8
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21135
EP 21164
DI 10.1007/s11042-021-10596-7
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628488100002
DA 2024-07-18
ER

EF